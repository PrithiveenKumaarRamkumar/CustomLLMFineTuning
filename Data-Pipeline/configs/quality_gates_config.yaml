"""
Quality Gate Configuration
Defines thresholds, criteria, and notification settings for automated quality assurance.
"""

# Quality gate thresholds and criteria
quality_gates:
  test_coverage:
    description: "Minimum code coverage percentage required"
    threshold: 80.0
    comparison: ">="
    severity: "high"
    metric_type: "coverage"
    enabled: true
    
  test_success_rate:
    description: "Minimum percentage of tests that must pass"
    threshold: 95.0
    comparison: ">="
    severity: "critical"
    metric_type: "test_results"
    enabled: true
    
  performance_throughput:
    description: "Minimum data processing throughput (files/second)"
    threshold: 2.0
    comparison: ">="
    severity: "medium"
    metric_type: "performance"
    enabled: true
    
  memory_usage:
    description: "Maximum memory usage during processing (MB)"
    threshold: 1000.0
    comparison: "<="
    severity: "medium"
    metric_type: "performance"
    enabled: true
    
  bias_severity_score:
    description: "Maximum acceptable bias severity score (0-4 scale)"
    threshold: 2.0
    comparison: "<="
    severity: "high"
    metric_type: "bias"
    enabled: true
    
  anomaly_count:
    description: "Maximum number of anomalies allowed"
    threshold: 5.0
    comparison: "<="
    severity: "medium"
    metric_type: "anomaly"
    enabled: true
    
  pii_false_positive_rate:
    description: "Maximum PII detection false positive rate"
    threshold: 0.03
    comparison: "<="
    severity: "critical"
    metric_type: "bias"
    enabled: true
    
  language_diversity:
    description: "Minimum number of programming languages represented"
    threshold: 3.0
    comparison: ">="
    severity: "low"
    metric_type: "bias"
    enabled: true
    
  processing_time_variance:
    description: "Maximum coefficient of variation in processing times"
    threshold: 0.5
    comparison: "<="
    severity: "low"
    metric_type: "performance"
    enabled: true

# Reporting configuration
reporting:
  output_directory: "quality_reports"
  generate_html_reports: true
  generate_json_reports: true
  generate_visualizations: true
  archive_reports: true
  archive_retention_days: 30
  
  # Report templates
  html_template: "quality_report_template.html"
  include_charts: true
  include_recommendations: true
  include_historical_trends: true

# Notification settings
notifications:
  enabled: true
  
  # Email notifications
  email:
    enabled: false
    smtp_server: "smtp.company.com"
    smtp_port: 587
    use_tls: true
    username: "pipeline-qa@company.com"
    password: "${SMTP_PASSWORD}"
    from_address: "pipeline-qa@company.com"
    to_addresses:
      - "team-lead@company.com"
      - "dev-team@company.com"
    
    # Notification triggers
    notify_on:
      - "critical_failures"
      - "quality_gate_failures"
      - "coverage_drop"
      - "bias_threshold_exceeded"
    
    subject_prefix: "[Pipeline QA]"
  
  # Slack notifications
  slack:
    enabled: false
    webhook_url: "${SLACK_WEBHOOK_URL}"
    channel: "#data-pipeline-alerts"
    username: "Pipeline QA Bot"
    
    notify_on:
      - "critical_failures"
      - "all_tests_passed"
      - "quality_gate_failures"

# Monitoring and alerting
monitoring:
  enabled: true
  
  # Prometheus metrics export
  prometheus:
    enabled: false
    port: 8000
    metrics_prefix: "data_pipeline_qa"
    
  # Custom alerting rules
  alerts:
    - name: "critical_quality_gate_failure"
      condition: "failed_critical_gates > 0"
      severity: "critical"
      message: "Critical quality gates have failed"
      
    - name: "coverage_drop"
      condition: "coverage_percentage < 75"
      severity: "warning"
      message: "Test coverage has dropped below 75%"
      
    - name: "high_bias_detected"
      condition: "bias_severity_score > 3"
      severity: "high"
      message: "High bias detected in dataset"

# Test execution configuration
test_execution:
  timeout_seconds: 1800  # 30 minutes
  parallel_execution: true
  max_parallel_jobs: 4
  
  # Test suite configuration
  test_suites:
    unit:
      pattern: "tests/unit/**/*test*.py"
      markers: ["unit"]
      timeout: 300
      
    integration:
      pattern: "tests/integration/**/*test*.py"
      markers: ["integration"]
      timeout: 600
      
    performance:
      pattern: "tests/performance/**/*test*.py"
      markers: ["performance"]
      timeout: 900
      
    bias:
      pattern: "tests/bias/**/*test*.py"
      markers: ["bias"]
      timeout: 300
      
    anomaly:
      pattern: "tests/anomaly/**/*test*.py"
      markers: ["anomaly"]
      timeout: 300
  
  # Coverage configuration
  coverage:
    source_directories:
      - "scripts"
      - "dags"
    exclude_patterns:
      - "*/tests/*"
      - "*/venv/*"
      - "*/__pycache__/*"
    report_formats:
      - "json"
      - "html"
      - "xml"

# Historical tracking
historical_tracking:
  enabled: true
  database_path: "quality_history.db"
  
  # Metrics to track over time
  tracked_metrics:
    - "test_success_rate"
    - "coverage_percentage"
    - "performance_throughput"
    - "bias_severity_score"
    - "anomaly_count"
    
  # Trend analysis
  trend_analysis:
    enabled: true
    lookback_days: 30
    alert_on_regression: true
    regression_threshold: 10.0  # Percent change

# Integration settings
integrations:
  # CI/CD pipeline integration
  cicd:
    enabled: true
    fail_pipeline_on_critical: true
    fail_pipeline_on_coverage_drop: true
    export_junit_xml: true
    junit_xml_path: "test-results.xml"
    
  # MLflow integration
  mlflow:
    enabled: false
    tracking_uri: "${MLFLOW_TRACKING_URI}"
    experiment_name: "data-pipeline-quality"
    log_quality_metrics: true
    
  # DVC integration
  dvc:
    enabled: true
    track_data_quality: true
    quality_metrics_file: "data_quality_metrics.json"

# Advanced configuration
advanced:
  # Custom quality gate implementations
  custom_gates:
    enabled: false
    python_module: "custom_quality_gates"
    
  # Machine learning based quality assessment
  ml_quality_assessment:
    enabled: false
    model_path: "models/quality_model.pkl"
    feature_extractors:
      - "code_complexity"
      - "test_patterns"
      - "performance_patterns"
  
  # Auto-remediation
  auto_remediation:
    enabled: false
    remediation_scripts:
      low_coverage: "scripts/improve_coverage.py"
      performance_issues: "scripts/optimize_performance.py"
      bias_detection: "scripts/address_bias.py"