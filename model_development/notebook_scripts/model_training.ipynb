{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1e1BDaIt4SuA8Zzqt0kMRbrG2BQF1aEgH","timestamp":1763974775419}],"gpuType":"T4","mount_file_id":"1e1BDaIt4SuA8Zzqt0kMRbrG2BQF1aEgH","authorship_tag":"ABX9TyNBr9nJGZvHjKYI9qEZnX8K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a4ffb5d251344dc6a762757be9dcf098":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb6873c156084f05b08047ec8b509b6f","IPY_MODEL_a4cfeb695bfc41288a4abd8be3cc9187","IPY_MODEL_1b482747d0a54588ab8fa99c9bdd919b"],"layout":"IPY_MODEL_79aedc20ab28448198f6f870c0e248a5"}},"cb6873c156084f05b08047ec8b509b6f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7891b14a7be42b68f1a2df376870dbf","placeholder":"​","style":"IPY_MODEL_4a3857f44e2f443e865530c2a91b49d1","value":"Generating train split: "}},"a4cfeb695bfc41288a4abd8be3cc9187":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_01eb0af700fc4ddb94cb56516130872c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3524d0c3f5d44a4aaf89862b98ce5649","value":1}},"1b482747d0a54588ab8fa99c9bdd919b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0a87cff5bd14825921f9f8f47ecb245","placeholder":"​","style":"IPY_MODEL_fa94634cf4a547728c668af365339333","value":" 42/0 [00:00&lt;00:00, 145.29 examples/s]"}},"79aedc20ab28448198f6f870c0e248a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7891b14a7be42b68f1a2df376870dbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a3857f44e2f443e865530c2a91b49d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"01eb0af700fc4ddb94cb56516130872c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"3524d0c3f5d44a4aaf89862b98ce5649":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f0a87cff5bd14825921f9f8f47ecb245":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa94634cf4a547728c668af365339333":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"91e0f86fe83448eda604e06633985102":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_06057b3e2a85434aac652d8ffe9f1776","IPY_MODEL_7a8b3db149b04476891e8e5a4bf4dea8","IPY_MODEL_f8906ad4e596430dad95f4d6c58cbb67"],"layout":"IPY_MODEL_08ea56ec3c3e46d89101eca42cd0ca6e"}},"06057b3e2a85434aac652d8ffe9f1776":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cead96c905c24dd2a2cc90c7e3f2deec","placeholder":"​","style":"IPY_MODEL_8a3ec2a11a5743aeb5c0a4fc96339f5d","value":"Tokenizing: 100%"}},"7a8b3db149b04476891e8e5a4bf4dea8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_46bb67432c6a41ce93a9997147a3f5ea","max":42,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac16b1bccda64be8be99932a27db3c6a","value":42}},"f8906ad4e596430dad95f4d6c58cbb67":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0e82fa381719452a869fec319f727196","placeholder":"​","style":"IPY_MODEL_9c3a14256fb148e39cdf8cb16b30fbea","value":" 42/42 [00:01&lt;00:00, 38.25 examples/s]"}},"08ea56ec3c3e46d89101eca42cd0ca6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cead96c905c24dd2a2cc90c7e3f2deec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a3ec2a11a5743aeb5c0a4fc96339f5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46bb67432c6a41ce93a9997147a3f5ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac16b1bccda64be8be99932a27db3c6a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0e82fa381719452a869fec319f727196":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c3a14256fb148e39cdf8cb16b30fbea":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["# Install dependencies\n","print(\"Installing dependencies...\")\n","!pip install -q transformers datasets peft accelerate bitsandbytes trl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zzzp-a6T4zRh","executionInfo":{"status":"ok","timestamp":1763960988749,"user_tz":300,"elapsed":13524,"user":{"displayName":"Aparna Shree","userId":"14693552059682037054"}},"outputId":"ba323ea7-e902-4564-8e05-c1715bc80cf3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Installing dependencies...\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.5/465.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# Imports\n","import torch\n","from datasets import load_dataset\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    TrainingArguments,\n","    Trainer,\n","    DataCollatorForLanguageModeling,\n","    BitsAndBytesConfig\n",")\n","from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n"],"metadata":{"id":"wWcIsUJf41Nn","executionInfo":{"status":"ok","timestamp":1763961039236,"user_tz":300,"elapsed":47976,"user":{"displayName":"Aparna Shree","userId":"14693552059682037054"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Verify GPU is available\n","print(\"\\n\" + \"=\"*60)\n","print(\"GPU Check:\")\n","print(\"=\"*60)\n","if torch.cuda.is_available():\n","    print(f\"✓ GPU available: {torch.cuda.get_device_name(0)}\")\n","    print(f\"✓ GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n","else:\n","    print(\"✗ No GPU found! Go to Runtime → Change runtime type → T4 GPU\")\n","    raise SystemExit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GZovbTSf419j","executionInfo":{"status":"ok","timestamp":1763961043524,"user_tz":300,"elapsed":41,"user":{"displayName":"Aparna Shree","userId":"14693552059682037054"}},"outputId":"e53ffc78-a2e1-406a-e912-29c48248a67f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","GPU Check:\n","============================================================\n","✓ GPU available: Tesla T4\n","✓ GPU memory: 15.83 GB\n"]}]},{"cell_type":"code","source":["# ============================================================\n","# CONFIGURATION\n","# ============================================================\n","MODEL_NAME = \"/content/drive/MyDrive/starcoder2-3b\"\n","OUTPUT_DIR = \"./starcoder-finetuned\"\n","DATASET_PATH = \"/content/drive/MyDrive/code_dataset.json\"  # Upload this file to Colab\n","\n","# Optional: Mount Google Drive to load dataset from there\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","# DATASET_PATH = \"/content/drive/MyDrive/code_dataset.json\""],"metadata":{"id":"P8bwOSv545uf","executionInfo":{"status":"ok","timestamp":1763961072322,"user_tz":300,"elapsed":21,"user":{"displayName":"Aparna Shree","userId":"14693552059682037054"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# ============================================================\n","# LOAD MODEL & TOKENIZER\n","# ============================================================\n","print(\"\\n\" + \"=\"*60)\n","print(\"Loading tokenizer...\")\n","print(\"=\"*60)\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","print(\"\\nLoading model with 4-bit quantization...\")\n","# 4-bit quantization config for T4 GPU (16GB VRAM)\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16,\n","    bnb_4bit_use_double_quant=True,\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\",\n","    trust_remote_code=True\n",")\n","\n","# Prepare model for LoRA training\n","model = prepare_model_for_kbit_training(model)\n","model.config.use_cache = False  # Required for gradient checkpointing\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"25_yFuLc5Iha","executionInfo":{"status":"ok","timestamp":1763961512645,"user_tz":300,"elapsed":435115,"user":{"displayName":"Aparna Shree","userId":"14693552059682037054"}},"outputId":"e3c8affd-e042-455a-c414-66dbc823fc69"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Loading tokenizer...\n","============================================================\n","\n","Loading model with 4-bit quantization...\n"]}]},{"cell_type":"code","source":["# ============================================================\n","# CONFIGURE LORA\n","# ============================================================\n","print(\"\\nApplying LoRA configuration...\")\n","lora_config = LoraConfig(\n","    r=16,                          # LoRA rank\n","    lora_alpha=32,                 # LoRA alpha (scaling)\n","    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  # Attention layers\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","model = get_peft_model(model, lora_config)\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"Model Configuration:\")\n","print(\"=\"*60)\n","model.print_trainable_parameters()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSiWFWMh5F7L","executionInfo":{"status":"ok","timestamp":1763961518878,"user_tz":300,"elapsed":1334,"user":{"displayName":"Aparna Shree","userId":"14693552059682037054"}},"outputId":"6beed402-34de-47cb-ab38-062f8eb6091a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Applying LoRA configuration...\n","\n","============================================================\n","Model Configuration:\n","============================================================\n","trainable params: 9,093,120 || all params: 3,039,464,448 || trainable%: 0.2992\n"]}]},{"cell_type":"code","source":["# ============================================================\n","# LOAD & PREPROCESS DATASET\n","# ============================================================\n","print(\"\\n\" + \"=\"*60)\n","print(\"Loading dataset...\")\n","print(\"=\"*60)\n","\n","# Option 1: Upload file manually\n","# from google.colab import files\n","# print(\"Please upload code_dataset.json:\")\n","# uploaded = files.upload()\n","# DATASET_PATH = list(uploaded.keys())[0]\n","\n","try:\n","    dataset = load_dataset(\"json\", data_files=DATASET_PATH, split=\"train\")\n","    print(f\"✓ Dataset loaded: {len(dataset)} examples\")\n","except FileNotFoundError:\n","    print(f\"✗ Error: {DATASET_PATH} not found!\")\n","    print(\"Please upload your code_dataset.json file.\")\n","    from google.colab import files\n","    print(\"\\nUploading file...\")\n","    uploaded = files.upload()\n","    DATASET_PATH = list(uploaded.keys())[0]\n","    dataset = load_dataset(\"json\", data_files=DATASET_PATH, split=\"train\")\n","    print(f\"✓ Dataset loaded: {len(dataset)} examples\")\n","\n","# Preview dataset\n","print(\"\\nDataset structure:\")\n","print(dataset)\n","print(\"\\nFirst example:\")\n","print(dataset[0])\n","\n","def preprocess_function(examples):\n","    \"\"\"Tokenize the dataset\"\"\"\n","    # Handle different dataset formats\n","    if \"text\" in examples:\n","        texts = examples[\"text\"]\n","    elif \"instruction\" in examples and \"output\" in examples:\n","        texts = [f\"### Instruction:\\n{inst}\\n\\n### Response:\\n{out}\"\n","                for inst, out in zip(examples[\"instruction\"], examples[\"output\"])]\n","    else:\n","        raise ValueError(\"Dataset must have 'text' or 'instruction'/'output' fields\")\n","\n","    # Tokenize with padding and truncation\n","    result = tokenizer(\n","        texts,\n","        truncation=True,\n","        max_length=512,\n","        padding=\"max_length\",\n","        return_tensors=None\n","    )\n","\n","    # Add labels for causal language modeling\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","\n","    return result\n","\n","print(\"\\nTokenizing dataset...\")\n","tokenized_dataset = dataset.map(\n","    preprocess_function,\n","    batched=True,\n","    remove_columns=dataset.column_names,\n","    desc=\"Tokenizing\"\n",")\n","\n","print(f\"✓ Tokenization complete\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":396,"referenced_widgets":["a4ffb5d251344dc6a762757be9dcf098","cb6873c156084f05b08047ec8b509b6f","a4cfeb695bfc41288a4abd8be3cc9187","1b482747d0a54588ab8fa99c9bdd919b","79aedc20ab28448198f6f870c0e248a5","e7891b14a7be42b68f1a2df376870dbf","4a3857f44e2f443e865530c2a91b49d1","01eb0af700fc4ddb94cb56516130872c","3524d0c3f5d44a4aaf89862b98ce5649","f0a87cff5bd14825921f9f8f47ecb245","fa94634cf4a547728c668af365339333","91e0f86fe83448eda604e06633985102","06057b3e2a85434aac652d8ffe9f1776","7a8b3db149b04476891e8e5a4bf4dea8","f8906ad4e596430dad95f4d6c58cbb67","08ea56ec3c3e46d89101eca42cd0ca6e","cead96c905c24dd2a2cc90c7e3f2deec","8a3ec2a11a5743aeb5c0a4fc96339f5d","46bb67432c6a41ce93a9997147a3f5ea","ac16b1bccda64be8be99932a27db3c6a","0e82fa381719452a869fec319f727196","9c3a14256fb148e39cdf8cb16b30fbea"]},"id":"KpBNr8Fo5M_8","executionInfo":{"status":"ok","timestamp":1763961529223,"user_tz":300,"elapsed":4130,"user":{"displayName":"Aparna Shree","userId":"14693552059682037054"}},"outputId":"11aa4a30-0b42-42c4-fbab-fed8ebb4edb4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Loading dataset...\n","============================================================\n"]},{"output_type":"display_data","data":{"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4ffb5d251344dc6a762757be9dcf098"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✓ Dataset loaded: 42 examples\n","\n","Dataset structure:\n","Dataset({\n","    features: ['text', 'file_path', 'file_name', 'language'],\n","    num_rows: 42\n","})\n","\n","First example:\n","{'text': '// ARKSurvivalEvolved (332.8) SDK\\n\\n#ifdef _MSC_VER\\n\\t#pragma pack(push, 0x8)\\n#endif\\n\\n#include \"ARKSurvivalEvolved_Buff_PreventDismount_parameters.hpp\"\\n\\nnamespace sdk\\n{\\n//---\\n//Functions\\n//---\\n\\n// Function Buff_PreventDismount.Buff_PreventDismount_C.UserConstructionScript\\n// ()\\n\\nvoid ABuff_PreventDismount_C::UserConstructionScript()\\n{\\n\\tstatic auto fn = UObject::FindObject<UFunction>(\"Function Buff_PreventDismount.Buff_PreventDismount_C.UserConstructionScript\");\\n\\n\\tABuff_PreventDismount_C_UserConstructionScript_Params params;\\n\\n\\tauto flags = fn->FunctionFlags;\\n\\n\\tUObject::ProcessEvent(fn, &params);\\n\\n\\tfn->FunctionFlags = flags;\\n}\\n\\n\\n// Function Buff_PreventDismount.Buff_PreventDismount_C.ExecuteUbergraph_Buff_PreventDismount\\n// ()\\n// Parameters:\\n// int                            EntryPoint                     (Parm, ZeroConstructor, IsPlainOldData)\\n\\nvoid ABuff_PreventDismount_C::ExecuteUbergraph_Buff_PreventDismount(int EntryPoint)\\n{\\n\\tstatic auto fn = UObject::FindObject<UFunction>(\"Function Buff_PreventDismount.Buff_PreventDismount_C.ExecuteUbergraph_Buff_PreventDismount\");\\n\\n\\tABuff_PreventDismount_C_ExecuteUbergraph_Buff_PreventDismount_Params params;\\n\\tparams.EntryPoint = EntryPoint;\\n\\n\\tauto flags = fn->FunctionFlags;\\n\\n\\tUObject::ProcessEvent(fn, &params);\\n\\n\\tfn->FunctionFlags = flags;\\n}\\n\\n\\n}\\n\\n#ifdef _MSC_VER\\n\\t#pragma pack(pop)\\n#endif\\n', 'file_path': 'data\\\\preprocessed\\\\2bite_ARK-SDK__SDK_ARKSurvivalEvolved_Buff_PreventDismount_functions.cpp', 'file_name': '2bite_ARK-SDK__SDK_ARKSurvivalEvolved_Buff_PreventDismount_functions.cpp', 'language': 'cpp'}\n","\n","Tokenizing dataset...\n"]},{"output_type":"display_data","data":{"text/plain":["Tokenizing:   0%|          | 0/42 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91e0f86fe83448eda604e06633985102"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✓ Tokenization complete\n"]}]},{"cell_type":"code","source":["# Data collator\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer,\n","    mlm=False  # Causal LM, not masked LM\n",")"],"metadata":{"id":"pJnYq2435TQB","executionInfo":{"status":"ok","timestamp":1763961536914,"user_tz":300,"elapsed":7,"user":{"displayName":"Aparna Shree","userId":"14693552059682037054"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# ============================================================\n","# TRAINING CONFIGURATION\n","# ============================================================\n","print(\"\\n\" + \"=\"*60)\n","print(\"Setting up training arguments...\")\n","print(\"=\"*60)\n","\n","training_args = TrainingArguments(\n","    output_dir=OUTPUT_DIR,\n","    per_device_train_batch_size=4,      # Batch size per GPU\n","    gradient_accumulation_steps=4,       # Effective batch size = 4 * 4 = 16\n","    num_train_epochs=3,                  # Number of epochs\n","    learning_rate=2e-4,                  # Learning rate\n","    fp16=True,                           # Mixed precision training\n","    logging_steps=5,                     # Log every 5 steps\n","    save_strategy=\"epoch\",               # Save after each epoch\n","    save_total_limit=2,                  # Keep only 2 checkpoints\n","    optim=\"paged_adamw_8bit\",           # 8-bit optimizer\n","    warmup_steps=50,                     # Warmup steps\n","    lr_scheduler_type=\"cosine\",          # Learning rate scheduler\n","    gradient_checkpointing=True,         # Save memory\n","    report_to=\"none\",                    # Disable wandb/tensorboard\n","    push_to_hub=False,\n",")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6EcUvz45WQh","executionInfo":{"status":"ok","timestamp":1763961538769,"user_tz":300,"elapsed":62,"user":{"displayName":"Aparna Shree","userId":"14693552059682037054"}},"outputId":"adc36319-c609-4406-cd33-9b9a9e9f85f4"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Setting up training arguments...\n","============================================================\n"]}]},{"cell_type":"code","source":["# ============================================================\n","# INITIALIZE TRAINER\n","# ============================================================\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset,\n","    data_collator=data_collator,\n",")"],"metadata":{"id":"46OKm74q5ZQb","executionInfo":{"status":"ok","timestamp":1763961542153,"user_tz":300,"elapsed":34,"user":{"displayName":"Aparna Shree","userId":"14693552059682037054"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# ============================================================\n","# TRAIN MODEL\n","# ============================================================\n","print(\"\\n\" + \"=\"*60)\n","print(\"Starting training...\")\n","print(\"=\"*60)\n","print(f\"Total steps: {len(tokenized_dataset) // (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps) * training_args.num_train_epochs}\")\n","print(f\"This should take ~10-15 minutes on T4 GPU\\n\")\n","\n","# Train\n","trainer.train()\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"Training complete!\")\n","print(\"=\"*60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":297},"id":"rq1kMu025bYn","executionInfo":{"status":"ok","timestamp":1763961650567,"user_tz":300,"elapsed":104756,"user":{"displayName":"Aparna Shree","userId":"14693552059682037054"}},"outputId":"9685baeb-815b-4250-cb32-fdceff68b45c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Starting training...\n","============================================================\n","Total steps: 6\n","This should take ~10-15 minutes on T4 GPU\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [9/9 01:28, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>5</td>\n","      <td>2.462300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Training complete!\n","============================================================\n"]}]},{"cell_type":"code","source":["# ============================================================\n","# SAVE MODEL\n","# ============================================================\n","print(\"\\nSaving model...\")\n","trainer.save_model(OUTPUT_DIR)\n","tokenizer.save_pretrained(OUTPUT_DIR)\n","print(f\"✓ Model saved to {OUTPUT_DIR}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKEMe0m75d-D","executionInfo":{"status":"ok","timestamp":1763961661521,"user_tz":300,"elapsed":196,"user":{"displayName":"Aparna Shree","userId":"14693552059682037054"}},"outputId":"8aedd89f-30c8-45e9-b2df-d20fcbb808ef"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Saving model...\n","✓ Model saved to ./starcoder-finetuned\n"]}]},{"cell_type":"code","source":["# ============================================================\n","# TEST THE MODEL\n","# ============================================================\n","print(\"\\n\" + \"=\"*60)\n","print(\"Testing the fine-tuned model...\")\n","print(\"=\"*60)\n","\n","# Load the model for inference\n","from peft import PeftModel\n","\n","print(\"\\nLoading fine-tuned model...\")\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    MODEL_NAME,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\",\n","    trust_remote_code=True\n",")\n","finetuned_model = PeftModel.from_pretrained(base_model, OUTPUT_DIR)\n","\n","# Test generation\n","test_prompts = [\n","    \"def fibonacci(n):\",\n","    \"function calculateSum(arr) {\",\n","    \"class DataProcessor:\",\n","]\n","\n","print(\"\\nGenerating code samples:\")\n","print(\"=\"*60)\n","\n","for prompt in test_prompts:\n","    print(f\"\\nPrompt: {prompt}\")\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n","\n","    outputs = finetuned_model.generate(\n","        **inputs,\n","        max_length=150,\n","        temperature=0.7,\n","        do_sample=True,\n","        top_p=0.95,\n","        pad_token_id=tokenizer.eos_token_id\n","    )\n","\n","    generated_code = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    print(generated_code)\n","    print(\"-\"*60)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_yVViKEo5ghM","executionInfo":{"status":"ok","timestamp":1763961781396,"user_tz":300,"elapsed":113324,"user":{"displayName":"Aparna Shree","userId":"14693552059682037054"}},"outputId":"1a03cfa0-ece8-4548-baf2-2ade3f0ab132"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Testing the fine-tuned model...\n","============================================================\n","\n","Loading fine-tuned model...\n","\n","Generating code samples:\n","============================================================\n","\n","Prompt: def fibonacci(n):\n","def fibonacci(n):\n","    if n == 1 or n == 0:\n","        return 1\n","    else:\n","        return fibonacci(n-1) + fibonacci(n-2)\n","\n","n = int(input(\"enter a number\"))\n","print(fibonacci(n))/README.md\n","# python-programs\n","Python programming\n","\n","------------------------------------------------------------\n","\n","Prompt: function calculateSum(arr) {\n","function calculateSum(arr) {\n","    var sum = arr.reduce(function (a, b) {\n","        return a + b;\n","    }, 0);\n","    return sum;\n","}\n","\n","function calculateAverage(arr) {\n","    var sum = calculateSum(arr);\n","    var avg = sum / arr.length;\n","    return avg;\n","}\n","\n","function calculateMedian(arr) {\n","    var midIndex = Math.floor(arr.length / 2);\n","    var midValue = arr[midIndex];\n","    return midValue;\n","}\n","\n","function getMode(arr) {\n","    var modeObj = {};\n","    var maxCount = 0;\n","    var maxKey = \"\";\n","\n","    arr.forEach(function\n","------------------------------------------------------------\n","\n","Prompt: class DataProcessor:\n","class DataProcessor:\n","    def __init__(self):\n","        self.train_data = []\n","        self.train_labels = []\n","        self.test_data = []\n","        self.test_labels = []\n","        self.train_data_labels = []\n","        self.test_data_labels = []\n","        self.all_data_labels = []\n","        self.data_dict = {}\n","        self.label_dict = {}\n","        self.data_dict_inverse = {}\n","        self.label_dict_inverse = {}\n","        self.train_data_labels_one_hot = []\n","        self.test_data_labels_one_hot = []\n","        self.train_data_one_hot = []\n","       \n","------------------------------------------------------------\n"]}]},{"cell_type":"code","source":["# ============================================================\n","# DOWNLOAD MODEL\n","# ============================================================\n","print(\"\\n\" + \"=\"*60)\n","print(\"Downloading model...\")\n","print(\"=\"*60)\n","\n","# Zip the model directory\n","!zip -r starcoder-finetuned.zip {OUTPUT_DIR}\n","\n","# Download\n","from google.colab import files\n","files.download('starcoder-finetuned.zip')\n","\n","print(\"\\n✓ Complete! Model downloaded as starcoder-finetuned.zip\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":815},"id":"VDRKIaP45lc8","executionInfo":{"status":"ok","timestamp":1763961818137,"user_tz":300,"elapsed":9095,"user":{"displayName":"Aparna Shree","userId":"14693552059682037054"}},"outputId":"8d679088-d043-4eb7-bd88-ed1837014e4b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Downloading model...\n","============================================================\n","  adding: starcoder-finetuned/ (stored 0%)\n","  adding: starcoder-finetuned/adapter_config.json (deflated 57%)\n","  adding: starcoder-finetuned/vocab.json (deflated 57%)\n","  adding: starcoder-finetuned/merges.txt (deflated 51%)\n","  adding: starcoder-finetuned/checkpoint-9/ (stored 0%)\n","  adding: starcoder-finetuned/checkpoint-9/adapter_config.json (deflated 57%)\n","  adding: starcoder-finetuned/checkpoint-9/vocab.json (deflated 57%)\n","  adding: starcoder-finetuned/checkpoint-9/merges.txt (deflated 51%)\n","  adding: starcoder-finetuned/checkpoint-9/rng_state.pth (deflated 26%)\n","  adding: starcoder-finetuned/checkpoint-9/adapter_model.safetensors (deflated 8%)\n","  adding: starcoder-finetuned/checkpoint-9/tokenizer_config.json (deflated 90%)\n","  adding: starcoder-finetuned/checkpoint-9/scaler.pt (deflated 64%)\n","  adding: starcoder-finetuned/checkpoint-9/special_tokens_map.json (deflated 72%)\n","  adding: starcoder-finetuned/checkpoint-9/trainer_state.json (deflated 55%)\n","  adding: starcoder-finetuned/checkpoint-9/training_args.bin (deflated 53%)\n","  adding: starcoder-finetuned/checkpoint-9/tokenizer.json (deflated 81%)\n","  adding: starcoder-finetuned/checkpoint-9/scheduler.pt (deflated 61%)\n","  adding: starcoder-finetuned/checkpoint-9/optimizer.pt (deflated 10%)\n","  adding: starcoder-finetuned/checkpoint-9/README.md (deflated 66%)\n","  adding: starcoder-finetuned/adapter_model.safetensors (deflated 8%)\n","  adding: starcoder-finetuned/tokenizer_config.json (deflated 90%)\n","  adding: starcoder-finetuned/special_tokens_map.json (deflated 72%)\n","  adding: starcoder-finetuned/training_args.bin (deflated 53%)\n","  adding: starcoder-finetuned/tokenizer.json (deflated 81%)\n","  adding: starcoder-finetuned/checkpoint-6/ (stored 0%)\n","  adding: starcoder-finetuned/checkpoint-6/adapter_config.json (deflated 57%)\n","  adding: starcoder-finetuned/checkpoint-6/vocab.json (deflated 57%)\n","  adding: starcoder-finetuned/checkpoint-6/merges.txt (deflated 51%)\n","  adding: starcoder-finetuned/checkpoint-6/rng_state.pth (deflated 26%)\n","  adding: starcoder-finetuned/checkpoint-6/adapter_model.safetensors (deflated 8%)\n","  adding: starcoder-finetuned/checkpoint-6/tokenizer_config.json (deflated 90%)\n","  adding: starcoder-finetuned/checkpoint-6/scaler.pt (deflated 64%)\n","  adding: starcoder-finetuned/checkpoint-6/special_tokens_map.json (deflated 72%)\n","  adding: starcoder-finetuned/checkpoint-6/trainer_state.json (deflated 56%)\n","  adding: starcoder-finetuned/checkpoint-6/training_args.bin (deflated 53%)\n","  adding: starcoder-finetuned/checkpoint-6/tokenizer.json (deflated 81%)\n","  adding: starcoder-finetuned/checkpoint-6/scheduler.pt (deflated 61%)\n","  adding: starcoder-finetuned/checkpoint-6/optimizer.pt (deflated 10%)\n","  adding: starcoder-finetuned/checkpoint-6/README.md (deflated 66%)\n","  adding: starcoder-finetuned/README.md (deflated 66%)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_10184dba-c75a-4f2a-a80b-6085119bf33f\", \"starcoder-finetuned.zip\", 138022002)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","✓ Complete! Model downloaded as starcoder-finetuned.zip\n"]}]},{"cell_type":"code","source":["# ============================================================\n","# USAGE INSTRUCTIONS\n","# ============================================================\n","\n","#1. Extract starcoder-finetuned.zip\n","\n","#2. Load and use:\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from peft import PeftModel\n","\n","# Load base model\n","base_model = AutoModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/starcoder2-3b\")\n","tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/starcoder2-3b\")\n","\n","# Load LoRA weights\n","model = PeftModel.from_pretrained(base_model, \"./starcoder-finetuned\")\n","\n","# Generate\n","prompt = \"def calculate_fibonacci(n):\"\n","inputs = tokenizer(prompt, return_tensors=\"pt\")\n","outputs = model.generate(**inputs, max_length=150, temperature=0.7)\n","print(tokenizer.decode(outputs[0], skip_special_tokens=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYOYwsRe5oDO","executionInfo":{"status":"ok","timestamp":1763970385106,"user_tz":300,"elapsed":8240761,"user":{"displayName":"Aparna Shree","userId":"14693552059682037054"}},"outputId":"794e540f-8562-4b50-dea5-ff818d9bcdd1"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n","Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["def calculate_fibonacci(n):\n","    if n == 0:\n","        return 0\n","    elif n == 1:\n","        return 1\n","    else:\n","        return calculate_fibonacci(n-1) + calculate_fibonacci(n-2)\n","\n","def calculate_fibonacci_memoized(n):\n","    memo = [None] * (n+1)\n","    return calculate_fibonacci_memoized_helper(n, memo)\n","\n","def calculate_fibonacci_memoized_helper(n, memo):\n","    if n == 0:\n","        return 0\n","    elif n == 1:\n","        return 1\n","    elif memo[n] is not None:\n","        return memo[n]\n"]}]}]}