<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="0" failures="3" skipped="0" tests="4" time="14.875" timestamp="2025-10-28T22:16:03.105388" hostname="ITSLOAN27102157"><testcase classname="tests.integration.test_pipeline_integration.TestPipelineIntegration" name="test_end_to_end_pipeline" time="1.501"><failure message="KeyError: 'complexity_threshold'">self = &lt;test_pipeline_integration.TestPipelineIntegration object at 0x0000019A5D46A9F0&gt;
sample_code_data = {'java_sample': '\npublic class Hello {\n    public static void main(String[] args) {\n        System.out.println("Hello, World!");\n    }\n}\n        ', 'python_sample': '\ndef hello_world():\n    print("Hello, World!")\n        '}

    def test_end_to_end_pipeline(self, sample_code_data):
        """Test complete data pipeline integration"""
        # Step 1: Data Acquisition
        download_result = self.data_acquisition.download_dataset(
            bucket="test-bucket",
            prefix="test-prefix"
        )
        assert "downloaded_files" in download_result
        assert len(download_result["downloaded_files"]) &gt; 0
    
        # Step 2: Initial Processing
        processed_files = []
        for file in download_result["downloaded_files"]:
            processed = {
                "content": self.pii_remover.remove_pii(file["content"]),
                "file_path": file.get("path", "test.py"),
                "metadata": {
                    "language": "python",
                    "size": len(file["content"])
                }
            }
            processed_files.append(processed)
        assert len(processed_files) &gt; 0
    
        # Step 3: Anomaly Detection
&gt;       anomalies = self.anomaly_detector.analyze_dataset(processed_files)

test_pipeline_integration.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\scripts\anomaly_detection.py:167: in analyze_dataset
    "complexity_anomalies": self._detect_complexity_anomalies(files),
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;scripts.anomaly_detection.AnomalyDetector object at 0x0000019A5AE97080&gt;
files = [{'content': ('def test(): pass', {'api_keys': 0, 'emails': 0, 'github_tokens': 0, 'ips': 0, ...}), 'file_path': 'test/file1.py', 'metadata': {'language': 'python', 'size': 16}}]

    def _detect_complexity_anomalies(self, files: List[Dict[str, Any]]) -&gt; List[Dict[str, Any]]:
        """Detect files with high code complexity."""
        anomalies = []
        for file in files:
&gt;           if file.get('complexity', 0) &gt; self.thresholds['complexity_threshold']:
E           KeyError: 'complexity_threshold'

..\..\scripts\anomaly_detection.py:201: KeyError</failure></testcase><testcase classname="tests.integration.test_pipeline_integration.TestPipelineIntegration" name="test_error_propagation" time="0.357" /><testcase classname="tests.integration.test_pipeline_integration.TestPipelineIntegration" name="test_data_consistency" time="0.339"><failure message="TypeError: expected string or bytes-like object, got 'tuple'">self = &lt;test_pipeline_integration.TestPipelineIntegration object at 0x0000019A5D46AD80&gt;
sample_code_data = {'java_sample': '\npublic class Hello {\n    public static void main(String[] args) {\n        System.out.println("Hello, World!");\n    }\n}\n        ', 'python_sample': '\ndef hello_world():\n    print("Hello, World!")\n        '}

    def test_data_consistency(self, sample_code_data):
        """Test data consistency through pipeline stages"""
        # Process sample data
        processed_data = {
            "content": sample_code_data["python_sample"],
            "file_path": "test.py",
            "metadata": {
                "language": "python",
                "size": len(sample_code_data["python_sample"])
            }
        }
    
        # Apply preprocessing
        processed_content = processed_data["content"]
        processed_content = self.pii_remover.remove_pii(processed_content)
        processed_data["content"] = processed_content
    
        # Run anomaly detection
&gt;       anomalies = self.anomaly_detector.analyze_single_file(processed_data)

test_pipeline_integration.py:96: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\scripts\anomaly_detection.py:275: in analyze_single_file
    "pii_detected": self._detect_pii([file_data])
..\..\scripts\anomaly_detection.py:216: in _detect_pii
    matches = re.findall(pattern, content)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

pattern = '\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'
string = ('\ndef hello_world():\n    print("Hello, World!")\n        ', {'api_keys': 0, 'emails': 0, 'github_tokens': 0, 'ips': 0, ...})
flags = 0

    def findall(pattern, string, flags=0):
        """Return a list of all non-overlapping matches in the string.
    
        If one or more capturing groups are present in the pattern, return
        a list of groups; this will be a list of tuples if the pattern
        has more than one group.
    
        Empty matches are included in the result."""
&gt;       return _compile(pattern, flags).findall(string)
E       TypeError: expected string or bytes-like object, got 'tuple'

..\..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\re\__init__.py:217: TypeError</failure></testcase><testcase classname="tests.integration.test_pipeline_integration.TestPipelineIntegration" name="test_performance_metrics" time="0.285"><failure message="TypeError: expected string or bytes-like object, got 'tuple'">self = &lt;test_pipeline_integration.TestPipelineIntegration object at 0x0000019A5D46AF60&gt;

    def test_performance_metrics(self):
        """Test pipeline performance metrics"""
        start_time = time.time()
    
        # Process a sample file
        file_data = {
            "content": "def test():\n    print('hello')",
            "file_path": "test.py",
            "size": 28
        }
    
        # Measure preprocessing time
        preprocess_start = time.time()
        processed = self.pii_remover.remove_pii(file_data["content"])
        file_data["content"] = processed
        preprocess_time = time.time() - preprocess_start
    
        # Measure anomaly detection time
        anomaly_start = time.time()
&gt;       self.anomaly_detector.analyze_single_file(file_data)

test_pipeline_integration.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
..\..\scripts\anomaly_detection.py:275: in analyze_single_file
    "pii_detected": self._detect_pii([file_data])
..\..\scripts\anomaly_detection.py:216: in _detect_pii
    matches = re.findall(pattern, content)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

pattern = '\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'
string = ("def test():\n    print('hello')", {'api_keys': 0, 'emails': 0, 'github_tokens': 0, 'ips': 0, ...})
flags = 0

    def findall(pattern, string, flags=0):
        """Return a list of all non-overlapping matches in the string.
    
        If one or more capturing groups are present in the pattern, return
        a list of groups; this will be a list of tuples if the pattern
        has more than one group.
    
        Empty matches are included in the result."""
&gt;       return _compile(pattern, flags).findall(string)
E       TypeError: expected string or bytes-like object, got 'tuple'

..\..\..\..\..\AppData\Local\Programs\Python\Python312\Lib\re\__init__.py:217: TypeError</failure></testcase></testsuite></testsuites>