[
  {
    "text": "// ARKSurvivalEvolved (332.8) SDK\n\n#ifdef _MSC_VER\n\t#pragma pack(push, 0x8)\n#endif\n\n#include \"ARKSurvivalEvolved_Buff_PreventDismount_parameters.hpp\"\n\nnamespace sdk\n{\n//---\n//Functions\n//---\n\n// Function Buff_PreventDismount.Buff_PreventDismount_C.UserConstructionScript\n// ()\n\nvoid ABuff_PreventDismount_C::UserConstructionScript()\n{\n\tstatic auto fn = UObject::FindObject<UFunction>(\"Function Buff_PreventDismount.Buff_PreventDismount_C.UserConstructionScript\");\n\n\tABuff_PreventDismount_C_UserConstructionScript_Params params;\n\n\tauto flags = fn->FunctionFlags;\n\n\tUObject::ProcessEvent(fn, &params);\n\n\tfn->FunctionFlags = flags;\n}\n\n\n// Function Buff_PreventDismount.Buff_PreventDismount_C.ExecuteUbergraph_Buff_PreventDismount\n// ()\n// Parameters:\n// int                            EntryPoint                     (Parm, ZeroConstructor, IsPlainOldData)\n\nvoid ABuff_PreventDismount_C::ExecuteUbergraph_Buff_PreventDismount(int EntryPoint)\n{\n\tstatic auto fn = UObject::FindObject<UFunction>(\"Function Buff_PreventDismount.Buff_PreventDismount_C.ExecuteUbergraph_Buff_PreventDismount\");\n\n\tABuff_PreventDismount_C_ExecuteUbergraph_Buff_PreventDismount_Params params;\n\tparams.EntryPoint = EntryPoint;\n\n\tauto flags = fn->FunctionFlags;\n\n\tUObject::ProcessEvent(fn, &params);\n\n\tfn->FunctionFlags = flags;\n}\n\n\n}\n\n#ifdef _MSC_VER\n\t#pragma pack(pop)\n#endif\n",
    "file_path": "data\\preprocessed\\2bite_ARK-SDK__SDK_ARKSurvivalEvolved_Buff_PreventDismount_functions.cpp",
    "file_name": "2bite_ARK-SDK__SDK_ARKSurvivalEvolved_Buff_PreventDismount_functions.cpp",
    "language": "cpp"
  },
  {
    "text": "\n#include \"FrameLib_Ternary_Objects.h\"\n#include \"FrameLib_MaxClass.h\"\n\nextern \"C\" int C74_EXPORT main(void)\n{\n    FrameLib_MaxClass_Expand<FrameLib_Clip, kDistribute>::makeClass(\"fl.clip~\");\n}\n\n",
    "file_path": "data\\preprocessed\\AlexHarker_FrameLib__FrameLib_Max_Objects_Ternary_fl.clip~.cpp",
    "file_name": "AlexHarker_FrameLib__FrameLib_Max_Objects_Ternary_fl.clip~.cpp",
    "language": "cpp"
  },
  {
    "text": "//\n// Copyright 2013 The ANGLE Project Authors. All rights reserved.\n// Use of this source code is governed by a BSD-style license that can be\n// found in the LICENSE file.\n//\n\n// angletypes.h : Defines a variety of structures and enum types that are used throughout libGLESv2\n\n#include \"libANGLE/angletypes.h\"\n#include \"libANGLE/Program.h\"\n#include \"libANGLE/State.h\"\n#include \"libANGLE/VertexArray.h\"\n#include \"libANGLE/VertexAttribute.h\"\n\n#include <limits>\n\nnamespace gl\n{\nnamespace\n{\nbool IsStencilNoOp(GLenum stencilFunc,\n                   GLenum stencilFail,\n                   GLenum stencilPassDepthFail,\n                   GLenum stencilPassDepthPass)\n{\n    const bool isNeverAndKeep           = stencilFunc == GL_NEVER && stencilFail == GL_KEEP;\n    const bool isAlwaysAndKeepOrAllKeep = (stencilFunc == GL_ALWAYS || stencilFail == GL_KEEP) &&\n                                          stencilPassDepthFail == GL_KEEP &&\n                                          stencilPassDepthPass == GL_KEEP;\n\n    return isNeverAndKeep || isAlwaysAndKeepOrAllKeep;\n}\n\n// Calculate whether the range [outsideLow, outsideHigh] encloses the range [insideLow, insideHigh]\nbool EnclosesRange(int outsideLow, int outsideHigh, int insideLow, int insideHigh)\n{\n    return outsideLow <= insideLow && outsideHigh >= insideHigh;\n}\n\nbool IsAdvancedBlendEquation(gl::BlendEquationType blendEquation)\n{\n    return blendEquation >= gl::BlendEquationType::Multiply &&\n           blendEquation <= gl::BlendEquationType::HslLuminosity;\n}\n}  // anonymous namespace\n\nRasterizerState::RasterizerState()\n{\n    memset(this, 0, sizeof(RasterizerState));\n\n    rasterizerDiscard   = false;\n    cullFace            = false;\n    cullMode            = CullFaceMode::Back;\n    frontFace           = GL_CCW;\n    polygonOffsetFill   = false;\n    polygonOffsetFactor = 0.0f;\n    polygonOffsetUnits  = 0.0f;\n    polygonOffsetClamp  = 0.0f;\n    pointDrawMode       = false;\n    multiSample         = false;\n    dither              = true;\n}\n\nRasterizerState::RasterizerState(const RasterizerState &other)\n{\n    memcpy(this, &other, sizeof(RasterizerState));\n}\n\nRasterizerState &RasterizerState::operator=(const RasterizerState &other)\n{\n    memcpy(this, &other, sizeof(RasterizerState));\n    return *this;\n}\n\nbool operator==(const RasterizerState &a, const RasterizerState &b)\n{\n    return memcmp(&a, &b, sizeof(RasterizerState)) == 0;\n}\n\nbool operator!=(const RasterizerState &a, const RasterizerState &b)\n{\n    return !(a == b);\n}\n\nBlendState::BlendState()\n{\n    memset(this, 0, sizeof(BlendState));\n\n    blend              = false;\n    sourceBlendRGB     = GL_ONE;\n    sourceBlendAlpha   = GL_ONE;\n    destBlendRGB       = GL_ZERO;\n    destBlendAlpha     = GL_ZERO;\n    blendEquationRGB   = GL_FUNC_ADD;\n    blendEquationAlpha = GL_FUNC_ADD;\n    colorMaskRed       = true;\n    colorMaskGreen     = true;\n    colorMaskBlue      = true;\n    colorMaskAlpha     = true;\n}\n\nBlendState::BlendState(const BlendState &other)\n{\n    memcpy(this, &other, sizeof(BlendState));\n}\n\nbool operator==(const BlendState &a, const BlendState &b)\n{\n    return memcmp(&a, &b, sizeof(BlendState)) == 0;\n}\n\nbool operator!=(const BlendState &a, const BlendState &b)\n{\n    return !(a == b);\n}\n\nDepthStencilState::DepthStencilState()\n{\n    memset(this, 0, sizeof(DepthStencilState));\n\n    depthTest                = false;\n    depthFunc                = GL_LESS;\n    depthMask                = true;\n    stencilTest              = false;\n    stencilFunc              = GL_ALWAYS;\n    stencilMask              = static_cast<GLuint>(-1);\n    stencilWritemask         = static_cast<GLuint>(-1);\n    stencilBackFunc          = GL_ALWAYS;\n    stencilBackMask          = static_cast<GLuint>(-1);\n    stencilBackWritemask     = static_cast<GLuint>(-1);\n    stencilFail              = GL_KEEP;\n    stencilPassDepthFail     = GL_KEEP;\n    stencilPassDepthPass     = GL_KEEP;\n    stencilBackFail          = GL_KEEP;\n    stencilBackPassDepthFail = GL_KEEP;\n    stencilBackPassDepthPass = GL_KEEP;\n}\n\nDepthStencilState::DepthStencilState(const DepthStencilState &other)\n{\n    memcpy(this, &other, sizeof(DepthStencilState));\n}\n\nDepthStencilState &DepthStencilState::operator=(const DepthStencilState &other)\n{\n    memcpy(this, &other, sizeof(DepthStencilState));\n    return *this;\n}\n\nbool DepthStencilState::isDepthMaskedOut() const\n{\n    return !depthMask;\n}\n\nbool DepthStencilState::isStencilMaskedOut() const\n{\n    return (stencilMask & stencilWritemask) == 0;\n}\n\nbool DepthStencilState::isStencilNoOp() const\n{\n    return isStencilMaskedOut() ||\n           IsStencilNoOp(stencilFunc, stencilFail, stencilPassDepthFail, stencilPassDepthPass);\n}\n\nbool DepthStencilState::isStencilBackNoOp() const\n{\n    const bool isStencilBackMaskedOut = (stencilBackMask & stencilBackWritemask) == 0;\n    return isStencilBackMaskedOut ||\n           IsStencilNoOp(stencilBackFunc, stencilBackFail, stencilBackPassDepthFail,\n                         stencilBackPassDepthPass);\n}\n\nbool operator==(const DepthStencilState &a, const DepthStencilState &b)\n{\n    return memcmp(&a, &b, sizeof(DepthStencilState)) == 0;\n}\n\nbool operator!=(const DepthStencilState &a, const DepthStencilState &b)\n{\n    return !(a == b);\n}\n\nSamplerState::SamplerState()\n{\n    memset(this, 0, sizeof(SamplerState));\n\n    setMinFilter(GL_NEAREST_MIPMAP_LINEAR);\n    setMagFilter(GL_LINEAR);\n    setWrapS(GL_REPEAT);\n    setWrapT(GL_REPEAT);\n    setWrapR(GL_REPEAT);\n    setMaxAnisotropy(1.0f);\n    setMinLod(-1000.0f);\n    setMaxLod(1000.0f);\n    setCompareMode(GL_NONE);\n    setCompareFunc(GL_LEQUAL);\n    setSRGBDecode(GL_DECODE_EXT);\n}\n\nSamplerState::SamplerState(const SamplerState &other) = default;\n\nSamplerState &SamplerState::operator=(const SamplerState &other) = default;\n\n// static\nSamplerState SamplerState::CreateDefaultForTarget(TextureType type)\n{\n    SamplerState state;\n\n    // According to OES_EGL_image_external and ARB_texture_rectangle: For external textures, the\n    // default min filter is GL_LINEAR and the default s and t wrap modes are GL_CLAMP_TO_EDGE.\n    if (type == TextureType::External || type == TextureType::Rectangle)\n    {\n        state.mMinFilter = GL_LINEAR;\n        state.mWrapS     = GL_CLAMP_TO_EDGE;\n        state.mWrapT     = GL_CLAMP_TO_EDGE;\n    }\n\n    return state;\n}\n\nbool SamplerState::setMinFilter(GLenum minFilter)\n{\n    if (mMinFilter != minFilter)\n    {\n        mMinFilter                    = minFilter;\n        mCompleteness.typed.minFilter = static_cast<uint8_t>(FromGLenum<FilterMode>(minFilter));\n        return true;\n    }\n    return false;\n}\n\nbool SamplerState::setMagFilter(GLenum magFilter)\n{\n    if (mMagFilter != magFilter)\n    {\n        mMagFilter                    = magFilter;\n        mCompleteness.typed.magFilter = static_cast<uint8_t>(FromGLenum<FilterMode>(magFilter));\n        return true;\n    }\n    return false;\n}\n\nbool SamplerState::setWrapS(GLenum wrapS)\n{\n    if (mWrapS != wrapS)\n    {\n        mWrapS                    = wrapS;\n        mCompleteness.typed.wrapS = static_cast<uint8_t>(FromGLenum<WrapMode>(wrapS));\n        return true;\n    }\n    return false;\n}\n\nbool SamplerState::setWrapT(GLenum wrapT)\n{\n    if (mWrapT != wrapT)\n    {\n        mWrapT = wrapT;\n        updateWrapTCompareMode();\n        return true;\n    }\n    return false;\n}\n\nbool SamplerState::setWrapR(GLenum wrapR)\n{\n    if (mWrapR != wrapR)\n    {\n        mWrapR = wrapR;\n        return true;\n    }\n    return false;\n}\n\nbool SamplerState::setMaxAnisotropy(float maxAnisotropy)\n{\n    if (mMaxAnisotropy != maxAnisotropy)\n    {\n        mMaxAnisotropy = maxAnisotropy;\n        return true;\n    }\n    return false;\n}\n\nbool SamplerState::setMinLod(GLfloat minLod)\n{\n    if (mMinLod != minLod)\n    {\n        mMinLod = minLod;\n        return true;\n    }\n    return false;\n}\n\nbool SamplerState::setMaxLod(GLfloat maxLod)\n{\n    if (mMaxLod != maxLod)\n    {\n        mMaxLod = maxLod;\n        return true;\n    }\n    return false;\n}\n\nbool SamplerState::setCompareMode(GLenum compareMode)\n{\n    if (mCompareMode != compareMode)\n    {\n        mCompareMode = compareMode;\n        updateWrapTCompareMode();\n        return true;\n    }\n    return false;\n}\n\nbool SamplerState::setCompareFunc(GLenum compareFunc)\n{\n    if (mCompareFunc != compareFunc)\n    {\n        mCompareFunc = compareFunc;\n        return true;\n    }\n    return false;\n}\n\nbool SamplerState::setSRGBDecode(GLenum sRGBDecode)\n{\n    if (mSRGBDecode != sRGBDecode)\n    {\n        mSRGBDecode = sRGBDecode;\n        return true;\n    }\n    return false;\n}\n\nbool SamplerState::setBorderColor(const ColorGeneric &color)\n{\n    if (mBorderColor != color)\n    {\n        mBorderColor = color;\n        return true;\n    }\n    return false;\n}\n\nvoid SamplerState::updateWrapTCompareMode()\n{\n    uint8_t wrap    = static_cast<uint8_t>(FromGLenum<WrapMode>(mWrapT));\n    uint8_t compare = static_cast<uint8_t>(mCompareMode == GL_NONE ? 0x10 : 0x00);\n    mCompleteness.typed.wrapTCompareMode = wrap | compare;\n}\n\nImageUnit::ImageUnit()\n    : texture(), level(0), layered(false), layer(0), access(GL_READ_ONLY), format(GL_R32UI)\n{}\n\nImageUnit::ImageUnit(const ImageUnit &other) = default;\n\nImageUnit::~ImageUnit() = default;\n\nBlendStateExt::BlendStateExt(const size_t drawBufferCount)\n    : mParameterMask(FactorStorage::GetMask(drawBufferCount)),\n      mSrcColor(FactorStorage::GetReplicatedValue(BlendFactorType::One, mParameterMask)),\n      mDstColor(FactorStorage::GetReplicatedValue(BlendFactorType::Zero, mParameterMask)),\n      mSrcAlpha(FactorStorage::GetReplicatedValue(BlendFactorType::One, mParameterMask)),\n      mDstAlpha(FactorStorage::GetReplicatedValue(BlendFactorType::Zero, mParameterMask)),\n      mEquationColor(EquationStorage::GetReplicatedValue(BlendEquationType::Add, mParameterMask)),\n      mEquationAlpha(EquationStorage::GetReplicatedValue(BlendEquationType::Add, mParameterMask)),\n      mAllColorMask(\n          ColorMaskStorage::GetReplicatedValue(PackColorMask(true, true, true, true),\n                                               ColorMaskStorage::GetMask(drawBufferCount))),\n      mColorMask(mAllColorMask),\n      mAllEnabledMask(0xFF >> (8 - drawBufferCount)),\n      mDrawBufferCount(drawBufferCount)\n{}\n\nBlendStateExt::BlendStateExt(const BlendStateExt &other) = default;\n\nBlendStateExt &BlendStateExt::operator=(const BlendStateExt &other) = default;\n\nvoid BlendStateExt::setEnabled(const bool enabled)\n{\n    mEnabledMask = enabled ? mAllEnabledMask : DrawBufferMask::Zero();\n}\n\nvoid BlendStateExt::setEnabledIndexed(const size_t index, const bool enabled)\n{\n    ASSERT(index < mDrawBufferCount);\n    mEnabledMask.set(index, enabled);\n}\n\nBlendStateExt::ColorMaskStorage::Type BlendStateExt::expandColorMaskValue(const bool red,\n   const bool green,\n   const bool blue,\n   const bool alpha) const\n{\n    return BlendStateExt::ColorMaskStorage::GetReplicatedValue(\n        PackColorMask(red, green, blue, alpha), mAllColorMask);\n}\n\nBlendStateExt::ColorMaskStorage::Type BlendStateExt::expandColorMaskIndexed(\n    const size_t index) const\n{\n    return ColorMaskStorage::GetReplicatedValue(\n        ColorMaskStorage::GetValueIndexed(index, mColorMask), mAllColorMask);\n}\n\nvoid BlendStateExt::setColorMask(const bool red,\n                                 const bool green,\n                                 const bool blue,\n                                 const bool alpha)\n{\n    mColorMask = expandColorMaskValue(red, green, blue, alpha);\n}\n\nvoid BlendStateExt::setColorMaskIndexed(const size_t index, const uint8_t value)\n{\n    ASSERT(index < mDrawBufferCount);\n    ASSERT(value <= 0xF);\n    ColorMaskStorage::SetValueIndexed(index, value, &mColorMask);\n}\n\nvoid BlendStateExt::setColorMaskIndexed(const size_t index,\n                                        const bool red,\n                                        const bool green,\n                                        const bool blue,\n                                        const bool alpha)\n{\n    ASSERT(index < mDrawBufferCount);\n    ColorMaskStorage::SetValueIndexed(index, PackColorMask(red, green, blue, alpha), &mColorMask);\n}\n\nuint8_t BlendStateExt::getColorMaskIndexed(const size_t index) const\n{\n    ASSERT(index < mDrawBufferCount);\n    return ColorMaskStorage::GetValueIndexed(index, mColorMask);\n}\n\nvoid BlendStateExt::getColorMaskIndexed(const size_t index,\n                                        bool *red,\n                                        bool *green,\n                                        bool *blue,\n                                        bool *alpha) const\n{\n    ASSERT(index < mDrawBufferCount);\n    UnpackColorMask(ColorMaskStorage::GetValueIndexed(index, mColorMask), red, green, blue, alpha);\n}\n\nDrawBufferMask BlendStateExt::compareColorMask(ColorMaskStorage::Type other) const\n{\n    return ColorMaskStorage::GetDiffMask(mColorMask, other);\n}\n\nBlendStateExt::EquationStorage::Type BlendStateExt::expandEquationValue(const GLenum mode) const\n{\n    return EquationStorage::GetReplicatedValue(FromGLenum<BlendEquationType>(mode), mParameterMask);\n}\n\nBlendStateExt::EquationStorage::Type BlendStateExt::expandEquationValue(\n    const gl::BlendEquationType equation) const\n{\n    return EquationStorage::GetReplicatedValue(equation, mParameterMask);\n}\n\nBlendStateExt::EquationStorage::Type BlendStateExt::expandEquationColorIndexed(\n    const size_t index) const\n{\n    return EquationStorage::GetReplicatedValue(\n        EquationStorage::GetValueIndexed(index, mEquationColor), mParameterMask);\n}\n\nBlendStateExt::EquationStorage::Type BlendStateExt::expandEquationAlphaIndexed(\n    const size_t index) const\n{\n    return EquationStorage::GetReplicatedValue(\n        EquationStorage::GetValueIndexed(index, mEquationAlpha), mParameterMask);\n}\n\nvoid BlendStateExt::setEquations(const GLenum modeColor, const GLenum modeAlpha)\n{\n    const gl::BlendEquationType colorEquation = FromGLenum<BlendEquationType>(modeColor);\n    const gl::BlendEquationType alphaEquation = FromGLenum<BlendEquationType>(modeAlpha);\n\n    mEquationColor = expandEquationValue(colorEquation);\n    mEquationAlpha = expandEquationValue(alphaEquation);\n\n    // Note that advanced blend equations cannot be independently set for color and alpha, so only\n    // the color equation can be checked.\n    if (IsAdvancedBlendEquation(colorEquation))\n    {\n        mUsesAdvancedBlendEquationMask = mAllEnabledMask;\n    }\n    else\n    {\n        mUsesAdvancedBlendEquationMask.reset();\n    }\n}\n\nvoid BlendStateExt::setEquationsIndexed(const size_t index,\n                                        const GLenum modeColor,\n                                        const GLenum modeAlpha)\n{\n    ASSERT(index < mDrawBufferCount);\n\n    const gl::BlendEquationType colorEquation = FromGLenum<BlendEquationType>(modeColor);\n    const gl::BlendEquationType alphaEquation = FromGLenum<BlendEquationType>(modeAlpha);\n\n    EquationStorage::SetValueIndexed(index, colorEquation, &mEquationColor);\n    EquationStorage::SetValueIndexed(index, alphaEquation, &mEquationAlpha);\n\n    mUsesAdvancedBlendEquationMask.set(index, IsAdvancedBlendEquation(colorEquation));\n}\n\nvoid BlendStateExt::setEquationsIndexed(const size_t index,\n                                        const size_t sourceIndex,\n                                        const BlendStateExt &source)\n{\n    ASSERT(index < mDrawBufferCount);\n    ASSERT(sourceIndex < source.mDrawBufferCount);\n\n    const gl::BlendEquationType colorEquation =\n        EquationStorage::GetValueIndexed(sourceIndex, source.mEquationColor);\n    const gl::BlendEquationType alphaEquation =\n        EquationStorage::GetValueIndexed(sourceIndex, source.mEquationAlpha);\n\n    EquationStorage::SetValueIndexed(index, colorEquation, &mEquationColor);\n    EquationStorage::SetValueIndexed(index, alphaEquation, &mEquationAlpha);\n\n    mUsesAdvancedBlendEquationMask.set(index, IsAdvancedBlendEquation(colorEquation));\n}\n\nGLenum BlendStateExt::getEquationColorIndexed(size_t index) const\n{\n    ASSERT(index < mDrawBufferCount);\n    return ToGLenum(EquationStorage::GetValueIndexed(index, mEquationColor));\n}\n\nGLenum BlendStateExt::getEquationAlphaIndexed(size_t index) const\n{\n    ASSERT(index < mDrawBufferCount);\n    return ToGLenum(EquationStorage::GetValueIndexed(index, mEquationAlpha));\n}\n\nDrawBufferMask BlendStateExt::compareEquations(const EquationStorage::Type color,\n                                               const EquationStorage::Type alpha) const\n{\n    return EquationStorage::GetDiffMask(mEquationColor, color) |\n           EquationStorage::GetDiffMask(mEquationAlpha, alpha);\n}\n\nBlendStateExt::FactorStorage::Type BlendStateExt::expandFactorValue(const GLenum func) const\n{\n    return FactorStorage::GetReplicatedValue(FromGLenum<BlendFactorType>(func), mParameterMask);\n}\n\nBlendStateExt::FactorStorage::Type BlendStateExt::expandSrcColorIndexed(const size_t index) const\n{\n    ASSERT(index < mDrawBufferCount);\n    return FactorStorage::GetReplicatedValue(FactorStorage::GetValueIndexed(index, mSrcColor),\n                                             mParameterMask);\n}\n\nBlendStateExt::FactorStorage::Type BlendStateExt::expandDstColorIndexed(const size_t index) const\n{\n    ASSERT(index < mDrawBufferCount);\n    return FactorStorage::GetReplicatedValue(FactorStorage::GetValueIndexed(index, mDstColor),\n                                             mParameterMask);\n}\n\nBlendStateExt::FactorStorage::Type BlendStateExt::expandSrcAlphaIndexed(const size_t index) const\n{\n    ASSERT(index < mDrawBufferCount);\n    return FactorStorage::GetReplicatedValue(FactorStorage::GetValueIndexed(index, mSrcAlpha),\n                                             mParameterMask);\n}\n\nBlendStateExt::FactorStorage::Type BlendStateExt::expandDstAlphaIndexed(const size_t index) const\n{\n    ASSERT(index < mDrawBufferCount);\n    return FactorStorage::GetReplicatedValue(FactorStorage::GetValueIndexed(index, mDstAlpha),\n                                             mParameterMask);\n}\n\nvoid BlendStateExt::setFactors(const GLenum srcColor,\n                               const GLenum dstColor,\n                               const GLenum srcAlpha,\n                               const GLenum dstAlpha)\n{\n    mSrcColor = expandFactorValue(srcColor);\n    mDstColor = expandFactorValue(dstColor);\n    mSrcAlpha = expandFactorValue(srcAlpha);\n    mDstAlpha = expandFactorValue(dstAlpha);\n}\n\nvoid BlendStateExt::setFactorsIndexed(const size_t index,\n                                      const GLenum srcColor,\n                                      const GLenum dstColor,\n                                      const GLenum srcAlpha,\n                                      const GLenum dstAlpha)\n{\n    ASSERT(index < mDrawBufferCount);\n    FactorStorage::SetValueIndexed(index, FromGLenum<BlendFactorType>(srcColor), &mSrcColor);\n    FactorStorage::SetValueIndexed(index, FromGLenum<BlendFactorType>(dstColor), &mDstColor);\n    FactorStorage::SetValueIndexed(index, FromGLenum<BlendFactorType>(srcAlpha), &mSrcAlpha);\n    FactorStorage::SetValueIndexed(index, FromGLenum<BlendFactorType>(dstAlpha), &mDstAlpha);\n}\n\nvoid BlendStateExt::setFactorsIndexed(const size_t index,\n                                      const size_t sourceIndex,\n                                      const BlendStateExt &source)\n{\n    ASSERT(index < mDrawBufferCount);\n    ASSERT(sourceIndex < source.mDrawBufferCount);\n    FactorStorage::SetValueIndexed(\n        index, FactorStorage::GetValueIndexed(sourceIndex, source.mSrcColor), &mSrcColor);\n    FactorStorage::SetValueIndexed(\n        index, FactorStorage::GetValueIndexed(sourceIndex, source.mDstColor), &mDstColor);\n    FactorStorage::SetValueIndexed(\n        index, FactorStorage::GetValueIndexed(sourceIndex, source.mSrcAlpha), &mSrcAlpha);\n    FactorStorage::SetValueIndexed(\n        index, FactorStorage::GetValueIndexed(sourceIndex, source.mDstAlpha), &mDstAlpha);\n}\n\nGLenum BlendStateExt::getSrcColorIndexed(size_t index) const\n{\n    ASSERT(index < mDrawBufferCount);\n    return ToGLenum(FactorStorage::GetValueIndexed(index, mSrcColor));\n}\n\nGLenum BlendStateExt::getDstColorIndexed(size_t index) const\n{\n    ASSERT(index < mDrawBufferCount);\n    return ToGLenum(FactorStorage::GetValueIndexed(index, mDstColor));\n}\n\nGLenum BlendStateExt::getSrcAlphaIndexed(size_t index) const\n{\n    ASSERT(index < mDrawBufferCount);\n    return ToGLenum(FactorStorage::GetValueIndexed(index, mSrcAlpha));\n}\n\nGLenum BlendStateExt::getDstAlphaIndexed(size_t index) const\n{\n    ASSERT(index < mDrawBufferCount);\n    return ToGLenum(FactorStorage::GetValueIndexed(index, mDstAlpha));\n}\n\nDrawBufferMask BlendStateExt::compareFactors(const FactorStorage::Type srcColor,\n                                             const FactorStorage::Type dstColor,\n                                             const FactorStorage::Type srcAlpha,\n                                             const FactorStorage::Type dstAlpha) const\n{\n    return FactorStorage::GetDiffMask(mSrcColor, srcColor) |\n           FactorStorage::GetDiffMask(mDstColor, dstColor) |\n           FactorStorage::GetDiffMask(mSrcAlpha, srcAlpha) |\n           FactorStorage::GetDiffMask(mDstAlpha, dstAlpha);\n}\n\nstatic void MinMax(int a, int b, int *minimum, int *maximum)\n{\n    if (a < b)\n    {\n        *minimum = a;\n        *maximum = b;\n    }\n    else\n    {\n        *minimum = b;\n        *maximum = a;\n    }\n}\n\ntemplate <>\nbool RectangleImpl<int>::empty() const\n{\n    return width == 0 && height == 0;\n}\n\ntemplate <>\nbool RectangleImpl<float>::empty() const\n{\n    return std::abs(width) < std::numeric_limits<float>::epsilon() &&\n           std::abs(height) < std::numeric_limits<float>::epsilon();\n}\n\nbool ClipRectangle(const Rectangle &source, const Rectangle &clip, Rectangle *intersection)\n{\n    angle::CheckedNumeric<int> sourceX2(source.x);\n    sourceX2 += source.width;\n    if (!sourceX2.IsValid())\n    {\n        return false;\n    }\n    angle::CheckedNumeric<int> sourceY2(source.y);\n    sourceY2 += source.height;\n    if (!sourceY2.IsValid())\n    {\n        return false;\n    }\n\n    int minSourceX, maxSourceX, minSourceY, maxSourceY;\n    MinMax(source.x, sourceX2.ValueOrDie(), &minSourceX, &maxSourceX);\n    MinMax(source.y, sourceY2.ValueOrDie(), &minSourceY, &maxSourceY);\n\n    angle::CheckedNumeric<int> clipX2(clip.x);\n    clipX2 += clip.width;\n    if (!clipX2.IsValid())\n    {\n        return false;\n    }\n    angle::CheckedNumeric<int> clipY2(clip.y);\n    clipY2 += clip.height;\n    if (!clipY2.IsValid())\n    {\n        return false;\n    }\n\n    int minClipX, maxClipX, minClipY, maxClipY;\n    MinMax(clip.x, clipX2.ValueOrDie(), &minClipX, &maxClipX);\n    MinMax(clip.y, clipY2.ValueOrDie(), &minClipY, &maxClipY);\n\n    if (minSourceX >= maxClipX || maxSourceX <= minClipX || minSourceY >= maxClipY ||\n        maxSourceY <= minClipY)\n    {\n        return false;\n    }\n\n    int x      = std::max(minSourceX, minClipX);\n    int y      = std::max(minSourceY, minClipY);\n    int width  = std::min(maxSourceX, maxClipX) - x;\n    int height = std::min(maxSourceY, maxClipY) - y;\n\n    if (intersection)\n    {\n        intersection->x      = x;\n        intersection->y      = y;\n        intersection->width  = width;\n        intersection->height = height;\n    }\n    return width != 0 && height != 0;\n}\n\nvoid GetEnclosingRectangle(const Rectangle &rect1, const Rectangle &rect2, Rectangle *rectUnion)\n{\n    // All callers use non-flipped framebuffer-size-clipped rectangles, so both flip and overflow\n    // are impossible.\n    ASSERT(!rect1.isReversedX() && !rect1.isReversedY());\n    ASSERT(!rect2.isReversedX() && !rect2.isReversedY());\n    ASSERT((angle::CheckedNumeric<int>(rect1.x) + rect1.width).IsValid());\n    ASSERT((angle::CheckedNumeric<int>(rect1.y) + rect1.height).IsValid());\n    ASSERT((angle::CheckedNumeric<int>(rect2.x) + rect2.width).IsValid());\n    ASSERT((angle::CheckedNumeric<int>(rect2.y) + rect2.height).IsValid());\n\n    // This function calculates a rectangle that covers both input rectangles:\n    //\n    //                     +---------+\n    //          rect1 -->  |         |\n    //                     |     +---+-----+\n    //                     |     |   |     | <-- rect2\n    //                     +-----+---+     |\n    //                           |         |\n    //                           +---------+\n    //\n    //   xy0 = min(rect1.xy0, rect2.xy0)\n    //                    \\\n    //                     +---------+-----+\n    //          union -->  |         .     |\n    //                     |     + . + . . +\n    //                     |     .   .     |\n    //                     + . . + . +     |\n    //                     |     .         |\n    //                     +-----+---------+\n    //                                    /\n    //                         xy1 = max(rect1.xy1, rect2.xy1)\n\n    int x0 = std::min(rect1.x0(), rect2.x0());\n    int y0 = std::min(rect1.y0(), rect2.y0());\n\n    int x1 = std::max(rect1.x1(), rect2.x1());\n    int y1 = std::max(rect1.y1(), rect2.y1());\n\n    rectUnion->x      = x0;\n    rectUnion->y      = y0;\n    rectUnion->width  = x1 - x0;\n    rectUnion->height = y1 - y0;\n}\n\nvoid ExtendRectangle(const Rectangle &source, const Rectangle &extend, Rectangle *extended)\n{\n    // All callers use non-flipped framebuffer-size-clipped rectangles, so both flip and overflow\n    // are impossible.\n    ASSERT(!source.isReversedX() && !source.isReversedY());\n    ASSERT(!extend.isReversedX() && !extend.isReversedY());\n    ASSERT((angle::CheckedNumeric<int>(source.x) + source.width).IsValid());\n    ASSERT((angle::CheckedNumeric<int>(source.y) + source.height).IsValid());\n    ASSERT((angle::CheckedNumeric<int>(extend.x) + extend.width).IsValid());\n    ASSERT((angle::CheckedNumeric<int>(extend.y) + extend.height).IsValid());\n\n    int x0 = source.x0();\n    int x1 = source.x1();\n    int y0 = source.y0();\n    int y1 = source.y1();\n\n    const int extendX0 = extend.x0();\n    const int extendX1 = extend.x1();\n    const int extendY0 = extend.y0();\n    const int extendY1 = extend.y1();\n\n    // For each side of the rectangle, calculate whether it can be extended by the second rectangle.\n    // If so, extend it and continue for the next side with the new dimensions.\n\n    // Left: Reduce x0 if the second rectangle's vertical edge covers the source's:\n    //\n    //     +--- - - -                +--- - - -\n    //     |                         |\n    //     |  +--------------+       +-----------------+\n    //     |  |    source    |  -->  |       source    |\n    //     |  +--------------+       +-----------------+\n    //     |                         |\n    //     +--- - - -                +--- - - -\n    //\n    const bool enclosesHeight = EnclosesRange(extendY0, extendY1, y0, y1);\n    if (extendX0 < x0 && extendX1 >= x0 && enclosesHeight)\n    {\n        x0 = extendX0;\n    }\n\n    // Right: Increase x1 simiarly.\n    if (extendX0 <= x1 && extendX1 > x1 && enclosesHeight)\n    {\n        x1 = extendX1;\n    }\n\n    // Top: Reduce y0 if the second rectangle's horizontal edge covers the source's potentially\n    // extended edge.\n    const bool enclosesWidth = EnclosesRange(extendX0, extendX1, x0, x1);\n    if (extendY0 < y0 && extendY1 >= y0 && enclosesWidth)\n    {\n        y0 = extendY0;\n    }\n\n    // Right: Increase y1 simiarly.\n    if (extendY0 <= y1 && extendY1 > y1 && enclosesWidth)\n    {\n        y1 = extendY1;\n    }\n\n    extended->x      = x0;\n    extended->y      = y0;\n    extended->width  = x1 - x0;\n    extended->height = y1 - y0;\n}\n\nbool Box::valid() const\n{\n    return width != 0 && height != 0 && depth != 0;\n}\n\nbool Box::operator==(const Box &other) const\n{\n    return (x == other.x && y == other.y && z == other.z && width == other.width &&\n            height == other.height && depth == other.depth);\n}\n\nbool Box::operator!=(const Box &other) const\n{\n    return !(*this == other);\n}\n\nRectangle Box::toRect() const\n{\n    ASSERT(z == 0 && depth == 1);\n    return Rectangle(x, y, width, height);\n}\n\nbool Box::coversSameExtent(const Extents &size) const\n{\n    return x == 0 && y == 0 && z == 0 && width == size.width && height == size.height &&\n           depth == size.depth;\n}\n\nbool Box::contains(const Box &other) const\n{\n    return x <= other.x && y <= other.y && z <= other.z && x + width >= other.x + other.width &&\n           y + height >= other.y + other.height && z + depth >= other.z + other.depth;\n}\n\nsize_t Box::volume() const\n{\n    return width * height * depth;\n}\n\nvoid Box::extend(const Box &other)\n{\n    // This extends the logic of \"ExtendRectangle\" to 3 dimensions\n\n    int x0 = x;\n    int x1 = x + width;\n    int y0 = y;\n    int y1 = y + height;\n    int z0 = z;\n    int z1 = z + depth;\n\n    const int otherx0 = other.x;\n    const int otherx1 = other.x + other.width;\n    const int othery0 = other.y;\n    const int othery1 = other.y + other.height;\n    const int otherz0 = other.z;\n    const int otherz1 = other.z + other.depth;\n\n    // For each side of the box, calculate whether it can be extended by the other box.\n    // If so, extend it and continue to the next side with the new dimensions.\n\n    const bool enclosesWidth  = EnclosesRange(otherx0, otherx1, x0, x1);\n    const bool enclosesHeight = EnclosesRange(othery0, othery1, y0, y1);\n    const bool enclosesDepth  = EnclosesRange(otherz0, otherz1, z0, z1);\n\n    // Left: Reduce x0 if the other box's Y and Z plane encloses the source\n    if (otherx0 < x0 && otherx1 >= x0 && enclosesHeight && enclosesDepth)\n    {\n        x0 = otherx0;\n    }\n\n    // Right: Increase x1 simiarly.\n    if (otherx0 <= x1 && otherx1 > x1 && enclosesHeight && enclosesDepth)\n    {\n        x1 = otherx1;\n    }\n\n    // Bottom: Reduce y0 if the other box's X and Z plane encloses the source\n    if (othery0 < y0 && othery1 >= y0 && enclosesWidth && enclosesDepth)\n    {\n        y0 = othery0;\n    }\n\n    // Top: Increase y1 simiarly.\n    if (othery0 <= y1 && othery1 > y1 && enclosesWidth && enclosesDepth)\n    {\n        y1 = othery1;\n    }\n\n    // Front: Reduce z0 if the other box's X and Y plane encloses the source\n    if (otherz0 < z0 && otherz1 >= z0 && enclosesWidth && enclosesHeight)\n    {\n        z0 = otherz0;\n    }\n\n    // Back: Increase z1 simiarly.\n    if (otherz0 <= z1 && otherz1 > z1 && enclosesWidth && enclosesHeight)\n    {\n        z1 = otherz1;\n    }\n\n    // Update member var with new dimensions\n    x      = x0;\n    width  = x1 - x0;\n    y      = y0;\n    height = y1 - y0;\n    z      = z0;\n    depth  = z1 - z0;\n}\n\nbool operator==(const Offset &a, const Offset &b)\n{\n    return a.x == b.x && a.y == b.y && a.z == b.z;\n}\n\nbool operator!=(const Offset &a, const Offset &b)\n{\n    return !(a == b);\n}\n\nbool operator==(const Extents &lhs, const Extents &rhs)\n{\n    return lhs.width == rhs.width && lhs.height == rhs.height && lhs.depth == rhs.depth;\n}\n\nbool operator!=(const Extents &lhs, const Extents &rhs)\n{\n    return !(lhs == rhs);\n}\n\nbool ValidateComponentTypeMasks(unsigned long outputTypes,\n                                unsigned long inputTypes,\n                                unsigned long outputMask,\n                                unsigned long inputMask)\n{\n    static_assert(IMPLEMENTATION_MAX_DRAW_BUFFERS <= kMaxComponentTypeMaskIndex,\n                  \"Output/input masks should fit into 16 bits - 1 bit per draw buffer. The \"\n                  \"corresponding type masks should fit into 32 bits - 2 bits per draw buffer.\");\n    static_assert(MAX_VERTEX_ATTRIBS <= kMaxComponentTypeMaskIndex,\n                  \"Output/input masks should fit into 16 bits - 1 bit per attrib. The \"\n                  \"corresponding type masks should fit into 32 bits - 2 bits per attrib.\");\n\n    // For performance reasons, draw buffer and attribute type validation is done using bit masks.\n    // We store two bits representing the type split, with the low bit in the lower 16 bits of the\n    // variable, and the high bit in the upper 16 bits of the variable. This is done so we can AND\n    // with the elswewhere used DrawBufferMask or AttributeMask.\n\n    // OR the masks with themselves, shifted 16 bits. This is to match our split type bits.\n    outputMask |= (outputMask << kMaxComponentTypeMaskIndex);\n    inputMask |= (inputMask << kMaxComponentTypeMaskIndex);\n\n    // To validate:\n    // 1. Remove any indexes that are not enabled in the input (& inputMask)\n    // 2. Remove any indexes that exist in output, but not in input (& outputMask)\n    // 3. Use == to verify equality\n    return (outputTypes & inputMask) == ((inputTypes & outputMask) & inputMask);\n}\n\nGLsizeiptr GetBoundBufferAvailableSize(const OffsetBindingPointer<Buffer> &binding)\n{\n    Buffer *buffer = binding.get();\n    if (buffer == nullptr)\n    {\n        return 0;\n    }\n\n    const GLsizeiptr bufferSize = static_cast<GLsizeiptr>(buffer->getSize());\n\n    if (binding.getSize() == 0)\n    {\n        return bufferSize;\n    }\n\n    const GLintptr offset = binding.getOffset();\n    const GLsizeiptr size = binding.getSize();\n\n    ASSERT(offset >= 0 && bufferSize >= 0);\n\n    if (bufferSize <= offset)\n    {\n        return 0;\n    }\n\n    return std::min(size, bufferSize - offset);\n}\n\n}  // namespace gl\n",
    "file_path": "data\\preprocessed\\apple-open-source_macos__WebKit_Source_ThirdParty_ANGLE_src_libANGLE_angletypes.cpp",
    "file_name": "apple-open-source_macos__WebKit_Source_ThirdParty_ANGLE_src_libANGLE_angletypes.cpp",
    "language": "cpp"
  },
  {
    "text": "#include \"ofApp.h\"\n\n//---\nvoid ofApp::setup(){\n\tofSetVerticalSync(true);\n\n\t// we add this listener before setting up so the initial circle resolution is correct\n\tcircleResolution.addListener(this, &ofApp::circleResolutionChanged);\n\tringButton.addListener(this, &ofApp::ringButtonPressed);\n\n\tgui.setup(); // most of the time you don't need a name\n\tgui.add(filled.setup(\"fill\", true));\n\tgui.add(radius.setup(\"radius\", 140, 10, 300));\n\tgui.add(center.setup(\"center\", {ofGetWidth()*.5, ofGetHeight()*.5}, {0, 0}, {ofGetWidth(), ofGetHeight()}));\n\tgui.add(color.setup(\"color\", ofColor(100, 100, 140), ofColor(0, 0), ofColor(255, 255)));\n\tgui.add(circleResolution.setup(\"circle res\", 5, 3, 90));\n\tgui.add(twoCircles.setup(\"two circles\"));\n\tgui.add(ringButton.setup(\"ring\"));\n\tgui.add(screenSize.setup(\"screen size\", ofToString(ofGetWidth())+\"x\"+ofToString(ofGetHeight())));\n\n\tbHide = false;\n\n\tring.load(\"ring.wav\");\n}\n\n//---\nvoid ofApp::exit(){\n\tringButton.removeListener(this, &ofApp::ringButtonPressed);\n}\n\n//---\nvoid ofApp::circleResolutionChanged(int &circleResolution){\n\tofSetCircleResolution(circleResolution);\n}\n\n//---\nvoid ofApp::ringButtonPressed(){\n\tring.play();\n}\n\n//---\nvoid ofApp::update(){\n\tofSetCircleResolution(circleResolution);\n}\n\n//---\nvoid ofApp::draw(){\n    ofBackgroundGradient(ofColor::white, ofColor::gray);\n\n\tif(filled){\n\t\tofFill();\n\t}else{\n\t\tofNoFill();\n\t}\n\n\tofSetColor(color);\n\tif(twoCircles){\n\t\tofDrawCircle(center->x-radius*.5, center->y, radius );\n\t\tofDrawCircle(center->x+radius*.5, center->y, radius );\n\t}else{\n\t\tofDrawCircle(center, radius );\n\t}\n\n\t// auto draw?\n\t// should the gui control hiding?\n\tif(!bHide){\n\t\tgui.draw();\n\t}\n}\n\n//---\nvoid ofApp::keyPressed(int key){\n\tif(key == 'h'){\n\t\tbHide = !bHide;\n\t}\n\telse if(key == 's'){\n\t\tgui.saveToFile(\"settings.xml\");\n\t}\n\telse if(key == 'l'){\n\t\tgui.loadFromFile(\"settings.xml\");\n\t}\n\telse if(key == ' '){\n\t\tcolor = ofColor(255);\n\t}\n}\n\n//---\nvoid ofApp::keyReleased(int key){\n\n}\n\n//---\nvoid ofApp::mouseMoved(int x, int y ){\n\n}\n\n//---\nvoid ofApp::mouseDragged(int x, int y, int button){\n\n}\n\n//---\nvoid ofApp::mousePressed(int x, int y, int button){\n\n}\n\n//---\nvoid ofApp::mouseReleased(int x, int y, int button){\n\n}\n\n//---\nvoid ofApp::mouseEntered(int x, int y){\n\n}\n\n//---\nvoid ofApp::mouseExited(int x, int y){\n\n}\n\n//---\nvoid ofApp::windowResized(int w, int h){\n    screenSize = ofToString(w) + \"x\" + ofToString(h);\n}\n\n//---\nvoid ofApp::gotMessage(ofMessage msg){\n\n}\n\n//---\nvoid ofApp::dragEvent(ofDragInfo dragInfo){\n\n}\n",
    "file_path": "data\\preprocessed\\arturoc_openFrameworks__examples_gui_guiExample_src_ofApp.cpp",
    "file_name": "arturoc_openFrameworks__examples_gui_guiExample_src_ofApp.cpp",
    "language": "cpp"
  },
  {
    "text": "/*\n * Copyright 2013 Google Inc.\n *\n * Use of this source code is governed by a BSD-style license that can be\n * found in the LICENSE file.\n */\n\n#include \"gm/gm.h\"\n#include \"include/core/SkCanvas.h\"\n#include \"include/core/SkColor.h\"\n#include \"include/core/SkColorFilter.h\"\n#include \"include/core/SkFont.h\"\n#include \"include/core/SkFontMetrics.h\"\n#include \"include/core/SkFontTypes.h\"\n#include \"include/core/SkImageFilter.h\"\n#include \"include/core/SkPaint.h\"\n#include \"include/core/SkPoint.h\"\n#include \"include/core/SkRect.h\"\n#include \"include/core/SkRefCnt.h\"\n#include \"include/core/SkScalar.h\"\n#include \"include/core/SkShader.h\"\n#include \"include/core/SkSize.h\"\n#include \"include/core/SkString.h\"\n#include \"include/core/SkTileMode.h\"\n#include \"include/core/SkTypeface.h\"\n#include \"include/core/SkTypes.h\"\n#include \"include/effects/SkColorMatrixFilter.h\"\n#include \"include/effects/SkGradientShader.h\"\n#include \"include/effects/SkImageFilters.h\"\n#include \"tools/ToolUtils.h\"\n\n#include <string.h>\n#include <initializer_list>\n#include <utility>\n\n/*\n * Spits out an arbitrary gradient to test blur with shader on paint\n */\nstatic sk_sp<SkShader> MakeLinear() {\n    constexpr SkPoint     kPts[] = { { 0, 0 }, { 32, 32 } };\n    constexpr SkScalar    kPos[] = { 0, SK_Scalar1/2, SK_Scalar1 };\n    constexpr SkColor kColors[] = {0x80F00080, 0xF0F08000, 0x800080F0 };\n    return SkGradientShader::MakeLinear(kPts, kColors, kPos, SK_ARRAY_COUNT(kColors),\n                                        SkTileMode::kClamp);\n}\n\nstatic sk_sp<SkImageFilter> make_grayscale(sk_sp<SkImageFilter> input) {\n    float matrix[20];\n    memset(matrix, 0, 20 * sizeof(float));\n    matrix[0] = matrix[5] = matrix[10] = 0.2126f;\n    matrix[1] = matrix[6] = matrix[11] = 0.7152f;\n    matrix[2] = matrix[7] = matrix[12] = 0.0722f;\n    matrix[18] = 1.0f;\n    sk_sp<SkColorFilter> filter(SkColorFilters::Matrix(matrix));\n    return SkImageFilters::ColorFilter(std::move(filter), std::move(input));\n}\n\nstatic sk_sp<SkImageFilter> make_blur(float amount, sk_sp<SkImageFilter> input) {\n    return SkImageFilters::Blur(amount, amount, std::move(input));\n}\n\nstatic sk_sp<SkColorFilter> make_color_filter() {\n    return SkColorMatrixFilter::MakeLightingFilter(SkColorSetRGB(0x00, 0x80, 0xFF),\n   SkColorSetRGB(0xFF, 0x20, 0x00));\n}\n\nnamespace skiagm {\n\nclass ColorEmojiGM : public GM {\npublic:\n    ColorEmojiGM() { }\n\nprotected:\n    struct EmojiFont {\n        sk_sp<SkTypeface> typeface;\n        const char* text;\n    } emojiFont;\n    void onOnceBeforeDraw() override {\n        emojiFont.typeface = ToolUtils::emoji_typeface();\n        emojiFont.text     = ToolUtils::emoji_sample_text();\n    }\n\n    SkString onShortName() override {\n        return SkString(\"coloremoji\");\n    }\n\n    SkISize onISize() override { return SkISize::Make(650, 1200); }\n\n    void onDraw(SkCanvas* canvas) override {\n\n        canvas->drawColor(SK_ColorGRAY);\n\n        SkFont font(emojiFont.typeface);\n        char const * const text = emojiFont.text;\n        size_t textLen = strlen(text);\n\n        // draw text at different point sizes\n        constexpr SkScalar textSizes[] = { 10, 30, 50, };\n        SkFontMetrics metrics;\n        SkScalar y = 0;\n        for (const bool& fakeBold : { false, true }) {\n            font.setEmbolden(fakeBold);\n            for (const SkScalar& textSize : textSizes) {\n                font.setSize(textSize);\n                font.getMetrics(&metrics);\n                y += -metrics.fAscent;\n                canvas->drawSimpleText(text, textLen, SkTextEncoding::kUTF8,\n                                       10, y, font, SkPaint());\n                y += metrics.fDescent + metrics.fLeading;\n            }\n        }\n\n        y += 20;\n        SkScalar savedY = y;\n        // draw with shaders and image filters\n        for (int makeLinear = 0; makeLinear < 2; makeLinear++) {\n            for (int makeBlur = 0; makeBlur < 2; makeBlur++) {\n                for (int makeGray = 0; makeGray < 2; makeGray++) {\n                    for (int makeMode = 0; makeMode < 2; ++makeMode) {\n                        for (int alpha = 0; alpha < 2; ++alpha) {\n                            SkFont shaderFont(font.refTypefaceOrDefault());\n                            SkPaint shaderPaint;\n                            if (SkToBool(makeLinear)) {\n                                shaderPaint.setShader(MakeLinear());\n                            }\n\n                            if (SkToBool(makeBlur) && SkToBool(makeGray)) {\n                                sk_sp<SkImageFilter> grayScale(make_grayscale(nullptr));\n                                sk_sp<SkImageFilter> blur(make_blur(3.0f, std::move(grayScale)));\n                                shaderPaint.setImageFilter(std::move(blur));\n                            } else if (SkToBool(makeBlur)) {\n                                shaderPaint.setImageFilter(make_blur(3.0f, nullptr));\n                            } else if (SkToBool(makeGray)) {\n                                shaderPaint.setImageFilter(make_grayscale(nullptr));\n                            }\n                            if (makeMode) {\n                                shaderPaint.setColorFilter(make_color_filter());\n                            }\n                            if (alpha) {\n                                shaderPaint.setAlphaf(0.5f);\n                            }\n                            shaderFont.setSize(30);\n                            shaderFont.getMetrics(&metrics);\n                            y += -metrics.fAscent;\n                            canvas->drawSimpleText(text, textLen, SkTextEncoding::kUTF8, 380, y,\n   shaderFont, shaderPaint);\n                            y += metrics.fDescent + metrics.fLeading;\n                        }\n                    }\n                }\n            }\n        }\n        // setup work needed to draw text with different clips\n        canvas->translate(10, savedY);\n        font.setSize(40);\n\n        // compute the bounds of the text\n        SkRect bounds;\n        font.measureText(text, textLen, SkTextEncoding::kUTF8, &bounds);\n\n        const SkScalar boundsHalfWidth = bounds.width() * SK_ScalarHalf;\n        const SkScalar boundsHalfHeight = bounds.height() * SK_ScalarHalf;\n        const SkScalar boundsQuarterWidth = boundsHalfWidth * SK_ScalarHalf;\n        const SkScalar boundsQuarterHeight = boundsHalfHeight * SK_ScalarHalf;\n\n        SkRect upperLeftClip = SkRect::MakeXYWH(bounds.left(), bounds.top(),\n                                                boundsHalfWidth, boundsHalfHeight);\n        SkRect lowerRightClip = SkRect::MakeXYWH(bounds.centerX(), bounds.centerY(),\n                                                 boundsHalfWidth, boundsHalfHeight);\n        SkRect interiorClip = bounds;\n        interiorClip.inset(boundsQuarterWidth, boundsQuarterHeight);\n\n        const SkRect clipRects[] = { bounds, upperLeftClip, lowerRightClip, interiorClip };\n\n        SkPaint clipHairline;\n        clipHairline.setColor(SK_ColorWHITE);\n        clipHairline.setStyle(SkPaint::kStroke_Style);\n\n        SkPaint paint;\n        for (const SkRect& clipRect : clipRects) {\n            canvas->translate(0, bounds.height());\n            canvas->save();\n            canvas->drawRect(clipRect, clipHairline);\n            paint.setAlpha(0x20);\n            canvas->drawSimpleText(text, textLen, SkTextEncoding::kUTF8, 0, 0, font, paint);\n            canvas->clipRect(clipRect);\n            paint.setAlphaf(1.0f);\n            canvas->drawSimpleText(text, textLen, SkTextEncoding::kUTF8, 0, 0, font, paint);\n            canvas->restore();\n            canvas->translate(0, SkIntToScalar(25));\n        }\n    }\n\n    using INHERITED = GM;\n};\n\n///\n\nDEF_GM(return new ColorEmojiGM;)\n\n}  // namespace skiagm\n",
    "file_path": "data\\preprocessed\\aseprite_skia__gm_coloremoji.cpp",
    "file_name": "aseprite_skia__gm_coloremoji.cpp",
    "language": "cpp"
  },
  {
    "text": "/*\n * Copyright 2012 Google Inc.\n *\n * Use of this source code is governed by a BSD-style license that can be\n * found in the LICENSE file.\n */\n#include \"src/core/SkGeometry.h\"\n#include \"src/pathops/SkIntersections.h\"\n#include \"src/pathops/SkPathOpsRect.h\"\n#include \"src/pathops/SkReduceOrder.h\"\n#include \"tests/PathOpsCubicIntersectionTestData.h\"\n#include \"tests/PathOpsTestCommon.h\"\n#include \"tests/Test.h\"\n\n#include <stdlib.h>\n\nusing namespace PathOpsCubicIntersectionTestData;\n\nstatic constexpr int kFirstCubicIntersectionTest = 9;\n\nstatic void standardTestCases(skiatest::Reporter* reporter) {\n    for (size_t index = kFirstCubicIntersectionTest; index < tests_count; ++index) {\n        int iIndex = static_cast<int>(index);\n        const CubicPts& cubic1 = tests[index][0];\n        const CubicPts& cubic2 = tests[index][1];\n        SkDCubic c1, c2;\n        c1.debugSet(cubic1.fPts);\n        c2.debugSet(cubic2.fPts);\n        SkReduceOrder reduce1, reduce2;\n        int order1 = reduce1.reduce(c1, SkReduceOrder::kNo_Quadratics);\n        int order2 = reduce2.reduce(c2, SkReduceOrder::kNo_Quadratics);\n        const bool showSkipped = false;\n        if (order1 < 4) {\n            if (showSkipped) {\n                SkDebugf(\"%s [%d] cubic1 order=%d\\n\", __FUNCTION__, iIndex, order1);\n            }\n            continue;\n        }\n        if (order2 < 4) {\n            if (showSkipped) {\n                SkDebugf(\"%s [%d] cubic2 order=%d\\n\", __FUNCTION__, iIndex, order2);\n            }\n            continue;\n        }\n        SkIntersections tIntersections;\n        tIntersections.intersect(c1, c2);\n        if (!tIntersections.used()) {\n            if (showSkipped) {\n                SkDebugf(\"%s [%d] no intersection\\n\", __FUNCTION__, iIndex);\n            }\n            continue;\n        }\n        if (tIntersections.isCoincident(0)) {\n            if (showSkipped) {\n                SkDebugf(\"%s [%d] coincident\\n\", __FUNCTION__, iIndex);\n            }\n            continue;\n        }\n        for (int pt = 0; pt < tIntersections.used(); ++pt) {\n            double tt1 = tIntersections[0][pt];\n            SkDPoint xy1 = c1.ptAtT(tt1);\n            double tt2 = tIntersections[1][pt];\n            SkDPoint xy2 = c2.ptAtT(tt2);\n            if (!xy1.approximatelyEqual(xy2)) {\n                SkDebugf(\"%s [%d,%d] x!= t1=%g (%g,%g) t2=%g (%g,%g)\\n\",\n                    __FUNCTION__, (int)index, pt, tt1, xy1.fX, xy1.fY, tt2, xy2.fX, xy2.fY);\n            }\n            REPORTER_ASSERT(reporter, xy1.approximatelyEqual(xy2));\n        }\n        reporter->bumpTestCount();\n    }\n}\n\nstatic const CubicPts testSet[] = {\n// FIXME: uncommenting these two will cause this to fail\n// this results in two curves very nearly but not exactly coincident\n#if 0\n{{{67.426548091427676, 37.993772624988935}, {23.483695892376684, 90.476863174921306},\n      {35.597065061143162, 79.872482633158796}, {75.38634169631932, 18.244890038969412}}},\n{{{67.4265481, 37.9937726}, {23.4836959, 90.4768632}, {35.5970651, 79.8724826},\n      {75.3863417, 18.24489}}},\n#endif\n\n{{{0, 0}, {0, 1}, {1, 1}, {1, 0}}},\n{{{1, 0}, {0, 0}, {0, 1}, {1, 1}}},\n\n{{{0, 1}, {4, 5}, {1, 0}, {5, 3}}},\n{{{0, 1}, {3, 5}, {1, 0}, {5, 4}}},\n\n{{{0, 1}, {1, 6}, {1, 0}, {1, 0}}},\n{{{0, 1}, {0, 1}, {1, 0}, {6, 1}}},\n\n{{{0, 1}, {3, 4}, {1, 0}, {5, 1}}},\n{{{0, 1}, {1, 5}, {1, 0}, {4, 3}}},\n\n{{{0, 1}, {1, 2}, {1, 0}, {6, 1}}},\n{{{0, 1}, {1, 6}, {1, 0}, {2, 1}}},\n\n{{{0, 1}, {0, 5}, {1, 0}, {4, 0}}},\n{{{0, 1}, {0, 4}, {1, 0}, {5, 0}}},\n\n{{{0, 1}, {3, 4}, {1, 0}, {3, 0}}},\n{{{0, 1}, {0, 3}, {1, 0}, {4, 3}}},\n\n{{{0, 0}, {1, 2}, {3, 4}, {4, 4}}},\n{{{0, 0}, {1, 2}, {3, 4}, {4, 4}}},\n{{{4, 4}, {3, 4}, {1, 2}, {0, 0}}},\n\n{{{0, 1}, {2, 3}, {1, 0}, {1, 0}}},\n{{{0, 1}, {0, 1}, {1, 0}, {3, 2}}},\n\n{{{0, 2}, {0, 1}, {1, 0}, {1, 0}}},\n{{{0, 1}, {0, 1}, {2, 0}, {1, 0}}},\n\n{{{0, 1}, {0, 2}, {1, 0}, {1, 0}}},\n{{{0, 1}, {0, 1}, {1, 0}, {2, 0}}},\n\n{{{0, 1}, {1, 6}, {1, 0}, {2, 0}}},\n{{{0, 1}, {0, 2}, {1, 0}, {6, 1}}},\n\n{{{0, 1}, {5, 6}, {1, 0}, {1, 0}}},\n{{{0, 1}, {0, 1}, {1, 0}, {6, 5}}},\n\n{{{95.837747722788592, 45.025976907939643}, {16.564570095652982, 0.72959763963222402},\n        {63.209855865319199, 68.047528419665767}, {57.640240647662544, 59.524565264361243}}},\n{{{51.593891741518817, 38.53849970667553}, {62.34752929878772, 74.924924725166022},\n        {74.810149322641152, 34.17966562983564}, {29.368398119401373, 94.66719277886078}}},\n\n{{{39.765160968417838, 33.060396198677083}, {5.1922921581157908, 66.854301452103215},\n        {31.619281802149157, 25.269248720849514}, {81.541621071073038, 70.025341524754353}}},\n{{{46.078911165743556, 48.259962651999651}, {20.24450549867214, 49.403916182650214},\n        {0.26325131778756683, 24.46489805563581}, {15.915006546264051, 83.515023059917155}}},\n\n{{{65.454505973241524, 93.881892270353575}, {45.867360264932437, 92.723972719499827},\n        {2.1464054482739447, 74.636369140183717}, {33.774068594804994, 40.770872887582925}}},\n{{{72.963387832494163, 95.659300729473728}, {11.809496633619768, 82.209921247423594},\n        {13.456139067865974, 57.329313623406605}, {36.060621606214262, 70.867335643091849}}},\n\n{{{32.484981432782945, 75.082940782924624}, {42.467313093350882, 48.131159948246157},\n        {3.5963115764764657, 43.208665839959245}, {79.442476890721579, 89.709102357602262}}},\n{{{18.98573861410177, 93.308887208490106}, {40.405250173250792, 91.039661826118675},\n        {8.0467721950480584, 42.100282172719147}, {40.883324221187891, 26.030185504830527}}},\n\n{{{7.5374809128872498, 82.441702896003477}, {22.444346930107265, 22.138854312775123},\n        {66.76091829629658, 50.753805856571446}, {78.193478508942519, 97.7932997968948}}},\n{{{97.700573130371311, 53.53260215070685}, {87.72443481149358, 84.575876772671876},\n        {19.215031396232092, 47.032676472809484}, {11.989686410869325, 10.659507480757082}}},\n\n{{{26.192053931854691, 9.8504326817814416}, {10.174241480498686, 98.476562741434464},\n        {21.177712558385782, 33.814968789841501}, {75.329030899018534, 55.02231980442177}}},\n{{{56.222082700683771, 24.54395039218662}, {95.589995289030483, 81.050822735322086},\n        {28.180450866082897, 28.837706255185282}, {60.128952916771617, 87.311672180570511}}},\n\n{{{42.449716172390481, 52.379709366885805}, {27.896043159019225, 48.797373636065686},\n        {92.770268299044233, 89.899302036454571}, {12.102066544863426, 99.43241951960718}}},\n{{{45.77532924980639, 45.958701495993274}, {37.458701356062065, 68.393691335056758},\n        {37.569326692060258, 27.673713456687381}, {60.674866037757539, 62.47349659096146}}},\n\n{{{67.426548091427676, 37.993772624988935}, {23.483695892376684, 90.476863174921306},\n        {35.597065061143162, 79.872482633158796}, {75.38634169631932, 18.244890038969412}}},\n{{{61.336508189019057, 82.693132843213675}, {44.639380902349664, 54.074825790745592},\n        {16.815615499771951, 20.049704667203923}, {41.866884958868326, 56.735503699973002}}},\n\n{{{18.1312339, 31.6473732}, {95.5711034, 63.5350219}, {92.3283165, 62.0158945},\n        {18.5656052, 32.1268808}}},\n{{{97.402018, 35.7169972}, {33.1127443, 25.8935163}, {1.13970027, 54.9424981},\n        {56.4860195, 60.529264}}},\n};\n\nconst int testSetCount = (int) SK_ARRAY_COUNT(testSet);\n\nstatic const CubicPts newTestSet[] = {\n\n{ { { 130.0427549999999997, 11417.41309999999976 },{ 130.2331240000000037, 11418.3192999999992 },{ 131.0370790000000056, 11419 },{ 132, 11419 } } },\n{ { { 132, 11419 },{ 130.8954319999999996, 11419 },{ 130, 11418.10449999999946 },{ 130, 11417 } } },\n\n{{{1,3}, {-1.0564518,1.79032254}, {1.45265341,0.229448318}, {1.45381773,0.22913377}}},\n{{{1.45381773,0.22913377}, {1.45425761,0.229014933}, {1.0967741,0.451612949}, {0,1}}},\n\n{{{1.64551306f, 3.57876182f}, {0.298127174f, 3.70454836f}, {-0.809808373f, 6.39524937f}, {-3.66666651f, 13.333334f}}},\n{{{1, 2}, {1, 2}, {-3.66666651f, 13.333334f}, {5, 6}}},\n\n{{{0.555-000-0000,1.65340209}, {-0.251940489,1.43560803}, {-0.782382965,-0.196299091}, {3.33333325,-0.666666627}}},\n{{{1,3}, {-1.22353387,1.09411383}, {0.319867611,0.12996155}, {0.886705518,0.107543148}}},\n\n{{{-0.13654758,2.10514426}, {-0.585797966,1.89349782}, {-0.807703257,-0.192306399}, {6,-1}}},\n{{{1,4}, {-2.25000453,1.42241001}, {1.1314013,0.555-000-0000}, {1.87140274,0.555-000-0000}}},\n\n{{{1.3127951622009277, 2.0637707710266113}, {1.8210518360137939, 1.9148571491241455}, {1.6106204986572266, -0.68700540065765381}, {8.5, -2.5}}},\n{{{3, 4}, {0.33333325386047363, 1.3333332538604736}, {3.6666667461395264, -0.66666674613952637}, {3.6666665077209473, -0.66666656732559204}}},\n\n{{{980.026001,1481.276}, {980.026001,1481.276}, {980.02594,1481.27576}, {980.025879,1481.27527}}},\n{{{980.025879,1481.27527}, {980.025452,1481.27222}, {980.023743,1481.26038}, {980.02179,1481.24072}}},\n\n{{{1.80943513,3.07782435}, {1.66686702,2.16806936}, {1.68301272,0}, {3,0}}},\n{{{0,1}, {0,3}, {3,2}, {5,2}}},\n\n{{{3.4386673,2.66977954}, {4.06668949,2.17046738}, {4.78887367,1.59629118}, {6,2}}},\n{{{1.71985495,3.49467373}, {2.11620402,2.7201426}, {2.91897964,1.15138781}, {6,3}}},\n\n{{{0,1}, {0.392703831,1.78540766}, {0.219947904,2.05676103}, {0.218561709,2.05630541}}},\n{{{0.218561709,2.05630541}, {0.216418028,2.05560064}, {0.624105453,1.40486407}, {4.16666651,1.00000012}}},\n\n{{{0, 1}, {3, 5}, {2, 1}, {3, 1}}},\n{{{1.01366711f, 2.21379328f}, {1.09074128f, 2.23241305f}, {1.60246587f, 0.451849401f}, {5, 3}}},\n\n{{{0, 1}, {0.541499972f, 3.16599989f}, {1.08299994f, 2.69299984f}, {2.10083938f, 1.80391729f}}},\n{{{0.806384504f, 2.85426903f}, {1.52740121f, 1.99355423f}, {2.81689167f, 0.454222918f}, {5, 1}}},\n\n{{{0, 1}, {1.90192389f, 2.90192389f}, {2.59807634f, 2.79422879f}, {3.1076951f, 2.71539044f}}},\n{{{2, 3}, {2.36602545f, 3.36602545f}, {2.330127f, 3.06217766f}, {2.28460979f, 2.67691422f}}},\n\n{{{0, 1}, {1.90192389f, 2.90192389f}, {2.59807634f, 2.79422879f}, {3.1076951f, 2.71539044f}}},\n{{{2.28460979f, 2.67691422f}, {2.20577145f, 2.00961876f}, {2.09807634f, 1.09807622f}, {4, 3}}},\n\n{{{0, 1}, {0.8211091160774231, 2.0948121547698975}, {0.91805583238601685, 2.515404224395752}, {0.91621249914169312, 2.5146586894989014}}},\n{{{0.91621249914169312, 2.5146586894989014}, {0.91132104396820068, 2.5126807689666748}, {0.21079301834106445, -0.45617169141769409}, {10.5, -1.6666665077209473}}},\n\n{{{42.6237564,68.9841232}, {32.449646,81.963089}, {14.7713947,103.565269}, {12.6310005,105.247002}}},\n{{{37.2640038,95.3540039}, {37.2640038,95.3540039}, {11.3710003,83.7339935}, {-25.0779991,124.912003}}},\n\n{{{0,1}, {4,5}, {6,0}, {1,0}}},\n{{{0,6}, {0,1}, {1,0}, {5,4}}},\n\n{{{0,1}, {4,6}, {5,1}, {6,2}}},\n{{{1,5}, {2,6}, {1,0}, {6,4}}},\n\n{{{322, 896.04803466796875}, {314.09201049804687, 833.4376220703125}, {260.24713134765625, 785}, {195, 785}}},\n{{{195, 785}, {265.14016723632812, 785}, {322, 842.30755615234375}, {322, 913}}},\n\n{{{1, 4}, {4, 5}, {3, 2}, {6, 3}}},\n{{{2, 3}, {3, 6}, {4, 1}, {5, 4}}},\n\n{{{67, 913}, {67, 917.388916015625}, {67.224380493164063, 921.72576904296875}, {67.662384033203125, 926}}},\n{{{194, 1041}, {123.85984039306641, 1041}, {67, 983.69244384765625}, {67, 913}}},\n\n{{{1,4}, {1,5}, {6,0}, {5,1}}},\n{{{0,6}, {1,5}, {4,1}, {5,1}}},\n\n{{{0,1}, {4,5}, {6,0}, {1,0}}},\n{{{0,6}, {0,1}, {1,0}, {5,4}}},\n\n{{{0,1}, {4,6}, {2,0}, {2,0}}},\n{{{0,2}, {0,2}, {1,0}, {6,4}}},\n\n{{{980.9000244140625, 1474.3280029296875}, {980.9000244140625, 1474.3280029296875}, {978.89300537109375, 1471.95703125}, {981.791015625, 1469.487060546875}}},\n{{{981.791015625, 1469.487060546875}, {981.791015625, 1469.4859619140625}, {983.3580322265625, 1472.72900390625}, {980.9000244140625, 1474.3280029296875}}},\n\n{{{275,532}, {277.209137,532}, {279,530.209106}, {279,528}}},\n{{{278,529}, {278,530.65686}, {276.65686,532}, {275,532}}},\n\n#if 0  // FIXME: asserts coincidence, not working yet\n{{{195, 785}, {124.30755615234375, 785}, {67, 841.85986328125}, {67, 912}}},\n{{{67, 913}, {67, 842.30755615234375}, {123.85984039306641, 785}, {194, 785}}},\n#endif\n\n{{{149,710.001465}, {149.000809,712.209961}, {150.791367,714}, {153,714}}},\n{{{154,715}, {151.238571,715}, {149,712.761414}, {149,710}}},\n\n{{{1,2}, {1,2}, {2,0}, {6,0}}},\n{{{0,2}, {0,6}, {2,1}, {2,1}}},\n\n{{{0,1}, {2,3}, {5,1}, {4,3}}},\n{{{1,5}, {3,4}, {1,0}, {3,2}}},\n\n{{{399,657}, {399,661.970581}, {403.029449,666}, {408,666}}},\n{{{406,666}, {402.686279,666}, {400,663.313721}, {400,660}}},\n\n{{{0,5}, {3,5}, {3,0}, {3,2}}},\n{{{0,3}, {2,3}, {5,0}, {5,3}}},\n\n{{{132, 11419}, {130.89543151855469, 11419}, {130, 11418.555-000-0000}, {130, 11417}}},\n\n{{{3, 4}, {1, 5}, {4, 3}, {6, 4}}},\n{{{3, 4}, {4, 6}, {4, 3}, {5, 1}}},\n\n{{{130.04275512695312, 11417.413085937500 },\n    {130.23312377929687, 11418.319335937500 },\n    {131.03707885742187, 11419.000000000000 },\n    {132.00000000000000, 11419.000000000000 }}},\n\n{{{132.00000000000000, 11419.000000000000 },\n    {130.89543151855469, 11419.000000000000 },\n    {130.00000000000000, 11418.104492187500 },\n    {130.00000000000000, 11417.000000000000 }}},\n\n{{{1.0516976506771041, 2.9684399028541346 },\n    {1.0604363140895228, 2.9633503074444141 },\n    {1.0692548215065762, 2.9580354426587459 },\n    {1.0781560339512140, 2.9525043684031349 }}},\n\n{{{1.0523038101345104, 2.9523755204833737 },\n    {1.0607035288264237, 2.9580853881628375 },\n    {1.0690530472271964, 2.9633896794787749 },\n    {1.0773566568712512, 2.9682969775000219 }}},\n\n{{{1.0386522625066592, 2.9759024812329078 },\n    {1.0559713690392631, 2.9661782500838885 },\n    {1.0736041309019990, 2.9555348259177858 },\n    {1.0915734362784633, 2.9440446879826569 }}},\n\n{{{1.0396670794879301, 2.9435062123457261 },\n    {1.0565690546812769, 2.9557413250983462 },\n    {1.0732616463413533, 2.9663369676594282 },\n    {1.0897791867435489, 2.9753618045797472 }}},\n\n{{{0.8685656183311091, 3.0409266475785208 },\n    {0.99189542936395292, 3.0212163698184424 },\n    {1.1302108367493320, 2.9265646471747306 },\n    {1.2952305904872474, 2.7940808546473788 }}},\n\n{{{0.85437872843682727, 2.7536036928549055 },\n    {1.0045584590592620, 2.9493041024831705 },\n    {1.1336998329885613, 3.0248027987251747 },\n    {1.2593809752247314, 3.0152560315809107 }}},\n\n{{{0, 1}, {1, 6}, {1, 0}, {6, 2}}},\n{{{0, 1}, {2, 6}, {1, 0}, {6, 1}}},\n\n{{{134,11414}, {131.990234375,11414}, {130.32666015625,11415.482421875}, {130.04275512695312,11417.555-000-0000}}},\n{{{132,11419}, {130.89543151855469,11419}, {130,11418.555-000-0000}, {130,11417}}},\n\n{{{132,11419}, {130.89543151855469,11419}, {130,11418.555-000-0000}, {130,11417}}},\n{{{130.04275512695312,11417.555-000-0000}, {130.23312377929687,11418.555-000-0000}, {131.03707885742187,11419}, {132,11419}}},\n\n{{{0, 1}, {2, 3}, {5, 1}, {4, 3}}},\n{{{1, 5}, {3, 4}, {1, 0}, {3, 2}}},\n\n{{{3, 5}, {1, 6}, {5, 0}, {3, 1}}},\n{{{0, 5}, {1, 3}, {5, 3}, {6, 1}}},\n\n{{{0, 1}, {1, 5}, {1, 0}, {1, 0}}},\n{{{0, 1}, {0, 1}, {1, 0}, {5, 1}}},\n\n{{{1, 3}, {5, 6}, {5, 3}, {5, 4}}},\n{{{3, 5}, {4, 5}, {3, 1}, {6, 5}}},\n\n{{{0, 5}, {0, 5}, {5, 4}, {6, 4}}},\n{{{4, 5}, {4, 6}, {5, 0}, {5, 0}}},\n\n{{{0, 4}, {1, 3}, {5, 4}, {4, 2}}},\n{{{4, 5}, {2, 4}, {4, 0}, {3, 1}}},\n\n{{{0, 2}, {1, 5}, {3, 2}, {4, 1}}},\n{{{2, 3}, {1, 4}, {2, 0}, {5, 1}}},\n\n{{{0, 2}, {2, 3}, {5, 1}, {3, 2}}},\n{{{1, 5}, {2, 3}, {2, 0}, {3, 2}}},\n\n{{{2, 6}, {4, 5}, {1, 0}, {6, 1}}},\n{{{0, 1}, {1, 6}, {6, 2}, {5, 4}}},\n\n{{{0, 1}, {1, 2}, {6, 5}, {5, 4}}},\n{{{5, 6}, {4, 5}, {1, 0}, {2, 1}}},\n\n{{{2.5119999999999996, 1.5710000000000002}, {2.6399999999999983, 1.6599999999999997},\n        {2.8000000000000007, 1.8000000000000003}, {3, 2}}},\n{{{2.4181876227114887, 1.9849772580462195}, {2.8269904869227211, 2.009330650246834},\n        {3.2004679292461624, 1.9942047174679169}, {3.4986199496818058, 2.0035994597094731}}},\n\n{{{2, 3}, {1, 4}, {1, 0}, {6, 0}}},\n{{{0, 1}, {0, 6}, {3, 2}, {4, 1}}},\n\n{{{0, 2}, {1, 5}, {1, 0}, {6, 1}}},\n{{{0, 1}, {1, 6}, {2, 0}, {5, 1}}},\n\n{{{0, 1}, {1, 5}, {2, 1}, {4, 0}}},\n{{{1, 2}, {0, 4}, {1, 0}, {5, 1}}},\n\n{{{0, 1}, {3, 5}, {2, 1}, {3, 1}}},\n{{{1, 2}, {1, 3}, {1, 0}, {5, 3}}},\n\n{{{0, 1}, {2, 5}, {6, 0}, {5, 3}}},\n{{{0, 6}, {3, 5}, {1, 0}, {5, 2}}},\n\n{{{0, 1}, {3, 6}, {1, 0}, {5, 2}}},\n{{{0, 1}, {2, 5}, {1, 0}, {6, 3}}},\n\n{{{1, 2}, {5, 6}, {1, 0}, {1, 0}}},\n{{{0, 1}, {0, 1}, {2, 1}, {6, 5}}},\n\n{{{0, 6}, {1, 2}, {1, 0}, {1, 0}}},\n{{{0, 1}, {0, 1}, {6, 0}, {2, 1}}},\n\n{{{0, 2}, {0, 1}, {3, 0}, {1, 0}}},\n{{{0, 3}, {0, 1}, {2, 0}, {1, 0}}},\n};\n\nconst int newTestSetCount = (int) SK_ARRAY_COUNT(newTestSet);\nstatic void oneOff(skiatest::Reporter* reporter, const CubicPts& cubic1, const CubicPts& cubic2,\n        bool coin) {\n    SkDCubic c1, c2;\n    c1.debugSet(cubic1.fPts);\n    c2.debugSet(cubic2.fPts);\n    SkASSERT(ValidCubic(c1));\n    SkASSERT(ValidCubic(c2));\n#if ONE_OFF_DEBUG\n    SkDebugf(\"computed quadratics given\\n\");\n    SkDebugf(\"  {{%1.9g,%1.9g}, {%1.9g,%1.9g}, {%1.9g,%1.9g}, {%1.9g,%1.9g}},\\n\",\n        cubic1[0].fX, cubic1[0].fY, cubic1[1].fX, cubic1[1].fY,\n        cubic1[2].fX, cubic1[2].fY, cubic1[3].fX, cubic1[3].fY);\n    SkDebugf(\"  {{%1.9g,%1.9g}, {%1.9g,%1.9g}, {%1.9g,%1.9g}, {%1.9g,%1.9g}},\\n\",\n        cubic2[0].fX, cubic2[0].fY, cubic2[1].fX, cubic2[1].fY,\n        cubic2[2].fX, cubic2[2].fY, cubic2[3].fX, cubic2[3].fY);\n#endif\n    SkIntersections intersections;\n    intersections.intersect(c1, c2);\n#if DEBUG_T_SECT_DUMP == 3\n    SkDebugf(\"</div>\\n\\n\");\n    SkDebugf(\"<script type=\\\"text/javascript\\\">\\n\\n\");\n    SkDebugf(\"var testDivs = [\\n\");\n    for (int index = 1; index <= gDumpTSectNum; ++index) {\n        SkDebugf(\"sect%d,\\n\", index);\n    }\n#endif\n    REPORTER_ASSERT(reporter, !coin || intersections.used() >= 2);\n    double tt1, tt2;\n    SkDPoint xy1, xy2;\n    for (int pt3 = 0; pt3 < intersections.used(); ++pt3) {\n        tt1 = intersections[0][pt3];\n        xy1 = c1.ptAtT(tt1);\n        tt2 = intersections[1][pt3];\n        xy2 = c2.ptAtT(tt2);\n        const SkDPoint& iPt = intersections.pt(pt3);\n#if ONE_OFF_DEBUG\n        SkDebugf(\"%s t1=%1.9g (%1.9g, %1.9g) (%1.9g, %1.9g) (%1.9g, %1.9g) t2=%1.9g\\n\",\n                __FUNCTION__, tt1, xy1.fX, xy1.fY, iPt.fX,\n                iPt.fY, xy2.fX, xy2.fY, tt2);\n#endif\n       REPORTER_ASSERT(reporter, xy1.approximatelyEqual(iPt));\n       REPORTER_ASSERT(reporter, xy2.approximatelyEqual(iPt));\n       REPORTER_ASSERT(reporter, xy1.approximatelyEqual(xy2));\n    }\n    reporter->bumpTestCount();\n}\n\nstatic void oneOff(skiatest::Reporter* reporter, int outer, int inner) {\n    const CubicPts& cubic1 = testSet[outer];\n    const CubicPts& cubic2 = testSet[inner];\n    oneOff(reporter, cubic1, cubic2, false);\n}\n\nstatic void newOneOff(skiatest::Reporter* reporter, int outer, int inner) {\n    const CubicPts& cubic1 = newTestSet[outer];\n    const CubicPts& cubic2 = newTestSet[inner];\n    oneOff(reporter, cubic1, cubic2, false);\n}\n\nstatic void testsOneOff(skiatest::Reporter* reporter, int index) {\n    const CubicPts& cubic1 = tests[index][0];\n    const CubicPts& cubic2 = tests[index][1];\n    oneOff(reporter, cubic1, cubic2, false);\n}\n\nstatic void oneOffTests(skiatest::Reporter* reporter) {\n    for (int outer = 0; outer < testSetCount - 1; ++outer) {\n        for (int inner = outer + 1; inner < testSetCount; ++inner) {\n            oneOff(reporter, outer, inner);\n        }\n    }\n    for (int outer = 0; outer < newTestSetCount - 1; ++outer) {\n        for (int inner = outer + 1; inner < newTestSetCount; ++inner) {\n            newOneOff(reporter, outer, inner);\n        }\n    }\n}\n\n#define DEBUG_CRASH 0\n\nstatic void CubicIntersection_RandTest(skiatest::Reporter* reporter) {\n    srand(0);\n    const int kNumTests = 10000000;\n#if !defined(SK_BUILD_FOR_WIN) && !defined(SK_BUILD_FOR_ANDROID)\n    unsigned seed = 0;\n#endif\n    for (int test = 0; test < kNumTests; ++test) {\n        CubicPts cubic1, cubic2;\n        for (int i = 0; i < 4; ++i) {\n            cubic1.fPts[i].fX = static_cast<double>(SK_RAND(seed)) / RAND_MAX * 100;\n            cubic1.fPts[i].fY = static_cast<double>(SK_RAND(seed)) / RAND_MAX * 100;\n            cubic2.fPts[i].fX = static_cast<double>(SK_RAND(seed)) / RAND_MAX * 100;\n            cubic2.fPts[i].fY = static_cast<double>(SK_RAND(seed)) / RAND_MAX * 100;\n        }\n    #if DEBUG_CRASH\n        char str[1024];\n        snprintf(str, sizeof(str),\n            \"{{{%1.9g, %1.9g}, {%1.9g, %1.9g}, {%1.9g, %1.9g}, {%1.9g, %1.9g}}},\\n\"\n            \"{{{%1.9g, %1.9g}, {%1.9g, %1.9g}, {%1.9g, %1.9g}, {%1.9g, %1.9g}}},\\n\",\n                cubic1[0].fX, cubic1[0].fY,  cubic1[1].fX, cubic1[1].fY, cubic1[2].fX, cubic1[2].fY,\n                cubic1[3].fX, cubic1[3].fY,\n                cubic2[0].fX, cubic2[0].fY,  cubic2[1].fX, cubic2[1].fY, cubic2[2].fX, cubic2[2].fY,\n                cubic2[3].fX, cubic2[3].fY);\n    #endif\n        SkDRect rect1, rect2;\n        SkDCubic c1, c2;\n        c1.debugSet(cubic1.fPts);\n        c2.debugSet(cubic2.fPts);\n        rect1.setBounds(c1);\n        rect2.setBounds(c2);\n        bool boundsIntersect = rect1.fLeft <= rect2.fRight && rect2.fLeft <= rect2.fRight\n                && rect1.fTop <= rect2.fBottom && rect2.fTop <= rect1.fBottom;\n        if (test == -1) {\n            SkDebugf(\"ready...\\n\");\n        }\n        SkIntersections intersections2;\n        int newIntersects = intersections2.intersect(c1, c2);\n        if (!boundsIntersect && newIntersects) {\n    #if DEBUG_CRASH\n            SkDebugf(\"%s %d unexpected intersection boundsIntersect=%d \"\n                    \" newIntersects=%d\\n%s %s\\n\", __FUNCTION__, test, boundsIntersect,\n                    newIntersects, __FUNCTION__, str);\n    #endif\n            REPORTER_ASSERT(reporter, 0);\n        }\n        for (int pt = 0; pt < intersections2.used(); ++pt) {\n            double tt1 = intersections2[0][pt];\n            SkDPoint xy1 = c1.ptAtT(tt1);\n            double tt2 = intersections2[1][pt];\n            SkDPoint xy2 = c2.ptAtT(tt2);\n            REPORTER_ASSERT(reporter, xy1.approximatelyEqual(xy2));\n        }\n        reporter->bumpTestCount();\n    }\n}\n\nstatic void intersectionFinder(int index0, int index1, double t1Seed, double t2Seed,\n        double t1Step, double t2Step) {\n    const CubicPts& cubic1 = newTestSet[index0];\n    const CubicPts& cubic2 = newTestSet[index1];\n    SkDPoint t1[3], t2[3];\n    bool toggle = true;\n    SkDCubic c1, c2;\n    c1.debugSet(cubic1.fPts);\n    c2.debugSet(cubic2.fPts);\n    do {\n        t1[0] = c1.ptAtT(t1Seed - t1Step);\n        t1[1] = c1.ptAtT(t1Seed);\n        t1[2] = c1.ptAtT(t1Seed + t1Step);\n        t2[0] = c2.ptAtT(t2Seed - t2Step);\n        t2[1] = c2.ptAtT(t2Seed);\n        t2[2] = c2.ptAtT(t2Seed + t2Step);\n        double dist[3][3];\n        dist[1][1] = t1[1].distance(t2[1]);\n        int best_i = 1, best_j = 1;\n        for (int i = 0; i < 3; ++i) {\n            for (int j = 0; j < 3; ++j) {\n                if (i == 1 && j == 1) {\n                    continue;\n                }\n                dist[i][j] = t1[i].distance(t2[j]);\n                if (dist[best_i][best_j] > dist[i][j]) {\n                    best_i = i;\n                    best_j = j;\n                }\n            }\n        }\n        if (best_i == 0) {\n            t1Seed -= t1Step;\n        } else if (best_i == 2) {\n            t1Seed += t1Step;\n        }\n        if (best_j == 0) {\n            t2Seed -= t2Step;\n        } else if (best_j == 2) {\n            t2Seed += t2Step;\n        }\n        if (best_i == 1 && best_j == 1) {\n            if ((toggle ^= true)) {\n                t1Step /= 2;\n            } else {\n                t2Step /= 2;\n            }\n        }\n    } while (!t1[1].approximatelyEqual(t2[1]));\n    t1Step = t2Step = 0.1;\n    double t10 = t1Seed - t1Step * 2;\n    double t12 = t1Seed + t1Step * 2;\n    double t20 = t2Seed - t2Step * 2;\n    double t22 = t2Seed + t2Step * 2;\n    SkDPoint test;\n    while (!approximately_zero(t1Step)) {\n        test = c1.ptAtT(t10);\n        t10 += t1[1].approximatelyEqual(test) ? -t1Step : t1Step;\n        t1Step /= 2;\n    }\n    t1Step = 0.1;\n    while (!approximately_zero(t1Step)) {\n        test = c1.ptAtT(t12);\n        t12 -= t1[1].approximatelyEqual(test) ? -t1Step : t1Step;\n        t1Step /= 2;\n    }\n    while (!approximately_zero(t2Step)) {\n        test = c2.ptAtT(t20);\n        t20 += t2[1].approximatelyEqual(test) ? -t2Step : t2Step;\n        t2Step /= 2;\n    }\n    t2Step = 0.1;\n    while (!approximately_zero(t2Step)) {\n        test = c2.ptAtT(t22);\n        t22 -= t2[1].approximatelyEqual(test) ? -t2Step : t2Step;\n        t2Step /= 2;\n    }\n#if ONE_OFF_DEBUG\n    SkDebugf(\"%s t1=(%1.9g<%1.9g<%1.9g) t2=(%1.9g<%1.9g<%1.9g)\\n\", __FUNCTION__,\n        t10, t1Seed, t12, t20, t2Seed, t22);\n    SkDPoint p10 = c1.ptAtT(t10);\n    SkDPoint p1Seed = c1.ptAtT(t1Seed);\n    SkDPoint p12 = c1.ptAtT(t12);\n    SkDebugf(\"%s p1=(%1.9g,%1.9g)<(%1.9g,%1.9g)<(%1.9g,%1.9g)\\n\", __FUNCTION__,\n        p10.fX, p10.fY, p1Seed.fX, p1Seed.fY, p12.fX, p12.fY);\n    SkDPoint p20 = c2.ptAtT(t20);\n    SkDPoint p2Seed = c2.ptAtT(t2Seed);\n    SkDPoint p22 = c2.ptAtT(t22);\n    SkDebugf(\"%s p2=(%1.9g,%1.9g)<(%1.9g,%1.9g)<(%1.9g,%1.9g)\\n\", __FUNCTION__,\n        p20.fX, p20.fY, p2Seed.fX, p2Seed.fY, p22.fX, p22.fY);\n#endif\n}\n\nstatic void CubicIntersection_IntersectionFinder() {\n//   double t1Seed = 0.87;\n//   double t2Seed = 0.87;\n    double t1Step = 0.000001;\n    double t2Step = 0.000001;\n    intersectionFinder(0, 1, 0.855895664, 0.864850875, t1Step, t2Step);\n    intersectionFinder(0, 1, 0.865207906, 0.865207887, t1Step, t2Step);\n    intersectionFinder(0, 1, 0.865213351, 0.865208087, t1Step, t2Step);\n}\n\nstatic const CubicPts selfSet[] = {\n    {{{2, 3}, {0, 4}, {3, 2}, {5, 3}}},\n    {{{3, 6}, {2, 3}, {4, 0}, {3, 2}}},\n    {{{0, 2}, {2, 3}, {5, 1}, {3, 2}}},\n    {{{0, 2}, {3, 5}, {5, 0}, {4, 2}}},\n    {{{3.34, 8.98}, {1.95, 10.27}, {3.76, 7.65}, {4.96, 10.64}}},\n    {{{3.13, 2.74}, {1.08, 4.62}, {3.71, 0.94}, {2.01, 3.81}}},\n    {{{6.71, 3.14}, {7.99, 2.75}, {8.27, 1.96}, {6.35, 3.57}}},\n    {{{12.81, 7.27}, {7.22, 6.98}, {12.49, 8.97}, {11.42, 6.18}}},\n};\n\nint selfSetCount = (int) SK_ARRAY_COUNT(selfSet);\n\nstatic void selfOneOff(skiatest::Reporter* reporter, int setIdx) {\n    const CubicPts& cubic = selfSet[setIdx];\n    SkPoint c[4];\n    for (int i = 0; i < 4; ++i) {\n        c[i] = cubic.fPts[i].asSkPoint();\n    }\n    SkScalar loopT[3];\n    SkCubicType cubicType = SkClassifyCubic(c);\n    int breaks = SkDCubic::ComplexBreak(c, loopT);\n    SkASSERT(breaks < 2);\n    if (breaks && cubicType == SkCubicType::kLoop) {\n        SkIntersections i;\n        SkPoint twoCubics[7];\n        SkChopCubicAt(c, twoCubics, loopT[0]);\n        SkDCubic chopped[2];\n        chopped[0].set(&twoCubics[0]);\n        chopped[1].set(&twoCubics[3]);\n        int result = i.intersect(chopped[0], chopped[1]);\n        REPORTER_ASSERT(reporter, result == 2);\n        REPORTER_ASSERT(reporter, i.used() == 2);\n        for (int index = 0; index < result; ++index) {\n            SkDPoint pt1 = chopped[0].ptAtT(i[0][index]);\n            SkDPoint pt2 = chopped[1].ptAtT(i[1][index]);\n            REPORTER_ASSERT(reporter, pt1.approximatelyEqual(pt2));\n            reporter->bumpTestCount();\n        }\n    }\n}\n\nstatic void cubicIntersectionSelfTest(skiatest::Reporter* reporter) {\n    int firstFail = 0;\n    for (int index = firstFail; index < selfSetCount; ++index) {\n        selfOneOff(reporter, index);\n    }\n}\n\nstatic const CubicPts coinSet[] = {\n    {{{72.350448608398438, 27.966041564941406}, {72.58441162109375, 27.861515045166016},\n        {72.818222045898437, 27.756658554077148}, {73.394996643066406, 27.49799919128418}}},\n    {{{73.394996643066406, 27.49799919128418}, {72.818222045898437, 27.756658554077148},\n        {72.58441162109375, 27.861515045166016}, {72.350448608398438, 27.966041564941406}}},\n\n    {{{297.04998779296875, 43.928997039794922}, {297.04998779296875, 43.928997039794922},\n        {300.69699096679688, 45.391998291015625}, {306.92498779296875, 43.08599853515625}}},\n    {{{297.04998779296875, 43.928997039794922}, {297.04998779296875, 43.928997039794922},\n        {300.69699096679688, 45.391998291015625}, {306.92498779296875, 43.08599853515625}}},\n\n    {{{2, 3}, {0, 4}, {3, 2}, {5, 3}}},\n    {{{2, 3}, {0, 4}, {3, 2}, {5, 3}}},\n\n    {{{317, 711}, {322.52285766601562, 711}, {327, 715.4771728515625}, {327, 721}}},\n    {{{324.07107543945312, 713.928955078125}, {324.4051513671875, 714.26300048828125},\n            {324.71566772460937, 714.62060546875}, {325, 714.555-000-0000}}},\n};\n\nstatic int coinSetCount = (int) SK_ARRAY_COUNT(coinSet);\n\nstatic void coinOneOff(skiatest::Reporter* reporter, int index) {\n    const CubicPts& cubic1 = coinSet[index];\n    const CubicPts& cubic2 = coinSet[index + 1];\n    oneOff(reporter, cubic1, cubic2, true);\n}\n\nstatic void cubicIntersectionCoinTest(skiatest::Reporter* reporter) {\n    int firstFail = 0;\n    for (int index = firstFail; index < coinSetCount; index += 2) {\n        coinOneOff(reporter, index);\n    }\n}\n\nDEF_TEST(PathOpsCubicCoinOneOff, reporter) {\n    coinOneOff(reporter, 0);\n}\n\nDEF_TEST(PathOpsCubicIntersectionOneOff, reporter) {\n    newOneOff(reporter, 0, 1);\n}\n\nDEF_TEST(PathOpsCubicIntersectionTestsOneOff, reporter) {\n    testsOneOff(reporter, 10);\n}\n\nDEF_TEST(PathOpsCubicSelfOneOff, reporter) {\n    selfOneOff(reporter, 0);\n}\n\nDEF_TEST(PathOpsCubicIntersection, reporter) {\n    oneOffTests(reporter);\n    cubicIntersectionSelfTest(reporter);\n    cubicIntersectionCoinTest(reporter);\n    standardTestCases(reporter);\n    if ((false)) CubicIntersection_IntersectionFinder();\n    if ((false)) CubicIntersection_RandTest(reporter);\n}\n",
    "file_path": "data\\preprocessed\\aseprite_skia__tests_PathOpsCubicIntersectionTest.cpp",
    "file_name": "aseprite_skia__tests_PathOpsCubicIntersectionTest.cpp",
    "language": "cpp"
  },
  {
    "text": "/**\n * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n * SPDX-License-Identifier: Apache-2.0.\n */\n\n#include <aws/events/model/HttpParameters.h>\n#include <aws/core/utils/json/JsonSerializer.h>\n\n#include <utility>\n\nusing namespace Aws::Utils::Json;\nusing namespace Aws::Utils;\n\nnamespace Aws\n{\nnamespace CloudWatchEvents\n{\nnamespace Model\n{\n\nHttpParameters::HttpParameters() :\n    m_pathParameterValuesHasBeenSet(false),\n    m_headerParametersHasBeenSet(false),\n    m_queryStringParametersHasBeenSet(false)\n{\n}\n\nHttpParameters::HttpParameters(JsonView jsonValue) :\n    m_pathParameterValuesHasBeenSet(false),\n    m_headerParametersHasBeenSet(false),\n    m_queryStringParametersHasBeenSet(false)\n{\n  *this = jsonValue;\n}\n\nHttpParameters& HttpParameters::operator =(JsonView jsonValue)\n{\n  if(jsonValue.ValueExists(\"PathParameterValues\"))\n  {\n    Aws::Utils::Array<JsonView> pathParameterValuesJsonList = jsonValue.GetArray(\"PathParameterValues\");\n    for(unsigned pathParameterValuesIndex = 0; pathParameterValuesIndex < pathParameterValuesJsonList.GetLength(); ++pathParameterValuesIndex)\n    {\n      m_pathParameterValues.push_back(pathParameterValuesJsonList[pathParameterValuesIndex].AsString());\n    }\n    m_pathParameterValuesHasBeenSet = true;\n  }\n\n  if(jsonValue.ValueExists(\"HeaderParameters\"))\n  {\n    Aws::Map<Aws::String, JsonView> headerParametersJsonMap = jsonValue.GetObject(\"HeaderParameters\").GetAllObjects();\n    for(auto& headerParametersItem : headerParametersJsonMap)\n    {\n      m_headerParameters[headerParametersItem.first] = headerParametersItem.second.AsString();\n    }\n    m_headerParametersHasBeenSet = true;\n  }\n\n  if(jsonValue.ValueExists(\"QueryStringParameters\"))\n  {\n    Aws::Map<Aws::String, JsonView> queryStringParametersJsonMap = jsonValue.GetObject(\"QueryStringParameters\").GetAllObjects();\n    for(auto& queryStringParametersItem : queryStringParametersJsonMap)\n    {\n      m_queryStringParameters[queryStringParametersItem.first] = queryStringParametersItem.second.AsString();\n    }\n    m_queryStringParametersHasBeenSet = true;\n  }\n\n  return *this;\n}\n\nJsonValue HttpParameters::Jsonize() const\n{\n  JsonValue payload;\n\n  if(m_pathParameterValuesHasBeenSet)\n  {\n   Aws::Utils::Array<JsonValue> pathParameterValuesJsonList(m_pathParameterValues.size());\n   for(unsigned pathParameterValuesIndex = 0; pathParameterValuesIndex < pathParameterValuesJsonList.GetLength(); ++pathParameterValuesIndex)\n   {\n     pathParameterValuesJsonList[pathParameterValuesIndex].AsString(m_pathParameterValues[pathParameterValuesIndex]);\n   }\n   payload.WithArray(\"PathParameterValues\", std::move(pathParameterValuesJsonList));\n\n  }\n\n  if(m_headerParametersHasBeenSet)\n  {\n   JsonValue headerParametersJsonMap;\n   for(auto& headerParametersItem : m_headerParameters)\n   {\n     headerParametersJsonMap.WithString(headerParametersItem.first, headerParametersItem.second);\n   }\n   payload.WithObject(\"HeaderParameters\", std::move(headerParametersJsonMap));\n\n  }\n\n  if(m_queryStringParametersHasBeenSet)\n  {\n   JsonValue queryStringParametersJsonMap;\n   for(auto& queryStringParametersItem : m_queryStringParameters)\n   {\n     queryStringParametersJsonMap.WithString(queryStringParametersItem.first, queryStringParametersItem.second);\n   }\n   payload.WithObject(\"QueryStringParameters\", std::move(queryStringParametersJsonMap));\n\n  }\n\n  return payload;\n}\n\n} // namespace Model\n} // namespace CloudWatchEvents\n} // namespace Aws\n",
    "file_path": "data\\preprocessed\\aws_aws-sdk-cpp__generated_src_aws-cpp-sdk-events_source_model_HttpParameters.cpp",
    "file_name": "aws_aws-sdk-cpp__generated_src_aws-cpp-sdk-events_source_model_HttpParameters.cpp",
    "language": "cpp"
  },
  {
    "text": "/***/\n/*  bytecode_23381a5.cpp                                                 */\n/***/\n\n#include \"core/io/marshalls.h\"\n#include \"core/string/print_string.h\"\n#include \"core/templates/rb_map.h\"\n\n#include \"bytecode_23381a5.h\"\n\nstatic const char *func_names[] = {\n\n\t\"sin\",\n\t\"cos\",\n\t\"tan\",\n\t\"sinh\",\n\t\"cosh\",\n\t\"tanh\",\n\t\"asin\",\n\t\"acos\",\n\t\"atan\",\n\t\"atan2\",\n\t\"sqrt\",\n\t\"fmod\",\n\t\"fposmod\",\n\t\"floor\",\n\t\"ceil\",\n\t\"round\",\n\t\"abs\",\n\t\"sign\",\n\t\"pow\",\n\t\"log\",\n\t\"exp\",\n\t\"is_nan\",\n\t\"is_inf\",\n\t\"ease\",\n\t\"decimals\",\n\t\"stepify\",\n\t\"lerp\",\n\t\"dectime\",\n\t\"randomize\",\n\t\"randi\",\n\t\"randf\",\n\t\"rand_range\",\n\t\"seed\",\n\t\"rand_seed\",\n\t\"deg2rad\",\n\t\"rad2deg\",\n\t\"linear2db\",\n\t\"db2linear\",\n\t\"max\",\n\t\"min\",\n\t\"clamp\",\n\t\"nearest_po2\",\n\t\"weakref\",\n\t\"funcref\",\n\t\"convert\",\n\t\"typeof\",\n\t\"type_exists\",\n\t\"char\",\n\t\"str\",\n\t\"print\",\n\t\"printt\",\n\t\"prints\",\n\t\"printerr\",\n\t\"printraw\",\n\t\"var2str\",\n\t\"str2var\",\n\t\"var2bytes\",\n\t\"bytes2var\",\n\t\"range\",\n\t\"load\",\n\t\"inst2dict\",\n\t\"dict2inst\",\n\t\"hash\",\n\t\"Color8\",\n\t\"ColorN\",\n\t\"print_stack\",\n\t\"instance_from_id\",\n};\n\nstatic constexpr uint64_t FUNC_MAX = sizeof(func_names) / sizeof(func_names[0]);\n\nenum Token {\n\n\tTK_EMPTY,\n\tTK_IDENTIFIER,\n\tTK_CONSTANT,\n\tTK_SELF,\n\tTK_BUILT_IN_TYPE,\n\tTK_BUILT_IN_FUNC,\n\tTK_OP_IN,\n\tTK_OP_EQUAL,\n\tTK_OP_NOT_EQUAL,\n\tTK_OP_LESS,\n\tTK_OP_LESS_EQUAL,\n\tTK_OP_GREATER,\n\tTK_OP_GREATER_EQUAL,\n\tTK_OP_AND,\n\tTK_OP_OR,\n\tTK_OP_NOT,\n\tTK_OP_ADD,\n\tTK_OP_SUB,\n\tTK_OP_MUL,\n\tTK_OP_DIV,\n\tTK_OP_MOD,\n\tTK_OP_SHIFT_LEFT,\n\tTK_OP_SHIFT_RIGHT,\n\tTK_OP_ASSIGN,\n\tTK_OP_ASSIGN_ADD,\n\tTK_OP_ASSIGN_SUB,\n\tTK_OP_ASSIGN_MUL,\n\tTK_OP_ASSIGN_DIV,\n\tTK_OP_ASSIGN_MOD,\n\tTK_OP_ASSIGN_SHIFT_LEFT,\n\tTK_OP_ASSIGN_SHIFT_RIGHT,\n\tTK_OP_ASSIGN_BIT_AND,\n\tTK_OP_ASSIGN_BIT_OR,\n\tTK_OP_ASSIGN_BIT_XOR,\n\tTK_OP_BIT_AND,\n\tTK_OP_BIT_OR,\n\tTK_OP_BIT_XOR,\n\tTK_OP_BIT_INVERT,\n\t//TK_OP_PLUS_PLUS,\n\t//TK_OP_MINUS_MINUS,\n\tTK_CF_IF,\n\tTK_CF_ELIF,\n\tTK_CF_ELSE,\n\tTK_CF_FOR,\n\tTK_CF_DO,\n\tTK_CF_WHILE,\n\tTK_CF_SWITCH,\n\tTK_CF_CASE,\n\tTK_CF_BREAK,\n\tTK_CF_CONTINUE,\n\tTK_CF_PASS,\n\tTK_CF_RETURN,\n\tTK_PR_FUNCTION,\n\tTK_PR_CLASS,\n\tTK_PR_EXTENDS,\n\tTK_PR_ONREADY,\n\tTK_PR_TOOL,\n\tTK_PR_STATIC,\n\tTK_PR_EXPORT,\n\tTK_PR_SETGET,\n\tTK_PR_CONST,\n\tTK_PR_VAR,\n\tTK_PR_ENUM,\n\tTK_PR_PRELOAD,\n\tTK_PR_ASSERT,\n\tTK_PR_YIELD,\n\tTK_PR_SIGNAL,\n\tTK_PR_BREAKPOINT,\n\tTK_PR_REMOTE,\n\tTK_PR_SYNC,\n\tTK_PR_MASTER,\n\tTK_PR_SLAVE,\n\tTK_BRACKET_OPEN,\n\tTK_BRACKET_CLOSE,\n\tTK_CURLY_BRACKET_OPEN,\n\tTK_CURLY_BRACKET_CLOSE,\n\tTK_PARENTHESIS_OPEN,\n\tTK_PARENTHESIS_CLOSE,\n\tTK_COMMA,\n\tTK_SEMICOLON,\n\tTK_PERIOD,\n\tTK_QUESTION_MARK,\n\tTK_COLON,\n\tTK_NEWLINE,\n\tTK_CONST_PI,\n\tTK_ERROR,\n\tTK_EOF,\n\tTK_CURSOR, //used for code completion\n\tTK_MAX\n};\n\nError GDScriptDecomp_23381a5::decompile_buffer(Vector<uint8_t> p_buffer) {\n\t//Cleanup\n\tscript_text = String();\n\n\t//Load bytecode\n\tVector<StringName> identifiers;\n\tVector<Variant> constants;\n\tVMap<uint32_t, uint32_t> lines;\n\tVector<uint32_t> tokens;\n\n\tconst uint8_t *buf = p_buffer.ptr();\n\tint total_len = p_buffer.size();\n\tERR_FAIL_COND_V(p_buffer.size() < 24 || p_buffer[0] != 'G' || p_buffer[1] != 'D' || p_buffer[2] != 'S' || p_buffer[3] != 'C', ERR_INVALID_DATA);\n\n\tint version = decode_uint32(&buf[4]);\n\tif (version != bytecode_version) {\n\t\tERR_FAIL_COND_V(version > bytecode_version, ERR_INVALID_DATA);\n\t}\n\tint identifier_count = decode_uint32(&buf[8]);\n\tint constant_count = decode_uint32(&buf[12]);\n\tint line_count = decode_uint32(&buf[16]);\n\tint token_count = decode_uint32(&buf[20]);\n\n\tconst uint8_t *b = &buf[24];\n\ttotal_len -= 24;\n\n\tidentifiers.resize(identifier_count);\n\tfor (int i = 0; i < identifier_count; i++) {\n\t\tint len = decode_uint32(b);\n\t\tERR_FAIL_COND_V(len > total_len, ERR_INVALID_DATA);\n\t\tb += 4;\n\t\tVector<uint8_t> cs;\n\t\tcs.resize(len);\n\t\tfor (int j = 0; j < len; j++) {\n\t\t\tcs.write[j] = b[j] ^ 0xb6;\n\t\t}\n\n\t\tcs.write[cs.size() - 1] = 0;\n\t\tString s;\n\t\ts.parse_utf8((const char *)cs.ptr());\n\t\tb += len;\n\t\ttotal_len -= len + 4;\n\t\tidentifiers.write[i] = s;\n\t}\n\n\tconstants.resize(constant_count);\n\tfor (int i = 0; i < constant_count; i++) {\n\t\tVariant v;\n\t\tint len;\n\t\tError err = VariantDecoderCompat::decode_variant_compat(variant_ver_major, v, b, total_len, &len);\n\t\tif (err) {\n\t\t\terror_message = RTR(\"Invalid constant\");\n\t\t\treturn err;\n\t\t}\n\t\tb += len;\n\t\ttotal_len -= len;\n\t\tconstants.write[i] = v;\n\t}\n\n\tERR_FAIL_COND_V(line_count * 8 > total_len, ERR_INVALID_DATA);\n\n\tfor (int i = 0; i < line_count; i++) {\n\t\tuint32_t token = decode_uint32(b);\n\t\tb += 4;\n\t\tuint32_t linecol = decode_uint32(b);\n\t\tb += 4;\n\n\t\tlines.insert(token, linecol);\n\t\ttotal_len -= 8;\n\t}\n\n\ttokens.resize(token_count);\n\n\tfor (int i = 0; i < token_count; i++) {\n\t\tERR_FAIL_COND_V(total_len < 1, ERR_INVALID_DATA);\n\n\t\tif ((*b) & TOKEN_BYTE_MASK) { //little endian always\n\t\t\tERR_FAIL_COND_V(total_len < 4, ERR_INVALID_DATA);\n\n\t\t\ttokens.write[i] = decode_uint32(b) & ~TOKEN_BYTE_MASK;\n\t\t\tb += 4;\n\t\t} else {\n\t\t\ttokens.write[i] = *b;\n\t\t\tb += 1;\n\t\t\ttotal_len--;\n\t\t}\n\t}\n\n\t//Decompile script\n\tString line;\n\tint indent = 0;\n\n\tToken prev_token = TK_NEWLINE;\n\tfor (int i = 0; i < tokens.size(); i++) {\n\t\tswitch (Token(tokens[i] & TOKEN_MASK)) {\n\t\t\tcase TK_EMPTY: {\n\t\t\t\t//skip\n\t\t\t} break;\n\t\t\tcase TK_IDENTIFIER: {\n\t\t\t\tuint32_t identifier = tokens[i] >> TOKEN_BITS;\n\t\t\t\tERR_FAIL_COND_V(identifier >= (uint32_t)identifiers.size(), ERR_INVALID_DATA);\n\t\t\t\tline += String(identifiers[identifier]);\n\t\t\t} break;\n\t\t\tcase TK_CONSTANT: {\n\t\t\t\tuint32_t constant = tokens[i] >> TOKEN_BITS;\n\t\t\t\tERR_FAIL_COND_V(constant >= (uint32_t)constants.size(), ERR_INVALID_DATA);\n\t\t\t\tline += get_constant_string(constants, constant);\n\t\t\t} break;\n\t\t\tcase TK_SELF: {\n\t\t\t\tline += \"self\";\n\t\t\t} break;\n\t\t\tcase TK_BUILT_IN_TYPE: {\n\t\t\t\tline += VariantDecoderCompat::get_variant_type_name(tokens[i] >> TOKEN_BITS, variant_ver_major);\n\t\t\t} break;\n\t\t\tcase TK_BUILT_IN_FUNC: {\n\t\t\t\tERR_FAIL_COND_V(tokens[i] >> TOKEN_BITS >= FUNC_MAX, ERR_INVALID_DATA);\n\t\t\t\tline += func_names[tokens[i] >> TOKEN_BITS];\n\t\t\t} break;\n\t\t\tcase TK_OP_IN: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"in \";\n\t\t\t} break;\n\t\t\tcase TK_OP_EQUAL: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"== \";\n\t\t\t} break;\n\t\t\tcase TK_OP_NOT_EQUAL: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"!= \";\n\t\t\t} break;\n\t\t\tcase TK_OP_LESS: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"< \";\n\t\t\t} break;\n\t\t\tcase TK_OP_LESS_EQUAL: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"<= \";\n\t\t\t} break;\n\t\t\tcase TK_OP_GREATER: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"> \";\n\t\t\t} break;\n\t\t\tcase TK_OP_GREATER_EQUAL: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \">= \";\n\t\t\t} break;\n\t\t\tcase TK_OP_AND: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"and \";\n\t\t\t} break;\n\t\t\tcase TK_OP_OR: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"or \";\n\t\t\t} break;\n\t\t\tcase TK_OP_NOT: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"not \";\n\t\t\t} break;\n\t\t\tcase TK_OP_ADD: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"+ \";\n\t\t\t} break;\n\t\t\tcase TK_OP_SUB: {\n\t\t\t\tif (prev_token != TK_NEWLINE)\n\t\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"- \";\n\t\t\t\t//TODO: do not add space after unary \"-\"\n\t\t\t} break;\n\t\t\tcase TK_OP_MUL: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"* \";\n\t\t\t} break;\n\t\t\tcase TK_OP_DIV: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"/ \";\n\t\t\t} break;\n\t\t\tcase TK_OP_MOD: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"% \";\n\t\t\t} break;\n\t\t\tcase TK_OP_SHIFT_LEFT: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"<< \";\n\t\t\t} break;\n\t\t\tcase TK_OP_SHIFT_RIGHT: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \">> \";\n\t\t\t} break;\n\t\t\tcase TK_OP_ASSIGN: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"= \";\n\t\t\t} break;\n\t\t\tcase TK_OP_ASSIGN_ADD: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"+= \";\n\t\t\t} break;\n\t\t\tcase TK_OP_ASSIGN_SUB: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"-= \";\n\t\t\t} break;\n\t\t\tcase TK_OP_ASSIGN_MUL: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"*= \";\n\t\t\t} break;\n\t\t\tcase TK_OP_ASSIGN_DIV: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"/= \";\n\t\t\t} break;\n\t\t\tcase TK_OP_ASSIGN_MOD: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"%= \";\n\t\t\t} break;\n\t\t\tcase TK_OP_ASSIGN_SHIFT_LEFT: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"<<= \";\n\t\t\t} break;\n\t\t\tcase TK_OP_ASSIGN_SHIFT_RIGHT: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \">>= \";\n\t\t\t} break;\n\t\t\tcase TK_OP_ASSIGN_BIT_AND: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"&= \";\n\t\t\t} break;\n\t\t\tcase TK_OP_ASSIGN_BIT_OR: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"|= \";\n\t\t\t} break;\n\t\t\tcase TK_OP_ASSIGN_BIT_XOR: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"^= \";\n\t\t\t} break;\n\t\t\tcase TK_OP_BIT_AND: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"& \";\n\t\t\t} break;\n\t\t\tcase TK_OP_BIT_OR: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"| \";\n\t\t\t} break;\n\t\t\tcase TK_OP_BIT_XOR: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"^ \";\n\t\t\t} break;\n\t\t\tcase TK_OP_BIT_INVERT: {\n\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"~ \";\n\t\t\t} break;\n\t\t\t//case TK_OP_PLUS_PLUS: {\n\t\t\t//\tline += \"++\";\n\t\t\t//} break;\n\t\t\t//case TK_OP_MINUS_MINUS: {\n\t\t\t//\tline += \"--\";\n\t\t\t//} break;\n\t\t\tcase TK_CF_IF: {\n\t\t\t\tif (prev_token != TK_NEWLINE)\n\t\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"if \";\n\t\t\t} break;\n\t\t\tcase TK_CF_ELIF: {\n\t\t\t\tline += \"elif \";\n\t\t\t} break;\n\t\t\tcase TK_CF_ELSE: {\n\t\t\t\tif (prev_token != TK_NEWLINE)\n\t\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"else \";\n\t\t\t} break;\n\t\t\tcase TK_CF_FOR: {\n\t\t\t\tline += \"for \";\n\t\t\t} break;\n\t\t\tcase TK_CF_DO: {\n\t\t\t\tline += \"do \";\n\t\t\t} break;\n\t\t\tcase TK_CF_WHILE: {\n\t\t\t\tline += \"while \";\n\t\t\t} break;\n\t\t\tcase TK_CF_SWITCH: {\n\t\t\t\tline += \"swith \";\n\t\t\t} break;\n\t\t\tcase TK_CF_CASE: {\n\t\t\t\tline += \"case \";\n\t\t\t} break;\n\t\t\tcase TK_CF_BREAK: {\n\t\t\t\tline += \"break\";\n\t\t\t} break;\n\t\t\tcase TK_CF_CONTINUE: {\n\t\t\t\tline += \"continue\";\n\t\t\t} break;\n\t\t\tcase TK_CF_PASS: {\n\t\t\t\tline += \"pass\";\n\t\t\t} break;\n\t\t\tcase TK_CF_RETURN: {\n\t\t\t\tline += \"return \";\n\t\t\t} break;\n\t\t\tcase TK_PR_FUNCTION: {\n\t\t\t\tline += \"func \";\n\t\t\t} break;\n\t\t\tcase TK_PR_CLASS: {\n\t\t\t\tline += \"class \";\n\t\t\t} break;\n\t\t\tcase TK_PR_EXTENDS: {\n\t\t\t\tif (prev_token != TK_NEWLINE)\n\t\t\t\t\t_ensure_space(line);\n\t\t\t\tline += \"extends \";\n\t\t\t} break;\n\t\t\tcase TK_PR_ONREADY: {\n\t\t\t\tline += \"onready \";\n\t\t\t} break;\n\t\t\tcase TK_PR_TOOL: {\n\t\t\t\tline += \"tool \";\n\t\t\t} break;\n\t\t\tcase TK_PR_STATIC: {\n\t\t\t\tline += \"static \";\n\t\t\t} break;\n\t\t\tcase TK_PR_EXPORT: {\n\t\t\t\tline += \"export \";\n\t\t\t} break;\n\t\t\tcase TK_PR_SETGET: {\n\t\t\t\tline += \" setget \";\n\t\t\t} break;\n\t\t\tcase TK_PR_CONST: {\n\t\t\t\tline += \"const \";\n\t\t\t} break;\n\t\t\tcase TK_PR_VAR: {\n\t\t\t\tif (line != String() && prev_token != TK_PR_ONREADY)\n\t\t\t\t\tline += \" \";\n\t\t\t\tline += \"var \";\n\t\t\t} break;\n\t\t\tcase TK_PR_ENUM: {\n\t\t\t\tline += \"enum \";\n\t\t\t} break;\n\t\t\tcase TK_PR_PRELOAD: {\n\t\t\t\tline += \"preload\";\n\t\t\t} break;\n\t\t\tcase TK_PR_ASSERT: {\n\t\t\t\tline += \"assert \";\n\t\t\t} break;\n\t\t\tcase TK_PR_YIELD: {\n\t\t\t\tline += \"yield \";\n\t\t\t} break;\n\t\t\tcase TK_PR_SIGNAL: {\n\t\t\t\tline += \"signal \";\n\t\t\t} break;\n\t\t\tcase TK_PR_BREAKPOINT: {\n\t\t\t\tline += \"breakpoint \";\n\t\t\t} break;\n\t\t\tcase TK_PR_REMOTE: {\n\t\t\t\tline += \"remote \";\n\t\t\t} break;\n\t\t\tcase TK_PR_SYNC: {\n\t\t\t\tline += \"sync \";\n\t\t\t} break;\n\t\t\tcase TK_PR_MASTER: {\n\t\t\t\tline += \"master \";\n\t\t\t} break;\n\t\t\tcase TK_PR_SLAVE: {\n\t\t\t\tline += \"slave \";\n\t\t\t} break;\n\t\t\tcase TK_BRACKET_OPEN: {\n\t\t\t\tline += \"[\";\n\t\t\t} break;\n\t\t\tcase TK_BRACKET_CLOSE: {\n\t\t\t\tline += \"]\";\n\t\t\t} break;\n\t\t\tcase TK_CURLY_BRACKET_OPEN: {\n\t\t\t\tline += \"{\";\n\t\t\t} break;\n\t\t\tcase TK_CURLY_BRACKET_CLOSE: {\n\t\t\t\tline += \"}\";\n\t\t\t} break;\n\t\t\tcase TK_PARENTHESIS_OPEN: {\n\t\t\t\tline += \"(\";\n\t\t\t} break;\n\t\t\tcase TK_PARENTHESIS_CLOSE: {\n\t\t\t\tline += \")\";\n\t\t\t} break;\n\t\t\tcase TK_COMMA: {\n\t\t\t\tline += \", \";\n\t\t\t} break;\n\t\t\tcase TK_SEMICOLON: {\n\t\t\t\tline += \";\";\n\t\t\t} break;\n\t\t\tcase TK_PERIOD: {\n\t\t\t\tline += \".\";\n\t\t\t} break;\n\t\t\tcase TK_QUESTION_MARK: {\n\t\t\t\tline += \"?\";\n\t\t\t} break;\n\t\t\tcase TK_COLON: {\n\t\t\t\tline += \":\";\n\t\t\t} break;\n\t\t\tcase TK_NEWLINE: {\n\t\t\t\tfor (int j = 0; j < indent; j++) {\n\t\t\t\t\tscript_text += \"\\t\";\n\t\t\t\t}\n\t\t\t\tscript_text += line + \"\\n\";\n\t\t\t\tline = String();\n\t\t\t\tindent = tokens[i] >> TOKEN_BITS;\n\t\t\t} break;\n\t\t\tcase TK_CONST_PI: {\n\t\t\t\tline += \"PI\";\n\t\t\t} break;\n\t\t\tcase TK_ERROR: {\n\t\t\t\t//skip - invalid\n\t\t\t} break;\n\t\t\tcase TK_EOF: {\n\t\t\t\t//skip - invalid\n\t\t\t} break;\n\t\t\tcase TK_CURSOR: {\n\t\t\t\t//skip - invalid\n\t\t\t} break;\n\t\t\tcase TK_MAX: {\n\t\t\t\t//skip - invalid\n\t\t\t} break;\n\t\t}\n\t\tprev_token = Token(tokens[i] & TOKEN_MASK);\n\t}\n\n\tif (!line.is_empty()) {\n\t\tfor (int j = 0; j < indent; j++) {\n\t\t\tscript_text += \"\\t\";\n\t\t}\n\t\tscript_text += line + \"\\n\";\n\t}\n\n\tif (script_text == String()) {\n\t\terror_message = RTR(\"Invalid token\");\n\t\treturn ERR_INVALID_DATA;\n\t}\n\n\treturn OK;\n}\n",
    "file_path": "data\\preprocessed\\bruvzg_gdsdecomp__bytecode_bytecode_23381a5.cpp",
    "file_name": "bruvzg_gdsdecomp__bytecode_bytecode_23381a5.cpp",
    "language": "cpp"
  },
  {
    "text": "// Copyright (c) 2010 Satoshi Nakamoto\n// Copyright (c) 2009-2016 The Bitcoin Core developers\n// Distributed under the MIT software license, see the accompanying\n// file COPYING or https://example.com/path\n\n#include \"noui.h\"\n\n#include \"ui_interface.h\"\n#include \"util.h\"\n\n#include <cstdio>\n#include <stdint.h>\n#include <string>\n\nstatic bool noui_ThreadSafeMessageBox(const std::string& message, const std::string& caption, unsigned int style)\n{\n    bool fSecure = style & CClientUIInterface::SECURE;\n    style &= ~CClientUIInterface::SECURE;\n\n    std::string strCaption;\n    // Check for usage of predefined caption\n    switch (style) {\n    case CClientUIInterface::MSG_ERROR:\n        strCaption += _(\"Error\");\n        break;\n    case CClientUIInterface::MSG_WARNING:\n        strCaption += _(\"Warning\");\n        break;\n    case CClientUIInterface::MSG_INFORMATION:\n        strCaption += _(\"Information\");\n        break;\n    default:\n        strCaption += caption; // Use supplied caption (can be empty)\n    }\n\n    if (!fSecure)\n        LogPrintf(\"%s: %s\\n\", strCaption, message);\n    fprintf(stderr, \"%s: %s\\n\", strCaption.c_str(), message.c_str());\n    return false;\n}\n\nstatic bool noui_ThreadSafeQuestion(const std::string& /* ignored interactive message */, const std::string& message, const std::string& caption, unsigned int style)\n{\n    return noui_ThreadSafeMessageBox(message, caption, style);\n}\n\nstatic void noui_InitMessage(const std::string& message)\n{\n    LogPrintf(\"init message: %s\\n\", message);\n}\n\nvoid noui_connect()\n{\n    // Connect bitcoind signal handlers\n    uiInterface.ThreadSafeMessageBox.connect(noui_ThreadSafeMessageBox);\n    uiInterface.ThreadSafeQuestion.connect(noui_ThreadSafeQuestion);\n    uiInterface.InitMessage.connect(noui_InitMessage);\n}\n",
    "file_path": "data\\preprocessed\\btc1_bitcoin__src_noui.cpp",
    "file_name": "btc1_bitcoin__src_noui.cpp",
    "language": "cpp"
  },
  {
    "text": "//!\n//! Copyright (c) 2015, The casual project\n//!\n//! This software is licensed under the MIT license, https://example.com/path\n//!\n\n\n#include \"xatmi.h\"\n\n#include \"common/algorithm.h\"\n#include \"common/process.h\"\n#include \"common/log/category.h\"\n#include \"common/exception/guard.h\"\n#include \"common/argument.h\"\n#include \"common/environment/expand.h\"\n#include \"common/chronology.h\"\n#include \"common/domain.h\"\n#include \"common/string/compose.h\"\n\n\n#include <locale>\n\nnamespace casual\n{\n   namespace example::server\n   {\n\n      namespace local\n      {\n         namespace\n         {\n            struct\n            {\n               casual::platform::time::unit startup{};\n               casual::platform::time::unit sleep{};\n               casual::platform::time::unit work{};\n               std::string forward;\n            } global;\n         } // <unnamed>\n      } // local\n\n      extern \"C\"\n      {\n         void casual_example_echo( TPSVCINFO* info);\n\n         int tpsvrinit( int argc, char* argv[])\n         {\n            return common::exception::main::log::guard( [&]()\n            {\n               auto arguments = common::range::make( argv + 1, argc - 1);\n               common::log::line( common::log::category::information, \"example server started with arguments: \", arguments);\n\n               auto time_value = []( auto& time)\n               {\n                  return [&time]( std::string value)\n                  {\n                     time = common::chronology::from::string( common::environment::expand( value));\n                  };\n               };\n\n               common::argument::Parse{ \"Shows a few ways services can be develop\",\n                  common::argument::Option{ time_value( local::global.startup), {\"--startup\"}, \"startup time\"},\n                  common::argument::Option{ time_value( local::global.sleep), {\"--sleep\"}, \"sleep time\"},\n                  common::argument::Option{ time_value( local::global.work), {\"--work\"}, \"work time\"},\n                  common::argument::Option{ std::tie( local::global.forward), {\"--forward\"}, \"service that casual/example/forward should call\"},\n               }( argc, argv);\n\n               if( local::global.startup != platform::time::unit::zero())\n                  common::process::sleep( local::global.startup);\n\n               auto advertise_echo = []( std::string_view name)\n               {\n                  tpadvertise( name.data(), &casual_example_echo);\n               };\n\n               advertise_echo( \"casual/example/advertised/echo\");\n               advertise_echo( common::string::compose( \"casual/example/domain/echo/\", common::domain::identity().name));\n               advertise_echo( common::string::compose( \"casual/example/domain/echo/\", common::domain::identity().id));\n\n\n               common::log::line( common::log::category::information, \"sleep: \", local::global.sleep);\n               common::log::line( common::log::category::information, \"work: \", local::global.work);\n            });\n         }\n\n        void casual_example_forward( TPSVCINFO* info)\n         {\n            auto len = info->len;\n            if( tpcall( local::global.forward.data(), info->data, info->len, &info->data, &len, 0) == 0)\n               tpreturn( TPSUCCESS, 0, info->data, info->len, 0);\n\n            tpreturn( TPFAIL, 0, nullptr, 0, 0);\n         }\n\n         void casual_example_sleep( TPSVCINFO* info)\n         {\n            common::process::sleep( local::global.sleep);\n            tpreturn( TPSUCCESS, 0, info->data, info->len, 0);\n         }\n\n         void casual_example_work( TPSVCINFO* info)\n         {\n            auto deadline = platform::time::clock::type::now() + local::global.work;\n\n            while( deadline < platform::time::clock::type::now())\n            {\n               ; // no-op\n            }\n\n            tpreturn( TPSUCCESS, 0, info->data, info->len, 0);\n         }\n      }\n\n   } // example::server\n} // casual\n\n",
    "file_path": "data\\preprocessed\\casualcore_casual__middleware_example_server_source_example_work.cpp",
    "file_name": "casualcore_casual__middleware_example_server_source_example_work.cpp",
    "language": "cpp"
  },
  {
    "text": "#include <iostream>\n#include <sstream>\n#include \"CondCore/Utilities/interface/PayloadInspector.h\"\n#include \"FWCore/MessageLogger/interface/MessageLogger.h\"\n#include \"FWCore/PluginManager/interface/PluginManager.h\"\n#include \"FWCore/PluginManager/interface/standard.h\"\n#include \"FWCore/PluginManager/interface/SharedLibrary.h\"\n#include \"FWCore/ServiceRegistry/interface/ServiceRegistry.h\"\n#include \"CondFormats/PPSObjects/interface/PPSTimingCalibration.h\"\n#include \"CondCore/CTPPSPlugins/interface/PPSTimingCalibrationPayloadInspectorHelper.h\"\n\nint main(int argc, char** argv) {\n  Py_Initialize();\n\n  edmplugin::PluginManager::Config config;\n  edmplugin::PluginManager::configure(edmplugin::standard::config());\n\n  std::vector<edm::ParameterSet> psets;\n  edm::ParameterSet pSet;\n  pSet.addParameter(\"@service_type\", std::string(\"SiteLocalConfigService\"));\n  psets.push_back(pSet);\n  edm::ServiceToken servToken(edm::ServiceRegistry::createSet(psets));\n  edm::ServiceRegistry::Operate operate(servToken);\n\n  std::string connectionString(\"frontier://FrontierProd/CMS_CONDITIONS\");\n\n  std::string tag = \"CTPPPSTimingCalibration_HPTDC_byPCL_v0_prompt\";\n  cond::Time_t start = static_cast<unsigned long long>(355892);\n  cond::Time_t end = static_cast<unsigned long long>(357079);\n\n  edm::LogPrint(\"testPPSCalibrationPI\") << \"## Exercising TimingCalibration plots \";\n\n  ParametersPerChannel<PPSTimingCalibrationPI::db0,\n                       PPSTimingCalibrationPI::plane0,\n                       PPSTimingCalibrationPI::parameter0,\n                       PPSTimingCalibration>\n      test;\n  test.process(connectionString, PI::mk_input(tag, start, end));\n  edm::LogPrint(\"testparametersPerChannel\") << test.data();\n  Py_Finalize();\n}\n",
    "file_path": "data\\preprocessed\\cms-sw_cmssw__CondCore_CTPPSPlugins_test_testPPSTimingCalibration.cpp",
    "file_name": "cms-sw_cmssw__CondCore_CTPPSPlugins_test_testPPSTimingCalibration.cpp",
    "language": "cpp"
  },
  {
    "text": "// Copyright (c) 2010 Satoshi Nakamoto\n// Copyright (c) 2009-2014 The Bitcoin developers\n// Copyright (c) 2014-2015 The Dash developers\n// Copyright (c) 2015-2017 The PIVX developers\n// Distributed under the MIT software license, see the accompanying\n// file COPYING or https://example.com/path\n\n#include \"base58.h\"\n#include \"checkpoints.h\"\n#include \"clientversion.h\"\n#include \"contractconfig.h\"\n\n#include \"main.h\"\n#include \"rpcserver.h\"\n#include \"sync.h\"\n#include \"txdb.h\"\n#include \"util.h\"\n#include \"core_io.h\"\n#include \"utilmoneystr.h\"\n\n#include <stdint.h>\n#include <univalue.h>\n#include <string>\n#include <algorithm>\n\nusing namespace std;\n\nextern void TxToJSON(const CTransaction& tx, const uint256 hashBlock, UniValue& entry);\nvoid ScriptPubKeyToJSON(const CScript& scriptPubKey, UniValue& out, bool fIncludeHex);\n\ndouble GetDifficulty(const CBlockIndex* blockindex)\n{\n    // Floating point number that is a multiple of the minimum difficulty,\n    // minimum difficulty = 1.0.\n    if (blockindex == NULL) {\n        if (chainActive.Tip() == NULL)\n            return 1.0;\n        else\n            blockindex = chainActive.Tip();\n    }\n\n    int nShift = (blockindex->nBits >> 24) & 0xff;\n\n    double dDiff =\n        (double)0x0000ffff / (double)(blockindex->nBits & 0x00ffffff);\n\n    while (nShift < 29) {\n        dDiff *= 256.0;\n        nShift++;\n    }\n    while (nShift > 29) {\n        dDiff /= 256.0;\n        nShift--;\n    }\n\n    return dDiff;\n}\n\nUniValue blockToJSON(const CBlock& block, const CBlockIndex* blockindex, bool txDetails = false)\n{\n    UniValue result(UniValue::VOBJ);\n    result.push_back(Pair(\"hash\", block.GetHash().GetHex()));\n    int confirmations = -1;\n    // Only report confirmations if the block is on the main chain\n    if (chainActive.Contains(blockindex))\n        confirmations = chainActive.Height() - blockindex->nHeight + 1;\n    result.push_back(Pair(\"confirmations\", confirmations));\n    result.push_back(Pair(\"size\", (int)::GetSerializeSize(block, SER_NETWORK, PROTOCOL_VERSION)));\n    result.push_back(Pair(\"height\", blockindex->nHeight));\n    result.push_back(Pair(\"version\", block.nVersion));\n    result.push_back(Pair(\"merkleroot\", block.hashMerkleRoot.GetHex()));\n    result.push_back(Pair(\"acc_checkpoint\", block.nAccumulatorCheckpoint.GetHex()));\n    UniValue txs(UniValue::VARR);\n    BOOST_FOREACH (const CTransaction& tx, block.vtx) {\n        if (txDetails) {\n            UniValue objTx(UniValue::VOBJ);\n            TxToJSON(tx, uint256(0), objTx);\n            txs.push_back(objTx);\n        } else\n            txs.push_back(tx.GetHash().GetHex());\n    }\n    result.push_back(Pair(\"tx\", txs));\n    result.push_back(Pair(\"time\", block.GetBlockTime()));\n    result.push_back(Pair(\"nonce\", (uint64_t)block.nNonce));\n    result.push_back(Pair(\"bits\", strprintf(\"%08x\", block.nBits)));\n    result.push_back(Pair(\"difficulty\", GetDifficulty(blockindex)));\n    result.push_back(Pair(\"chainwork\", blockindex->nChainWork.GetHex()));\n\n    if (blockindex->pprev)\n        result.push_back(Pair(\"previousblockhash\", blockindex->pprev->GetBlockHash().GetHex()));\n    CBlockIndex* pnext = chainActive.Next(blockindex);\n    if (pnext)\n        result.push_back(Pair(\"nextblockhash\", pnext->GetBlockHash().GetHex()));\n\n    result.push_back(Pair(\"moneysupply\",ValueFromAmount(blockindex->nMoneySupply)));\n\n    UniValue ztsrObj(UniValue::VOBJ);\n    for (auto denom : libzerocoin::zerocoinDenomList) {\n        ztsrObj.push_back(Pair(to_string(denom), ValueFromAmount(blockindex->mapZerocoinSupply.at(denom) * (denom*COIN))));\n    }\n    ztsrObj.push_back(Pair(\"total\", ValueFromAmount(blockindex->GetZerocoinSupply())));\n    result.push_back(Pair(\"zGKCsupply\", ztsrObj));\n\n    return result;\n}\n\n\nUniValue blockHeaderToJSON(const CBlock& block, const CBlockIndex* blockindex)\n{\n    UniValue result(UniValue::VOBJ);\n    result.push_back(Pair(\"version\", block.nVersion));\n    if (blockindex->pprev)\n        result.push_back(Pair(\"previousblockhash\", blockindex->pprev->GetBlockHash().GetHex()));\n    result.push_back(Pair(\"merkleroot\", block.hashMerkleRoot.GetHex()));\n    result.push_back(Pair(\"time\", block.GetBlockTime()));\n    result.push_back(Pair(\"bits\", strprintf(\"%08x\", block.nBits)));\n    result.push_back(Pair(\"nonce\", (uint64_t)block.nNonce));\n\tresult.push_back(Pair(\"hash\",blockindex->GetBlockHash().GetHex()));\n\tresult.push_back(Pair(\"height\",blockindex->nHeight));\n    return result;\n}\n\n\nUniValue getblockcount(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() != 0)\n        throw runtime_error(\n            \"getblockcount\\n\"\n            \"\\nReturns the number of blocks in the longest block chain.\\n\"\n            \"\\nResult:\\n\"\n            \"n    (numeric) The current block count\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"getblockcount\", \"\") + HelpExampleRpc(\"getblockcount\", \"\"));\n\n    return chainActive.Height();\n}\n\nUniValue getbestblockhash(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() != 0)\n        throw runtime_error(\n            \"getbestblockhash\\n\"\n            \"\\nReturns the hash of the best (tip) block in the longest block chain.\\n\"\n            \"\\nResult\\n\"\n            \"\\\"hex\\\"      (string) the block hash hex encoded\\n\"\n            \"\\nExamples\\n\" +\n            HelpExampleCli(\"getbestblockhash\", \"\") + HelpExampleRpc(\"getbestblockhash\", \"\"));\n\n    return chainActive.Tip()->GetBlockHash().GetHex();\n}\n\nUniValue getdifficulty(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() != 0)\n        throw runtime_error(\n            \"getdifficulty\\n\"\n            \"\\nReturns the proof-of-work difficulty as a multiple of the minimum difficulty.\\n\"\n            \"\\nResult:\\n\"\n            \"n.nnn       (numeric) the proof-of-work difficulty as a multiple of the minimum difficulty.\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"getdifficulty\", \"\") + HelpExampleRpc(\"getdifficulty\", \"\"));\n\n    return GetDifficulty();\n}\n\n\nUniValue getrawmempool(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() > 1)\n        throw runtime_error(\n            \"getrawmempool ( verbose )\\n\"\n            \"\\nReturns all transaction ids in memory pool as a json array of string transaction ids.\\n\"\n            \"\\nArguments:\\n\"\n            \"1. verbose           (boolean, optional, default=false) true for a json object, false for array of transaction ids\\n\"\n            \"\\nResult: (for verbose = false):\\n\"\n            \"[                     (json array of string)\\n\"\n            \"  \\\"transactionid\\\"     (string) The transaction id\\n\"\n            \"  ,...\\n\"\n            \"]\\n\"\n            \"\\nResult: (for verbose = true):\\n\"\n            \"{                           (json object)\\n\"\n            \"  \\\"transactionid\\\" : {       (json object)\\n\"\n            \"    \\\"size\\\" : n,             (numeric) transaction size in bytes\\n\"\n            \"    \\\"fee\\\" : n,              (numeric) transaction fee in gkc\\n\"\n            \"    \\\"time\\\" : n,             (numeric) local time transaction entered pool in seconds since 1 Jan 1970 GMT\\n\"\n            \"    \\\"height\\\" : n,           (numeric) block height when transaction entered pool\\n\"\n            \"    \\\"startingpriority\\\" : n, (numeric) priority when transaction entered pool\\n\"\n            \"    \\\"currentpriority\\\" : n,  (numeric) transaction priority now\\n\"\n            \"    \\\"depends\\\" : [           (array) unconfirmed transactions used as inputs for this transaction\\n\"\n            \"        \\\"transactionid\\\",    (string) parent transaction id\\n\"\n            \"       ... ]\\n\"\n            \"  }, ...\\n\"\n            \"]\\n\"\n            \"\\nExamples\\n\" +\n            HelpExampleCli(\"getrawmempool\", \"true\") + HelpExampleRpc(\"getrawmempool\", \"true\"));\n\n    bool fVerbose = false;\n    if (params.size() > 0)\n        fVerbose = params[0].get_bool();\n\n    if (fVerbose) {\n        LOCK(mempool.cs);\n        UniValue o(UniValue::VOBJ);\n        BOOST_FOREACH (const PAIRTYPE(uint256, CTxMemPoolEntry) & entry, mempool.mapTx) {\n            const uint256& hash = entry.first;\n            const CTxMemPoolEntry& e = entry.second;\n            UniValue info(UniValue::VOBJ);\n            info.push_back(Pair(\"size\", (int)e.GetTxSize()));\n            info.push_back(Pair(\"fee\", ValueFromAmount(e.GetFee())));\n            info.push_back(Pair(\"time\", e.GetTime()));\n            info.push_back(Pair(\"height\", (int)e.GetHeight()));\n            info.push_back(Pair(\"startingpriority\", e.GetPriority(e.GetHeight())));\n            info.push_back(Pair(\"currentpriority\", e.GetPriority(chainActive.Height())));\n            const CTransaction& tx = e.GetTx();\n            set<string> setDepends;\n            BOOST_FOREACH (const CTxIn& txin, tx.vin) {\n                if (mempool.exists(txin.prevout.hash))\n                    setDepends.insert(txin.prevout.hash.ToString());\n            }\n\n            UniValue depends(UniValue::VARR);\n            BOOST_FOREACH(const string& dep, setDepends) {\n                depends.push_back(dep);\n            }\n\n            info.push_back(Pair(\"depends\", depends));\n            o.push_back(Pair(hash.ToString(), info));\n        }\n        return o;\n    } else {\n        vector<uint256> vtxid;\n        mempool.queryHashes(vtxid);\n\n        UniValue a(UniValue::VARR);\n        BOOST_FOREACH (const uint256& hash, vtxid)\n            a.push_back(hash.ToString());\n\n        return a;\n    }\n}\n\nUniValue getblockhash(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() != 1)\n        throw runtime_error(\n            \"getblockhash index\\n\"\n            \"\\nReturns hash of block in best-block-chain at index provided.\\n\"\n            \"\\nArguments:\\n\"\n            \"1. index         (numeric, required) The block index\\n\"\n            \"\\nResult:\\n\"\n            \"\\\"hash\\\"         (string) The block hash\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"getblockhash\", \"1000\") + HelpExampleRpc(\"getblockhash\", \"1000\"));\n\n    int nHeight = params[0].get_int();\n    if (nHeight < 0 || nHeight > chainActive.Height())\n        throw JSONRPCError(RPC_INVALID_PARAMETER, \"Block height out of range\");\n\n    CBlockIndex* pblockindex = chainActive[nHeight];\n    return pblockindex->GetBlockHash().GetHex();\n}\n\n//------------------cpoy from blockexplorer.cpp\ninline std::string utostr(unsigned int n)\n{\n    return strprintf(\"%u\", n);\n}\n\nstatic std::string makeHRef(const std::string& Str)\n{\n    return \"<a href=\\\"\" + Str + \"\\\">\" + Str + \"</a>\";\n}\n\nCTxOut getPrevOut2(const COutPoint& out)\n{\n    CTransaction tx;\n    uint256 hashBlock;\n    if (GetTransaction(out.hash, tx, hashBlock, true))\n        return tx.vout[out.n];\n    return CTxOut();\n}\n\nstatic CAmount getTxIn(const CTransaction& tx)\n{\n    if (tx.IsCoinBase())\n        return 0;\n\n    CAmount Sum = 0;\n    for (unsigned int i = 0; i < tx.vin.size(); i++)\n        Sum += getPrevOut2(tx.vin[i].prevout).nValue;\n    return Sum;\n}\n\nstatic std::string ValueToString(CAmount nValue, bool AllowNegative = false)\n{\n    if (nValue < 0 && !AllowNegative)\n        return \"<span>unknown</span>\";\n\n    double value  = nValue*1.0/100000000;\n\n    std::string Str = std::to_string(value);\n\n\n    if (AllowNegative && nValue > 0)\n        Str = '+' + Str;\n    else if(AllowNegative && nValue < 0)\n        Str = '-' + Str;\n\n\n    return std::string(\"<span>\") + Str + \"</span>\";\n}\n\nstatic std::string ValueToString2(CAmount nValue, bool AllowNegative = false)\n{\n    if (nValue < 0 && !AllowNegative)\n        return \"unknown\";\n\n    int64_t n_abs = (nValue > 0 ? nValue : -nValue);\n    int64_t quotient = n_abs / COIN;\n    int64_t remainder = n_abs % COIN;\n\n    std::string Str = strprintf(\"%lld.%08lld\",quotient,remainder);\n\n\n    if (AllowNegative && nValue > 0)\n        Str = '+' + Str;\n    else if(AllowNegative && nValue < 0)\n        Str = '-' + Str;\n\n\n    return  Str;\n}\n\nstring FormatScript2(const CScript& script)\n{\n    string ret;\n    CScript::const_iterator it = script.begin();\n    opcodetype op;\n    while (it != script.end()) {\n        CScript::const_iterator it2 = it;\n        vector<unsigned char> vch;\n        if (script.GetOp2(it, op, &vch)) {\n            if (op == OP_0) {\n                ret += \"0 \";\n                continue;\n            } else if ((op >= OP_1 && op <= OP_16) || op == OP_1NEGATE) {\n                ret += strprintf(\"%i \", op - OP_1NEGATE - 1);\n                continue;\n            } else if (op >= OP_NOP && op <= OP_CHECKMULTISIGVERIFY) {\n                string str(GetOpName(op));\n                if (str.substr(0, 3) == string(\"OP_\")) {\n                    ret += str.substr(3, string::npos) + \" \";\n                    continue;\n                }\n            }\n            if (vch.size() > 0) {\n                ret += strprintf(\"0x%x 0x%x \", HexStr(it2, it - vch.size()), HexStr(it - vch.size(), it));\n            } else {\n                ret += strprintf(\"0x%x\", HexStr(it2, it));\n            }\n            continue;\n        }\n        ret += strprintf(\"0x%x \", HexStr(it2, script.end()));\n        break;\n    }\n    return ret.substr(0, ret.size() - 1);\n}\n\nstatic std::string ScriptToString(const CScript& Script, bool Long = false, bool Highlight = false)\n{\n    if (Script.empty())\n        return \"unknown\";\n\n    CTxDestination Dest;\n    CBitcoinAddress Address;\n    if (ExtractDestination(Script, Dest) && Address.Set(Dest)) {\n        if (Highlight)\n            return \"<span class=\\\"addr\\\">\" + Address.ToString() + \"</span>\";\n        else\n            return makeHRef(Address.ToString());\n    } else\n        return Long ? \"<pre>\" + FormatScript2(Script) + \"</pre>\" : \"Non-standard script\";\n}\n\nstatic std::string ScriptToString2(const CScript& Script, bool Long = false, bool Highlight = false)\n{\n    if (Script.empty())\n        return \"unknown\";\n\n    CTxDestination Dest;\n    CBitcoinAddress Address;\n    if (ExtractDestination(Script, Dest) && Address.Set(Dest)) {\n            return Address.ToString();\n    } else\n        return (Long || Script.Find(OP_RETURN)==1) ? FormatScript2(Script): \"Non-standard script\";\n}\n\nstatic std::string TimeToString(uint64_t Time)\n{\n    time_t t;\n    tm* local;\n    char buf[128]= {0};\n\n    t = (long int)Time;\n\n    local = localtime(&t);\n    strftime(buf, 64, \"%Y-%m-%d %H:%M:%S\", local);\n\n    return buf;\n}\n\nstatic std::string makeHTMLTableRow(const std::string* pCells, int n)\n{\n    std::string Result = \"<tr>\";\n    for (int i = 0; i < n; i++) {\n        Result += \"<td class=\\\"d\" + utostr(i) + \"\\\">\";\n        Result += pCells[i];\n        Result += \"</td>\";\n    }\n    Result += \"</tr>\";\n    return Result;\n}\n\nstatic const char* table = \"<table>\";\n\nstatic std::string makeHTMLTable(const std::string* pCells, int nRows, int nColumns)\n{\n    std::string Table = table;\n    for (int i = 0; i < nRows; i++)\n        Table += makeHTMLTableRow(pCells + i * nColumns, nColumns);\n    Table += \"</table>\";\n    return Table;\n}\n\n\nstatic std::string TxToRow(const CTransaction& tx, const CKeyID& Highlight = CKeyID(), const std::string& Prepend = std::string(), int64_t* pSum = NULL)\n{\n    std::string InAmounts, InAddresses, OutAmounts, OutAddresses;\n    int64_t Delta = 0;\n    for (unsigned int j = 0; j < tx.vin.size(); j++) {\n        if (tx.IsCoinBase()) {\n            InAmounts += ValueToString(tx.GetValueOut());\n            InAddresses += \"coinbase\";\n        } else {\n            CTxOut PrevOut = getPrevOut2(tx.vin[j].prevout);\n            InAmounts += ValueToString(PrevOut.nValue);\n            CKeyID KeyID = uint160(1);\n            CTxDestination PrevOutDest;\n            if (ExtractDestination(PrevOut.scriptPubKey, PrevOutDest)) {\n                if (typeid(CKeyID) == PrevOutDest.type()) {\n                    KeyID = boost:: get<CKeyID>(PrevOutDest);\n                }\n            }\n            InAddresses += ScriptToString(PrevOut.scriptPubKey, false, KeyID == Highlight).c_str();\n            if (KeyID == Highlight)\n                Delta -= PrevOut.nValue;\n        }\n        if (j + 1 != tx.vin.size()) {\n            InAmounts += \"<br/>\";\n            InAddresses += \"<br/>\";\n        }\n    }\n    for (unsigned int j = 0; j < tx.vout.size(); j++) {\n        CTxOut Out = tx.vout[j];\n        OutAmounts += ValueToString(Out.nValue);\n        CKeyID KeyID = uint160(1);\n        CTxDestination TxOutDest;\n        if (ExtractDestination(Out.scriptPubKey, TxOutDest)) {\n            if (typeid(CKeyID) == TxOutDest.type()) {\n                KeyID = boost:: get<CKeyID>(TxOutDest);\n            }\n        }\n        OutAddresses += ScriptToString(Out.scriptPubKey, false, KeyID == Highlight);\n        if (KeyID == Highlight)\n            Delta += Out.nValue;\n        if (j + 1 != tx.vout.size()) {\n            OutAmounts += \"<br/>\";\n            OutAddresses += \"<br/>\";\n        }\n    }\n\n    std::string List[8] =\n        {\n            Prepend,\n            makeHRef(tx.GetHash().GetHex()),\n            InAddresses,\n            InAmounts,\n            OutAddresses,\n            OutAmounts,\n            \"\",\n            \"\"\n    };\n\n    int n = sizeof(List) / sizeof(std::string) - 2;\n\n    if (CKeyID() != Highlight) {\n        List[n++] = std::string(\"<font color=\\\"\") + ((Delta > 0) ? \"green\" : \"red\") + \"\\\">\" + ValueToString(Delta, true) + \"</font>\";\n        *pSum += Delta;\n        List[n++] = ValueToString(*pSum);\n        return makeHTMLTableRow(List, n);\n    }\n    return makeHTMLTableRow(List + 1, n - 1);\n}\n\nstatic UniValue TxToRow2(const CTransaction& tx, const CBlockIndex* pIndex, const CScript& Highlight = CScript(), const std::string& Prepend = std::string(), int64_t* pSum = NULL)\n{\n\tconst bool isCoinbase = tx.IsCoinBase();\n\tconst bool isCoinstake = tx.IsCoinStake();\n\tint64_t coinstakeInputAmount = 0;\n\tCAmount totalIn = 0, totalOut = 0;\n    UniValue info(UniValue::VOBJ);\n    UniValue from_array(UniValue::VARR);\n    UniValue to_array(UniValue::VARR);\n\n    int64_t Delta = 0;\n    for (unsigned int j = 0; j < tx.vin.size(); j++) {\n        std::string InAmounts, InAddresses;\n        if (tx.IsCoinBase()) {\n            InAmounts = ValueToString2(0);\n            InAddresses = \"coinbase\";\n        } else if (isCoinstake) {\n            InAmounts = \"Proof of Stake\";\n            InAddresses = \"coinstake\";\n            CTxOut PrevOut = getPrevOut2(tx.vin[j].prevout);\n            coinstakeInputAmount = PrevOut.nValue;\n\t\t\ttotalIn += PrevOut.nValue;\n        } else {\n            CTxOut PrevOut = getPrevOut2(tx.vin[j].prevout);\n\t\t\ttotalIn += PrevOut.nValue;\n            InAmounts = ValueToString2(PrevOut.nValue);\n            InAddresses = ScriptToString2(PrevOut.scriptPubKey, false, PrevOut.scriptPubKey == Highlight).c_str();\n            if (PrevOut.scriptPubKey == Highlight)\n                Delta -= PrevOut.nValue;\n        }\n\n\n        UniValue from_item(UniValue::VOBJ);\n        from_item.push_back(Pair(InAddresses,InAmounts));\n\n        from_array.push_back(from_item);\n\n    }\n\tconst bool isContractTx = isCoinstake && tx.vout.size() > 1 && tx.vout[1].scriptPubKey.HasOpVmHashState();\n\tconst int minerOutIndexFirst = isContractTx ? 2 : 1;\n\tbool hasMinerOutIndexSecond = false;\n    for (unsigned int j = 0; j < tx.vout.size(); j++) {\n\t\tif(isCoinstake && j==0)\n\t\t\tcontinue;\n\n        std::string  OutAmounts, OutAddresses;\n\n        CTxOut Out = tx.vout[j];\n\t\ttotalOut += Out.nValue;\n\n\t\tif(isCoinstake) {\n\t\t\tif(pIndex && pIndex->nHeight >= Entrustment::GetInstance().forkHeightForSpecifyMinerRewardReceiver && Out.nValue == coinstakeInputAmount) {\n\t\t\t\tif(j==minerOutIndexFirst)\n\t\t\t\t\tcontinue;\n\t\t\t}\n\t\t\telse if(j==minerOutIndexFirst) {\n\t\t\t\tif(Out.nValue >= coinstakeInputAmount)\n\t\t\t\t\tOutAmounts = ValueToString2(Out.nValue - coinstakeInputAmount);\n\t\t\t\telse {\n\t\t\t\t\tcoinstakeInputAmount -= Out.nValue;\n\t\t\t\t\thasMinerOutIndexSecond = true;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if(hasMinerOutIndexSecond && j==minerOutIndexFirst+1) {\n\t\t\t\tif(Out.nValue >= coinstakeInputAmount)\n\t\t\t\t\tOutAmounts = ValueToString2(Out.nValue - coinstakeInputAmount);\n\t\t\t}\n\t\t}\n\n\t\tif(OutAmounts.empty())\n        \tOutAmounts = ValueToString2(Out.nValue);\n\n        OutAddresses = ScriptToString2(Out.scriptPubKey, false, Out.scriptPubKey == Highlight);\n        if (Out.scriptPubKey == Highlight)\n            Delta += Out.nValue;\n\n        UniValue to_item(UniValue::VOBJ);\n        to_item.push_back(Pair(OutAddresses,OutAmounts));\n\n        to_array.push_back(to_item);\n    }\n\n\n    info.push_back(Pair(\"txid\", tx.GetHash().GetHex()));\n    info.push_back(Pair(\"type\", tx.GetTypeString()));\n    info.push_back(Pair(\"from_array\",from_array ));\n    info.push_back(Pair(\"to_array\",to_array ));\n    info.push_back(Pair(\"total_out\",(isCoinbase || isCoinstake) ? ValueToString2(totalOut-totalIn) : std::string()));\n\n    return info;\n}\n\nstd::string getexplorerBlockHash2(int64_t Height)\n{\n    std::string genesisblockhash = \"0000041e482b9b9691d98eefb48473405c0b8ec31b76df3797c74a78680ef818\";\n    CBlockIndex* pindexBest = mapBlockIndex[chainActive.Tip()->GetBlockHash()];\n    if ((Height < 0) || (Height > pindexBest->nHeight)) {\n        return genesisblockhash;\n    }\n\n    CBlock block;\n    CBlockIndex* pblockindex = mapBlockIndex[chainActive.Tip()->GetBlockHash()];\n    while (pblockindex->nHeight > Height)\n        pblockindex = pblockindex->pprev;\n    return pblockindex->GetBlockHash().GetHex(); // pblockindex->phashBlock->GetHex();\n}\n\n\nconst CBlockIndex* getexplorerBlockIndex2(int64_t height)\n{\n    std::string hex = getexplorerBlockHash2(height);\n    uint256 hash = uint256S(hex);\n    return mapBlockIndex[hash];\n}\n\nUniValue BlocksToString(int64_t from,int64_t to)\n{\n    UniValue res(UniValue::VOBJ);\n\n    for(int64_t i = from ;i <= to;i++)\n    {\n        const CBlockIndex* pBlock = getexplorerBlockIndex2(i);\n\n        if(pBlock == nullptr)\n            continue;\n\n\n        CBlock block;\n        ReadBlockFromDisk(block, pBlock);\n\n        CAmount totalOut = 0;\n        for (unsigned int i = 0; i < block.vtx.size(); i++) {\n            const CTransaction& tx = block.vtx[i];\n\n            CAmount In = getTxIn(tx);\n            CAmount Out = tx.GetValueOut();\n            if(tx.IsCoinStake())\n\t\t\t\ttotalOut += (Out-In);\n            else\n                totalOut += Out;\n        }\n\n        UniValue info(UniValue::VOBJ);\n        info.push_back(Pair(\"Timestamp\", TimeToString(block.nTime)));\n        info.push_back(Pair(\"Transactions\", itostr(block.vtx.size())));\n        info.push_back(Pair(\"Value\", ValueToString2(totalOut)));\n        info.push_back(Pair(\"Difficulty\", strprintf(\"%.4f\", GetDifficulty(pBlock))));\n\n        res.push_back(Pair(itostr(i), info));\n    }\n\n\n    return res;\n}\n\n\nUniValue BlockToString2(CBlockIndex* pBlock)\n{\n\n\n    if (!pBlock)\n        return \"\";\n\n    UniValue info(UniValue::VOBJ);\n    UniValue tx_array(UniValue::VARR);\n\n    CBlock block;\n    ReadBlockFromDisk(block, pBlock);\n\n\n    CAmount Fees = 0;\n    CAmount OutVolume = 0;\n    CAmount Reward = 0;\n\n    std::string TxLabels[] = {\"Hash\", \"From\", \"Amount\", \"To\", \"Amount\"};\n\n    std::string TxContent = table + makeHTMLTableRow(TxLabels, sizeof(TxLabels) / sizeof(std::string));\n    for (unsigned int i = 0; i < block.vtx.size(); i++) {\n        const CTransaction& tx = block.vtx[i];\n        tx_array.push_back( TxToRow2(tx, pBlock) );\n\n        CAmount In = getTxIn(tx);\n        CAmount Out = tx.GetValueOut();\n        if (tx.IsCoinBase())\n            Reward += Out;\n        else if (In < 0)\n            Fees = -Params().MaxMoneyOut();\n\t\telse if(tx.IsCoinStake()) {\n            OutVolume += (Out-In);\n\t\t}\n        else {\n            Fees += (In - Out);\n            OutVolume += Out;\n        }\n    }\n    TxContent += \"</table>\";\n\n\n    CAmount Generated;\n    if (pBlock->nHeight == 0)\n        Generated = OutVolume;\n    else\n        Generated = GetBlockValue(pBlock->nHeight - 1);\n\n\n//    return TimeToString(block.nTime);\n//    return strprintf(\"%.4f\", GetDifficulty(pBlock));\n\n    std::string BlockContentCells[] =\n        {\n            \"Height\", itostr(pBlock->nHeight),\n            \"Size\", itostr(GetSerializeSize(block, SER_NETWORK, PROTOCOL_VERSION)),\n            \"Number of Transactions\", itostr(block.vtx.size()),\n            \"Value Out\", ValueToString(OutVolume),\n            \"Fees\", ValueToString(Fees),\n            \"Generated\", ValueToString(Generated),\n            \"Timestamp\", TimeToString(block.nTime),\n            \"Difficulty\", strprintf(\"%.4f\", GetDifficulty(pBlock)),\n            \"Bits\", utostr(block.nBits),\n            \"Nonce\", utostr(block.nNonce),\n            \"Version\", itostr(block.nVersion),\n            \"Hash\", \"<pre>\" + block.GetHash().GetHex() + \"</pre>\",\n            \"Merkle Root\", \"<pre>\" + block.hashMerkleRoot.GetHex() + \"</pre>\",\n//             _(\"Hash Whole Block\"), \"<pre>\" + block.hashWholeBlock.GetHex() + \"</pre>\"\n//             _(\"Miner Signature\"), \"<pre>\" + block.MinerSignature.ToString() + \"</pre>\"\n        };\n\n\n    info.push_back(Pair(\"height\",itostr(pBlock->nHeight)));\n    info.push_back(Pair(\"size\",itostr(GetSerializeSize(block, SER_NETWORK, PROTOCOL_VERSION))));\n    info.push_back(Pair(\"tx_num\",itostr(block.vtx.size())));\n    info.push_back(Pair(\"value_out\",ValueToString2(OutVolume)));\n    info.push_back(Pair(\"fees\",ValueToString2(Fees)));\n    info.push_back(Pair(\"generated\",ValueToString2(Generated)));\n    info.push_back(Pair(\"timestamp\",TimeToString(block.nTime)));\n    info.push_back(Pair(\"difficulty\",strprintf(\"%.4f\", GetDifficulty(pBlock))));\n    info.push_back(Pair(\"bits\",utostr(block.nBits)));\n    info.push_back(Pair(\"nonce\",utostr(block.nNonce)));\n    info.push_back(Pair(\"version\",itostr(block.nVersion)));\n    info.push_back(Pair(\"hash\",block.GetHash().GetHex()));\n    info.push_back(Pair(\"merkle_root\",block.hashMerkleRoot.GetHex()));\n    info.push_back(Pair(\"tx_array\",tx_array));\n\n    return info;\n}\n\n\nUniValue getblockhashexplorer(const UniValue& params, bool fHelp)\n{\n    UniValue result(UniValue::VOBJ);\n\n    if (fHelp || params.size() != 1)\n        throw runtime_error(\n            \"getblockhashexplorer index\\n\"\n            \"\\nReturns hash of block in best-block-chain at index provided.\\n\"\n            \"\\nArguments:\\n\"\n            \"1. index         (numeric, required) The block index\\n\"\n            \"\\nResult:\\n\"\n            \"\\\"hash\\\"         (string) The block hash\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"getblockhashexplorer\", \"1000\") + HelpExampleRpc(\"getblockhashexplorer\", \"1000\"));\n\n    int64_t nHeight = (int64_t)(params[0].get_int());\n    if (nHeight < 0 || nHeight > chainActive.Height())\n        throw JSONRPCError(RPC_INVALID_PARAMETER, \"Block height out of range\");\n\n    const CBlockIndex* block_index = getexplorerBlockIndex2(nHeight);\n\n    if(block_index == nullptr)\n        throw JSONRPCError(RPC_INVALID_PARAMETER, \"Block not found\");\n\n\n    result = BlockToString2((CBlockIndex*)block_index);\n\n\n    return result;\n}\n\nvoid getNextIn2(const COutPoint& Out, uint256& Hash, unsigned int& n)\n{\n    // Hash = 0;\n    // n = 0;\n    // if (paddressmap)\n    //    paddressmap->ReadNextIn(Out, Hash, n);\n}\n\nUniValue TxToString2(uint256 BlockHash, const CTransaction& tx)\n{\n\tconst bool isCoinbase = tx.IsCoinBase();\n\tconst bool isCoinstake = tx.IsCoinStake();\n\tint64_t coinstakeInputAmount = 0;\n    CAmount Input = 0;\n    CAmount Output = tx.GetValueOut();\n    UniValue info(UniValue::VOBJ);\n    UniValue in_txes(UniValue::VOBJ);\n    UniValue out_txes(UniValue::VOBJ);\n\tCBlockIndex* pIndex = nullptr;\n\n    BlockMap::iterator iter = mapBlockIndex.find(BlockHash);\n    if (iter != mapBlockIndex.end())\n        pIndex = iter->second;\n\n    std::string InputsContentCells[] = {\"#\", \"Taken from\", \"Address\", \"Amount\"};\n    std::string InputsContent = makeHTMLTableRow(InputsContentCells, sizeof(InputsContentCells) / sizeof(std::string));\n    std::string OutputsContentCells[] = {\"#\", \"Redeemed in\", \"Address\", \"Amount\"};\n    std::string OutputsContent = makeHTMLTableRow(OutputsContentCells, sizeof(OutputsContentCells) / sizeof(std::string));\n\n    if (tx.IsCoinBase()) {\n        std::string InputsContentCells[] =\n            {\n                \"0\",\n                \"coinbase\",\n                \"-\",\n                ValueToString(0)};\n        InputsContent += makeHTMLTableRow(InputsContentCells, sizeof(InputsContentCells) / sizeof(std::string));\n\n        UniValue tx(UniValue::VOBJ);\n        tx.push_back(Pair(\"from\",\"coinbase\"));\n        tx.push_back(Pair(\"number\",itostr(0)));\n        tx.push_back(Pair(\"address\",\"coinbase\"));\n        tx.push_back(Pair(\"amount\",ValueToString2(0)));\n        in_txes.push_back(Pair(\"0\",tx));\n    } else\n        for (unsigned int i = 0; i < tx.vin.size(); i++) {\n            COutPoint Out = tx.vin[i].prevout;\n            CTxOut PrevOut = getPrevOut2(tx.vin[i].prevout);\n            if (PrevOut.nValue < 0)\n                Input = -Params().MaxMoneyOut();\n            else\n                Input += PrevOut.nValue;\n            std::string InputsContentCells[] =\n                {\n                    itostr(i),\n                    \"<span>\" + makeHRef(Out.hash.GetHex()) + \":\" + itostr(Out.n) + \"</span>\",\n                    ScriptToString(PrevOut.scriptPubKey, true),\n                    ValueToString(PrevOut.nValue)};\n            InputsContent += makeHTMLTableRow(InputsContentCells, sizeof(InputsContentCells) / sizeof(std::string));\n\n            UniValue tx(UniValue::VOBJ);\n            tx.push_back(Pair(\"from\",Out.hash.GetHex()));\n            tx.push_back(Pair(\"number\",itostr(Out.n)));\n\t\t\tif(isCoinstake) {\n\t            tx.push_back(Pair(\"address\",\"coinstake\"));\n\t            tx.push_back(Pair(\"amount\",\"Proof of Stake\"));\n\t            coinstakeInputAmount = PrevOut.nValue;\n\t\t\t} else {\n\t            tx.push_back(Pair(\"address\",ScriptToString2(PrevOut.scriptPubKey, true)));\n\t            tx.push_back(Pair(\"amount\",ValueToString2(PrevOut.nValue)));\n\t\t\t}\n            in_txes.push_back(Pair(itostr(i),tx));\n        }\n\n\tconst bool isContractTx = isCoinstake && tx.vout.size() > 1 && tx.vout[1].scriptPubKey.HasOpVmHashState();\n\tconst int minerOutIndexFirst = isContractTx ? 2 : 1;\n\tbool hasMinerOutIndexSecond = false;\n    uint256 TxHash = tx.GetHash();\n    for (unsigned int i = 0; i < tx.vout.size(); i++) {\n\t\tif(isCoinstake && i==0)\n\t\t\tcontinue;\n\n        const CTxOut& Out = tx.vout[i];\n\n\t\tstd::string  OutAmounts;\n\t\tif(isCoinstake) {\n\t\t\tif(pIndex && pIndex->nHeight >= Entrustment::GetInstance().forkHeightForSpecifyMinerRewardReceiver && Out.nValue == coinstakeInputAmount) {\n\t\t\t\tif(i==minerOutIndexFirst)\n\t\t\t\t\tcontinue;\n\t\t\t}\n\t\t\telse if(i==minerOutIndexFirst) {\n\t\t\t\tif(Out.nValue >= coinstakeInputAmount)\n\t\t\t\t\tOutAmounts = ValueToString2(Out.nValue - coinstakeInputAmount);\n\t\t\t\telse {\n\t\t\t\t\tcoinstakeInputAmount -= Out.nValue;\n\t\t\t\t\thasMinerOutIndexSecond = true;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if(hasMinerOutIndexSecond && i==minerOutIndexFirst+1) {\n\t\t\t\tif(Out.nValue >= coinstakeInputAmount)\n\t\t\t\t\tOutAmounts = ValueToString2(Out.nValue - coinstakeInputAmount);\n\t\t\t}\n\t\t}\n\t\tif(OutAmounts.empty())\n        \tOutAmounts = ValueToString2(Out.nValue);\n\n        uint256 HashNext = uint256S(\"0\");\n        unsigned int nNext = 0;\n        bool fAddrIndex = false;\n        getNextIn2(COutPoint(TxHash, i), HashNext, nNext);\n        std::string OutputsContentCells[] =\n            {\n                itostr(i),\n                (HashNext == uint256S(\"0\")) ? (fAddrIndex ? \"no\" : \"unknown\") : \"<span>\" + makeHRef(HashNext.GetHex()) + \":\" + itostr(nNext) + \"</span>\",\n                ScriptToString(Out.scriptPubKey, true),\n                ValueToString(Out.nValue)};\n        OutputsContent += makeHTMLTableRow(OutputsContentCells, sizeof(OutputsContentCells) / sizeof(std::string));\n\n        UniValue tx(UniValue::VOBJ);\n        tx.push_back(Pair(\"redeemed_in\",(HashNext == uint256S(\"0\")) ? (fAddrIndex ? \"no\" : \"unknown\") : makeHRef(HashNext.GetHex()) + \":\" + itostr(nNext) ));\n        tx.push_back(Pair(\"address\",ScriptToString2(Out.scriptPubKey, false)));\n        tx.push_back(Pair(\"amount\",OutAmounts));\n        out_txes.push_back(Pair(itostr(i),tx));\n    }\n\n    InputsContent = table + InputsContent + \"</table>\";\n    OutputsContent = table + OutputsContent + \"</table>\";\n\n    std::string Hash = TxHash.GetHex();\n\n\tif(isCoinstake){\n\t\tInput -= coinstakeInputAmount;\n\t\tOutput -= coinstakeInputAmount;\n\t}\n\n    std::string Labels[] =\n        {\n            \"In Block\", \"\",\n            \"Size\", itostr(GetSerializeSize(tx, SER_NETWORK, PROTOCOL_VERSION)),\n            \"Input\", ValueToString(Input),\n            \"Output\", ValueToString(Output),\n            \"Fees\", ValueToString(isCoinbase || isCoinstake ? 0 : Input - Output),\n            \"Timestamp\", \"\",\n            \"Hash\", \"<pre>\" + Hash + \"</pre>\",\n        };\n\n    info.push_back(Pair(\"size\",itostr(GetSerializeSize(tx, SER_NETWORK, PROTOCOL_VERSION))));\n    info.push_back(Pair(\"input\",ValueToString2(Input)));\n    info.push_back(Pair(\"output\",ValueToString2(Output)));\n    info.push_back(Pair(\"fees\",ValueToString2(isCoinbase || isCoinstake ? 0 : Input - Output)));\n    info.push_back(Pair(\"hash\",Hash));\n\n    info.push_back(Pair(\"out_txes\",out_txes));\n    info.push_back(Pair(\"in_txes\",in_txes));\n\n\n    bool height_time_parsed = false;\n    if (pIndex) {\n       // Labels[0 * 2 + 1] = makeHRef(itostr(pIndex->nHeight));\n       // Labels[5 * 2 + 1] = TimeToString(pIndex->nTime);\n        height_time_parsed = true;\n        info.pushKV(\"height\",itostr(pIndex->nHeight));\n        info.pushKV(\"timestamp\",TimeToString(pIndex->nTime));\n    }\n\n    if(!height_time_parsed){\n        info.pushKV(\"height\",\"\");\n        info.pushKV(\"timestamp\",\"\");\n    }\n//    std::string Content;\n//    Content += \"<h2>Transaction&nbsp;<span>\" + Hash + \"</span></h2>\";\n//    Content += makeHTMLTable(Labels, sizeof(Labels) / (2 * sizeof(std::string)), 2);\n//    Content += \"</br>\";\n//    Content += \"<h3>Inputs</h3>\";\n//    Content += InputsContent;\n//    Content += \"</br>\";\n//    Content += \"<h3>Outputs</h3>\";\n//    Content += OutputsContent;\n\n    info.push_back(Pair(\"total_out\",(isCoinbase || isCoinstake) ? ValueToString2(Output-Input) : std::string()));\n\n    return info;\n}\n\n\nUniValue gettxexplorer(const UniValue& params, bool fHelp)\n{\n    UniValue result(UniValue::VOBJ);\n\n    if (fHelp || params.size() != 1)\n        throw runtime_error(\n            \"gettxexplorer txid\\n\"\n            \"\\nReturns tx of txid in best-block-chain.\\n\"\n            \"\\nArguments:\\n\"\n            \"1. txid         (string, required) The txid\\n\"\n            \"\\nResult:\\n\"\n            \"\\\"hash\\\"         (string) The block txid\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"gettxexplorer\", \"dae45bd9250b18a940cde56c92ac9821d868cb386ee5a18fbb85885a911438c5\") + HelpExampleRpc(\"gettxexplorer\", \"dae45bd9250b18a940cde56c92ac9821d868cb386ee5a18fbb85885a911438c5\"));\n\n    std::string strHash = params[0].get_str();\n    uint256 hash(strHash);\n\n    CTransaction tx;\n    uint256 hashBlock = 0;\n   // std::string tx_str;\n    if (GetTransaction(hash, tx, hashBlock, true)) {\n        result = TxToString2(hashBlock, tx);\n    }\n    else\n    {\n        throw JSONRPCError(RPC_INVALID_PARAMETER, \"Tx not found\");\n    }\n\n//    result.push_back(Pair(\"txid\", strHash));\n//    result.push_back(Pair(\"tx_str\", tx_str));\n\n    return result;\n}\n\n\nbool AddressToString2(const CBitcoinAddress& Address, UniValue & Result)\n{\n    CAmount     Balance     = 0;\n    CAmount     TotalRecv   = 0;\n    CAmount     TotalSent   = 0;\n    CAmount     NetIncome   = 0;\n\n    CKeyID      KeyID;\n\n    UniValue    uvTransactions(UniValue::VARR);\n\n    if (!Address.GetKeyID(KeyID))\n        return false;\n\n    if (!fAddrIndex) {\n        return false;\n    } else {\n        std::vector<CDiskTxPos> vTxDiskPos;\n        paddressmap->GetTxs(vTxDiskPos, CScriptID(KeyID));\n        BOOST_FOREACH (const CDiskTxPos& diskpos, vTxDiskPos)\n        {\n            CBlock block;\n            CTransaction tx;\n\n            ReadTransaction(diskpos, tx, block);\n            BlockMap::iterator iter = mapBlockIndex.find(block.GetHash());\n            if (iter == mapBlockIndex.end())\n                continue;\n            CBlockIndex* pindex = (*iter).second;\n            if (!pindex || !chainActive.Contains(pindex))\n                continue;\n\n            UniValue uvTx(UniValue::VOBJ);\n            UniValue uvTxIns(UniValue::VARR);\n            UniValue uvTxOuts(UniValue::VARR);\n\n            NetIncome = 0;\n            for (const auto & txin : tx.vin) {\n                UniValue    uvTxIn(UniValue::VARR);\n\n                if (tx.IsCoinBase()) {\n                    uvTxIn.push_back(\"coinbase\");\n                    uvTxIn.push_back(ValueFromAmount(tx.GetValueOut()));\n                } else {\n                    CTxOut PrevOut = getPrevOut(txin);\n\n                    CKeyID  PrevKeyID;\n                    CTxDestination PrevTxDest;\n                    CBitcoinAddress PrevAddress;\n                    if (ExtractDestination(PrevOut.scriptPubKey, PrevTxDest) && PrevAddress.Set(PrevTxDest)) {\n                        if (typeid(CKeyID) == PrevTxDest.type()) {\n                            PrevKeyID = boost::get<CKeyID>(PrevTxDest);\n\n                            if (KeyID == PrevKeyID) {\n                                NetIncome -= PrevOut.nValue;\n                                TotalSent += PrevOut.nValue;\n                            }\n                        }\n                        uvTxIn.push_back(PrevAddress.ToString());\n                    } else {\n                        uvTxIn.push_back(FormatScript(PrevOut.scriptPubKey));\n                    }\n                    uvTxIn.push_back(ValueFromAmount(PrevOut.nValue));\n                }\n\n                uvTxIns.push_back(uvTxIn);\n            }\n\n            for (const auto & txout : tx.vout) {\n                UniValue    uvTxOut(UniValue::VARR);\n\n                CKeyID  TxOutKeyID;\n                CTxDestination TxOutDest;\n                CBitcoinAddress TxOutAddress;\n                if (ExtractDestination(txout.scriptPubKey, TxOutDest) && TxOutAddress.Set(TxOutDest)) {\n                    if (typeid(CKeyID) == TxOutDest.type()) {\n                        TxOutKeyID = boost::get<CKeyID>(TxOutDest);\n\n                        if (KeyID == TxOutKeyID) {\n                            NetIncome += txout.nValue;\n                            TotalRecv += txout.nValue;\n                        }\n                    }\n                    uvTxOut.push_back(TxOutAddress.ToString());\n                } else {\n                    uvTxOut.push_back(FormatScript(txout.scriptPubKey));\n                }\n                uvTxOut.push_back(ValueFromAmount(txout.nValue));\n\n                uvTxOuts.push_back(uvTxOut);\n            }\n\n            uvTx.push_back(Pair(\"Date\", TimeToString(pindex->nTime)));\n            uvTx.push_back(Pair(\"Hash\", tx.GetHash().GetHex()));\n            uvTx.push_back(std::make_pair(\"From\", uvTxIns));\n            uvTx.push_back(std::make_pair(\"To\", uvTxOuts));\n            uvTx.push_back(std::make_pair(\"Delta\", ValueFromAmount(NetIncome)));\n            uvTx.push_back(std::make_pair(\"Balance\", ValueFromAmount(TotalRecv - TotalSent)));\n\n            uvTransactions.push_back(uvTx);\n        }\n\n        Result.push_back(Pair(\"address\", Address.ToString()));\n        Result.push_back(std::make_pair(\"received\", ValueFromAmount(TotalRecv)));\n        Result.push_back(std::make_pair(\"sent\", ValueFromAmount(TotalSent)));\n        Result.push_back(std::make_pair(\"balance\", ValueFromAmount(TotalRecv - TotalSent)));\n        Result.push_back(std::make_pair(\"transactions\", uvTransactions));\n    }\n\n    return true;\n}\n\nUniValue getblocksinfoexplorer(const UniValue& params, bool fHelp)\n{\n\n    if (fHelp || params.size() != 2)\n        throw runtime_error(\n            \"getblocksinfoexplorer from to\\n\"\n            \"\\nReturns blocksinfo from height \\\"from\\\" to height \\\"to\\\" in best-block-chain.\\n\"\n            \"\\nArguments:\\n\"\n            \"1. from         (numeric, required) The height from\\n\"\n            \"2. to         (numeric, required) The height to\\n\"\n            \"\\nResult:\\n\"\n            \"\\\"hash\\\"         (string) The height from\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"getblocksinfoexplorer\", \"10 25\") + HelpExampleRpc(\"getblocksinfoexplorer\",\"10 25\"));\n\n\tLogPrint(\"explorer\",\"getblocksinfoexplorer | info | param[0]: isObj=%d, isStr=%d, isNum=%d\\n\",params[0].isObject(),params[0].isStr(),params[0].isNum());\n\tLogPrint(\"explorer\",\"getblocksinfoexplorer | info | param[1]: isObj=%d, isStr=%d, isNum=%d\\n\",params[1].isObject(),params[1].isStr(),params[1].isNum());\n\n\tint64_t from = 0, to = 0;\n\tif(params[0].isStr())\n\t\tfrom = atoi64(params[0].get_str());\n\telse\n\t\tfrom = (int64_t)(params[0].get_int());\n\tLogPrint(\"explorer\",\"getblocksinfoexplorer | info | from=%lld\\n\",from);\n\n\tif(params[1].isStr())\n\t\tto = atoi64(params[1].get_str());\n\telse\n\t\tto = (int64_t)(params[1].get_int());\n\tLogPrint(\"explorer\",\"getblocksinfoexplorer | info | to=%lld\\n\",to);\n\n\n    if (from < 0 || from > chainActive.Height())\n        throw JSONRPCError(RPC_INVALID_PARAMETER, \"Block from out of range\");\n\n    if (to < 0 || to > chainActive.Height())\n        throw JSONRPCError(RPC_INVALID_PARAMETER, \"Block to out of range\");\n\n    if (to < from)\n        throw JSONRPCError(RPC_INVALID_PARAMETER, \"Block to out of range\");\n\n    return BlocksToString(from,to);\n\n}\n\n\nUniValue getqueryexplorer(const UniValue& params, bool fHelp)\n{\n    UniValue result(UniValue::VOBJ);\n\n    if (fHelp || params.size() != 1)\n        throw runtime_error(\n            \"getqueryexplorer hash\\n\"\n            \"\\nReturns info of hash in best-block-chain.\\n\"\n            \"\\nArguments:\\n\"\n            \"1. hash         (string, required) The hash\\n\"\n            \"\\nResult:\\n\"\n            \"\\\"hash\\\"         (string) The hash\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"getqueryexplorer\", \"8e6d5b52c0242972c285a0046d5904991887ef528d45ae043afdb02c4737786c\") + HelpExampleRpc(\"getqueryexplorer\", \"8e6d5b52c0242972c285a0046d5904991887ef528d45ae043afdb02c4737786c\"));\n\n    std::string strHash;\n\n\tLogPrint(\"explorer\",\"getqueryexplorer | info | param[0]: isObj=%d, isStr=%d\\n\",params[0].isObject(),params[0].isStr());\n\n    try\n    {\n        strHash = params[0].get_str();\n    }\n    catch(std::runtime_error& e)\n    {\n        int64_t nHeight = (int64_t)(params[0].get_int());\n        if (nHeight < 0 || nHeight > chainActive.Height())\n            throw JSONRPCError(RPC_INVALID_PARAMETER, \"Block height out of range\");\n\n        const CBlockIndex* block_index = getexplorerBlockIndex2(nHeight);\n        if(block_index == nullptr)\n            throw JSONRPCError(RPC_INVALID_PARAMETER, \"Block not found\");\n\n        result = BlockToString2((CBlockIndex*)block_index);\n        result.push_back(Pair(\"type\",\"block\"));\n        return result;\n\n    }\n\n    // If the query is not an integer, assume it is a block hash\n    uint256 hash = uint256S(strHash);\n\n    // std::map<uint256, CBlockIndex*>::iterator iter = mapBlockIndex.find(hash);\n    BlockMap::iterator iter = mapBlockIndex.find(hash);\n    if (iter != mapBlockIndex.end()) {\n        result = BlockToString2(iter->second);\n        result.push_back(Pair(\"type\",\"block\"));\n        return result;\n    }\n\n    // If the query is neither an integer nor a block hash, assume a transaction hash\n    CTransaction tx;\n    uint256 hashBlock = 0;\n   // std::string tx_str;\n    if (GetTransaction(hash, tx, hashBlock, true)) {\n        result = TxToString2(hashBlock, tx);\n        result.push_back(Pair(\"type\",\"transaction\"));\n//        result.push_back(Pair(\"tx_str\", tx_str));\n        return result;\n    }\n\n\n    // If the query is not an integer, nor a block hash, nor a transaction hash, assume an address\n    CBitcoinAddress Address;\n    std::string address_str;\n\n    Address.SetString(strHash);\n    if (Address.IsValid()) {\n        if (AddressToString2(Address, result))\n        {\n            result.push_back(Pair(\"type\",\"address\"));\n            return result;\n        }\n    }\n\n    throw JSONRPCError(RPC_INVALID_PARAMETER, \"Query Invalid\");\n\n\n    return result;\n\n}\n\nUniValue getaddressbalance(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() < 3)\n        throw runtime_error(\n            \"getaddressbalance startheight endheight address1 [address2] [...]\\n\"\n            \"\\nReturns balance of address between height range [start,end). \\n\"\n            \"\\nArguments:\\n\"\n            \"1. startheight (string, required) The start height of blockchain\\n\"\n\t\t\t\"2. endheight \t(string, required) The end height of blockchain.\\n\"\n\t\t\t\"3. address1\t(string, required) The GKC address\\n\"\n\t\t\t\"n. addressn\t(string, optional) The GKC address\\n\"\n            \"\\nResult:\\n\"\n\t\t\t\"\\\"balance\\\"\t (string) The balance of address within blockheight range\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"getaddressbalance\", \"0 99999 UWTD1rHBFXG5dtvNDuabnXSFfh7W8XhUeD\") + HelpExampleRpc(\"getaddressbalance\", \"0 99999 UWTD1rHBFXG5dtvNDuabnXSFfh7W8XhUeD\"));\n\n\tif (!fAddrIndex)\n\t\tthrow JSONRPCError(RPC_INVALID_PARAMETER, \"This RPC supported in explorer only!\");\n\n\tBlockHeight startheight = 0, endheight = 0;\n\tstd::map<CBitcoinAddress,CAmount> addrMap;\n\n\tstartheight = atoi(params[0].get_str());\n\tendheight = atoi(params[1].get_str());\n\tint addrLen = params.size() - 2;\n\tfor(int i=0; i<addrLen; i++){\n\t\taddrMap[CBitcoinAddress(params[2+i].get_str())] = 0;\n\t}\n\n    UniValue result(UniValue::VOBJ);\n\tCAmount totalBalance = 0;\n\tUniValue balanceArray(UniValue::VARR);\n\tfor(std::map<CBitcoinAddress,CAmount>::iterator addrIt = addrMap.begin(); addrIt != addrMap.end(); addrIt++){\n\n\t\tconst CBitcoinAddress addr = addrIt->first;\n\t\tCAmount& balance = addrIt->second;\n\n\t\tCKeyID keyID;\n\t\tassert(balance == 0);\n\n\t\tif (!addr.GetKeyID(keyID))\n\t\t\tthrow JSONRPCError(RPC_INVALID_PARAMETER, \"Invalid GKC address\");\n\n\t\tstd::vector<CDiskTxPos> vTxDiskPos;\n\t\tpaddressmap->GetTxs(vTxDiskPos, CScriptID(keyID));\n\t\tBOOST_FOREACH (const CDiskTxPos& diskpos, vTxDiskPos)\n\t\t{\n\t\t\tCBlock block;\n\t\t\tCTransaction tx;\n\n\t\t\tReadTransaction(diskpos, tx, block);\n\t\t\tBlockMap::iterator iter = mapBlockIndex.find(block.GetHash());\n\t\t\tif (iter == mapBlockIndex.end())\n\t\t\t\tcontinue;\n\t\t\tCBlockIndex* pindex = (*iter).second;\n\t\t\tif (!pindex || !chainActive.Contains(pindex))\n\t\t\t\tcontinue;\n\t\t\tif(pindex->nHeight < startheight || endheight <= pindex->nHeight)\n\t\t\t\tcontinue;\n\n\t\t\tCAmount NetIncome = 0;\n\t\t\tfor (const auto & txin : tx.vin) {\n\t\t\t\tif (tx.IsCoinBase())\n\t\t\t\t\tcontinue;\n\t\t\t\tCTxOut PrevOut = getPrevOut(txin);\n\t\t\t\tCKeyID\tPrevKeyID;\n\t\t\t\tCTxDestination PrevTxDest;\n\t\t\t\tCBitcoinAddress PrevAddress;\n\t\t\t\tif (ExtractDestination(PrevOut.scriptPubKey, PrevTxDest) && PrevAddress.Set(PrevTxDest)) {\n\t\t\t\t\tif (typeid(CKeyID) == PrevTxDest.type()) {\n\t\t\t\t\t\tPrevKeyID = boost::get<CKeyID>(PrevTxDest);\n\t\t\t\t\t\tif (keyID == PrevKeyID) {\n\t\t\t\t\t\t\tNetIncome -= PrevOut.nValue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfor (const auto & txout : tx.vout) {\n\t\t\t\tCKeyID\tTxOutKeyID;\n\t\t\t\tCTxDestination TxOutDest;\n\t\t\t\tCBitcoinAddress TxOutAddress;\n\t\t\t\tif (ExtractDestination(txout.scriptPubKey, TxOutDest) && TxOutAddress.Set(TxOutDest)) {\n\t\t\t\t\tif (typeid(CKeyID) == TxOutDest.type()) {\n\t\t\t\t\t\tTxOutKeyID = boost::get<CKeyID>(TxOutDest);\n\n\t\t\t\t\t\tif (keyID == TxOutKeyID) {\n\t\t\t\t\t\t\tNetIncome += txout.nValue;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tbalance += NetIncome;\n\t\t}\n\n\t\tUniValue balanceObj(UniValue::VOBJ);\n\t\tbalanceObj.push_back(Pair(addr.ToString(),ValueFromAmount(balance).write()));\n\n\t\tbalanceArray.push_back(balanceObj);\n\n\t\ttotalBalance += balance;\n\t}\n\n\tif(addrLen == 1) {\n\t\tresult = ValueFromAmount(totalBalance).write();\n\t} else {\n\t\tresult.push_back(Pair(\"addr_balance\",balanceArray));\n\t\tresult.push_back(Pair(\"total\",ValueFromAmount(totalBalance).write()));\n\t}\n\n\treturn result;\n}\n\nUniValue getaddressexplorer(const UniValue& params, bool fHelp)\n{\n    UniValue result(UniValue::VOBJ);\n\n    if (fHelp || params.size() != 1)\n        throw runtime_error(\n            \"getaddressexplorer address\\n\"\n            \"\\nReturns txes of address in best-block-chain.\\n\"\n            \"\\nArguments:\\n\"\n            \"1. txid         (string, required) The address\\n\"\n            \"\\nResult:\\n\"\n            \"\\\"hash\\\"         (string) The address\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"getaddressexplorer\", \"UWTD1rHBFXG5dtvNDuabnXSFfh7W8XhUeD\") + HelpExampleRpc(\"getaddressexplorer\", \"UWTD1rHBFXG5dtvNDuabnXSFfh7W8XhUeD\"));\n\n    std::string strHash = params[0].get_str();\n    std::string address_str;\n    CBitcoinAddress Address;\n\n    Address.SetString(strHash);\n    if (Address.IsValid()) {\n        if (!AddressToString2(Address, result))\n            throw JSONRPCError(RPC_INVALID_PARAMETER, \"Address No Txes\");\n    }\n    else\n    {\n        throw JSONRPCError(RPC_INVALID_PARAMETER, \"Address Invalid\");\n    }\n\n    return result;\n}\n\n\nUniValue getblock(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() < 1 || params.size() > 2)\n        throw runtime_error(\n            \"getblock \\\"hash\\\" ( verbose )\\n\"\n            \"\\nIf verbose is false, returns a string that is serialized, hex-encoded data for block 'hash'.\\n\"\n            \"If verbose is true, returns an Object with information about block <hash>.\\n\"\n            \"\\nArguments:\\n\"\n            \"1. \\\"hash\\\"          (string, required) The block hash\\n\"\n            \"2. verbose           (boolean, optional, default=true) true for a json object, false for the hex encoded data\\n\"\n            \"\\nResult (for verbose = true):\\n\"\n            \"{\\n\"\n            \"  \\\"hash\\\" : \\\"hash\\\",     (string) the block hash (same as provided)\\n\"\n            \"  \\\"confirmations\\\" : n,   (numeric) The number of confirmations, or -1 if the block is not on the main chain\\n\"\n            \"  \\\"size\\\" : n,            (numeric) The block size\\n\"\n            \"  \\\"height\\\" : n,          (numeric) The block height or index\\n\"\n            \"  \\\"version\\\" : n,         (numeric) The block version\\n\"\n            \"  \\\"merkleroot\\\" : \\\"xxxx\\\", (string) The merkle root\\n\"\n            \"  \\\"tx\\\" : [               (array of string) The transaction ids\\n\"\n            \"     \\\"transactionid\\\"     (string) The transaction id\\n\"\n            \"     ,...\\n\"\n            \"  ],\\n\"\n            \"  \\\"time\\\" : ttt,          (numeric) The block time in seconds since epoch (Jan 1 1970 GMT)\\n\"\n            \"  \\\"nonce\\\" : n,           (numeric) The nonce\\n\"\n            \"  \\\"bits\\\" : \\\"1d00ffff\\\", (string) The bits\\n\"\n            \"  \\\"difficulty\\\" : x.xxx,  (numeric) The difficulty\\n\"\n            \"  \\\"previousblockhash\\\" : \\\"hash\\\",  (string) The hash of the previous block\\n\"\n            \"  \\\"nextblockhash\\\" : \\\"hash\\\"       (string) The hash of the next block\\n\"\n            \"  \\\"moneysupply\\\" : \\\"supply\\\"       (numeric) The money supply when this block was added to the blockchain\\n\"\n            \"  \\\"zGKCsupply\\\" :\\n\"\n            \"  {\\n\"\n            \"     \\\"1\\\" : n,            (numeric) supply of 1 zGKC denomination\\n\"\n            \"     \\\"5\\\" : n,            (numeric) supply of 5 zGKC denomination\\n\"\n            \"     \\\"10\\\" : n,           (numeric) supply of 10 zGKC denomination\\n\"\n            \"     \\\"50\\\" : n,           (numeric) supply of 50 zGKC denomination\\n\"\n            \"     \\\"100\\\" : n,          (numeric) supply of 100 zGKC denomination\\n\"\n            \"     \\\"500\\\" : n,          (numeric) supply of 500 zGKC denomination\\n\"\n            \"     \\\"1000\\\" : n,         (numeric) supply of 1000 zGKC denomination\\n\"\n            \"     \\\"5000\\\" : n,         (numeric) supply of 5000 zGKC denomination\\n\"\n            \"     \\\"total\\\" : n,        (numeric) The total supply of all zGKC denominations\\n\"\n            \"  }\\n\"\n            \"}\\n\"\n            \"\\nResult (for verbose=false):\\n\"\n            \"\\\"data\\\"             (string) A string that is serialized, hex-encoded data for block 'hash'.\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"getblock\", \"\\\"00000000000fd08c2fb661d2fcb0d49abb3a91e5f27082ce64feed3b4dede2e2\\\"\") + HelpExampleRpc(\"getblock\", \"\\\"00000000000fd08c2fb661d2fcb0d49abb3a91e5f27082ce64feed3b4dede2e2\\\"\"));\n\n    std::string strHash = params[0].get_str();\n    uint256 hash(strHash);\n\n    bool fVerbose = true;\n    if (params.size() > 1)\n        fVerbose = params[1].get_bool();\n\n    if (mapBlockIndex.count(hash) == 0)\n        throw JSONRPCError(RPC_INVALID_ADDRESS_OR_KEY, \"Block not found\");\n\n    CBlock block;\n    CBlockIndex* pblockindex = mapBlockIndex[hash];\n\n    if (!ReadBlockFromDisk(block, pblockindex))\n        throw JSONRPCError(RPC_INTERNAL_ERROR, \"Can't read block from disk\");\n\n    if (!fVerbose) {\n        CDataStream ssBlock(SER_NETWORK, PROTOCOL_VERSION);\n        ssBlock << block;\n        std::string strHex = HexStr(ssBlock.begin(), ssBlock.end());\n        return strHex;\n    }\n\n    return blockToJSON(block, pblockindex);\n}\n\nUniValue getblockbalance(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() < 1)\n        throw runtime_error(\"getblockbalance blockhash [address] [address] [...]\");\n\n\tuint256 blockhash;\n\tstd::set<CBitcoinAddress> addrFilter;\n\n\tblockhash.SetHex(params[0].get_str());\n\tint addrLen = params.size() - 1;\n\tfor(int i=0; i<addrLen; i++){\n\t\taddrFilter.insert(CBitcoinAddress(params[1+i].get_str()));\n\t}\n\tconst bool useFilter = !addrFilter.empty();\n\n\tif (mapBlockIndex.count(blockhash) == 0)\n\t\tthrow JSONRPCError(RPC_INVALID_ADDRESS_OR_KEY, \"Block not found\");\n\n\tCBlock block;\n\tCBlockIndex* pblockindex = mapBlockIndex[blockhash];\n\n\tif (!ReadBlockFromDisk(block, pblockindex))\n\t\tthrow JSONRPCError(RPC_INTERNAL_ERROR, \"Can't read block from disk\");\n\n    std::map<CBitcoinAddress,std::pair<CAmount,CAmount> > addrBalanceMap;\n    for (const CTransaction& tx: block.vtx) {\n\t\tCAmount NetIncome = 0;\n\t\tfor (const CTxIn & txin : tx.vin) {\n\t\t\tCTxOut PrevOut = getPrevOut(txin);\n\t\t\tCTxDestination PrevTxDest;\n\t\t\tCBitcoinAddress PrevAddress;\n\t\t\tif (ExtractDestination(PrevOut.scriptPubKey, PrevTxDest) && PrevAddress.Set(PrevTxDest)) {\n\t\t\t\tif(useFilter && addrFilter.count(PrevAddress)==0)\n\t\t\t\t\tcontinue;\n\t\t\t\tif(addrBalanceMap.count(PrevAddress)==0)\n\t\t\t\t\taddrBalanceMap[PrevAddress] = std::make_pair<CAmount,CAmount>(0,0);\n\t\t\t\taddrBalanceMap[PrevAddress].first += PrevOut.nValue;\n\t\t\t}\n\t\t}\n\t\tfor (const CTxOut & txout : tx.vout) {\n\t\t\tCTxDestination TxOutDest;\n\t\t\tCBitcoinAddress TxOutAddress;\n\t\t\tif (ExtractDestination(txout.scriptPubKey, TxOutDest) && TxOutAddress.Set(TxOutDest)) {\n\t\t\t\tif(useFilter && addrFilter.count(TxOutAddress)==0)\n\t\t\t\t\tcontinue;\n\t\t\t\tif(addrBalanceMap.count(TxOutAddress)==0)\n\t\t\t\t\taddrBalanceMap[TxOutAddress] = std::make_pair<CAmount,CAmount>(0,0);\n\t\t\t\taddrBalanceMap[TxOutAddress].second += txout.nValue;\n\t\t\t}\n\t\t}\n    }\n\n\tUniValue result(UniValue::VARR);\n\tfor(std::map<CBitcoinAddress,std::pair<CAmount,CAmount>>::const_iterator it = addrBalanceMap.begin(); it != addrBalanceMap.end(); it++){\n\t\tUniValue addrBalanceObj(UniValue::VOBJ);\n\t\taddrBalanceObj.push_back(Pair(\"address\",it->first.ToString()));\n\t\taddrBalanceObj.push_back(Pair(\"send\",ValueFromAmount(it->second.first).write()));\n\t\taddrBalanceObj.push_back(Pair(\"recv\",ValueFromAmount(it->second.second).write()));\n\t\taddrBalanceObj.push_back(Pair(\"balance\",ValueFromAmount(it->second.second-it->second.first).write()));\n\t\tresult.push_back(addrBalanceObj);\n\t}\n\n\treturn result;\n}\n\nUniValue getblockheader(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() < 1 || params.size() > 2)\n        throw runtime_error(\n            \"getblockheader \\\"hash\\\" ( verbose )\\n\"\n            \"\\nIf verbose is false, returns a string that is serialized, hex-encoded data for block 'hash' header.\\n\"\n            \"If verbose is true, returns an Object with information about block <hash> header.\\n\"\n            \"\\nArguments:\\n\"\n            \"1. \\\"hash\\\"          (string, required) The block hash\\n\"\n            \"2. verbose           (boolean, optional, default=true) true for a json object, false for the hex encoded data\\n\"\n            \"\\nResult (for verbose = true):\\n\"\n            \"{\\n\"\n            \"  \\\"version\\\" : n,         (numeric) The block version\\n\"\n            \"  \\\"previousblockhash\\\" : \\\"hash\\\",  (string) The hash of the previous block\\n\"\n            \"  \\\"merkleroot\\\" : \\\"xxxx\\\", (string) The merkle root\\n\"\n            \"  \\\"time\\\" : ttt,          (numeric) The block time in seconds since epoch (Jan 1 1970 GMT)\\n\"\n            \"  \\\"bits\\\" : \\\"1d00ffff\\\", (string) The bits\\n\"\n            \"  \\\"nonce\\\" : n,           (numeric) The nonce\\n\"\n            \"}\\n\"\n            \"\\nResult (for verbose=false):\\n\"\n            \"\\\"data\\\"             (string) A string that is serialized, hex-encoded data for block 'hash' header.\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"getblockheader\", \"\\\"00000000000fd08c2fb661d2fcb0d49abb3a91e5f27082ce64feed3b4dede2e2\\\"\") + HelpExampleRpc(\"getblockheader\", \"\\\"00000000000fd08c2fb661d2fcb0d49abb3a91e5f27082ce64feed3b4dede2e2\\\"\"));\n\n    std::string strHash = params[0].get_str();\n    uint256 hash(strHash);\n\n    bool fVerbose = true;\n    if (params.size() > 1)\n        fVerbose = params[1].get_bool();\n\n    if (mapBlockIndex.count(hash) == 0)\n        throw JSONRPCError(RPC_INVALID_ADDRESS_OR_KEY, \"Block not found\");\n\n    CBlock block;\n    CBlockIndex* pblockindex = mapBlockIndex[hash];\n\n    if (!ReadBlockFromDisk(block, pblockindex))\n        throw JSONRPCError(RPC_INTERNAL_ERROR, \"Can't read block from disk\");\n\n    if (!fVerbose) {\n        CDataStream ssBlock(SER_NETWORK, PROTOCOL_VERSION);\n        ssBlock << block.GetBlockHeader();\n        std::string strHex = HexStr(ssBlock.begin(), ssBlock.end());\n        return strHex;\n    }\n\n    return blockHeaderToJSON(block, pblockindex);\n}\n\nUniValue gettxoutsetinfo(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() != 0)\n        throw runtime_error(\n            \"gettxoutsetinfo\\n\"\n            \"\\nReturns statistics about the unspent transaction output set.\\n\"\n            \"Note this call may take some time.\\n\"\n            \"\\nResult:\\n\"\n            \"{\\n\"\n            \"  \\\"height\\\":n,     (numeric) The current block height (index)\\n\"\n            \"  \\\"bestblock\\\": \\\"hex\\\",   (string) the best block hash hex\\n\"\n            \"  \\\"transactions\\\": n,      (numeric) The number of transactions\\n\"\n            \"  \\\"txouts\\\": n,            (numeric) The number of output transactions\\n\"\n            \"  \\\"bytes_serialized\\\": n,  (numeric) The serialized size\\n\"\n            \"  \\\"hash_serialized\\\": \\\"hash\\\",   (string) The serialized hash\\n\"\n            \"  \\\"total_amount\\\": x.xxx          (numeric) The total amount\\n\"\n            \"}\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"gettxoutsetinfo\", \"\") + HelpExampleRpc(\"gettxoutsetinfo\", \"\"));\n\n    UniValue ret(UniValue::VOBJ);\n\n    CCoinsStats stats;\n    FlushStateToDisk();\n    if (pcoinsTip->GetStats(stats)) {\n        ret.push_back(Pair(\"height\", (int64_t)stats.nHeight));\n        ret.push_back(Pair(\"bestblock\", stats.hashBlock.GetHex()));\n        ret.push_back(Pair(\"transactions\", (int64_t)stats.nTransactions));\n        ret.push_back(Pair(\"txouts\", (int64_t)stats.nTransactionOutputs));\n        ret.push_back(Pair(\"bytes_serialized\", (int64_t)stats.nSerializedSize));\n        ret.push_back(Pair(\"hash_serialized\", stats.hashSerialized.GetHex()));\n        ret.push_back(Pair(\"total_amount\", ValueFromAmount(stats.nTotalAmount)));\n    }\n    return ret;\n}\n\nUniValue gettxout(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() < 2 || params.size() > 3)\n        throw runtime_error(\n            \"gettxout \\\"txid\\\" n ( includemempool )\\n\"\n            \"\\nReturns details about an unspent transaction output.\\n\"\n            \"\\nArguments:\\n\"\n            \"1. \\\"txid\\\"       (string, required) The transaction id\\n\"\n            \"2. n              (numeric, required) vout value\\n\"\n            \"3. includemempool  (boolean, optional) Whether to included the mem pool\\n\"\n            \"\\nResult:\\n\"\n            \"{\\n\"\n            \"  \\\"bestblock\\\" : \\\"hash\\\",    (string) the block hash\\n\"\n            \"  \\\"confirmations\\\" : n,       (numeric) The number of confirmations\\n\"\n            \"  \\\"value\\\" : x.xxx,           (numeric) The transaction value in btc\\n\"\n            \"  \\\"scriptPubKey\\\" : {         (json object)\\n\"\n            \"     \\\"asm\\\" : \\\"code\\\",       (string) \\n\"\n            \"     \\\"hex\\\" : \\\"hex\\\",        (string) \\n\"\n            \"     \\\"reqSigs\\\" : n,          (numeric) Number of required signatures\\n\"\n            \"     \\\"type\\\" : \\\"pubkeyhash\\\", (string) The type, eg pubkeyhash\\n\"\n            \"     \\\"addresses\\\" : [          (array of string) array of gkc addresses\\n\"\n            \"     \\\"gkcaddress\\\"   \t \t(string) gkc address\\n\"\n            \"        ,...\\n\"\n            \"     ]\\n\"\n            \"  },\\n\"\n            \"  \\\"version\\\" : n,            (numeric) The version\\n\"\n            \"  \\\"coinbase\\\" : true|false   (boolean) Coinbase or not\\n\"\n            \"}\\n\"\n\n            \"\\nExamples:\\n\"\n            \"\\nGet unspent transactions\\n\" +\n            HelpExampleCli(\"listunspent\", \"\") +\n            \"\\nView the details\\n\" + HelpExampleCli(\"gettxout\", \"\\\"txid\\\" 1\") +\n            \"\\nAs a json rpc call\\n\" + HelpExampleRpc(\"gettxout\", \"\\\"txid\\\", 1\"));\n\n    UniValue ret(UniValue::VOBJ);\n\n    std::string strHash = params[0].get_str();\n    uint256 hash(strHash);\n    int n = params[1].get_int();\n    bool fMempool = true;\n    if (params.size() > 2)\n        fMempool = params[2].get_bool();\n\n    CCoins coins;\n    if (fMempool) {\n        LOCK(mempool.cs);\n        CCoinsViewMemPool view(pcoinsTip, mempool);\n        if (!view.GetCoins(hash, coins))\n            return NullUniValue;\n        mempool.pruneSpent(hash, coins); // TODO: this should be done by the CCoinsViewMemPool\n    } else {\n        if (!pcoinsTip->GetCoins(hash, coins))\n            return NullUniValue;\n    }\n    if (n < 0 || (unsigned int)n >= coins.vout.size() || coins.vout[n].IsNull())\n        return NullUniValue;\n\n    BlockMap::iterator it = mapBlockIndex.find(pcoinsTip->GetBestBlock());\n    CBlockIndex* pindex = it->second;\n    ret.push_back(Pair(\"bestblock\", pindex->GetBlockHash().GetHex()));\n    if ((unsigned int)coins.nHeight == MEMPOOL_HEIGHT)\n        ret.push_back(Pair(\"confirmations\", 0));\n    else\n        ret.push_back(Pair(\"confirmations\", pindex->nHeight - coins.nHeight + 1));\n    ret.push_back(Pair(\"value\", ValueFromAmount(coins.vout[n].nValue)));\n    UniValue o(UniValue::VOBJ);\n    ScriptPubKeyToJSON(coins.vout[n].scriptPubKey, o, true);\n    ret.push_back(Pair(\"scriptPubKey\", o));\n    ret.push_back(Pair(\"version\", coins.nVersion));\n    ret.push_back(Pair(\"coinbase\", coins.fCoinBase));\n#ifdef DPOS\n\tconst CTxOut& txout = coins.vout[n];\n    ret.push_back(Pair(\"type\", txout.GetTypeString()));\n#endif\n\n    return ret;\n}\n\nUniValue verifychain(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() > 2)\n        throw runtime_error(\n            \"verifychain ( numblocks )\\n\"\n            \"\\nVerifies blockchain database.\\n\"\n            \"\\nArguments:\\n\"\n            \"1. numblocks    (numeric, optional, default=288, 0=all) The number of blocks to check.\\n\"\n            \"\\nResult:\\n\"\n            \"true|false       (boolean) Verified or not\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"verifychain\", \"\") + HelpExampleRpc(\"verifychain\", \"\"));\n\n    int nCheckLevel = 4;\n    int nCheckDepth = GetArg(\"-checkblocks\", 288);\n    if (params.size() > 0)\n        nCheckDepth = params[1].get_int();\n\n    return CVerifyDB().VerifyDB(pcoinsTip, nCheckLevel, nCheckDepth);\n}\n\n///gkc-vm\nUniValue getaccountinfo(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() < 1)\n        throw std::runtime_error(\n                \"getaccountinfo \\\"address\\\"\\n\"\n                \"\\nArgument:\\n\"\n                \"1. \\\"address\\\"          (string, required) The account address\\n\");\n\n    bool IsEnabled = (chainActive.Tip()->nVersion > ZEROCOIN_VERSION);\n    if (!IsEnabled)\n        throw JSONRPCError(RPC_INTERNAL_ERROR, \"not arrive to the contract height,disabled\");\n\n    LOCK(cs_main);\n\n    std::string strAddr = params[0].get_str();\n    if (strAddr.size() != 40 || !IsHex(strAddr))\n        throw JSONRPCError(RPC_INVALID_ADDRESS_OR_KEY, \"Incorrect address\");\n\n    if (!AddressInUse(strAddr))\n        throw JSONRPCError(RPC_INVALID_ADDRESS_OR_KEY, \"Address does not exist\");\n\n    dev::Address addrAccount(strAddr);\n\n    UniValue result(UniValue::VOBJ);\n\n    result.push_back(Pair(\"address\", strAddr));\n    result.push_back(Pair(\"balance\", GetContractBalance(addrAccount)));\n    std::vector<uint8_t> code = GetContractCode(addrAccount);\n\n    std::map<dev::h256, std::pair<dev::u256, dev::u256>> storage = GetStorageByAddress(strAddr);\n\n    UniValue storageUV(UniValue::VOBJ);\n    for (auto j: storage)\n    {\n        UniValue e(UniValue::VOBJ);\n        e.pushKV(dev::toHex(dev::h256(j.second.first)), dev::toHex(dev::h256(j.second.second)));\n        storageUV.push_back(Pair(j.first.hex(), e));\n    }\n\n    result.push_back(Pair(\"storage\", storageUV));\n\n    result.push_back(Pair(\"code\", HexStr(code.begin(), code.end())));\n\n    dev::h256 hash;\n    uint32_t nVout;\n    dev::u256 value;\n    uint8_t alive;\n    if (GetContractVin(addrAccount, hash, nVout, value, alive))\n    {\n        UniValue vin(UniValue::VOBJ);\n        valtype vchHash(hash.asBytes());\n        vin.push_back(Pair(\"hash\", HexStr(vchHash.rbegin(), vchHash.rend())));\n        vin.push_back(Pair(\"nVout\", uint64_t(nVout)));\n        vin.push_back(Pair(\"value\", uint64_t(value)));\n        vin.push_back(Pair(\"alive\", uint8_t(alive)));\n        result.push_back(Pair(\"vin\", vin));\n    }\n\n    return result;\n}\n\nUniValue getstorage(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() < 1)\n        throw std::runtime_error(\n                \"getstorage \\\"address\\\"\\n\"\n                \"\\nArgument:\\n\"\n                \"1. \\\"address\\\"          (string, required) The address to get the storage from\\n\"\n                \"2. \\\"blockNum\\\"         (string, optional) Number of block to get state from, \\\"latest\\\" keyword supported. Latest if not passed.\\n\"\n                \"3. \\\"index\\\"            (number, optional) Zero-based index position of the storage\\n\");\n\n    bool IsEnabled = (chainActive.Tip()->nVersion > ZEROCOIN_VERSION);\n    if (!IsEnabled)\n        throw JSONRPCError(RPC_INTERNAL_ERROR, \"not arrive to the contract height,disabled\");\n\n    LOCK(cs_main);\n\n    std::string strAddr = params[0].get_str();\n    if (strAddr.size() != 40 || !IsHex(strAddr))\n        throw JSONRPCError(RPC_INVALID_ADDRESS_OR_KEY, \"Incorrect address\");\n\n    if (params.size() > 1)\n    {\n        if (params[1].isNum())\n        {\n            auto blockNum = params[1].get_int();\n            if ((blockNum < 0 && blockNum != -1) || blockNum > chainActive.Height())\n                throw JSONRPCError(RPC_INVALID_PARAMS, \"Incorrect block number\");\n\n            if (blockNum != -1)\n            {\n                uint256 hashStateRoot;\n                uint256 hashUTXORoot;\n                CBlock block;\n                if (!ReadBlockFromDisk(block, chainActive[blockNum]))\n                {\n                    std::ostringstream stringStream;\n                    stringStream << \"ReadBlockFromDisk failed at hegiht \" << chainActive[blockNum]->nHeight << \" hash: \" << chainActive[blockNum]->GetBlockHash().ToString();\n                    throw JSONRPCError(RPC_INVALID_PARAMS, stringStream.str());\n                } else\n                {\n                    if(block.GetVMState(hashStateRoot, hashUTXORoot) == RET_VM_STATE_ERR){\n                        throw JSONRPCError(RPC_INVALID_PARAMS, \"Incorrect GetVMState\");\n                    }\n                }\n                SetTemporaryState(hashStateRoot, hashUTXORoot);\n                //                ifContractObj->SetTemporaryState(chainActive[blockNum]->hashStateRoot,\n                //                                                 chainActive[blockNum]->hashUTXORoot);\n            }\n        } else\n        {\n            throw JSONRPCError(RPC_INVALID_PARAMS, \"Incorrect block number\");\n        }\n    }\n\n    if (!AddressInUse(strAddr))\n        throw JSONRPCError(RPC_INVALID_ADDRESS_OR_KEY, \"Address does not exist\");\n\n    UniValue result(UniValue::VOBJ);\n\n    bool onlyIndex = params.size() > 2;\n    unsigned index = 0;\n    if (onlyIndex)\n        index = params[2].get_int();\n\n    std::map<dev::h256, std::pair<dev::u256, dev::u256>> storage = GetStorageByAddress(strAddr);\n    if (onlyIndex)\n    {\n        if (index >= storage.size())\n        {\n            std::ostringstream stringStream;\n            stringStream << \"Storage size: \" << storage.size() << \" got index: \" << index;\n            throw JSONRPCError(RPC_INVALID_PARAMS, stringStream.str());\n        }\n        auto elem = std::next(storage.begin(), index);\n        UniValue e(UniValue::VOBJ);\n\n        storage = {{elem->first, {elem->second.first, elem->second.second}}};\n    }\n    for (const auto &j: storage)\n    {\n        UniValue e(UniValue::VOBJ);\n        e.pushKV(dev::toHex(dev::h256(j.second.first)), dev::toHex(dev::h256(j.second.second)));\n        result.push_back(Pair(j.first.hex(), e));\n    }\n\n    return result;\n}\n\n\nUniValue callcontract(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() < 2)\n        throw std::runtime_error(\n                \"callcontract \\\"address\\\" \\\"data\\\" ( address )\\n\"\n                \"\\nArgument:\\n\"\n                \"1. \\\"address\\\"          (string, required) The account address\\n\"\n                \"2. \\\"data\\\"             (string, required) The data hex string\\n\"\n                \"3. address              (string, optional) The sender address hex string\\n\"\n                \"4. gasLimit  (numeric or string, optional) gasLimit, default: \" +\n                i64tostr(DEFAULT_GAS_LIMIT_OP_SEND) + \"\\n\");\n\n    bool IsEnabled = (chainActive.Tip()->nVersion > ZEROCOIN_VERSION);\n    if (!IsEnabled)\n         throw JSONRPCError(RPC_INTERNAL_ERROR, \"not arrive to the contract height,disabled\");\n\n    LOCK(cs_main);\n\n    std::string strAddr = params[0].get_str();\n    std::string data = params[1].get_str();\n\n    if (!IsHex(data))\n        throw JSONRPCError(RPC_TYPE_ERROR, \"Invalid data (data not hex)\");\n\n    if (strAddr.size() != 40 || !IsHex(strAddr))\n        throw JSONRPCError(RPC_INVALID_ADDRESS_OR_KEY, \"Incorrect address\");\n\n\n    CBlockIndex * pBlockIndex = chainActive.Tip();\n    if (pBlockIndex->nHeight < Params().Contract_StartHeight())\n        throw JSONRPCError(RPC_INVALID_REQUEST, \"contract not enabled.\");\n\n    if (!AddressInUse(strAddr))\n        throw JSONRPCError(RPC_INVALID_ADDRESS_OR_KEY, \"Address does not exist\");\n\n    string sender = \"\";\n    if (params.size() == 3)\n    {\n        CBitcoinAddress btcSenderAddress(params[2].get_str());\n        if (btcSenderAddress.IsValid())\n        {\n            CKeyID keyid;\n            btcSenderAddress.GetKeyID(keyid);\n\n            sender = HexStr(valtype(keyid.begin(), keyid.end()));\n        } else\n        {\n            sender = params[2].get_str();\n        }\n    }\n    uint64_t gasLimit = 0;\n    if (params.size() == 4)\n    {\n        //        gasLimit = params[3].get_int();\n        if (params[3].isNum())\n        {\n            gasLimit = params[3].get_int64();\n        } else if (params[3].isStr())\n        {\n            gasLimit = atoi64(params[3].get_str());\n        } else\n        {\n            throw JSONRPCError(RPC_TYPE_ERROR, \"JSON value for gasLimit is not (numeric or string)\");\n        }\n\n    }\n\n    UniValue result(UniValue::VOBJ);\n    result.push_back(Pair(\"address\", strAddr));\n\n    RPCCallContract(result, strAddr, ParseHex(data), sender, gasLimit);\n\n    return result;\n}\n\nUniValue SimpleCallContract(const std::string& contractAddr, const std::string& function)\n{\n\tUniValue params(UniValue::VARR);\n\tparams.push_back(contractAddr);\n\tparams.push_back(function);\n\treturn callcontract(params,false);\n}\n\nuint256 GetOutputNumber(const std::string& outputStr)\n{\n\tif(outputStr.length()==64)\n\t{\n\t\treturn uint256(outputStr);\n\t}\n\treturn 0;\n}\n\nstd::string GetOutputAddress(const std::string& outputStr)\n{\n\tif(outputStr.length()==64)\n\t{\n\t\treturn outputStr.substr(24);\n\t}\n\treturn 0;\n}\n\nstd::string GetOutputString(const std::string& outputStr)\n{\n\tstd::string result;\n\tif(outputStr.length()==192)\n\t{\n\t\tchar temp[65]={0};\n\t\tconst char *script = outputStr.c_str();\n\t\tmemcpy(temp, script, 64);\n\t\tint aa;\n\t\tsscanf(temp,\"%x\",&aa);\n\n\t\tmemcpy(temp, script+64, 64);\n\t\tsscanf(temp,\"%x\",&aa);\n\n\t\tmemcpy(temp, script+128, 64);\n\t\tint i=0;\n\t\tint array[32];\n\t\twhile(i<aa)\n\t\t{\n\t\t\tchar t[3] = {0};\n\t\t\tmemcpy(t, temp+i*2, 2);\n\t\t\tint b = 0;\n\t\t\tsscanf(t,\"%x\",&b);\n\t\t\tresult.push_back((char)b);\n\t\t\ti++;\n\t\t}\n\t}\n\treturn result;\n}\n\nUniValue gettokeninfo(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() < 1)\n        throw std::runtime_error(\n                \"gettokeninfo \\\"address\\\"\\n\"\n                \"\\nArgument:\\n\"\n                \"1. \\\"address\\\"          (string, required) The ERC20(Token) contract address\\n\");\n\n\tstd::string contractAddr = params[0].get_str();\n\n\tstd::string fn_name(\"06fdde03\");\n\tstd::string fn_totalSupply(\"18160ddd\");\n\tstd::string fn_totalFee(\"1df4ccfc\");\n\tstd::string fn_decimals(\"313ce567\");\n\tstd::string fn_version(\"54fd4d50\");\n\tstd::string fn_symbol(\"95d89b41\");\n\tstd::string fn_owner(\"8da5cb5b\");\n\n\tUniValue callResult;\n\tcallResult = SimpleCallContract(contractAddr,fn_name);\n\tstd::string name = GetOutputString(callResult[\"executionResult\"][\"output\"].get_str());\n\tcallResult = SimpleCallContract(contractAddr,fn_totalSupply);\n\tint64_t totalSupply = GetOutputNumber(callResult[\"executionResult\"][\"output\"].get_str()).Get64();\n\tcallResult = SimpleCallContract(contractAddr,fn_totalFee);\n\tint64_t totalFee = GetOutputNumber(callResult[\"executionResult\"][\"output\"].get_str()).Get64();\n\tcallResult = SimpleCallContract(contractAddr,fn_decimals);\n\tint64_t decimals = GetOutputNumber(callResult[\"executionResult\"][\"output\"].get_str()).Get64();\n\tcallResult = SimpleCallContract(contractAddr,fn_version);\n\tstd::string version = GetOutputString(callResult[\"executionResult\"][\"output\"].get_str());\n\tcallResult = SimpleCallContract(contractAddr,fn_symbol);\n\tstd::string symbol = GetOutputString(callResult[\"executionResult\"][\"output\"].get_str());\n\tcallResult = SimpleCallContract(contractAddr,fn_owner);\n\tstd::string owner = GetOutputAddress(callResult[\"executionResult\"][\"output\"].get_str());\n\n\n\tUniValue result(UniValue::VOBJ);\n\tresult.push_back(Pair(\"name\",name));\n\tresult.push_back(Pair(\"totalSupply\",totalSupply));\n\tresult.push_back(Pair(\"totalFee\",totalFee));\n\tresult.push_back(Pair(\"decimals\",decimals));\n\tresult.push_back(Pair(\"version\",version));\n\tresult.push_back(Pair(\"symbol\",symbol));\n\tresult.push_back(Pair(\"owner\",owner));\n\n\treturn result;\n}\n\nvoid assignJSON(UniValue& entry, const TransactionReceiptInfo& resExec) {\n    entry.push_back(Pair(\"blockHash\", resExec.blockHash.GetHex()));\n    entry.push_back(Pair(\"blockNumber\", uint64_t(resExec.blockNumber)));\n    entry.push_back(Pair(\"transactionHash\", resExec.transactionHash.GetHex()));\n    entry.push_back(Pair(\"transactionIndex\", uint64_t(resExec.transactionIndex)));\n    entry.push_back(Pair(\"from\", resExec.from.hex()));\n    entry.push_back(Pair(\"to\", resExec.to.hex()));\n    entry.push_back(Pair(\"cumulativeGasUsed\", CAmount(resExec.cumulativeGasUsed)));\n    entry.push_back(Pair(\"gasUsed\", CAmount(resExec.gasUsed)));\n    entry.push_back(Pair(\"contractAddress\", resExec.contractAddress.hex()));\n    std::stringstream ss;\n    ss << resExec.excepted;\n    entry.push_back(Pair(\"excepted\",ss.str()));\n}\n\nvoid assignJSON(UniValue& logEntry, const dev::eth::LogEntry& log,\n        bool includeAddress) {\n    if (includeAddress) {\n        logEntry.push_back(Pair(\"address\", log.address.hex()));\n    }\n\n    UniValue topics(UniValue::VARR);\n    for (dev::h256 hash : log.topics) {\n        topics.push_back(hash.hex());\n    }\n    logEntry.push_back(Pair(\"topics\", topics));\n    logEntry.push_back(Pair(\"data\", HexStr(log.data)));\n}\n\nvoid transactionReceiptInfoToJSON(const TransactionReceiptInfo& resExec, UniValue& entry) {\n    assignJSON(entry, resExec);\n\n    const auto& logs = resExec.logs;\n    UniValue logEntries(UniValue::VARR);\n    for(const auto&log : logs){\n        UniValue logEntry(UniValue::VOBJ);\n        assignJSON(logEntry, log, true);\n        logEntries.push_back(logEntry);\n    }\n    entry.push_back(Pair(\"log\", logEntries));\n}\n\n\n//////-------gkc\n\n\nsize_t parseUInt(const UniValue &val, size_t defaultVal)\n{\n    if (val.isNull())\n    {\n        return defaultVal;\n    } else\n    {\n    \tint n = -1;\n\t\tif(val.isStr())\n\t\t\tn = atoi(val.get_str().c_str());\n\t\telse if(val.isNum())\n\t\t\tn = val.get_int();\n\t\telse\n\t\t\tn = 0;\n        if (n < 0)\n        {\n            throw JSONRPCError(RPC_INVALID_PARAMS, \"Expects unsigned integer\");\n        }\n\n        return n;\n    }\n}\n\nint parseInt(const UniValue &val, int defaultVal)\n{\n\tint n = defaultVal;\n\tif(val.isNum())\n\t\tn = val.get_int();\n\telse if(val.isStr())\n\t\tn = atoi(val.get_str().c_str());\n    return n;\n}\n\nbool parseBool(const UniValue &val, bool defaultVal)\n{\n\tbool b = defaultVal;\n\tif(val.isBool())\n\t\tb = val.get_bool();\n\telse if(val.isStr())\n\t\tb = (val.get_str() != \"false\" && val.get_str() != \"0\");\n\telse if(val.isNum())\n\t\tb = (val.get_int() != 0);\n    return b;\n}\n\nint parseBlockHeight(const UniValue &val)\n{\n    if (val.isStr())\n    {\n        auto blockKey = val.get_str();\n\n        if (blockKey == \"latest\")\n        {\n            return chainActive.Height();;\n        } else\n        {\n            throw JSONRPCError(RPC_INVALID_PARAMS, \"invalid block number\");\n        }\n    }\n\n    if (val.isNum())\n    {\n        int blockHeight = val.get_int();\n\n        if (blockHeight < 0)\n        {\n            return chainActive.Height();;\n        }\n\n        return blockHeight;\n    }\n\n    throw JSONRPCError(RPC_INVALID_PARAMS, \"invalid block number\");\n}\n\n\nint parseBlockHeight(const UniValue &val, int defaultVal)\n{\n    if (val.isNull())\n    {\n        return defaultVal;\n    } else\n    {\n        return parseBlockHeight(val);\n    }\n}\ndev::h160 parseParamH160(const UniValue &val)\n{\n    if (!val.isStr())\n    {\n        throw JSONRPCError(RPC_INVALID_PARAMS, \"Invalid hex 160\");\n    }\n\n    auto addrStr = val.get_str();\n\n    if (addrStr.length() != 40 || !IsHex(addrStr))\n    {\n        throw JSONRPCError(RPC_INVALID_PARAMS, \"Invalid hex 160 string\");\n    }\n    return dev::h160(addrStr);\n}\n\nvoid parseParam(const UniValue &val, std::vector<dev::h160> &h160s)\n{\n    if (val.isNull())\n    {\n        return;\n    }\n\n    // Treat a string as an array of length 1\n    if (val.isStr())\n    {\n        h160s.push_back(parseParamH160(val.get_str()));\n        return;\n    }\n\n    if (!val.isArray())\n    {\n        throw JSONRPCError(RPC_INVALID_PARAMS, \"Expect an array of hex 160 strings\");\n    }\n\n    auto vals = val.getValues();\n    h160s.resize(vals.size());\n\n    std::transform(vals.begin(), vals.end(), h160s.begin(), [](UniValue val) -> dev::h160\n    {\n        return parseParamH160(val);\n    });\n}\n\nvoid parseParam(const UniValue &val, std::set<dev::h160> &h160s)\n{\n    std::vector<dev::h160> v;\n    parseParam(val, v);\n    h160s.insert(v.begin(), v.end());\n}\n\nvoid parseParam(const UniValue &val, std::vector<boost::optional<dev::h256>> &h256s)\n{\n    if (val.isNull())\n    {\n        return;\n    }\n\n    if (!val.isArray())\n    {\n        throw JSONRPCError(RPC_INVALID_PARAMS, \"Expect an array of hex 256 strings\");\n    }\n\n    auto vals = val.getValues();\n    h256s.resize(vals.size());\n\n    std::transform(vals.begin(), vals.end(), h256s.begin(), [](UniValue val) -> boost::optional<dev::h256>\n    {\n        if (val.isNull())\n        {\n            return boost::optional<dev::h256>();\n        }\n\n        if (!val.isStr())\n        {\n            throw JSONRPCError(RPC_INVALID_PARAMS, \"Invalid hex 256 string\");\n        }\n\n        auto addrStr = val.get_str();\n\n        if (addrStr.length() != 64 || !IsHex(addrStr))\n        {\n            throw JSONRPCError(RPC_INVALID_PARAMS, \"Invalid hex 256 string\");\n        }\n\n        return boost::optional<dev::h256>(dev::h256(addrStr));\n    });\n}\n\nclass SearchLogsParams\n{\npublic:\n    size_t fromBlock;\n    size_t toBlock;\n    size_t minconf;\n\n    std::set<dev::h160> addresses;\n    std::vector<boost::optional<dev::h256>> topics;\n\n    SearchLogsParams(const UniValue &params)\n    {\n      //  std::unique_lock<std::mutex> lock(cs_blockchange);\n\n        setFromBlock(params[0]);\n        setToBlock(params[1]);\n\n        parseParam(params[2][\"addresses\"], addresses);\n        parseParam(params[3][\"topics\"], topics);\n\n        minconf = parseUInt(params[4], 0);\n    }\n\nprivate:\n    void setFromBlock(const UniValue &val)\n    {\n        if (!val.isNull())\n        {\n            fromBlock = parseBlockHeight(val);\n        } else\n        {\n            fromBlock = chainActive.Height();;\n        }\n    }\n\n    void setToBlock(const UniValue &val)\n    {\n        if (!val.isNull())\n        {\n            toBlock = parseBlockHeight(val);\n        } else\n        {\n            toBlock = chainActive.Height();;\n        }\n    }\n\n};\n/// ----------gkc\n\n\nUniValue searchlogs(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() < 2 || params.size() > 8)\n        throw std::runtime_error(\n                \"searchlogs <fromBlock> <toBlock> (address) (topics)\\n\"\n                \"requires -logevents to be enabled\"\n                \"\\nArgument:\\n\"\n                \"1. \\\"fromBlock\\\"        (numeric, required) The number of the earliest block (latest may be given to mean the most recent block).\\n\"\n                \"2. \\\"toBlock\\\"          (string, required) The number of the latest block (-1 may be given to mean the most recent block).\\n\"\n                \"3. \\\"address\\\"          (string, optional) An address or a list of addresses to only get logs from particular account(s).\\n\"\n                \"4. \\\"topics\\\"           (string, optional) An array of values from which at least one must appear in the log entries. The order is important, if you want to leave topics out use null, e.g. [\\\"null\\\", \\\"0x00...\\\"]. \\n\"\n                \"5. \\\"minconf\\\"          (uint, optional, default=0) Minimal number of confirmations before a log is returned\\n\"\n\t\t\t\t\"6. \\\"reverseOrder\\\"\t (bool, optional, default=\\\"false\\\") \\n\"\n\t\t\t\t\"7. \\\"offset\\\"\t\t\t (numeric, optional, default=0) \\n\"\n\t\t\t\t\"8. \\\"count\\\"\t\t\t (numeric, optional, default=-1) \\n\"\n                \"\\nExamples:\\n\"\n                + HelpExampleCli(\"searchlogs\",\n                \"0 100 '{\\\"addresses\\\": [\\\"12ae42729af478ca92c8c66773a3e32115717be4\\\"]}' '{\\\"topics\\\": [\\\"null\\\",\\\"b436c2bf863ccd7b8f63171201efd4792066b4ce8e543dde9c3e9e9ab98e216c\\\"]}'\")\n                + HelpExampleRpc(\"searchlogs\",\n                \"0 100 {\\\"addresses\\\": [\\\"12ae42729af478ca92c8c66773a3e32115717be4\\\"]} {\\\"topics\\\": [\\\"null\\\",\\\"b436c2bf863ccd7b8f63171201efd4792066b4ce8e543dde9c3e9e9ab98e216c\\\"]}\"));\n\n    bool IsEnabled = (chainActive.Tip()->nVersion > ZEROCOIN_VERSION);\n    if (!IsEnabled)\n        throw JSONRPCError(RPC_INTERNAL_ERROR, \"not arrive to the contract height,disabled\");\n\n    if (!fLogEvents)\n        throw JSONRPCError(RPC_INTERNAL_ERROR, \"Events indexing disabled\");\n\n    int curheight = 0;\n\n    LOCK(cs_main);\n\n    SearchLogsParams params_(params);\n\tbool reverseOrder = parseBool(params[5],false);\n\tint offset = parseInt(params[6],0);\n\tint count = parseInt(params[7],-1);\n\n    std::vector<std::vector<uint256>> hashesToBlock;\n    curheight = pblocktree->ReadHeightIndex(params_.fromBlock, params_.toBlock, params_.minconf,\n                                            hashesToBlock,\n                                            params_.addresses);\n\n\n    if (curheight == -1)\n    {\n        throw JSONRPCError(RPC_INVALID_PARAMETER, \"Incorrect params\");\n    }\n\n    UniValue result(UniValue::VARR);\n    auto topics = params_.topics;\n\n\tif(reverseOrder)\n\t\tstd::reverse(hashesToBlock.begin(),hashesToBlock.end());\n\tint index = 0;\n\tbool fEnd = false;\n    for (auto &hashesTx : hashesToBlock)\n    {\n\t\tif(reverseOrder)\n\t\t\tstd::reverse(hashesTx.begin(),hashesTx.end());\n        for (const auto &e : hashesTx)\n        {\n            std::vector<TransactionReceiptInfo> receipts = GetResult(e);\n\n            for (const auto &receipt : receipts)\n            {\n                if (receipt.logs.empty())\n                {\n                    continue;\n                }\n\n                if (!topics.empty())\n                {\n                    for (size_t i = 0; i < topics.size(); i++)\n                    {\n                        const auto &tc = topics[i];\n\n                        if (!tc)\n                        {\n                            continue;\n                        }\n\n                        for (const auto &log: receipt.logs)\n                        {\n                            auto filterTopicContent = tc.get();\n\n                            if (i >= log.topics.size())\n                            {\n                                continue;\n                            }\n\n                            if (filterTopicContent == log.topics[i])\n                            {\n                                goto push;\n                            }\n                        }\n                    }\n\n                    // Skip the log if none of the topics are matched\n                    continue;\n                }\n\n                push:\n\n\t\t\t\tif(index < offset){\n\t\t\t\t\tindex++;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n                UniValue tri(UniValue::VOBJ);\n                transactionReceiptInfoToJSON(receipt, tri);\n                result.push_back(tri);\n\n\t\t\t\tindex++;\n\t\t\t\tif(count > -1 && index >= offset+count)\n\t\t\t\t\tfEnd = true;\n\n\t\t\t\tif(fEnd)\n\t\t\t\t\tbreak;\n            }\n\t\t\tif(fEnd)\n\t\t\t\tbreak;\n        }\n\t\tif(fEnd)\n\t\t\tbreak;\n    }\n\n    return result;\n}\n\nUniValue gettransactionreceipt(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() < 1)\n        throw std::runtime_error(\n                \"gettransactionreceipt \\\"hash\\\"\\n\"\n                \"requires -logevents to be enabled\"\n                \"\\nArgument:\\n\"\n                \"1. \\\"hash\\\"          (string, required) The transaction hash\\n\");\n\n    bool IsEnabled = (chainActive.Tip()->nVersion > ZEROCOIN_VERSION);\n    if (!IsEnabled)\n        throw JSONRPCError(RPC_INTERNAL_ERROR, \"not arrive to the contract height,disabled\");\n\n    if (!fLogEvents)\n        throw JSONRPCError(RPC_INTERNAL_ERROR, \"Events indexing disabled\");\n\n    LOCK(cs_main);\n\n    std::string hashTemp = params[0].get_str();\n    if (hashTemp.size() != 64)\n    {\n        throw JSONRPCError(RPC_INVALID_ADDRESS_OR_KEY, \"Incorrect hash\");\n    }\n\n    uint256 hash(uint256S(hashTemp));\n\n    std::vector<TransactionReceiptInfo> transactionReceiptInfo = GetResult(hash);\n\n    UniValue result(UniValue::VARR);\n    for (TransactionReceiptInfo &t : transactionReceiptInfo)\n    {\n        UniValue tri(UniValue::VOBJ);\n        transactionReceiptInfoToJSON(t, tri);\n        result.push_back(tri);\n    }\n\n    return result;\n}\n\nUniValue listcontracts(const UniValue& params, bool fHelp)\n{\n    if (fHelp)\n        throw std::runtime_error(\n                \"listcontracts (start maxDisplay)\\n\"\n                \"\\nArgument:\\n\"\n                \"1. start     (numeric or string, optional) The starting account index, default 1\\n\"\n                \"2. maxDisplay       (numeric or string, optional) Max accounts to list, default 20\\n\");\n\n    bool IsEnabled = (chainActive.Tip()->nVersion > ZEROCOIN_VERSION);\n    if (!IsEnabled)\n        throw JSONRPCError(RPC_INTERNAL_ERROR, \"not arrive to the contract height,disabled\");\n\n    LOCK(cs_main);\n\n    int start = 1;\n    if (params.size() > 0)\n    {\n        start = params[0].get_int();\n        if (start <= 0)\n            throw JSONRPCError(RPC_TYPE_ERROR, \"Invalid start, min=1\");\n    }\n\n    int maxDisplay = 20;\n    if (params.size() > 1)\n    {\n        maxDisplay = params[1].get_int();\n        if (maxDisplay <= 0)\n            throw JSONRPCError(RPC_TYPE_ERROR, \"Invalid maxDisplay\");\n    }\n\n    UniValue result(UniValue::VOBJ);\n\n    std::unordered_map<dev::h160, dev::u256> map = GetContractList();\n    int contractsCount = (int)map.size();\n\n    if (contractsCount > 0 && start > contractsCount)\n        throw JSONRPCError(RPC_TYPE_ERROR, \"start greater than max index \" + itostr(contractsCount));\n\n    int itStartPos = std::min(start - 1, contractsCount);\n    int i = 0;\n\n    for (auto it = std::next(map.begin(), itStartPos); it != map.end(); it++)\n    {\n        CAmount balance = GetContractBalance(it->first);\n        result.push_back(Pair(it->first.hex(), ValueFromAmount(balance)));\n        i++;\n        if (i == maxDisplay)\n            break;\n    }\n\n    return result;\n}\n\n///\n\nUniValue getblockchaininfo(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() != 0)\n        throw runtime_error(\n            \"getblockchaininfo\\n\"\n            \"Returns an object containing various state info regarding block chain processing.\\n\"\n            \"\\nResult:\\n\"\n            \"{\\n\"\n            \"  \\\"chain\\\": \\\"xxxx\\\",        (string) current network name as defined in BIP70 (main, test, regtest)\\n\"\n            \"  \\\"blocks\\\": xxxxxx,         (numeric) the current number of blocks processed in the server\\n\"\n            \"  \\\"headers\\\": xxxxxx,        (numeric) the current number of headers we have validated\\n\"\n            \"  \\\"bestblockhash\\\": \\\"...\\\", (string) the hash of the currently best block\\n\"\n            \"  \\\"difficulty\\\": xxxxxx,     (numeric) the current difficulty\\n\"\n            \"  \\\"verificationprogress\\\": xxxx, (numeric) estimate of verification progress [0..1]\\n\"\n            \"  \\\"chainwork\\\": \\\"xxxx\\\"     (string) total amount of work in active chain, in hexadecimal\\n\"\n            \"}\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"getblockchaininfo\", \"\") + HelpExampleRpc(\"getblockchaininfo\", \"\"));\n\n    UniValue obj(UniValue::VOBJ);\n    obj.push_back(Pair(\"chain\", Params().NetworkIDString()));\n    obj.push_back(Pair(\"blocks\", (int)chainActive.Height()));\n    obj.push_back(Pair(\"headers\", pindexBestHeader ? pindexBestHeader->nHeight : -1));\n    obj.push_back(Pair(\"bestblockhash\", chainActive.Tip()->GetBlockHash().GetHex()));\n    obj.push_back(Pair(\"difficulty\", (double)GetDifficulty()));\n    obj.push_back(Pair(\"verificationprogress\", Checkpoints::GuessVerificationProgress(chainActive.Tip())));\n    obj.push_back(Pair(\"chainwork\", chainActive.Tip()->nChainWork.GetHex()));\n    return obj;\n}\n\n/** Comparison function for sorting the getchaintips heads.  */\nstruct CompareBlocksByHeight {\n    bool operator()(const CBlockIndex* a, const CBlockIndex* b) const\n    {\n        /* Make sure that unequal blocks with the same height do not compare\n           equal. Use the pointers themselves to make a distinction. */\n\n        if (a->nHeight != b->nHeight)\n            return (a->nHeight > b->nHeight);\n\n        return a < b;\n    }\n};\n\nUniValue getchaintips(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() != 0)\n        throw runtime_error(\n            \"getchaintips\\n\"\n            \"Return information about all known tips in the block tree,\"\n            \" including the main chain as well as orphaned branches.\\n\"\n            \"\\nResult:\\n\"\n            \"[\\n\"\n            \"  {\\n\"\n            \"    \\\"height\\\": xxxx,         (numeric) height of the chain tip\\n\"\n            \"    \\\"hash\\\": \\\"xxxx\\\",         (string) block hash of the tip\\n\"\n            \"    \\\"branchlen\\\": 0          (numeric) zero for main chain\\n\"\n            \"    \\\"status\\\": \\\"active\\\"      (string) \\\"active\\\" for the main chain\\n\"\n            \"  },\\n\"\n            \"  {\\n\"\n            \"    \\\"height\\\": xxxx,\\n\"\n            \"    \\\"hash\\\": \\\"xxxx\\\",\\n\"\n            \"    \\\"branchlen\\\": 1          (numeric) length of branch connecting the tip to the main chain\\n\"\n            \"    \\\"status\\\": \\\"xxxx\\\"        (string) status of the chain (active, valid-fork, valid-headers, headers-only, invalid)\\n\"\n            \"  }\\n\"\n            \"]\\n\"\n            \"Possible values for status:\\n\"\n            \"1.  \\\"invalid\\\"               This branch contains at least one invalid block\\n\"\n            \"2.  \\\"headers-only\\\"          Not all blocks for this branch are available, but the headers are valid\\n\"\n            \"3.  \\\"valid-headers\\\"         All blocks are available for this branch, but they were never fully validated\\n\"\n            \"4.  \\\"valid-fork\\\"            This branch is not part of the active chain, but is fully validated\\n\"\n            \"5.  \\\"active\\\"                This is the tip of the active main chain, which is certainly valid\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"getchaintips\", \"\") + HelpExampleRpc(\"getchaintips\", \"\"));\n\n    /* Build up a list of chain tips.  We start with the list of all\n       known blocks, and successively remove blocks that appear as pprev\n       of another block.  */\n    std::set<const CBlockIndex*, CompareBlocksByHeight> setTips;\n    BOOST_FOREACH (const PAIRTYPE(const uint256, CBlockIndex*) & item, mapBlockIndex)\n        setTips.insert(item.second);\n    BOOST_FOREACH (const PAIRTYPE(const uint256, CBlockIndex*) & item, mapBlockIndex) {\n        const CBlockIndex* pprev = item.second->pprev;\n        if (pprev)\n            setTips.erase(pprev);\n    }\n\n    // Always report the currently active tip.\n    setTips.insert(chainActive.Tip());\n\n    /* Construct the output array.  */\n    UniValue res(UniValue::VARR);\n    BOOST_FOREACH (const CBlockIndex* block, setTips) {\n        UniValue obj(UniValue::VOBJ);\n        obj.push_back(Pair(\"height\", block->nHeight));\n        obj.push_back(Pair(\"hash\", block->phashBlock->GetHex()));\n\n        const int branchLen = block->nHeight - chainActive.FindFork(block)->nHeight;\n        obj.push_back(Pair(\"branchlen\", branchLen));\n\n        string status;\n        if (chainActive.Contains(block)) {\n            // This block is part of the currently active chain.\n            status = \"active\";\n        } else if (block->nStatus & BLOCK_FAILED_MASK) {\n            // This block or one of its ancestors is invalid.\n            status = \"invalid\";\n        } else if (block->nChainTx == 0) {\n            // This block cannot be connected because full block data for it or one of its parents is missing.\n            status = \"headers-only\";\n        } else if (block->IsValid(BLOCK_VALID_SCRIPTS)) {\n            // This block is fully validated, but no longer part of the active chain. It was probably the active block once, but was reorganized.\n            status = \"valid-fork\";\n        } else if (block->IsValid(BLOCK_VALID_TREE)) {\n            // The headers for this block are valid, but it has not been validated. It was probably never part of the most-work chain.\n            status = \"valid-headers\";\n        } else {\n            // No clue.\n            status = \"unknown\";\n        }\n        obj.push_back(Pair(\"status\", status));\n\n        res.push_back(obj);\n    }\n\n    return res;\n}\n\nUniValue getfeeinfo(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() != 1)\n        throw runtime_error(\n                \"getfeeinfo blocks\\n\"\n                        \"\\nReturns details of transaction fees over the last n blocks.\\n\"\n                        \"\\nArguments:\\n\"\n                        \"1. blocks     (int, required) the number of blocks to get transaction data from\\n\"\n                        \"\\nResult:\\n\"\n                        \"{\\n\"\n                        \"  \\\"txcount\\\": xxxxx                (numeric) Current tx count\\n\"\n                        \"  \\\"txbytes\\\": xxxxx                (numeric) Sum of all tx sizes\\n\"\n                        \"  \\\"ttlfee\\\": xxxxx                 (numeric) Sum of all fees\\n\"\n                        \"  \\\"feeperkb\\\": xxxxx               (numeric) Average fee per kb over the block range\\n\"\n                        \"  \\\"rec_highpriorityfee_perkb\\\": xxxxx    (numeric) Recommended fee per kb to use for a high priority tx\\n\"\n                        \"}\\n\"\n                        \"\\nExamples:\\n\" +\n                HelpExampleCli(\"getfeeinfo\", \"5\") + HelpExampleRpc(\"getfeeinfo\", \"5\"));\n\n\n    int nBlocks = params[0].get_int();\n    int nBestHeight = chainActive.Height();\n    int nStartHeight = nBestHeight - nBlocks;\n    if (nBlocks < 0 || nStartHeight <= 0)\n        throw JSONRPCError(RPC_INVALID_PARAMETER, \"invalid start height\");\n\n    CAmount nFees = 0;\n    int64_t nBytes = 0;\n    int64_t nTotal = 0;\n    for (int i = nStartHeight; i <= nBestHeight; i++) {\n        CBlockIndex* pindex = chainActive[i];\n        CBlock block;\n        if (!ReadBlockFromDisk(block, pindex))\n            throw JSONRPCError(RPC_DATABASE_ERROR, \"failed to read block from disk\");\n\n        CAmount nValueIn = 0;\n        CAmount nValueOut = 0;\n        for (const CTransaction& tx : block.vtx) {\n            if (tx.IsCoinBase() || tx.IsCoinStake())\n                continue;\n\n            for (unsigned int j = 0; j < tx.vin.size(); j++) {\n                if (tx.vin[j].scriptSig.IsZerocoinSpend()) {\n                    nValueIn += tx.vin[j].nSequence * COIN;\n                    continue;\n                }\n\n                COutPoint prevout = tx.vin[j].prevout;\n                CTransaction txPrev;\n                uint256 hashBlock;\n                if(!GetTransaction(prevout.hash, txPrev, hashBlock, true))\n                    throw JSONRPCError(RPC_DATABASE_ERROR, \"failed to read tx from disk\");\n                nValueIn += txPrev.vout[prevout.n].nValue;\n            }\n\n            for (unsigned int j = 0; j < tx.vout.size(); j++) {\n                nValueOut += tx.vout[j].nValue;\n            }\n\n            nFees += nValueIn - nValueOut;\n            nBytes += tx.GetSerializeSize(SER_NETWORK, CLIENT_VERSION);\n            nTotal++;\n        }\n\n        pindex = chainActive.Next(pindex);\n        if (!pindex)\n            break;\n    }\n\n    UniValue ret(UniValue::VOBJ);\n    CFeeRate nFeeRate = CFeeRate(nFees, nBytes);\n    ret.push_back(Pair(\"txcount\", (int64_t)nTotal));\n    ret.push_back(Pair(\"txbytes\", (int64_t)nBytes));\n    ret.push_back(Pair(\"ttlfee\", FormatMoney(nFees)));\n    ret.push_back(Pair(\"feeperkb\", FormatMoney(nFeeRate.GetFeePerK())));\n    ret.push_back(Pair(\"rec_highpriorityfee_perkb\", FormatMoney(nFeeRate.GetFeePerK() + 1000)));\n\n    return ret;\n}\n\nUniValue getmempoolinfo(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() != 0)\n        throw runtime_error(\n            \"getmempoolinfo\\n\"\n            \"\\nReturns details on the active state of the TX memory pool.\\n\"\n            \"\\nResult:\\n\"\n            \"{\\n\"\n            \"  \\\"size\\\": xxxxx                (numeric) Current tx count\\n\"\n            \"  \\\"bytes\\\": xxxxx               (numeric) Sum of all tx sizes\\n\"\n            \"}\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"getmempoolinfo\", \"\") + HelpExampleRpc(\"getmempoolinfo\", \"\"));\n\n    UniValue ret(UniValue::VOBJ);\n    ret.push_back(Pair(\"size\", (int64_t)mempool.size()));\n    ret.push_back(Pair(\"bytes\", (int64_t)mempool.GetTotalTxSize()));\n\n    return ret;\n}\n\nUniValue hashstateandutxo(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() != 1)\n        throw runtime_error(\n            \"hashstateandutxo \\n\"\n            \"\\nShows globalState hashstate and hashutxo.\\n\"\n            \"\\nArguments:\\n\"\n            \"\\nResult:\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"hashstateandutxo\",\"\") + HelpExampleRpc(\"hashstateandutxo\",\"\"));\n\n    UniValue hashstateandutxo(UniValue::VARR);\n\n    {\n        LOCK(cs_main);\n\n        uint256 hashStateRoot, hashUTXORoot;\n        hashStateRoot.SetNull();\n        hashUTXORoot.SetNull();\n\n        GetState(hashStateRoot,hashUTXORoot);\n\n\n        UniValue state_obj(UniValue::VOBJ);\n        UniValue utxo_obj(UniValue::VOBJ);\n\n        state_obj.push_back(Pair(\"state\", hashStateRoot.GetHex()));\n        utxo_obj.push_back(Pair(\"utxo\",hashUTXORoot.GetHex() ));\n        hashstateandutxo.push_back(state_obj);\n        hashstateandutxo.push_back(utxo_obj);\n\n\n    }\n\n    return hashstateandutxo;\n}\n\nUniValue invalidateblock(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() != 1)\n        throw runtime_error(\n            \"invalidateblock \\\"hash\\\"\\n\"\n            \"\\nPermanently marks a block as invalid, as if it violated a consensus rule.\\n\"\n            \"\\nArguments:\\n\"\n            \"1. hash   (string, required) the hash of the block to mark as invalid\\n\"\n            \"\\nResult:\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"invalidateblock\", \"\\\"blockhash\\\"\") + HelpExampleRpc(\"invalidateblock\", \"\\\"blockhash\\\"\"));\n\n    std::string strHash = params[0].get_str();\n    uint256 hash(strHash);\n    CValidationState state;\n\n    {\n        LOCK(cs_main);\n        if (mapBlockIndex.count(hash) == 0)\n            throw JSONRPCError(RPC_INVALID_ADDRESS_OR_KEY, \"Block not found\");\n\n        CBlockIndex* pblockindex = mapBlockIndex[hash];\n        InvalidateBlock(state, pblockindex);\n    }\n\n    if (state.IsValid()) {\n        ActivateBestChain(state);\n    }\n\n    if (!state.IsValid()) {\n        throw JSONRPCError(RPC_DATABASE_ERROR, state.GetRejectReason());\n    }\n\n    return NullUniValue;\n}\n\nUniValue reconsiderblock(const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() != 1)\n        throw runtime_error(\n            \"reconsiderblock \\\"hash\\\"\\n\"\n            \"\\nRemoves invalidity status of a block and its descendants, reconsider them for activation.\\n\"\n            \"This can be used to undo the effects of invalidateblock.\\n\"\n            \"\\nArguments:\\n\"\n            \"1. hash   (string, required) the hash of the block to reconsider\\n\"\n            \"\\nResult:\\n\"\n            \"\\nExamples:\\n\" +\n            HelpExampleCli(\"reconsiderblock\", \"\\\"blockhash\\\"\") + HelpExampleRpc(\"reconsiderblock\", \"\\\"blockhash\\\"\"));\n\n    std::string strHash = params[0].get_str();\n    uint256 hash(strHash);\n    CValidationState state;\n\n    {\n        LOCK(cs_main);\n        if (mapBlockIndex.count(hash) == 0)\n            throw JSONRPCError(RPC_INVALID_ADDRESS_OR_KEY, \"Block not found\");\n\n        CBlockIndex* pblockindex = mapBlockIndex[hash];\n        ReconsiderBlock(state, pblockindex);\n    }\n\n    if (state.IsValid()) {\n        ActivateBestChain(state);\n    }\n\n    if (!state.IsValid()) {\n        throw JSONRPCError(RPC_DATABASE_ERROR, state.GetRejectReason());\n    }\n\n    return NullUniValue;\n}\n\nUniValue getinvalid (const UniValue& params, bool fHelp)\n{\n    if (fHelp || params.size() > 1)\n        throw runtime_error(\n                \"getinvalid \\n\"\n                        \"\\nGet a summary of invalidated outpoints.\\n\"\n                        \"\\nArguments:\\n\"\n                        \"1. all   (string, optional) return a full list of outpoints even if they are spent\\n\"\n                        \"\\nExamples:\\n\" +\n                HelpExampleCli(\"getinvalid\", \"\\\"all\\\"\") + HelpExampleRpc(\"getinvalid\", \"\\\"all\\\"\"));\n\n    string strCommand;\n    if (params.size() == 1){\n        strCommand = params[0].get_str();\n    }\n\n    if (strCommand == \"serials\") {\n        UniValue ret(UniValue::VARR);\n        CAmount nSerialTotal = 0;\n        for (auto it : mapInvalidSerials) {\n            UniValue objSerial(UniValue::VOBJ);\n            objSerial.push_back(Pair(it.first.GetHex(), FormatMoney(it.second)));\n            nSerialTotal += it.second;\n            ret.push_back(objSerial);\n        }\n\n        UniValue objTotal(UniValue::VOBJ);\n        objTotal.push_back(Pair(\"total_value\", FormatMoney(nSerialTotal)));\n        ret.push_back(objTotal);\n        return ret;\n    }\n\n    bool fShowAll = false;\n    if (strCommand == \"all\")\n        fShowAll = true;\n\n    CAmount nUnspent = 0;\n    CAmount nMint = 0;\n    CAmount nMixedValid = 0;\n    map<CBitcoinAddress, CAmount> mapBanAddress;\n    map<COutPoint, int> mapMixedValid;\n\n    UniValue ret(UniValue::VARR);\n    for (auto it : mapInvalidOutPoints) {\n        COutPoint out = it.first;\n        //Get the tx that the outpoint is from\n        CTransaction tx;\n        uint256 hashBlock;\n        if (!GetTransaction(out.hash, tx, hashBlock, true)) {\n            continue;\n        }\n\n        UniValue objTx(UniValue::VOBJ);\n        objTx.push_back(Pair(\"inv_out\", it.first.ToString()));\n\n        CAmount nValue = tx.vout[out.n].nValue;\n        objTx.push_back(Pair(\"value\", FormatMoney(nValue)));\n\n        //Search the txin's to see if any of them are \"valid\".\n        UniValue objMixedValid(UniValue::VOBJ);\n\n        //if some of the other inputs are valid\n        for(CTxIn in2 : tx.vin) {\n            //See if this is already accounted for\n            if(mapInvalidOutPoints.count(in2.prevout) || mapMixedValid.count(in2.prevout))\n                continue;\n\n            CTransaction txPrev;\n            uint256 hashBlock;\n            if(!GetTransaction(in2.prevout.hash, txPrev, hashBlock, true))\n                continue;\n\n            //This is a valid outpoint that mixed with an invalid outpoint. Investigate this person.\n            //Information leakage, not covering their tracks well enough\n            CAmount nValid = txPrev.vout[in2.prevout.n].nValue;\n            objMixedValid.push_back(Pair(FormatMoney(nValid), in2.prevout.ToString()));\n\n            nMixedValid += nValid;\n            mapMixedValid[in2.prevout] = 1;\n        }\n\n        //Check whether this bad outpoint has been spent\n        bool fSpent = false;\n        CCoinsViewCache cache(pcoinsTip);\n        const CCoins* coins = cache.AccessCoins(out.hash);\n        if (!coins || !coins->IsAvailable(out.n))\n            fSpent = true;\n\n        objTx.push_back(Pair(\"spent\", fSpent));\n        if (!objMixedValid.empty())\n            objTx.push_back(Pair(\"mixed_with_valid\", objMixedValid));\n\n        CScript scriptPubKey = tx.vout[out.n].scriptPubKey;\n        if (scriptPubKey.IsZerocoinMint()) {\n            nMint += nValue;\n        } else if (!fSpent) {\n            CTxDestination dest;\n            if (!ExtractDestination(scriptPubKey, dest)) {\n                continue;\n            }\n            CBitcoinAddress address(dest);\n            mapBanAddress[address] += nValue;\n            nUnspent += nValue;\n        }\n\n        if (fSpent && !fShowAll)\n            continue;\n\n        ret.push_back(objTx);\n    }\n\n    UniValue objAddresses(UniValue::VOBJ);\n    for (auto it : mapBanAddress)\n        objAddresses.push_back(Pair(it.first.ToString(), FormatMoney(it.second)));\n\n    UniValue obj(UniValue::VOBJ);\n    obj.push_back(Pair(\"addresses_with_invalid\", objAddresses));\n    obj.push_back(Pair(\"total_unspent\", FormatMoney(nUnspent)));\n    obj.push_back(Pair(\"total_minted\", FormatMoney(nMint)));\n    obj.push_back(Pair(\"total_valid_used\", FormatMoney(nMixedValid)));\n\n    ret.push_back(obj);\n    return ret;\n}\n\nUniValue findserial(const UniValue& params, bool fHelp)\n{\n    if(fHelp || params.size() != 1)\n        throw runtime_error(\n            \"findserial \\\"serial\\\"\\n\"\n                \"\\nSearches the zerocoin database for a zerocoin spend transaction that contains the specified serial\\n\"\n                \"\\nArguments:\\n\"\n                \"1. serial   (string, required) the serial of a zerocoin spend to search for.\\n\"\n                \"\\nResult:\\n\"\n                \"{\\n\"\n                \"  \\\"success\\\": true/false        (boolean) Whether the serial was found\\n\"\n                \"  \\\"txid\\\": xxxxx                (numeric) The transaction that contains the spent serial\\n\"\n                \"}\\n\"\n                \"\\nExamples:\\n\" +\n            HelpExampleCli(\"findserial\", \"\\\"serial\\\"\") + HelpExampleRpc(\"findserial\", \"\\\"serial\\\"\"));\n\n    std::string strSerial = params[0].get_str();\n    CBigNum bnSerial = 0;\n    bnSerial.SetHex(strSerial);\n    if (!bnSerial)\n    throw JSONRPCError(RPC_INVALID_ADDRESS_OR_KEY, \"Invalid serial\");\n\n    uint256 txid = 0;\n    bool fSuccess = zerocoinDB->ReadCoinSpend(bnSerial, txid);\n\n    UniValue ret(UniValue::VOBJ);\n    ret.push_back(Pair(\"success\", fSuccess));\n    ret.push_back(Pair(\"txid\", txid.GetHex()));\n\n    return ret;\n}\n",
    "file_path": "data\\preprocessed\\gkcproject_gkccash_core__src_rpcblockchain.cpp",
    "file_name": "gkcproject_gkccash_core__src_rpcblockchain.cpp",
    "language": "cpp"
  },
  {
    "text": "//\n// Copyright (C) 2002-2005  3Dlabs Inc. Ltd.\n// Copyright (C) 2013 LunarG, Inc.\n// Copyright (C) 2017 ARM Limited.\n// Copyright (C) 2015-2018 Google, Inc.\n//\n// All rights reserved.\n//\n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted provided that the following conditions\n// are met:\n//\n//    Redistributions of source code must retain the above copyright\n//    notice, this list of conditions and the following disclaimer.\n//\n//    Redistributions in binary form must reproduce the above\n//    copyright notice, this list of conditions and the following\n//    disclaimer in the documentation and/or other materials provided\n//    with the distribution.\n//\n//    Neither the name of 3Dlabs Inc. Ltd. nor the names of its\n//    contributors may be used to endorse or promote products derived\n//    from this software without specific prior written permission.\n//\n// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n// \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n// FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE\n// COPYRIGHT HOLDERS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n// INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,\n// BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n// LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER\n// CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n// LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN\n// ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n// POSSIBILITY OF SUCH DAMAGE.\n//\n/***\\\nCopyright (c) 2002, NVIDIA Corporation.\n\nNVIDIA Corporation(\"NVIDIA\") supplies this software to you in\nconsideration of your agreement to the following terms, and your use,\ninstallation, modification or redistribution of this NVIDIA software\nconstitutes acceptance of these terms.  If you do not agree with these\nterms, please do not use, install, modify or redistribute this NVIDIA\nsoftware.\n\nIn consideration of your agreement to abide by the following terms, and\nsubject to these terms, NVIDIA grants you a personal, non-exclusive\nlicense, under NVIDIA's copyrights in this original NVIDIA software (the\n\"NVIDIA Software\"), to use, reproduce, modify and redistribute the\nNVIDIA Software, with or without modifications, in source and/or binary\nforms; provided that if you redistribute the NVIDIA Software, you must\nretain the copyright notice of NVIDIA, this notice and the following\ntext and disclaimers in all such redistributions of the NVIDIA Software.\nNeither the name, trademarks, service marks nor logos of NVIDIA\nCorporation may be used to endorse or promote products derived from the\nNVIDIA Software without specific prior written permission from NVIDIA.\nExcept as expressly stated in this notice, no other rights or licenses\nexpress or implied, are granted by NVIDIA herein, including but not\nlimited to any patent rights that may be infringed by your derivative\nworks or by other works in which the NVIDIA Software may be\nincorporated. No hardware is licensed hereunder.\n\nTHE NVIDIA SOFTWARE IS BEING PROVIDED ON AN \"AS IS\" BASIS, WITHOUT\nWARRANTIES OR CONDITIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED,\nINCLUDING WITHOUT LIMITATION, WARRANTIES OR CONDITIONS OF TITLE,\nNON-INFRINGEMENT, MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, OR\nITS USE AND OPERATION EITHER ALONE OR IN COMBINATION WITH OTHER\nPRODUCTS.\n\nIN NO EVENT SHALL NVIDIA BE LIABLE FOR ANY SPECIAL, INDIRECT,\nINCIDENTAL, EXEMPLARY, CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED\nTO, LOST PROFITS; PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF\nUSE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) OR ARISING IN ANY WAY\nOUT OF THE USE, REPRODUCTION, MODIFICATION AND/OR DISTRIBUTION OF THE\nNVIDIA SOFTWARE, HOWEVER CAUSED AND WHETHER UNDER THEORY OF CONTRACT,\nTORT (INCLUDING NEGLIGENCE), STRICT LIABILITY OR OTHERWISE, EVEN IF\nNVIDIA HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\\***/\n\n#ifndef _CRT_SECURE_NO_WARNINGS\n#define _CRT_SECURE_NO_WARNINGS\n#endif\n\n#include <cstdlib>\n#include <cstring>\n\n#include \"PpContext.h\"\n#include \"PpTokens.h\"\n#include \"../Scan.h\"\n\nnamespace glslang {\n\n///\n/////////////////////////////////// Floating point constants: /////////////////////////////////\n///\n\n//\n// Scan a single- or double-precision floating point constant.\n// Assumes that the scanner has seen at least one digit,\n// followed by either a decimal '.' or the letter 'e', or a\n// precision ending (e.g., F or LF).\n//\n// This is technically not correct, as the preprocessor should just\n// accept the numeric literal along with whatever suffix it has, but\n// currently, it stops on seeing a bad suffix, treating that as the\n// next token. This effects things like token pasting, where it is\n// relevant how many tokens something was broken into.\n//\n// See peekContinuedPasting().\nint TPpContext::lFloatConst(int len, int ch, TPpToken* ppToken)\n{\n    const auto saveName = [&](int ch) {\n        if (len <= MaxTokenLength)\n            ppToken->name[len++] = static_cast<char>(ch);\n    };\n\n    // find the range of non-zero digits before the decimal point\n    int startNonZero = 0;\n    while (startNonZero < len && ppToken->name[startNonZero] == '0')\n        ++startNonZero;\n    int endNonZero = len;\n    while (endNonZero > startNonZero && ppToken->name[endNonZero-1] == '0')\n        --endNonZero;\n    int numWholeNumberDigits = endNonZero - startNonZero;\n\n    // accumulate the range's value\n    bool fastPath = numWholeNumberDigits <= 15;  // when the number gets too complex, set to false\n    unsigned long long wholeNumber = 0;\n    if (fastPath) {\n        for (int i = startNonZero; i < endNonZero; ++i)\n            wholeNumber = wholeNumber * 10 + (ppToken->name[i] - '0');\n    }\n    int decimalShift = len - endNonZero;\n\n    // Decimal point:\n    bool hasDecimalOrExponent = false;\n    if (ch == '.') {\n        hasDecimalOrExponent = true;\n        saveName(ch);\n        ch = getChar();\n        int firstDecimal = len;\n\n#ifdef ENABLE_HLSL\n        // 1.#INF or -1.#INF\n        if (ch == '#' && (ifdepth > 0 || parseContext.intermediate.getSource() == EShSourceHlsl)) {\n            if ((len <  2) ||\n                (len == 2 && ppToken->name[0] != '1') ||\n                (len == 3 && ppToken->name[1] != '1' && !(ppToken->name[0] == '-' || ppToken->name[0] == '+')) ||\n                (len >  3))\n                parseContext.ppError(ppToken->loc, \"unexpected use of\", \"#\", \"\");\n            else {\n                // we have 1.# or -1.# or +1.#, check for 'INF'\n                if ((ch = getChar()) != 'I' ||\n                    (ch = getChar()) != 'N' ||\n                    (ch = getChar()) != 'F')\n                    parseContext.ppError(ppToken->loc, \"expected 'INF'\", \"#\", \"\");\n                else {\n                    // we have [+-].#INF, and we are targeting IEEE 754, so wrap it up:\n                    saveName('I');\n                    saveName('N');\n                    saveName('F');\n                    ppToken->name[len] = '\\0';\n                    if (ppToken->name[0] == '-')\n                        ppToken->i64val = 0xfff0000000000000; // -Infinity\n                    else\n                        ppToken->i64val = 0x7ff0000000000000; // +Infinity\n                    return PpAtomConstFloat;\n                }\n            }\n        }\n#endif\n\n        // Consume leading-zero digits after the decimal point\n        while (ch == '0') {\n            saveName(ch);\n            ch = getChar();\n        }\n        int startNonZeroDecimal = len;\n        int endNonZeroDecimal = len;\n\n        // Consume remaining digits, up to the exponent\n        while (ch >= '0' && ch <= '9') {\n            saveName(ch);\n            if (ch != '0')\n                endNonZeroDecimal = len;\n            ch = getChar();\n        }\n\n        // Compute accumulation up to the last non-zero digit\n        if (endNonZeroDecimal > startNonZeroDecimal) {\n            numWholeNumberDigits += endNonZeroDecimal - endNonZero - 1; // don't include the \".\"\n            if (numWholeNumberDigits > 15)\n                fastPath = false;\n            if (fastPath) {\n                for (int i = endNonZero; i < endNonZeroDecimal; ++i) {\n                    if (ppToken->name[i] != '.')\n                        wholeNumber = wholeNumber * 10 + (ppToken->name[i] - '0');\n                }\n            }\n            decimalShift = firstDecimal - endNonZeroDecimal;\n        }\n    }\n\n    // Exponent:\n    bool negativeExponent = false;\n    double exponentValue = 0.0;\n    int exponent = 0;\n    {\n        if (ch == 'e' || ch == 'E') {\n            hasDecimalOrExponent = true;\n            saveName(ch);\n            ch = getChar();\n            if (ch == '+' || ch == '-') {\n                negativeExponent = ch == '-';\n                saveName(ch);\n                ch = getChar();\n            }\n            if (ch >= '0' && ch <= '9') {\n                while (ch >= '0' && ch <= '9') {\n                    exponent = exponent * 10 + (ch - '0');\n                    saveName(ch);\n                    ch = getChar();\n                }\n            } else {\n                parseContext.ppError(ppToken->loc, \"bad character in float exponent\", \"\", \"\");\n            }\n        }\n\n        // Compensate for location of decimal\n        if (negativeExponent)\n            exponent -= decimalShift;\n        else {\n            exponent += decimalShift;\n            if (exponent < 0) {\n                negativeExponent = true;\n                exponent = -exponent;\n            }\n        }\n        if (exponent > 22)\n            fastPath = false;\n\n        if (fastPath) {\n            // Compute the floating-point value of the exponent\n            exponentValue = 1.0;\n            if (exponent > 0) {\n                double expFactor = 10;\n                while (exponent > 0) {\n                    if (exponent & 0x1)\n                        exponentValue *= expFactor;\n                    expFactor *= expFactor;\n                    exponent >>= 1;\n                }\n            }\n        }\n    }\n\n    // Suffix:\n    bool isDouble = false;\n    bool isFloat16 = false;\n#ifndef GLSLANG_WEB\n    if (ch == 'l' || ch == 'L') {\n        if (ifdepth == 0 && parseContext.intermediate.getSource() == EShSourceGlsl)\n            parseContext.doubleCheck(ppToken->loc, \"double floating-point suffix\");\n        if (ifdepth == 0 && !hasDecimalOrExponent)\n            parseContext.ppError(ppToken->loc, \"float literal needs a decimal point or exponent\", \"\", \"\");\n        if (parseContext.intermediate.getSource() == EShSourceGlsl) {\n            int ch2 = getChar();\n            if (ch2 != 'f' && ch2 != 'F') {\n                ungetChar();\n                ungetChar();\n            } else {\n                saveName(ch);\n                saveName(ch2);\n                isDouble = true;\n            }\n        } else if (parseContext.intermediate.getSource() == EShSourceHlsl) {\n            saveName(ch);\n            isDouble = true;\n        }\n    } else if (ch == 'h' || ch == 'H') {\n        if (ifdepth == 0 && parseContext.intermediate.getSource() == EShSourceGlsl)\n            parseContext.float16Check(ppToken->loc, \"half floating-point suffix\");\n        if (ifdepth == 0 && !hasDecimalOrExponent)\n            parseContext.ppError(ppToken->loc, \"float literal needs a decimal point or exponent\", \"\", \"\");\n        if (parseContext.intermediate.getSource() == EShSourceGlsl) {\n            int ch2 = getChar();\n            if (ch2 != 'f' && ch2 != 'F') {\n                ungetChar();\n                ungetChar();\n            } else {\n                saveName(ch);\n                saveName(ch2);\n                isFloat16 = true;\n            }\n        } else if (parseContext.intermediate.getSource() == EShSourceHlsl) {\n            saveName(ch);\n            isFloat16 = true;\n        }\n    } else\n#endif\n    if (ch == 'f' || ch == 'F') {\n#ifndef GLSLANG_WEB\n        if (ifdepth == 0)\n            parseContext.profileRequires(ppToken->loc,  EEsProfile, 300, nullptr, \"floating-point suffix\");\n        if (ifdepth == 0 && !parseContext.relaxedErrors())\n            parseContext.profileRequires(ppToken->loc, ~EEsProfile, 120, nullptr, \"floating-point suffix\");\n#endif\n        if (ifdepth == 0 && !hasDecimalOrExponent)\n            parseContext.ppError(ppToken->loc, \"float literal needs a decimal point or exponent\", \"\", \"\");\n        saveName(ch);\n    } else\n        ungetChar();\n\n    // Patch up the name and length for overflow\n\n    if (len > MaxTokenLength) {\n        len = MaxTokenLength;\n        parseContext.ppError(ppToken->loc, \"float literal too long\", \"\", \"\");\n    }\n    ppToken->name[len] = '\\0';\n\n    // Compute the numerical value\n    if (fastPath) {\n        // compute the floating-point value of the exponent\n        if (exponentValue == 0.0)\n            ppToken->dval = (double)wholeNumber;\n        else if (negativeExponent)\n            ppToken->dval = (double)wholeNumber / exponentValue;\n        else\n            ppToken->dval = (double)wholeNumber * exponentValue;\n    } else {\n        // slow path\n        ppToken->dval = 0.0;\n\n        // remove suffix\n        TString numstr(ppToken->name);\n        if (numstr.back() == 'f' || numstr.back() == 'F')\n            numstr.pop_back();\n        if (numstr.back() == 'h' || numstr.back() == 'H')\n            numstr.pop_back();\n        if (numstr.back() == 'l' || numstr.back() == 'L')\n            numstr.pop_back();\n\n        // use platform library\n        strtodStream.clear();\n        strtodStream.str(numstr.c_str());\n        strtodStream >> ppToken->dval;\n        if (strtodStream.fail()) {\n            // Assume failure combined with a large exponent was overflow, in\n            // an attempt to set INF.\n            if (!negativeExponent && exponent + numWholeNumberDigits > 300)\n                ppToken->i64val = 0x7ff0000000000000; // +Infinity\n            // Assume failure combined with a small exponent was overflow.\n            if (negativeExponent && exponent + numWholeNumberDigits > 300)\n                ppToken->dval = 0.0;\n            // Unknown reason for failure. Theory is that either\n            //  - the 0.0 is still there, or\n            //  - something reasonable was written that is better than 0.0\n        }\n    }\n\n    // Return the right token type\n    if (isDouble)\n        return PpAtomConstDouble;\n    else if (isFloat16)\n        return PpAtomConstFloat16;\n    else\n        return PpAtomConstFloat;\n}\n\n// Recognize a character literal.\n//\n// The first ' has already been accepted, read the rest, through the closing '.\n//\n// Always returns PpAtomConstInt.\n//\nint TPpContext::characterLiteral(TPpToken* ppToken)\n{\n    ppToken->name[0] = 0;\n    ppToken->ival = 0;\n\n    if (parseContext.intermediate.getSource() != EShSourceHlsl) {\n        // illegal, except in macro definition, for which case we report the character\n        return '\\'';\n    }\n\n    int ch = getChar();\n    switch (ch) {\n    case '\\'':\n        // As empty sequence:  ''\n        parseContext.ppError(ppToken->loc, \"unexpected\", \"\\'\", \"\");\n        return PpAtomConstInt;\n    case '\\\\':\n        // As escape sequence:  '\\XXX'\n        switch (ch = getChar()) {\n        case 'a':\n            ppToken->ival = 7;\n            break;\n        case 'b':\n            ppToken->ival = 8;\n            break;\n        case 't':\n            ppToken->ival = 9;\n            break;\n        case 'n':\n            ppToken->ival = 10;\n            break;\n        case 'v':\n            ppToken->ival = 11;\n            break;\n        case 'f':\n            ppToken->ival = 12;\n            break;\n        case 'r':\n            ppToken->ival = 13;\n            break;\n        case 'x':\n        case '0':\n            parseContext.ppError(ppToken->loc, \"octal and hex sequences not supported\", \"\\\\\", \"\");\n            break;\n        default:\n            // This catches '\\'', '\\\"', '\\?', etc.\n            // Also, things like '\\C' mean the same thing as 'C'\n            // (after the above cases are filtered out).\n            ppToken->ival = ch;\n            break;\n        }\n        break;\n    default:\n        ppToken->ival = ch;\n        break;\n    }\n    ppToken->name[0] = (char)ppToken->ival;\n    ppToken->name[1] = '\\0';\n    ch = getChar();\n    if (ch != '\\'') {\n        parseContext.ppError(ppToken->loc, \"expected\", \"\\'\", \"\");\n        // Look ahead for a closing '\n        do {\n            ch = getChar();\n        } while (ch != '\\'' && ch != EndOfInput && ch != '\\n');\n    }\n\n    return PpAtomConstInt;\n}\n\n//\n// Scanner used to tokenize source stream.\n//\n// N.B. Invalid numeric suffixes are not consumed.//\n// This is technically not correct, as the preprocessor should just\n// accept the numeric literal along with whatever suffix it has, but\n// currently, it stops on seeing a bad suffix, treating that as the\n// next token. This effects things like token pasting, where it is\n// relevant how many tokens something was broken into.\n// See peekContinuedPasting().\n//\nint TPpContext::tStringInput::scan(TPpToken* ppToken)\n{\n    int AlreadyComplained = 0;\n    int len = 0;\n    int ch = 0;\n    int ii = 0;\n    unsigned long long ival = 0;\n    const auto floatingPointChar = [&](int ch) { return ch == '.' || ch == 'e' || ch == 'E' ||\n   ch == 'f' || ch == 'F' ||\n   ch == 'h' || ch == 'H'; };\n\n    static const char* const Int64_Extensions[] = {\n        E_GL_ARB_gpu_shader_int64,\n        E_GL_EXT_shader_explicit_arithmetic_types,\n        E_GL_EXT_shader_explicit_arithmetic_types_int64 };\n    static const int Num_Int64_Extensions = sizeof(Int64_Extensions) / sizeof(Int64_Extensions[0]);\n\n    static const char* const Int16_Extensions[] = {\n        E_GL_AMD_gpu_shader_int16,\n        E_GL_EXT_shader_explicit_arithmetic_types,\n        E_GL_EXT_shader_explicit_arithmetic_types_int16 };\n    static const int Num_Int16_Extensions = sizeof(Int16_Extensions) / sizeof(Int16_Extensions[0]);\n\n    ppToken->ival = 0;\n    ppToken->i64val = 0;\n    ppToken->space = false;\n    ch = getch();\n    for (;;) {\n        while (ch == ' ' || ch == '\\t') {\n            ppToken->space = true;\n            ch = getch();\n        }\n\n        ppToken->loc = pp->parseContext.getCurrentLoc();\n        len = 0;\n        switch (ch) {\n        default:\n            // Single character token, including EndOfInput, '#' and '\\' (escaped newlines are handled at a lower level, so this is just a '\\' token)\n            if (ch > PpAtomMaxSingle)\n                ch = PpAtomBadToken;\n            return ch;\n\n        case 'A': case 'B': case 'C': case 'D': case 'E':\n        case 'F': case 'G': case 'H': case 'I': case 'J':\n        case 'K': case 'L': case 'M': case 'N': case 'O':\n        case 'P': case 'Q': case 'R': case 'S': case 'T':\n        case 'U': case 'V': case 'W': case 'X': case 'Y':\n        case 'Z': case '_':\n        case 'a': case 'b': case 'c': case 'd': case 'e':\n        case 'f': case 'g': case 'h': case 'i': case 'j':\n        case 'k': case 'l': case 'm': case 'n': case 'o':\n        case 'p': case 'q': case 'r': case 's': case 't':\n        case 'u': case 'v': case 'w': case 'x': case 'y':\n        case 'z':\n            do {\n                if (len < MaxTokenLength) {\n                    ppToken->name[len++] = (char)ch;\n                    ch = getch();\n                } else {\n                    if (! AlreadyComplained) {\n                        pp->parseContext.ppError(ppToken->loc, \"name too long\", \"\", \"\");\n                        AlreadyComplained = 1;\n                    }\n                    ch = getch();\n                }\n            } while ((ch >= 'a' && ch <= 'z') ||\n                     (ch >= 'A' && ch <= 'Z') ||\n                     (ch >= '0' && ch <= '9') ||\n                     ch == '_');\n\n            // line continuation with no token before or after makes len == 0, and need to start over skipping white space, etc.\n            if (len == 0)\n                continue;\n\n            ppToken->name[len] = '\\0';\n            ungetch();\n            return PpAtomIdentifier;\n        case '0':\n            ppToken->name[len++] = (char)ch;\n            ch = getch();\n            if (ch == 'x' || ch == 'X') {\n                // must be hexadecimal\n\n                bool isUnsigned = false;\n                bool isInt64 = false;\n                bool isInt16 = false;\n                ppToken->name[len++] = (char)ch;\n                ch = getch();\n                if ((ch >= '0' && ch <= '9') ||\n                    (ch >= 'A' && ch <= 'F') ||\n                    (ch >= 'a' && ch <= 'f')) {\n\n                    ival = 0;\n                    do {\n                        if (len < MaxTokenLength && ival <= 0x0fffffffffffffffull) {\n                            ppToken->name[len++] = (char)ch;\n                            if (ch >= '0' && ch <= '9') {\n                                ii = ch - '0';\n                            } else if (ch >= 'A' && ch <= 'F') {\n                                ii = ch - 'A' + 10;\n                            } else if (ch >= 'a' && ch <= 'f') {\n                                ii = ch - 'a' + 10;\n                            } else\n                                pp->parseContext.ppError(ppToken->loc, \"bad digit in hexadecimal literal\", \"\", \"\");\n                            ival = (ival << 4) | ii;\n                        } else {\n                            if (! AlreadyComplained) {\n                                if(len < MaxTokenLength)\n                                    pp->parseContext.ppError(ppToken->loc, \"hexadecimal literal too big\", \"\", \"\");\n                                else\n                                    pp->parseContext.ppError(ppToken->loc, \"hexadecimal literal too long\", \"\", \"\");\n                                AlreadyComplained = 1;\n                            }\n                            ival = 0xffffffffffffffffull;\n                        }\n                        ch = getch();\n                    } while ((ch >= '0' && ch <= '9') ||\n                             (ch >= 'A' && ch <= 'F') ||\n                             (ch >= 'a' && ch <= 'f'));\n                } else {\n                    pp->parseContext.ppError(ppToken->loc, \"bad digit in hexadecimal literal\", \"\", \"\");\n                }\n                if (ch == 'u' || ch == 'U') {\n                    if (len < MaxTokenLength)\n                        ppToken->name[len++] = (char)ch;\n                    isUnsigned = true;\n\n#ifndef GLSLANG_WEB\n                    int nextCh = getch();\n                    if (nextCh == 'l' || nextCh == 'L') {\n                        if (len < MaxTokenLength)\n                            ppToken->name[len++] = (char)nextCh;\n                        isInt64 = true;\n                    } else\n                        ungetch();\n\n                    nextCh = getch();\n                    if ((nextCh == 's' || nextCh == 'S') &&\n                            pp->parseContext.intermediate.getSource() == EShSourceGlsl) {\n                        if (len < MaxTokenLength)\n                            ppToken->name[len++] = (char)nextCh;\n                        isInt16 = true;\n                    } else\n                        ungetch();\n                } else if (ch == 'l' || ch == 'L') {\n                    if (len < MaxTokenLength)\n                        ppToken->name[len++] = (char)ch;\n                    isInt64 = true;\n                } else if ((ch == 's' || ch == 'S') &&\n                           pp->parseContext.intermediate.getSource() == EShSourceGlsl) {\n                    if (len < MaxTokenLength)\n                        ppToken->name[len++] = (char)ch;\n                    isInt16 = true;\n#endif\n                } else\n                    ungetch();\n                ppToken->name[len] = '\\0';\n\n                if (isInt64 && pp->parseContext.intermediate.getSource() == EShSourceGlsl) {\n                    if (pp->ifdepth == 0) {\n                        pp->parseContext.requireProfile(ppToken->loc, ~EEsProfile,\n   \"64-bit hexadecimal literal\");\n                        pp->parseContext.profileRequires(ppToken->loc, ~EEsProfile, 0,\n                            Num_Int64_Extensions, Int64_Extensions, \"64-bit hexadecimal literal\");\n                    }\n                    ppToken->i64val = ival;\n                    return isUnsigned ? PpAtomConstUint64 : PpAtomConstInt64;\n                } else if (isInt16) {\n                    if (pp->ifdepth == 0) {\n                        if (pp->parseContext.intermediate.getSource() == EShSourceGlsl) {\n                            pp->parseContext.requireProfile(ppToken->loc, ~EEsProfile,\n   \"16-bit hexadecimal literal\");\n                            pp->parseContext.profileRequires(ppToken->loc, ~EEsProfile, 0,\n                                Num_Int16_Extensions, Int16_Extensions, \"16-bit hexadecimal literal\");\n                        }\n                    }\n                    ppToken->ival = (int)ival;\n                    return isUnsigned ? PpAtomConstUint16 : PpAtomConstInt16;\n                } else {\n                    if (ival > 0xffffffffu && !AlreadyComplained)\n                        pp->parseContext.ppError(ppToken->loc, \"hexadecimal literal too big\", \"\", \"\");\n                    ppToken->ival = (int)ival;\n                    return isUnsigned ? PpAtomConstUint : PpAtomConstInt;\n                }\n            } else {\n                // could be octal integer or floating point, speculative pursue octal until it must be floating point\n\n                bool isUnsigned = false;\n                bool isInt64 = false;\n                bool isInt16 = false;\n                bool octalOverflow = false;\n                bool nonOctal = false;\n                ival = 0;\n\n                // see how much octal-like stuff we can read\n                while (ch >= '0' && ch <= '7') {\n                    if (len < MaxTokenLength)\n                        ppToken->name[len++] = (char)ch;\n                    else if (! AlreadyComplained) {\n                        pp->parseContext.ppError(ppToken->loc, \"numeric literal too long\", \"\", \"\");\n                        AlreadyComplained = 1;\n                    }\n                    if (ival <= 0x1fffffffffffffffull) {\n                        ii = ch - '0';\n                        ival = (ival << 3) | ii;\n                    } else\n                        octalOverflow = true;\n                    ch = getch();\n                }\n\n                // could be part of a float...\n                if (ch == '8' || ch == '9') {\n                    nonOctal = true;\n                    do {\n                        if (len < MaxTokenLength)\n                            ppToken->name[len++] = (char)ch;\n                        else if (! AlreadyComplained) {\n                            pp->parseContext.ppError(ppToken->loc, \"numeric literal too long\", \"\", \"\");\n                            AlreadyComplained = 1;\n                        }\n                        ch = getch();\n                    } while (ch >= '0' && ch <= '9');\n                }\n                if (floatingPointChar(ch))\n                    return pp->lFloatConst(len, ch, ppToken);\n\n                // wasn't a float, so must be octal...\n                if (nonOctal)\n                    pp->parseContext.ppError(ppToken->loc, \"octal literal digit too large\", \"\", \"\");\n\n                if (ch == 'u' || ch == 'U') {\n                    if (len < MaxTokenLength)\n                        ppToken->name[len++] = (char)ch;\n                    isUnsigned = true;\n\n#ifndef GLSLANG_WEB\n                    int nextCh = getch();\n                    if (nextCh == 'l' || nextCh == 'L') {\n                        if (len < MaxTokenLength)\n                            ppToken->name[len++] = (char)nextCh;\n                        isInt64 = true;\n                    } else\n                        ungetch();\n\n                    nextCh = getch();\n                    if ((nextCh == 's' || nextCh == 'S') &&\n                                pp->parseContext.intermediate.getSource() == EShSourceGlsl) {\n                        if (len < MaxTokenLength)\n                            ppToken->name[len++] = (char)nextCh;\n                        isInt16 = true;\n                    } else\n                        ungetch();\n                } else if (ch == 'l' || ch == 'L') {\n                    if (len < MaxTokenLength)\n                        ppToken->name[len++] = (char)ch;\n                    isInt64 = true;\n                } else if ((ch == 's' || ch == 'S') &&\n                                pp->parseContext.intermediate.getSource() == EShSourceGlsl) {\n                    if (len < MaxTokenLength)\n                        ppToken->name[len++] = (char)ch;\n                    isInt16 = true;\n#endif\n                } else\n                    ungetch();\n                ppToken->name[len] = '\\0';\n\n                if (!isInt64 && ival > 0xffffffffu)\n                    octalOverflow = true;\n\n                if (octalOverflow)\n                    pp->parseContext.ppError(ppToken->loc, \"octal literal too big\", \"\", \"\");\n\n                if (isInt64 && pp->parseContext.intermediate.getSource() == EShSourceGlsl) {\n                    if (pp->ifdepth == 0) {\n                        pp->parseContext.requireProfile(ppToken->loc, ~EEsProfile,\n   \"64-bit octal literal\");\n                        pp->parseContext.profileRequires(ppToken->loc, ~EEsProfile, 0,\n                            Num_Int64_Extensions, Int64_Extensions, \"64-bit octal literal\");\n                    }\n                    ppToken->i64val = ival;\n                    return isUnsigned ? PpAtomConstUint64 : PpAtomConstInt64;\n                } else if (isInt16) {\n                    if (pp->ifdepth == 0) {\n                        if (pp->parseContext.intermediate.getSource() == EShSourceGlsl) {\n                            pp->parseContext.requireProfile(ppToken->loc, ~EEsProfile,\n   \"16-bit octal literal\");\n                            pp->parseContext.profileRequires(ppToken->loc, ~EEsProfile, 0,\n                                Num_Int16_Extensions, Int16_Extensions, \"16-bit octal literal\");\n                        }\n                    }\n                    ppToken->ival = (int)ival;\n                    return isUnsigned ? PpAtomConstUint16 : PpAtomConstInt16;\n                } else {\n                    ppToken->ival = (int)ival;\n                    return isUnsigned ? PpAtomConstUint : PpAtomConstInt;\n                }\n            }\n            break;\n        case '1': case '2': case '3': case '4':\n        case '5': case '6': case '7': case '8': case '9':\n            // can't be hexadecimal or octal, is either decimal or floating point\n\n            do {\n                if (len < MaxTokenLength)\n                    ppToken->name[len++] = (char)ch;\n                else if (! AlreadyComplained) {\n                    pp->parseContext.ppError(ppToken->loc, \"numeric literal too long\", \"\", \"\");\n                    AlreadyComplained = 1;\n                }\n                ch = getch();\n            } while (ch >= '0' && ch <= '9');\n            if (floatingPointChar(ch))\n                return pp->lFloatConst(len, ch, ppToken);\n            else {\n                // Finish handling signed and unsigned integers\n                int numericLen = len;\n                bool isUnsigned = false;\n                bool isInt64 = false;\n                bool isInt16 = false;\n                if (ch == 'u' || ch == 'U') {\n                    if (len < MaxTokenLength)\n                        ppToken->name[len++] = (char)ch;\n                    isUnsigned = true;\n\n#ifndef GLSLANG_WEB\n                    int nextCh = getch();\n                    if (nextCh == 'l' || nextCh == 'L') {\n                        if (len < MaxTokenLength)\n                            ppToken->name[len++] = (char)nextCh;\n                        isInt64 = true;\n                    } else\n                        ungetch();\n\n                    nextCh = getch();\n                    if ((nextCh == 's' || nextCh == 'S') &&\n                                pp->parseContext.intermediate.getSource() == EShSourceGlsl) {\n                        if (len < MaxTokenLength)\n                            ppToken->name[len++] = (char)nextCh;\n                        isInt16 = true;\n                    } else\n                        ungetch();\n                } else if (ch == 'l' || ch == 'L') {\n                    if (len < MaxTokenLength)\n                        ppToken->name[len++] = (char)ch;\n                    isInt64 = true;\n                } else if ((ch == 's' || ch == 'S') &&\n                                pp->parseContext.intermediate.getSource() == EShSourceGlsl) {\n                    if (len < MaxTokenLength)\n                        ppToken->name[len++] = (char)ch;\n                    isInt16 = true;\n#endif\n                } else\n                    ungetch();\n\n                ppToken->name[len] = '\\0';\n                ival = 0;\n                const unsigned oneTenthMaxInt  = 0xFFFFFFFFu / 10;\n                const unsigned remainderMaxInt = 0xFFFFFFFFu - 10 * oneTenthMaxInt;\n                const unsigned long long oneTenthMaxInt64  = 0xFFFFFFFFFFFFFFFFull / 10;\n                const unsigned long long remainderMaxInt64 = 0xFFFFFFFFFFFFFFFFull - 10 * oneTenthMaxInt64;\n                const unsigned short oneTenthMaxInt16  = 0xFFFFu / 10;\n                const unsigned short remainderMaxInt16 = 0xFFFFu - 10 * oneTenthMaxInt16;\n                for (int i = 0; i < numericLen; i++) {\n                    ch = ppToken->name[i] - '0';\n                    bool overflow = false;\n                    if (isInt64)\n                        overflow = (ival > oneTenthMaxInt64 || (ival == oneTenthMaxInt64 && (unsigned long long)ch > remainderMaxInt64));\n                    else if (isInt16)\n                        overflow = (ival > oneTenthMaxInt16 || (ival == oneTenthMaxInt16 && (unsigned short)ch > remainderMaxInt16));\n                    else\n                        overflow = (ival > oneTenthMaxInt || (ival == oneTenthMaxInt && (unsigned)ch > remainderMaxInt));\n                    if (overflow) {\n                        pp->parseContext.ppError(ppToken->loc, \"numeric literal too big\", \"\", \"\");\n                        ival = 0xFFFFFFFFFFFFFFFFull;\n                        break;\n                    } else\n                        ival = ival * 10 + ch;\n                }\n\n                if (isInt64 && pp->parseContext.intermediate.getSource() == EShSourceGlsl) {\n                    if (pp->ifdepth == 0) {\n                        pp->parseContext.requireProfile(ppToken->loc, ~EEsProfile,\n   \"64-bit literal\");\n                        pp->parseContext.profileRequires(ppToken->loc, ~EEsProfile, 0,\n                            Num_Int64_Extensions, Int64_Extensions, \"64-bit literal\");\n                    }\n                    ppToken->i64val = ival;\n                    return isUnsigned ? PpAtomConstUint64 : PpAtomConstInt64;\n                } else if (isInt16) {\n                    if (pp->ifdepth == 0 && pp->parseContext.intermediate.getSource() == EShSourceGlsl) {\n                        pp->parseContext.requireProfile(ppToken->loc, ~EEsProfile,\n   \"16-bit  literal\");\n                        pp->parseContext.profileRequires(ppToken->loc, ~EEsProfile, 0,\n                            Num_Int16_Extensions, Int16_Extensions, \"16-bit literal\");\n                    }\n                    ppToken->ival = (int)ival;\n                    return isUnsigned ? PpAtomConstUint16 : PpAtomConstInt16;\n                } else {\n                    ppToken->ival = (int)ival;\n                    return isUnsigned ? PpAtomConstUint : PpAtomConstInt;\n                }\n            }\n            break;\n        case '-':\n            ch = getch();\n            if (ch == '-') {\n                return PpAtomDecrement;\n            } else if (ch == '=') {\n                return PPAtomSubAssign;\n            } else {\n                ungetch();\n                return '-';\n            }\n        case '+':\n            ch = getch();\n            if (ch == '+') {\n                return PpAtomIncrement;\n            } else if (ch == '=') {\n                return PPAtomAddAssign;\n            } else {\n                ungetch();\n                return '+';\n            }\n        case '*':\n            ch = getch();\n            if (ch == '=') {\n                return PPAtomMulAssign;\n            } else {\n                ungetch();\n                return '*';\n            }\n        case '%':\n            ch = getch();\n            if (ch == '=') {\n                return PPAtomModAssign;\n            } else {\n                ungetch();\n                return '%';\n            }\n        case '^':\n            ch = getch();\n            if (ch == '^') {\n                return PpAtomXor;\n            } else {\n                if (ch == '=')\n                    return PpAtomXorAssign;\n                else{\n                    ungetch();\n                    return '^';\n                }\n            }\n\n        case '=':\n            ch = getch();\n            if (ch == '=') {\n                return PpAtomEQ;\n            } else {\n                ungetch();\n                return '=';\n            }\n        case '!':\n            ch = getch();\n            if (ch == '=') {\n                return PpAtomNE;\n            } else {\n                ungetch();\n                return '!';\n            }\n        case '|':\n            ch = getch();\n            if (ch == '|') {\n                return PpAtomOr;\n            } else if (ch == '=') {\n                return PpAtomOrAssign;\n            } else {\n                ungetch();\n                return '|';\n            }\n        case '&':\n            ch = getch();\n            if (ch == '&') {\n                return PpAtomAnd;\n            } else if (ch == '=') {\n                return PpAtomAndAssign;\n            } else {\n                ungetch();\n                return '&';\n            }\n        case '<':\n            ch = getch();\n            if (ch == '<') {\n                ch = getch();\n                if (ch == '=')\n                    return PpAtomLeftAssign;\n                else {\n                    ungetch();\n                    return PpAtomLeft;\n                }\n            } else if (ch == '=') {\n                return PpAtomLE;\n            } else {\n                ungetch();\n                return '<';\n            }\n        case '>':\n            ch = getch();\n            if (ch == '>') {\n                ch = getch();\n                if (ch == '=')\n                    return PpAtomRightAssign;\n                else {\n                    ungetch();\n                    return PpAtomRight;\n                }\n            } else if (ch == '=') {\n                return PpAtomGE;\n            } else {\n                ungetch();\n                return '>';\n            }\n        case '.':\n            ch = getch();\n            if (ch >= '0' && ch <= '9') {\n                ungetch();\n                return pp->lFloatConst(0, '.', ppToken);\n            } else {\n                ungetch();\n                return '.';\n            }\n        case '/':\n            ch = getch();\n            if (ch == '/') {\n                pp->inComment = true;\n                do {\n                    ch = getch();\n                } while (ch != '\\n' && ch != EndOfInput);\n                ppToken->space = true;\n                pp->inComment = false;\n\n                return ch;\n            } else if (ch == '*') {\n                ch = getch();\n                do {\n                    while (ch != '*') {\n                        if (ch == EndOfInput) {\n                            pp->parseContext.ppError(ppToken->loc, \"End of input in comment\", \"comment\", \"\");\n                            return ch;\n                        }\n                        ch = getch();\n                    }\n                    ch = getch();\n                    if (ch == EndOfInput) {\n                        pp->parseContext.ppError(ppToken->loc, \"End of input in comment\", \"comment\", \"\");\n                        return ch;\n                    }\n                } while (ch != '/');\n                ppToken->space = true;\n                // loop again to get the next token...\n                break;\n            } else if (ch == '=') {\n                return PPAtomDivAssign;\n            } else {\n                ungetch();\n                return '/';\n            }\n            break;\n        case '\\'':\n            return pp->characterLiteral(ppToken);\n        case '\"':\n            // #include uses scanHeaderName() to ignore these escape sequences.\n            ch = getch();\n            while (ch != '\"' && ch != '\\n' && ch != EndOfInput) {\n                if (len < MaxTokenLength) {\n                    if (ch == '\\\\' && !pp->disableEscapeSequences) {\n                        int nextCh = getch();\n                        switch (nextCh) {\n                        case '\\'': ch = 0x27; break;\n                        case '\"':  ch = 0x22; break;\n                        case '?':  ch = 0x3f; break;\n                        case '\\\\': ch = 0x5c; break;\n                        case 'a':  ch = 0x07; break;\n                        case 'b':  ch = 0x08; break;\n                        case 'f':  ch = 0x0c; break;\n                        case 'n':  ch = 0x0a; break;\n                        case 'r':  ch = 0x0d; break;\n                        case 't':  ch = 0x09; break;\n                        case 'v':  ch = 0x0b; break;\n                        case 'x':\n                            // Hex value, arbitrary number of characters. Terminated by the first\n                            // non-hex digit\n                            {\n                                int numDigits = 0;\n                                ch = 0;\n                                while (true) {\n                                    nextCh = getch();\n                                    if (nextCh >= '0' && nextCh <= '9')\n                                        nextCh -= '0';\n                                    else if (nextCh >= 'A' && nextCh <= 'F')\n                                        nextCh -= 'A' - 10;\n                                    else if (nextCh >= 'a' && nextCh <= 'f')\n                                        nextCh -= 'a' - 10;\n                                    else {\n                                        ungetch();\n                                        break;\n                                    }\n                                    numDigits++;\n                                    ch = ch * 0x10 + nextCh;\n                                }\n                                if (numDigits == 0) {\n                                    pp->parseContext.ppError(ppToken->loc, \"Expected hex value in escape sequence\", \"string\", \"\");\n                                }\n                                break;\n                            }\n                        case '0':\n                        case '1':\n                        case '2':\n                        case '3':\n                        case '4':\n                        case '5':\n                        case '6':\n                        case '7':\n                            // Octal value, up to three octal digits\n                            {\n                                int numDigits = 1;\n                                ch = nextCh - '0';\n                                while (numDigits < 3) {\n                                    nextCh = getch();\n                                    if (nextCh >= '0' && nextCh <= '7')\n                                        nextCh -= '0';\n                                    else {\n                                        ungetch();\n                                        break;\n                                    }\n                                    numDigits++;\n                                    ch = ch * 8 + nextCh;\n                                }\n                                break;\n                            }\n                        default:\n                            pp->parseContext.ppError(ppToken->loc, \"Invalid escape sequence\", \"string\", \"\");\n                            break;\n                        }\n                    }\n                    ppToken->name[len] = (char)ch;\n                    len++;\n                    ch = getch();\n                } else\n                    break;\n            };\n            ppToken->name[len] = '\\0';\n            if (ch != '\"') {\n                ungetch();\n                pp->parseContext.ppError(ppToken->loc, \"End of line in string\", \"string\", \"\");\n            }\n            return PpAtomConstString;\n        case ':':\n            ch = getch();\n            if (ch == ':')\n                return PpAtomColonColon;\n            ungetch();\n            return ':';\n        }\n\n        ch = getch();\n    }\n}\n\n//\n// The main functional entry point into the preprocessor, which will\n// scan the source strings to figure out and return the next processing token.\n//\n// Return the token, or EndOfInput when no more tokens.\n//\nint TPpContext::tokenize(TPpToken& ppToken)\n{\n    for(;;) {\n        int token = scanToken(&ppToken);\n\n        // Handle token-pasting logic\n        token = tokenPaste(token, ppToken);\n\n        if (token == EndOfInput) {\n            missingEndifCheck();\n            return EndOfInput;\n        }\n        if (token == '#') {\n            if (previous_token == '\\n') {\n                token = readCPPline(&ppToken);\n                if (token == EndOfInput) {\n                    missingEndifCheck();\n                    return EndOfInput;\n                }\n                continue;\n            } else {\n                parseContext.ppError(ppToken.loc, \"preprocessor directive cannot be preceded by another token\", \"#\", \"\");\n                return EndOfInput;\n            }\n        }\n        previous_token = token;\n\n        if (token == '\\n')\n            continue;\n\n        // expand macros\n        if (token == PpAtomIdentifier) {\n            switch (MacroExpand(&ppToken, false, true)) {\n            case MacroExpandNotStarted:\n                break;\n            case MacroExpandError:\n                return EndOfInput;\n            case MacroExpandStarted:\n            case MacroExpandUndef:\n                continue;\n            }\n        }\n\n        switch (token) {\n        case PpAtomIdentifier:\n        case PpAtomConstInt:\n        case PpAtomConstUint:\n        case PpAtomConstFloat:\n        case PpAtomConstInt64:\n        case PpAtomConstUint64:\n        case PpAtomConstInt16:\n        case PpAtomConstUint16:\n        case PpAtomConstDouble:\n        case PpAtomConstFloat16:\n            if (ppToken.name[0] == '\\0')\n                continue;\n            break;\n        case PpAtomConstString:\n            // HLSL allows string literals.\n            // GLSL allows string literals with GL_EXT_debug_printf.\n            if (ifdepth == 0 && parseContext.intermediate.getSource() != EShSourceHlsl) {\n              const char* const string_literal_EXTs[] = { E_GL_EXT_debug_printf, E_GL_EXT_spirv_intrinsics };\n              parseContext.requireExtensions(ppToken.loc, 2, string_literal_EXTs, \"string literal\");\n              if (!parseContext.extensionTurnedOn(E_GL_EXT_debug_printf) &&\n                  !parseContext.extensionTurnedOn(E_GL_EXT_spirv_intrinsics))\n                  continue;\n            }\n            break;\n        case '\\'':\n            parseContext.ppError(ppToken.loc, \"character literals not supported\", \"\\'\", \"\");\n            continue;\n        default:\n            snprintf(ppToken.name, sizeof(ppToken.name), \"%s\", atomStrings.getString(token));\n            break;\n        }\n\n        return token;\n    }\n}\n\n//\n// Do all token-pasting related combining of two pasted tokens when getting a\n// stream of tokens from a replacement list. Degenerates to no processing if a\n// replacement list is not the source of the token stream.\n//\nint TPpContext::tokenPaste(int token, TPpToken& ppToken)\n{\n    // starting with ## is illegal, skip to next token\n    if (token == PpAtomPaste) {\n        parseContext.ppError(ppToken.loc, \"unexpected location\", \"##\", \"\");\n        return scanToken(&ppToken);\n    }\n\n    int resultToken = token; // \"foo\" pasted with \"35\" is an identifier, not a number\n\n    // ## can be chained, process all in the chain at once\n    while (peekPasting()) {\n        TPpToken pastedPpToken;\n\n        // next token has to be ##\n        token = scanToken(&pastedPpToken);\n        assert(token == PpAtomPaste);\n\n        // This covers end of macro expansion\n        if (endOfReplacementList()) {\n            parseContext.ppError(ppToken.loc, \"unexpected location; end of replacement list\", \"##\", \"\");\n            break;\n        }\n\n        // Get the token(s) after the ##.\n        // Because of \"space\" semantics, and prior tokenization, what\n        // appeared a single token, e.g. \"3A\", might have been tokenized\n        // into two tokens \"3\" and \"A\", but the \"A\" will have 'space' set to\n        // false.  Accumulate all of these to recreate the original lexical\n        // appearing token.\n        do {\n            token = scanToken(&pastedPpToken);\n\n            // This covers end of argument expansion\n            if (token == tMarkerInput::marker) {\n                parseContext.ppError(ppToken.loc, \"unexpected location; end of argument\", \"##\", \"\");\n                return resultToken;\n            }\n\n            // get the token text\n            switch (resultToken) {\n            case PpAtomIdentifier:\n                // already have the correct text in token.names\n                break;\n            case '=':\n            case '!':\n            case '-':\n            case '~':\n            case '+':\n            case '*':\n            case '/':\n            case '%':\n            case '<':\n            case '>':\n            case '|':\n            case '^':\n            case '&':\n            case PpAtomRight:\n            case PpAtomLeft:\n            case PpAtomAnd:\n            case PpAtomOr:\n            case PpAtomXor:\n                snprintf(ppToken.name, sizeof(ppToken.name), \"%s\", atomStrings.getString(resultToken));\n                snprintf(pastedPpToken.name, sizeof(pastedPpToken.name), \"%s\", atomStrings.getString(token));\n                break;\n            default:\n                parseContext.ppError(ppToken.loc, \"not supported for these tokens\", \"##\", \"\");\n                return resultToken;\n            }\n\n            // combine the tokens\n            if (strlen(ppToken.name) + strlen(pastedPpToken.name) > MaxTokenLength) {\n                parseContext.ppError(ppToken.loc, \"combined tokens are too long\", \"##\", \"\");\n                return resultToken;\n            }\n            snprintf(&ppToken.name[0] + strlen(ppToken.name), sizeof(ppToken.name) - strlen(ppToken.name),\n                \"%s\", pastedPpToken.name);\n\n            // correct the kind of token we are making, if needed (identifiers stay identifiers)\n            if (resultToken != PpAtomIdentifier) {\n                int newToken = atomStrings.getAtom(ppToken.name);\n                if (newToken > 0)\n                    resultToken = newToken;\n                else\n                    parseContext.ppError(ppToken.loc, \"combined token is invalid\", \"##\", \"\");\n            }\n        } while (peekContinuedPasting(resultToken));\n    }\n\n    return resultToken;\n}\n\n// Checks if we've seen balanced #if...#endif\nvoid TPpContext::missingEndifCheck()\n{\n    if (ifdepth > 0)\n        parseContext.ppError(parseContext.getCurrentLoc(), \"missing #endif\", \"\", \"\");\n}\n\n} // end namespace glslang\n",
    "file_path": "data\\preprocessed\\google_filament__third_party_glslang_glslang_MachineIndependent_preprocessor_PpScanner.cpp",
    "file_name": "google_filament__third_party_glslang_glslang_MachineIndependent_preprocessor_PpScanner.cpp",
    "language": "cpp"
  },
  {
    "text": "// Copyright 2019 Google LLC.\n// Use of this source code is governed by a BSD-style license that can be found in the LICENSE file.\n#include \"tools/fiddle/examples.h\"\n// HASH=05db6a937225e8e31ae3481173d25dae\nREG_FIDDLE(Canvas_kInitWithPrevious_SaveLayerFlag, 256, 160, false, 0) {\nvoid draw(SkCanvas* canvas) {\n    SkPaint redPaint, bluePaint, scalePaint;\n    redPaint.setColor(SK_ColorRED);\n    canvas->drawCircle(21, 21, 8, redPaint);\n    bluePaint.setColor(SK_ColorBLUE);\n    canvas->drawCircle(31, 21, 8, bluePaint);\n    SkMatrix matrix;\n    matrix.setScale(4, 4);\n    scalePaint.setAlpha(0x40);\n    scalePaint.setImageFilter(\n            SkImageFilters::MatrixTransform(matrix, SkSamplingOptions(), nullptr));\n    SkCanvas::SaveLayerRec saveLayerRec(nullptr, &scalePaint,\n            SkCanvas::kInitWithPrevious_SaveLayerFlag);\n    canvas->saveLayer(saveLayerRec);\n    canvas->restore();\n}\n}  // END FIDDLE\n",
    "file_path": "data\\preprocessed\\google_skia__docs_examples_Canvas_kInitWithPrevious_SaveLayerFlag.cpp",
    "file_name": "google_skia__docs_examples_Canvas_kInitWithPrevious_SaveLayerFlag.cpp",
    "language": "cpp"
  },
  {
    "text": "/***\n *\n * Copyright (C) 1990-2007, Condor Team, Computer Sciences Department,\n * University of Wisconsin-Madison, WI.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\"); you\n * may not use this file except in compliance with the License.  You may\n * obtain a copy of the License at\n *\n *    https://example.com/path\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n ***/\n\n#include \"condor_common.h\"\n#include \"pipe.WINDOWS.h\"\n#include \"stl_string_utils.h\"\n\nextern CRITICAL_SECTION Big_fat_mutex;\n\nPipeEnd::PipeEnd(HANDLE handle, bool overlapped, bool nonblocking, int pipe_size) :\n\t\tm_handle(handle), m_overlapped(overlapped),\n\t\tm_nonblocking(nonblocking), m_pipe_size(pipe_size),\n\t\tm_registered(false), m_watched_event(NULL)\n{\n\tstd::string event_name;\n\n\t// create a manual reset Event, set initially to signaled\n\t// to be used for overlapped operations\n\tformatstr(event_name, \"pipe_event_%d_%x\", GetCurrentProcessId(), m_handle);\n\tm_event = CreateEvent( NULL, TRUE, TRUE, event_name.c_str() );\n\tASSERT(m_event);\n\n\t// create the event for waiting until a PID-watcher\n\t// is done using this object\n\tformatstr(event_name, \"pipe_watched_event_%d_%x\",\n\t\tGetCurrentProcessId(), m_handle);\n\tm_watched_event = CreateEvent(NULL, TRUE, TRUE, event_name.c_str());\n\tASSERT(m_watched_event);\n}\n\n// this will be called from Close_Pipe\nPipeEnd::~PipeEnd()\n{\n\t// make sure we've been cancelled first\n\tASSERT(!m_registered);\n\n\tCloseHandle(m_watched_event);\n\tCloseHandle(m_event);\n\tCloseHandle(m_handle);\n}\n\n// method to wrap WaitForSingleObject so we release our mutex that\n// is shared with the daemoncore pid watcher thread.  if we don't\n// do this, we will deadlock!!!\nDWORD PipeEnd::WaitForSingleObject(HANDLE handle, DWORD millisecs)\n{\n\tDWORD result;\n\n\t::LeaveCriticalSection(&Big_fat_mutex); // release big fat mutex\n\tresult = ::WaitForSingleObject(handle,millisecs);\n\t::EnterCriticalSection(&Big_fat_mutex); // enter big fat mutex\n\n\treturn result;\n}\n\n// this will be called from Register_Pipe, before WatchPid\nvoid PipeEnd::set_registered()\n{\n\tASSERT(m_overlapped && !m_registered);\n\n\t// mark ourself as registered\n\tm_registered = true;\n}\n\n// the is called in DaemonCore from WatchPid\nvoid PipeEnd::set_watched()\n{\n\tASSERT(m_registered && m_watched_event);\n\tResetEvent(m_watched_event);\n}\n\n// this is either called from the PID-watcher if it detects the\n// deallocate flag is set, or from cancel() if there is no\n// PID-watcher for this object\nvoid PipeEnd::set_unregistered()\n{\n\tASSERT(m_registered && m_watched_event);\n\n\t// mark ourselves unregistered\n\tm_registered = false;\n\n\t// tell the main thread that the PID-watcher thread\n\t// will no longer touch this object\n\tSetEvent(m_watched_event);\n}\n\n// this is called from Cancel_Pipe - it returns\n// when we know that there is no longer a PID-watcher\n// thread watching this PipeEnd and this PipeEnd\n// has been unregistered\nvoid PipeEnd::cancel()\n{\n\t// wait until we know a PID-watcher is no longer using this object\n\tDWORD result = WaitForSingleObject(m_watched_event, INFINITE);\n\tASSERT(result == WAIT_OBJECT_0);\n\n\t// if the PID-watcher did not call set_unregistered, do it here\n\tif (m_registered) {\n\t\tset_unregistered();\n\t}\n}\n\nHANDLE ReadPipeEnd::pre_wait()\n{\n\tASSERT(m_registered);\n\n\tif (m_async_io_state == IO_UNSTARTED) {\n\n\t\t// begin an overlapped read of one byte\n\n\t\tZeroMemory(&m_overlapped_struct, sizeof(OVERLAPPED));\n\t\tm_overlapped_struct.hEvent = m_event;\n\n\t\tDWORD bytes;\n\t\tif (ReadFile(m_handle,\n\t\t\t\t\t &m_async_io_buf,\n\t\t\t\t\t 1,\n\t\t\t\t\t &bytes,\n\t\t\t\t\t &m_overlapped_struct)\n\t\t) {\n\t\t\t// read succeeded immediately and so the event is left signaled\n\t\t\tm_async_io_state = IO_DONE;\n\t\t\tif (bytes == 0) {\n\t\t\t\tm_async_io_error = ERROR_HANDLE_EOF;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tm_async_io_error = 0;\n\t\t\t}\n\t\t}\n\t\telse if (GetLastError() == ERROR_IO_PENDING) {\n\t\t\t// event is now unsignaled and will go to signaled when\n\t\t\t// the operation is complete\n\t\t\tm_async_io_state = IO_PENDING;\n\t\t\tm_async_io_error = 0;\n\t\t}\n\t\telse {\n\t\t\t// An error occured. Make sure our event object is set\n\t\t\t// so that a read won't block\n\t\t\tm_async_io_state = IO_DONE;\n\t\t\tm_async_io_error = GetLastError();\n\t\t\tSetEvent(m_event);\n\t\t}\n\t}\n\n\treturn m_event;\n}\n\nbool ReadPipeEnd::post_wait()\n{\n\tif (m_async_io_state == IO_PENDING) {\n\t\tDWORD bytes;\n\t\tif (!GetOverlappedResult(m_handle, &m_overlapped_struct, &bytes, TRUE)) {\n\t\t\tm_async_io_error = GetLastError();\n\t\t}\n\t\telse if (bytes == 0) {\n\t\t\tm_async_io_error = ERROR_HANDLE_EOF;\n\t\t}\n\t\telse {\n\t\t\tm_async_io_error = 0;\n\t\t}\n\t\tm_async_io_state = IO_DONE;\n\t}\n\n\tASSERT(m_async_io_state == IO_DONE);\n\n\t// tell the main thread that the PID-watcher is done with\n\t// this object\n\tSetEvent(m_watched_event);\n\n\treturn true;\n}\n\n// this is called from DaemonCore::Driver to ensure that it is safe\n// to fire the handler without fear of blocking\nbool ReadPipeEnd::io_ready()\n{\n\treturn m_async_io_state == IO_DONE;\n}\n\nint ReadPipeEnd::read(void* buffer, int len)\n{\n\tint ret;\n\n\t// len can be at most the size of the pipe buffer.\n\t// The caller should be able to handle short reads\n\tif (len > m_pipe_size) {\n\t\tlen = m_pipe_size;\n\t}\n\n\t// start with errno set to something other than EWOULDBLOCK\n\terrno = EINVAL;\n\n\t// wait until we are not being managed by a PID-watcher\n\tDWORD result = WaitForSingleObject(m_watched_event, m_nonblocking ? 0 : INFINITE);\n\tif (result == WAIT_TIMEOUT) {\n\t\terrno = EWOULDBLOCK;\n\t\treturn -1;\n\t}\n\tASSERT(result == WAIT_OBJECT_0);\n\n\t// if we're unregistered and there's a pending ReadFile, then we\n\t// need to check the operation's status, since the PID-watcher thread\n\t// is no longer around to monitor it\n\tif (m_async_io_state == IO_PENDING) {\n\n\t\tASSERT(!m_registered);\n\n\t\tDWORD res = WaitForSingleObject(m_event, m_nonblocking ? 0 : INFINITE);\n\t\tif (res == WAIT_TIMEOUT) {\n\t\t\terrno = EWOULDBLOCK;\n\t\t\treturn -1;\n\t\t}\n\n\t\tDWORD bytes;\n\t\tif (!GetOverlappedResult(m_handle, &m_overlapped_struct, &bytes, TRUE)) {\n\t\t\tm_async_io_error = GetLastError();\n\t\t}\n\t\telse if (bytes == 0) {\n\t\t\tm_async_io_error = ERROR_HANDLE_EOF;\n\t\t}\n\t\telse {\n\t\t\tm_async_io_error = 0;\n\t\t}\n\t\tm_async_io_state = IO_DONE;\n\t}\n\n\tASSERT(m_async_io_state != IO_PENDING);\n\n\tif (m_async_io_state == IO_DONE) {\n\n\t\tif (m_async_io_error) {\n\t\t\tif (m_async_io_error == ERROR_HANDLE_EOF || m_async_io_error == ERROR_BROKEN_PIPE) {\n\t\t\t\tret = 0;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tret = -1;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\t// an asynchronous operation has completed, we copy out the\n\t\t\t// single byte and then peek ahead to see if there's anything\n\t\t\t// else to read\n\t\t\t*(char*)buffer = m_async_io_buf;\n\n\t\t\tDWORD bytes_left;\n\t\t\tif (!PeekNamedPipe(m_handle, NULL, 0, NULL, &bytes_left, NULL)) {\n\t\t\t\tdprintf(D_ALWAYS, \"PeekNamedPipe error: %d\\n\", GetLastError());\n\t\t\t\tret = -1;\n\t\t\t}\n\t\t\telse if (bytes_left > 0) {\n\t\t\t\t// read what's left on the pipe - we know this won't block or return\n\t\t\t\t// with errno == EWOULDBLOCK because of the peek\n\t\t\t\tret = read_helper((char*)buffer + 1, len - 1);\n\t\t\t\tif (ret != -1) {\n\t\t\t\t\t// we want to return the total number of bytes placed in the buffer,\n\t\t\t\t\t// which is whatever we just read plus the one from the async_io_buf\n\t\t\t\t\tret += 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\t// no more data on the pipe; just 1 byte was read\n\t\t\t\tret = 1;\n\t\t\t}\n\t\t\tm_async_io_state = IO_UNSTARTED;\n\t\t}\n\t}\n\telse {\n\t\t\t// we're not registered and there's no outstanding async I/O - just read\n\t\t\tret = read_helper(buffer, len);\n\t}\n\n\treturn ret;\n}\n\nint ReadPipeEnd::read_helper(void* buffer, int len)\n{\n\t// set errno to something other than EWOULDBLOCK\n\terrno = EINVAL;\n\n\t// if we're nonblocking, we peek ahead and only read\n\t// if we know there's data to be read\n\tif (m_nonblocking) {\n\t\tDWORD bytes_avail;\n\t\tif (!PeekNamedPipe(m_handle, NULL, 0, NULL, &bytes_avail, NULL)) {\n\t\t\tif (GetLastError() == ERROR_BROKEN_PIPE) {\n\t\t\t\t// this happens on EOF\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\tdprintf(D_ALWAYS, \"PeekNamedPipe error: %d\\n\", GetLastError());\n\t\t\treturn -1;\n\t\t}\n\t\tif (bytes_avail == 0) {\n\t\t\terrno = EWOULDBLOCK;\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\t// setup an overlapped structure if the pipe is\n\t// opened in overlapped mode\n\tOVERLAPPED tmp_overlapped;\n\tOVERLAPPED *p_overlapped = NULL;\n\tif (m_overlapped) {\n\t\tZeroMemory(&tmp_overlapped, sizeof(OVERLAPPED));\n\t\tp_overlapped = &tmp_overlapped;\n\t}\n\n\t// do the read\n\tDWORD bytes;\n\tif (!ReadFile(m_handle, buffer, len, &bytes, p_overlapped)) {\n\t\tif (m_overlapped) {\n\t\t\tif (GetLastError() == ERROR_IO_PENDING) {\n\t\t\t\tif (!GetOverlappedResult(m_handle, p_overlapped, &bytes, TRUE)) {\n\t\t\t\t\tif (GetLastError() == ERROR_HANDLE_EOF || GetLastError() == ERROR_BROKEN_PIPE) {\n\t\t\t\t\t\tbytes = 0;\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tdprintf(D_ALWAYS | D_BACKTRACE, \"read_helper: GetOverlappedResult error: %d\\n\", GetLastError());\n\t\t\t\t\t\treturn -1;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse if (GetLastError() == ERROR_HANDLE_EOF || GetLastError() == ERROR_BROKEN_PIPE) {\n\t\t\tbytes = 0;\n\t\t}\n\t\telse {\n\t\t\tdprintf(D_ALWAYS, \"ReadFile error: %d\\n\", GetLastError());\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\treturn bytes;\n}\n\n// just return the Event handle to wait for an  outstanding operation to complete,\n// if one exists\nHANDLE WritePipeEnd::pre_wait()\n{\n\treturn m_event;\n}\n\n// an outstanding operation has completed, so issue\n// the GetOverlappedResult and update our internal\n// state based on the results\nbool WritePipeEnd::post_wait()\n{\n\tif (m_async_io_buf) {\n\n\t\t// an asynchronous operation was pending; get\n\t\t// the result\n\t\tDWORD bytes;\n\t\tGetOverlappedResult(m_handle, &m_overlapped_struct, &bytes, TRUE);\n\t\tif (bytes < m_async_io_size) {\n\n\t\t\t// only a portion of the buffer was written\n\t\t\t// update our buffer data\n\t\t\tm_async_io_size -= bytes;\n\t\t\tchar* buf = new char[m_async_io_size];\n\t\t\tmemcpy(buf, m_async_io_buf + bytes, m_async_io_size);\n\t\t\tdelete[] m_async_io_buf;\n\t\t\tm_async_io_buf = buf;\n\n\t\t\t// attempt to write the rest of the buffer; note that it is\n\t\t\t// possible that this will result in another outstanding\n\t\t\t// overlapped I/O.\n\t\t\tasync_write_helper();\n\n\n\t\t}\n\t\telse {\n\t\t\tdelete[] m_async_io_buf;\n\t\t\tm_async_io_buf = NULL;\n\t\t}\n\t}\n\n\tif (m_async_io_buf) {\n\t\t// if there's still and outstanding write, we aren't done yet\n\t\treturn false;\n\t}\n\telse {\n\t\t// the write is complete! signal the Event object that the\n\t\t// PID-watcher is done with this thread\n\t\tSetEvent(m_watched_event);\n\n\t\treturn true;\n\t}\n}\n\n// called from DaemonCore::Driver by main thread after\n// the PID-watcher thread has called post_wait\nbool WritePipeEnd::io_ready()\n{\n\treturn m_async_io_buf == NULL;\n}\n\nint WritePipeEnd::write(const void* buffer, int len)\n{\n\t// set errno to something other than EWOULDBLOCK\n\terrno = EINVAL;\n\n\tif (!m_overlapped) {\n\n\t\t// we're not overlapped - just issue a blocking write\n\t\t// (if Create_Pipe had write_nonblocking set, we'd be overlapped)\n\t\tDWORD bytes;\n\t\tif (!WriteFile(m_handle, buffer, len, &bytes, NULL)) {\n\t\t\tdprintf(D_ALWAYS, \"WriteFile error: %d\\n\", GetLastError());\n\t\t\treturn -1;\n\t\t}\n\t\treturn bytes;\n\t}\n\telse {\n\n\t\t// wait for the PID-watcher to stop using this object\n\t\tDWORD result = WaitForSingleObject(m_watched_event, m_nonblocking ? 0 : INFINITE);\n\t\tif (result == WAIT_TIMEOUT) {\n\t\t\terrno = EWOULDBLOCK;\n\t\t\treturn -1;\n\t\t}\n\t\tASSERT(result == WAIT_OBJECT_0);\n\n\t\t// can't proceed unless m_async_io_buf is NULL\n\t\twhile (m_async_io_buf) {\n\n\t\t\t// attempt to complete the outstanding overlapped operation\n\t\t\tif (!complete_async_write(m_nonblocking)) {\n\t\t\t\terrno = EWOULDBLOCK;\n\t\t\t\treturn -1;\n\t\t\t}\n\t\t}\n\n\t\tint ret = len;\n\n\t\tif (m_async_io_error) {\n\t\t\tif (ERROR_BROKEN_PIPE == m_async_io_error) errno = EPIPE;\n\t\t\tret = -1;\n\t\t}\n\t\telse {\n\t\t\t// ok, so now we can proceed with the write\n\t\t\tm_async_io_size = len;\n\t\t\tm_async_io_buf = new char[m_async_io_size];\n\t\t\tmemcpy(m_async_io_buf, buffer, m_async_io_size);\n\t\t\tif (async_write_helper() == -1) {\n\t\t\t\tif (ERROR_BROKEN_PIPE == m_async_io_error) errno = EPIPE;\n\t\t\t\tret = -1;\n\t\t\t}\n\t\t\telse {\n\t\t\t\tret = len;\n\t\t\t}\n\t\t}\n\n\t\treturn ret;\n\t}\n}\n\n// issues an asyncronous write and handles the case when the async\n// operation completes right away with a short write\n// possible outcomes:\n//   - the write operation completes\n//   - the wrtie operation is pending\n//   - some number of writes succeed but do not write all the data,\n//     leaving us with a shorter pending write\n//   - an error occurs\nint WritePipeEnd::async_write_helper()\n{\n\tint ret;\n\n\tm_async_io_error = 0;\n\n\tbool keep_going;\n\tdo {\n\t\tkeep_going = false;\n\t\tZeroMemory(&m_overlapped_struct, sizeof(OVERLAPPED));\n\t\tm_overlapped_struct.hEvent = m_event;\n\t\tDWORD bytes;\n\t\tif (WriteFile(m_handle, m_async_io_buf, m_async_io_size, &bytes, &m_overlapped_struct)) {\n\t\t\tif (bytes == m_async_io_size) {\n\t\t\t\t// the write succeeded in full; deallocate the buffer and return\n\t\t\t\tdelete[] m_async_io_buf;\n\t\t\t\tm_async_io_buf = NULL;\n\t\t\t\tm_async_io_size = 0;\n\t\t\t\tret = 0;\n\t\t\t}\n\t\t\telse {\n\t\t\t\t// the write is partially completed; adjust buffer and keep going\n\t\t\t\tm_async_io_size -= bytes;\n\t\t\t\tchar* buf = new char[m_async_io_size];\n\t\t\t\tmemcpy(buf, m_async_io_buf + bytes, m_async_io_size);\n\t\t\t\tdelete[] m_async_io_buf;\n\t\t\t\tm_async_io_buf = buf;\n\t\t\t\tkeep_going = true;\n\t\t\t}\n\t\t}\n\t\telse if (GetLastError() == ERROR_IO_PENDING) {\n\t\t\t// the write is pending; nothing more we can do right now\n\t\t\tret = 0;\n\t\t}\n\t\telse {\n\t\t\t// some type of failure occurred\n\t\t\tm_async_io_error = GetLastError();\n\t\t\tdelete[] m_async_io_buf;\n\t\t\tm_async_io_buf = NULL;\n\t\t\tret = -1;\n\n\t\t\t// make sure our Event object is signaled\n\t\t\tSetEvent(m_event);\n\t\t}\n\t} while (keep_going);\n\n\treturn ret;\n}\n\nbool WritePipeEnd::complete_async_write(bool nonblocking)\n{\n\twhile (m_async_io_buf) {\n\n\t\t// wait on the overlapped event\n\t\tDWORD result = WaitForSingleObject(m_event, nonblocking ? 0 : INFINITE);\n\t\tif (result == WAIT_TIMEOUT) {\n\t\t\treturn false;\n\t\t}\n\t\tASSERT(result == WAIT_OBJECT_0);\n\n\t\tDWORD bytes;\n\t\tif (!GetOverlappedResult(m_handle, &m_overlapped_struct, &bytes, TRUE)) {\n\t\t\tdprintf(D_ALWAYS | D_BACKTRACE, \"complete_async_write: GetOverlappedResult error: %d\\n\", GetLastError());\n\t\t\tm_async_io_error = GetLastError();\n\t\t\tif (m_async_io_error == ERROR_PIPE_NOT_CONNECTED || m_async_io_error == ERROR_BROKEN_PIPE) {\n\t\t\t\t// the operation cannot complete\n\t\t\t\tdelete[] m_async_io_buf;\n\t\t\t\tm_async_io_buf = NULL;\n\t\t\t}\n\n\t\t\t// return true since false indicates EWOULDBLOCK, which is not what we want\n\t\t\treturn true;\n\t\t}\n\t\tif (bytes < m_async_io_size) {\n\t\t\t// only a portion of the buffer was written\n\t\t\t// start a new async I/O with the remaining bytes\n\t\t\tm_async_io_size -= bytes;\n\t\t\tchar* buf = new char[m_async_io_size];\n\t\t\tmemcpy(buf, m_async_io_buf + bytes, m_async_io_size);\n\t\t\tdelete[] m_async_io_buf;\n\t\t\tm_async_io_buf = buf;\n\t\t\tasync_write_helper();\n\t\t}\n\t\telse {\n\t\t\t// the operation is complete\n\t\t\tdelete[] m_async_io_buf;\n\t\t\tm_async_io_buf = NULL;\n\t\t}\n\t}\n\n\treturn true;\n}\n\n",
    "file_path": "data\\preprocessed\\htcondor_htcondor__src_condor_daemon_core.V6_pipe.WINDOWS.cpp",
    "file_name": "htcondor_htcondor__src_condor_daemon_core.V6_pipe.WINDOWS.cpp",
    "language": "cpp"
  },
  {
    "text": "/*\n * Copyright (C) 2018 Intel Corporation. All rights reserved.\n *\n * SPDX-License-Identifier: BSD-3-Clause\n*/\n/**\n * @file    IasAvbClockDomain.cpp\n * @brief   The implementation of the IasAvbClockDomain class.\n * @date    2013\n */\n\n#include \"avb_streamhandler/IasAvbClockDomain.hpp\"\n#include \"avb_streamhandler/IasAvbStreamHandlerEnvironment.hpp\"\n#include <cmath>\n#include <dlt_cpp_extension.hpp>\n\nnamespace IasMediaTransportAvb {\n\nstatic const std::string cClassName = \"IasAvbClockDomain::\";\n#define LOG_PREFIX cClassName + __func__ + \"(\" + std::to_string(__LINE__) + \"):\"\n\n/*\n *  Constructor.\n */\nIasAvbClockDomain::IasAvbClockDomain(DltContext &dltContext, IasAvbClockDomainType type)\n  : mType(type)\n  , mTimeConstant(0.0)\n  , mAvgCallsPerSec(1)\n  , mRateRatio(1.0)\n  , mCompensation(1.0)\n  , mEventCount(0u)\n  , mEventRate(0u)\n  , mEventTimeStamp(0u)\n  , mRateRatioSlow(1.0)\n  , mRateRatioFast(1.0)\n  , mCoeffSlowLocked(0.0)\n  , mCoeffSlowUnlocked(0.0)\n  , mCoeffFastLocked(0.0)\n  , mCoeffFastUnlocked(0.0)\n  , mThresholdSlowLow(0.0)\n  , mThresholdSlowHigh(0.0)\n  , mThresholdFastLow(0.0)\n  , mThresholdFastHigh(0.0)\n  , mInitialValue(1.0)\n  , mDerivationFactorUnlock(1.0)\n  , mDerivationFactorLongTerm(1.0)\n  , mLockState(eIasAvbLockStateInit)\n  , mLock()\n  , mDebugCount(0u)\n  , mDebugUnlockCount(0u)\n  , mDebugLockedPercentage(1.0)\n  , mDebugMinRatio(1.0/0.0)\n  , mDebugMaxRatio(0.0)\n  , mDebugOver(0u)\n  , mDebugUnder(0u)\n  , mDebugIn(0u)\n  , mClient(NULL)\n  , mDebugLogInterval(5u)\n  , mResetRequest(false)\n  , mClockId(-1)\n  , mLog(&dltContext)\n{\n  (void) IasAvbStreamHandlerEnvironment::getConfigValue(IasRegKeys::cDebugClkDomainIntvl, mDebugLogInterval);\n}\n\n\n/*\n *  Destructor.\n */\nIasAvbClockDomain::~IasAvbClockDomain()\n{\n  // do nothing\n}\n\n\nvoid IasAvbClockDomain::updateRateRatio(double newRatio)\n{\n  // sanity check, needed for ptp epoch changes\n  if ((newRatio < 0.0) || (newRatio > 10.0))\n  {\n    return;\n  }\n\n  const bool locked1high = (newRatio < (mThresholdFastHigh * mRateRatioFast));\n  const bool locked1low = (newRatio > (mThresholdFastLow * mRateRatioFast));\n\n  const bool locked1 = locked1high && locked1low;\n\n  if (eIasAvbLockStateLocked == mLockState)\n  {\n    smooth(mRateRatioSlow, newRatio, mCoeffSlowLocked);\n    smooth(mRateRatioFast, newRatio, mCoeffFastLocked);\n  }\n  else\n  {\n    smooth(mRateRatioSlow, newRatio, mCoeffSlowUnlocked);\n    smooth(mRateRatioFast, newRatio, mCoeffFastUnlocked);\n  }\n\n  mDebugMinRatio = newRatio < mDebugMinRatio ? newRatio : mDebugMinRatio;\n  mDebugMaxRatio = newRatio > mDebugMaxRatio ? newRatio : mDebugMaxRatio;\n  smooth( mDebugLockedPercentage, locked1 ? 1.0 : 0.0, mCoeffFastUnlocked );\n  mDebugOver += locked1high ? 0 : 1;\n  mDebugUnder += locked1low ? 0 : 1;\n  mDebugIn += locked1 ? 1 : 0;\n\n  const double rateRatioMax = mThresholdSlowHigh * mRateRatioSlow;\n  const double rateRatioMin = mThresholdSlowLow * mRateRatioSlow;\n\n  const bool locked2 = (mRateRatioFast < rateRatioMax) && (mRateRatioFast > rateRatioMin);\n\n  if (mDebugCount++ > (mAvgCallsPerSec * mDebugLogInterval))\n  {\n    mDebugCount = 0u;\n\n    DLT_LOG_CXX(*mLog, DLT_LOG_DEBUG, LOG_PREFIX, \"clock[\", int32_t(mType),\n        \"/\", uint64_t(this), \"]:\", newRatio, mRateRatioFast, mRateRatioSlow, (locked1 ? \"1\" : \"-\"),\n        (locked2 ? \"2\" : \"-\"), (mLockState == eIasAvbLockStateLocked ? \"L\" : \"-\"), mDebugUnlockCount);\n\n    DLT_LOG_CXX(*mLog, DLT_LOG_VERBOSE, LOG_PREFIX, \"clock[\", int32_t(mType),\n        \"/\", uint64_t(this), \"]: max\", mDebugMaxRatio, \"min\", mDebugMinRatio, \"locked1\", mDebugLockedPercentage, mDebugOver,\n        \"/\", mDebugIn, \"/\", mDebugUnder, float( mDebugOver ) / float( mDebugUnder ));\n\n    mDebugMinRatio = 1.0/0.0;\n    mDebugMaxRatio = 0.0;\n  }\n\n  if (NULL != mClient)\n  {\n    mClient->notifyUpdateRatio(this);\n  }\n\n  switch (mLockState)\n  {\n  case eIasAvbLockStateInit:\n    mRateRatioSlow = mInitialValue;\n    mRateRatioFast = mInitialValue;\n    // fall-through\n\n  case eIasAvbLockStateUnlocked:\n    mLockState = eIasAvbLockStateLocking;\n    // fall-through\n\n  case eIasAvbLockStateLocking:\n    if (locked1 && locked2)\n    {\n      mLockState = eIasAvbLockStateLocked;\n      lockStateChanged();\n    }\n    break;\n\n  case eIasAvbLockStateLocked:\n    if (!locked2)\n    {\n      mLockState = eIasAvbLockStateUnlocked;\n      lockStateChanged();\n      mDebugUnlockCount++;\n    }\n    break;\n\n  default:\n    break;\n  }\n\n  mRateRatio = mRateRatioFast > rateRatioMax ? rateRatioMax : (mRateRatioFast < rateRatioMin ? rateRatioMin : mRateRatioFast);\n  mRateRatio *= mCompensation;\n}\n\nIasAvbProcessingResult IasAvbClockDomain::setDriftCompensation(int32_t val)\n{\n  IasAvbProcessingResult ret = eIasAvbProcOK;\n\n  /*\n   * The following is a simple linear approximation of pow(mRatioBendMax, -relFillLevel) within the required range\n   */\n  if ((val >= 0) && (val <= 1000000))\n  {\n    mCompensation = 1.0 / (1.0 + (double(val) * 1e-6));\n  }\n  else if ((val < 0) && (val >= -1000000))\n  {\n    mCompensation = 1.0 + (double(-val) * 1e-6);\n  }\n  else\n  {\n    // relFillLevel out of range\n    ret = eIasAvbProcInvalidParam;\n  }\n\n  return ret;\n}\n\n\nvoid IasAvbClockDomain::lockStateChanged()\n{\n  if (NULL != mClient)\n  {\n    mClient->notifyUpdateLockState(this);\n  }\n  else\n  {\n    /**\n     * @log Change in the clock domain lock state but the client is null, unable to notify.\n     */\n    DLT_LOG_CXX(*mLog, DLT_LOG_VERBOSE, LOG_PREFIX, \"no client\");\n  }\n}\n\n\nvoid IasAvbClockDomain::setInitialValue(double initVal)\n{\n  if (initVal >= 0.0)\n  {\n    mInitialValue = initVal;\n  }\n}\n\n\nvoid IasAvbClockDomain::setFilter(double timeConstant, uint32_t avgCallsPerSec)\n{\n  if (timeConstant >= 0.0)\n  {\n    mTimeConstant = timeConstant;\n    mAvgCallsPerSec = avgCallsPerSec;\n    const double tc = timeConstant * double(avgCallsPerSec);\n\n    mCoeffFastLocked = calculateCoefficient(tc);\n    mCoeffFastUnlocked = calculateCoefficient(tc * mDerivationFactorUnlock);\n    mCoeffSlowLocked = calculateCoefficient(tc * mDerivationFactorLongTerm);\n    mCoeffSlowUnlocked = calculateCoefficient(tc * mDerivationFactorLongTerm * mDerivationFactorUnlock);\n\n    DLT_LOG_CXX(*mLog, DLT_LOG_DEBUG, LOG_PREFIX, \"[IasAvbClockDomain::setFilter] tc=\", mTimeConstant,\n        mAvgCallsPerSec, \"call/sec (\", mCoeffFastLocked,\n        \"/\", mCoeffFastUnlocked, \"/\", mCoeffSlowLocked,\n        \"/\", mCoeffSlowUnlocked);\n\n    if (mLockState > eIasAvbLockStateUnlocked)\n    {\n      mLockState = eIasAvbLockStateUnlocked;\n      lockStateChanged();\n    }\n  }\n}\n\n\nvoid IasAvbClockDomain::setDerivationFactors(double factorLongTerm, double factorUnlock)\n{\n  mDerivationFactorLongTerm = factorLongTerm;\n  mDerivationFactorUnlock = factorUnlock;\n  setFilter(mTimeConstant, mAvgCallsPerSec);\n}\n\n\nvoid IasAvbClockDomain::setLockThreshold1( uint32_t ppm )\n{\n  if (ppm > 0u)\n  {\n    mThresholdFastHigh = 1.0 + (1e-6 * double(ppm));\n    mThresholdFastLow = 1.0 / mThresholdFastHigh;\n  }\n}\n\n\nvoid IasAvbClockDomain::setLockThreshold2(uint32_t ppm)\n{\n  if (ppm > 0u)\n  {\n    mThresholdSlowHigh = 1.0 + (1e-6 * double(ppm));\n    mThresholdSlowLow = 1.0 / mThresholdSlowHigh;\n  }\n}\n\n\ndouble IasAvbClockDomain::calculateCoefficient(double timeConstant)\n{\n  return (0.0 == timeConstant) ? 0.0 : (std::exp(-1.0 / timeConstant));\n}\n\nIasAvbProcessingResult IasAvbClockDomain::registerClient(IasAvbClockDomainClientInterface * const client)\n{\n  IasAvbProcessingResult ret = eIasAvbProcInvalidParam;\n\n  if (NULL != client)\n  {\n    if (NULL != mClient)\n    {\n      ret = eIasAvbProcAlreadyInUse;\n    }\n    else\n    {\n      ret = eIasAvbProcOK;\n      mClient = client;\n    }\n  }\n\n  return ret;\n}\n\nIasAvbProcessingResult IasAvbClockDomain::unregisterClient(IasAvbClockDomainClientInterface * const client)\n{\n  IasAvbProcessingResult ret = eIasAvbProcInvalidParam;\n\n  if (client == mClient)\n  {\n    ret = eIasAvbProcOK;\n    mClient = NULL;\n  }\n\n  return ret;\n}\n\n\n} // namespace IasMediaTransportAvb\n",
    "file_path": "data\\preprocessed\\intel_AVBStreamHandler__private_src_avb_streamhandler_IasAvbClockDomain.cpp",
    "file_name": "intel_AVBStreamHandler__private_src_avb_streamhandler_IasAvbClockDomain.cpp",
    "language": "cpp"
  },
  {
    "text": "/***\n\nYASK: Yet Another Stencil Kit\nCopyright (c) 2014-2023, Intel Corporation\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to\ndeal in the Software without restriction, including without limitation the\nrights to use, copy, modify, merge, publish, distribute, sublicense, and/or\nsell copies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\n* The above copyright notice and this permission notice shall be included in\n  all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\nFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\nIN THE SOFTWARE.\n\n***/\n\n#include \"yask_stencil.hpp\"\nusing namespace std;\n\n// Set MODEL_CACHE to 1 or 2 to model that cache level\n// and create a global cache object here.\n#ifdef MODEL_CACHE\nCache cache_model(MODEL_CACHE);\n#endif\n\nnamespace yask {\n\n    ////// MPI utils //////\n\n    // Exit properly.\n    void KernelEnv::exit(int code) {\n\n#ifdef USE_MPI\n        if (code == 0)\n            finalize();\n\n        else {\n            int flag;\n            MPI_Initialized(&flag);\n            if (flag) {\n                int num_ranks = 1;\n                MPI_Comm_size(MPI_COMM_WORLD, &num_ranks);\n                if (num_ranks > 1)\n                    MPI_Abort(MPI_COMM_WORLD, code);\n            }\n        }\n#endif\n        ::exit(code);\n    }\n\n    void KernelEnv::finalize() {\n        TRACE_MSG(\"finalize_needed = \" << finalize_needed);\n        if (comm != MPI_COMM_NULL && finalize_needed) {\n            MPI_Finalize();\n            comm = MPI_COMM_NULL;\n            shm_comm = MPI_COMM_NULL;\n        }\n        finalize_needed = false;\n    }\n\n    // Find sum of rank_vals over all ranks.\n    idx_t KernelEnv::sum_over_ranks(idx_t rank_val) const {\n        idx_t sum_val = rank_val;\n#ifdef USE_MPI\n        MPI_Allreduce(&rank_val, &sum_val, 1, MPI_INTEGER8, MPI_SUM, comm);\n#endif\n        return sum_val;\n    }\n\n    // Make sure rank_val is same over all ranks.\n    void KernelEnv::assert_equality_over_ranks(idx_t rank_val,\n                                               const string& descr) const {\n        idx_t min_val = rank_val;\n        idx_t max_val = rank_val;\n#ifdef USE_MPI\n        MPI_Allreduce(&rank_val, &min_val, 1, MPI_INTEGER8, MPI_MIN, comm);\n        MPI_Allreduce(&rank_val, &max_val, 1, MPI_INTEGER8, MPI_MAX, comm);\n#endif\n\n        if (min_val != rank_val || max_val != rank_val) {\n            FORMAT_AND_THROW_YASK_EXCEPTION(descr << \" ranges from \" << min_val << \" to \" <<\n                                            max_val << \" across the ranks; they should all be identical\");\n        }\n    }\n\n}\n",
    "file_path": "data\\preprocessed\\intel_yask__src_kernel_lib_utils.cpp",
    "file_name": "intel_yask__src_kernel_lib_utils.cpp",
    "language": "cpp"
  },
  {
    "text": "// Copyright 2017 The PDFium Authors\n// Use of this source code is governed by a BSD-style license that can be\n// found in the LICENSE file.\n\n// Original code copyright 2014 Foxit Software Inc. https://example.com/path\n\n#include \"xfa/fxfa/parser/cxfa_solid.h\"\n\n#include \"fxjs/xfa/cjx_node.h\"\n#include \"xfa/fxfa/parser/cxfa_document.h\"\n\nnamespace {\n\nconst CXFA_Node::PropertyData kSolidPropertyData[] = {\n    {XFA_Element::Extras, 1, {}},\n};\n\nconst CXFA_Node::AttributeData kSolidAttributeData[] = {\n    {XFA_Attribute::Id, XFA_AttributeType::CData, nullptr},\n    {XFA_Attribute::Use, XFA_AttributeType::CData, nullptr},\n    {XFA_Attribute::Usehref, XFA_AttributeType::CData, nullptr},\n};\n\n}  // namespace\n\nCXFA_Solid::CXFA_Solid(CXFA_Document* doc, XFA_PacketType packet)\n    : CXFA_Node(doc,\n                packet,\n                {XFA_XDPPACKET::kTemplate, XFA_XDPPACKET::kForm},\n                XFA_ObjectType::Node,\n                XFA_Element::Solid,\n                kSolidPropertyData,\n                kSolidAttributeData,\n                cppgc::MakeGarbageCollected<CJX_Node>(\n                    doc->GetHeap()->GetAllocationHandle(),\n                    this)) {}\n\nCXFA_Solid::~CXFA_Solid() = default;\n",
    "file_path": "data\\preprocessed\\iridium-browser_iridium-browser__third_party_pdfium_xfa_fxfa_parser_cxfa_solid.cpp",
    "file_name": "iridium-browser_iridium-browser__third_party_pdfium_xfa_fxfa_parser_cxfa_solid.cpp",
    "language": "cpp"
  },
  {
    "text": "/*\n * KINOVA (R) KORTEX (TM)\n *\n * Copyright (c) 2021 Kinova inc. All rights reserved.\n *\n * This software may be modified and distributed\n * under the terms of the BSD 3-Clause license.\n *\n * Refer to the LICENSE file for details.\n *\n */\n\n#include \"kortex_driver/non-generated/cartesian_trajectory_action_server.h\"\n#include <sstream>\n#include <fstream>\n#include <thread> // for gcc 11 support\n\nCartesianTrajectoryActionServer::CartesianTrajectoryActionServer(const std::string& server_name, ros::NodeHandle& nh, Kinova::Api::Base::BaseClient* base, Kinova::Api::BaseCyclic::BaseCyclicClient* base_cyclic):\n    m_server_name(server_name),\n    m_node_handle(nh),\n    m_server(nh, server_name, boost::bind(&CartesianTrajectoryActionServer::goal_received_callback, this, _1), boost::bind(&CartesianTrajectoryActionServer::preempt_received_callback, this, _1), false),\n    m_base(base),\n    m_server_state(ActionServerState::INITIALIZING),\n    m_currentActionID(0)\n{\n    // Get the ROS params\n    if (!ros::param::get(\"~prefix\", m_prefix))\n    {\n        std::string error_string = \"Prefix name was not specified in the launch file, shutting down the node...\";\n        ROS_ERROR(\"%s\", error_string.c_str());\n        throw new std::runtime_error(error_string);\n    }\n\n    // Subscribe to the arm's Action Notifications\n    m_sub_action_notif_handle = m_base->OnNotificationActionTopic(std::bind(&CartesianTrajectoryActionServer::action_notif_callback, this, std::placeholders::_1), Kinova::Api::Common::NotificationOptions());\n\n    // Ready to receive goal\n    m_server.start();\n    set_server_state(ActionServerState::IDLE);\n}\n\nCartesianTrajectoryActionServer::~CartesianTrajectoryActionServer()\n{\n    try\n    {\n        m_base->Unsubscribe(m_sub_action_notif_handle);\n    }\n    catch (Kinova::Api::KDetailedException& ex)\n    {\n        ROS_ERROR(\"Kortex exception while unsubscribing to action notification.\");\n        ROS_ERROR(\"Error code: %s\\n\", Kinova::Api::ErrorCodes_Name(ex.getErrorInfo().getError().error_code()).c_str());\n        ROS_ERROR(\"Error sub code: %s\\n\", Kinova::Api::SubErrorCodes_Name(Kinova::Api::SubErrorCodes(ex.getErrorInfo().getError().error_sub_code())).c_str());\n        ROS_ERROR(\"Error description: %s\\n\", ex.what());\n        m_goal.setAborted();\n    }\n    catch (std::runtime_error& ex_runtime)\n    {\n        ROS_ERROR(\"Runtime exception detected while unsubscribing to action notification.\");\n        ROS_ERROR(\"%s\", ex_runtime.what());\n        m_goal.setAborted();\n    }\n    catch (std::future_error& ex_future)\n    {\n        ROS_ERROR(\"Future exception detected while unsubscribing to action notification.\");\n        ROS_ERROR(\"%s\", ex_future.what());\n        m_goal.setAborted();\n    }\n}\n\nvoid CartesianTrajectoryActionServer::goal_received_callback(actionlib::ActionServer<kortex_driver::FollowCartesianTrajectoryAction>::GoalHandle new_goal_handle)\n{\n    ROS_INFO(\"New Cartesian goal received.\");\n    if (!is_goal_acceptable(new_goal_handle))\n    {\n        ROS_ERROR(\"Cartesian Trajectory Goal is rejected.\");\n        new_goal_handle.setRejected();\n        return;\n    }\n\n    if (m_server_state != ActionServerState::IDLE)\n    {\n        ROS_WARN(\"There is already an active cartesian goal. It is being cancelled.\");\n        // We have to call Stop after having received the ACTION_START notification from the arm\n        stop_all_movement();\n    }\n\n    // Accept the goal\n    ROS_INFO(\"Cartesian Trajectory Goal is accepted.\");\n    m_goal = new_goal_handle;\n    m_goal.setAccepted();\n\n    auto action = Kinova::Api::Base::Action();\n    action.set_name(\"Cartesian waypoint\");\n    action.set_application_data(\"\");\n\n    auto proto_trajectory = action.mutable_execute_waypoint_list();\n\n    proto_trajectory->set_duration(new_goal_handle.getGoal()->goal_time_tolerance.toSec());\n    proto_trajectory->set_use_optimal_blending(new_goal_handle.getGoal()->use_optimal_blending);\n\n    for (unsigned int i = 0; i < new_goal_handle.getGoal()->trajectory.size(); i++)\n    {\n        const auto traj_point = new_goal_handle.getGoal()->trajectory.at(i);\n\n        Kinova::Api::Base::Waypoint* proto_waypoint = proto_trajectory->add_waypoints();\n        proto_waypoint->set_name(\"waypoint_\" + std::to_string(i));\n\n        auto cartesian_waypoint = proto_waypoint->mutable_cartesian_waypoint();\n\n        auto tempPose = cartesian_waypoint->mutable_pose();\n        tempPose->set_x(traj_point.pose.x);\n        tempPose->set_y(traj_point.pose.y);\n        tempPose->set_z(traj_point.pose.z);\n\n        tempPose->set_theta_x(KortexMathUtil::toDeg(traj_point.pose.theta_x));\n        tempPose->set_theta_y(KortexMathUtil::toDeg(traj_point.pose.theta_y));\n        tempPose->set_theta_z(KortexMathUtil::toDeg(traj_point.pose.theta_z));\n\n        cartesian_waypoint->set_reference_frame((Kinova::Api::Common::CartesianReferenceFrame)traj_point.reference_frame);\n        cartesian_waypoint->set_maximum_angular_velocity(traj_point.maximum_angular_velocity);\n        cartesian_waypoint->set_maximum_linear_velocity(traj_point.maximum_linear_velocity);\n        cartesian_waypoint->set_blending_radius(traj_point.blending_radius);\n    }\n\n    try\n    {\n        // Validate the waypoints and reject the goal if they fail validation\n        auto report = m_base->ValidateWaypointList(*proto_trajectory);\n        if (report.trajectory_error_report().trajectory_error_elements_size() > 0)\n        {\n            ROS_ERROR(\"Cartesian Trajectory failed validation in the arm.\");\n\n            // Go through report and print errors\n            for (unsigned int i = 0; i < report.trajectory_error_report().trajectory_error_elements_size(); i++)\n            {\n                ROS_ERROR(\"Error %i : %s\", i+1, report.trajectory_error_report().trajectory_error_elements(i).message().c_str());\n            }\n            new_goal_handle.setRejected();\n            m_goal.setAborted();\n            return;\n        }\n\n        // Make sure to clear the faults before moving the robot\n        m_base->ClearFaults();\n\n        std::this_thread::sleep_for(std::chrono::milliseconds(1000));\n\n        // Send the trajectory to the robot\n        m_base->ExecuteAction(action);\n        set_server_state(ActionServerState::PRE_PROCESSING_PENDING);\n    }\n    catch (Kinova::Api::KDetailedException& ex)\n    {\n        ROS_ERROR(\"Kortex exception while sending the trajectory\");\n        ROS_ERROR(\"Error code: %s\\n\", Kinova::Api::ErrorCodes_Name(ex.getErrorInfo().getError().error_code()).c_str());\n        ROS_ERROR(\"Error sub code: %s\\n\", Kinova::Api::SubErrorCodes_Name(Kinova::Api::SubErrorCodes(ex.getErrorInfo().getError().error_sub_code())).c_str());\n        ROS_ERROR(\"Error description: %s\\n\", ex.what());\n        m_goal.setAborted();\n    }\n    catch (std::runtime_error& ex_runtime)\n    {\n        ROS_ERROR(\"Runtime exception detected while sending the trajectory\");\n        ROS_ERROR(\"%s\", ex_runtime.what());\n        m_goal.setAborted();\n    }\n    catch (std::future_error& ex_future)\n    {\n        ROS_ERROR(\"Future exception detected while sending the trajectory\");\n        ROS_ERROR(\"%s\", ex_future.what());\n        m_goal.setAborted();\n    }\n}\n\n// Called in a separate thread when a preempt request comes in from the Action Client\nvoid CartesianTrajectoryActionServer::preempt_received_callback(actionlib::ActionServer<kortex_driver::FollowCartesianTrajectoryAction>::GoalHandle goal_handle)\n{\n    if (m_server_state == ActionServerState::TRAJECTORY_EXECUTION_IN_PROGRESS)\n    {\n        stop_all_movement();\n    }\n}\n\n// Called in a separate thread when a notification comes in\nvoid CartesianTrajectoryActionServer::action_notif_callback(Kinova::Api::Base::ActionNotification notif)\n{\n    if(m_server_state == ActionServerState::IDLE)\n    {\n        return;\n    }\n    Kinova::Api::Base::ActionEvent event = notif.action_event();\n    Kinova::Api::Base::ActionHandle handle = notif.handle();\n    Kinova::Api::Base::ActionType type = handle.action_type();\n    ROS_DEBUG(\"Action notification received of type %s\", Kinova::Api::Base::ActionEvent_Name(event).c_str());\n\n    std::lock_guard<std::mutex> guard(m_action_notification_thread_lock);\n\n    kortex_driver::FollowCartesianTrajectoryResult result;\n    std::ostringstream oss;\n\n    if (type == Kinova::Api::Base::ActionType::EXECUTE_WAYPOINT_LIST)\n    {\n        if(event == Kinova::Api::Base::ActionEvent::ACTION_PREPROCESS_START)\n        {\n            m_currentActionID = notif.handle().identifier();\n\n            // It should be starting\n            if (m_server_state == ActionServerState::PRE_PROCESSING_PENDING)\n            {\n                ROS_INFO(\"Preprocessing has started in the arm.\");\n                set_server_state(ActionServerState::PRE_PROCESSING_IN_PROGRESS);\n            }\n            // We should not have received that\n            else\n            {\n                ROS_DEBUG(\"Notification mismatch : received ACTION_PREPROCESS_START but we are in %s\", actionServerStateNames[int(m_server_state)]);\n            }\n        }\n        else if(m_currentActionID == notif.handle().identifier())\n        {\n            switch (event)\n            {\n\n            // The pre-processing has ended successfully in the arm\n            case Kinova::Api::Base::ActionEvent::ACTION_PREPROCESS_END:\n                // It was ongoing and now it ended\n                if (m_server_state == ActionServerState::PRE_PROCESSING_PENDING ||\n                    m_server_state == ActionServerState::PRE_PROCESSING_IN_PROGRESS)\n                {\n                    ROS_INFO(\"Preprocessing has finished in the arm and goal has been accepted.\");\n                    set_server_state(ActionServerState::TRAJECTORY_EXECUTION_PENDING);\n                }\n                // FIXME KOR-3563 Sometimes the notifications arrive in the wrong order so it is possible to receive\n                // a ACTION_PREPROCESS_END notification after the ACTION_START\n                // When this bug will be fixed this else if can be removed\n                else if (m_server_state == ActionServerState::TRAJECTORY_EXECUTION_IN_PROGRESS)\n                {\n                    ROS_DEBUG(\"Notification order mismatch : We received the ACTION_PREPROCESS_END after the ACTION_START\");\n                    break;\n                }\n                // We should not have received that\n                else\n                {\n                    ROS_DEBUG(\"Notification mismatch : received ACTION_PREPROCESS_END but we are in %s\", actionServerStateNames[int(m_server_state)]);\n                }\n                break;\n\n            // The pre-processing has failed in the arm\n            // TODO This could be much lighter since ValidateWaypoints already does that\n            case Kinova::Api::Base::ActionEvent::ACTION_PREPROCESS_ABORT:\n                // It was ongoing and now it ended (and failed)\n                if ((m_server_state == ActionServerState::PRE_PROCESSING_IN_PROGRESS))\n                {\n                    ROS_DEBUG(\"Preprocessing has finished in the arm and goal has been rejected. Fetching the error report from the arm...\");\n\n                    result.error_code = result.INVALID_GOAL;\n\n                    // Get the error report and show errors here\n                    Kinova::Api::Base::TrajectoryErrorReport report = m_base->GetTrajectoryErrorReport();\n                    oss << \"Error report has been fetched and error elements are listed below : \" << std::endl;\n                    int i = 1;\n                    for (auto error_element : report.trajectory_error_elements())\n                    {\n                        oss << \"-----------------------------\" << std::endl;\n                        oss << \"Error #\" << i << std::endl;\n                        oss << \"Type : \" << Kinova::Api::Base::TrajectoryErrorType_Name(error_element.error_type()) << std::endl;\n                        oss << \"Erroneous value is \" << error_element.error_value() << \" but minimum permitted is \" << error_element.min_value() << \" and maximum permitted is \" << error_element.max_value() << std::endl;\n                        if (error_element.message() != \"\")\n                        {\n                            oss << \"Additional message is : \" << error_element.message() << std::endl;\n                        }\n                        oss << \"-----------------------------\" << std::endl;\n\n                        i++;\n                    }\n\n                    ROS_ERROR(\"%s\", oss.str().c_str());\n\n                    result.error_string = oss.str();\n                    m_goal.setAborted(result);\n\n                    set_server_state(ActionServerState::IDLE);\n                }\n                // We should not have received that\n                else\n                {\n                    ROS_DEBUG(\"Notification mismatch : received ACTION_PREPROCESS_ABORT but we are in %s\", actionServerStateNames[int(m_server_state)]);\n                }\n                break;\n\n            // The arm is starting to move\n            case Kinova::Api::Base::ActionEvent::ACTION_START:\n                // The preprocessing was done and the goal is still active (not preempted)\n                if ((m_server_state == ActionServerState::TRAJECTORY_EXECUTION_PENDING ||\n                    m_server_state == ActionServerState::PRE_PROCESSING_IN_PROGRESS) && // FIXME KOR-3563 this happens if we received a ACTION_START before a ACTION_PREPROCESS_END\n                    m_goal.getGoalStatus().status == actionlib_msgs::GoalStatus::ACTIVE)\n                {\n                    ROS_INFO(\"Trajectory has started.\");\n                    set_server_state(ActionServerState::TRAJECTORY_EXECUTION_IN_PROGRESS);\n                    // Remember when the trajectory started\n                    m_trajectory_start_time = std::chrono::system_clock::now();\n                }\n                // The preprocessing was done but the goal put to \"PREEMPTING\" by the client while preprocessing\n                // The stop_all_movement() call will trigger a ACTION_ABORT notification\n                else if ((m_server_state == ActionServerState::TRAJECTORY_EXECUTION_PENDING) &&\n                        m_goal.getGoalStatus().status == actionlib_msgs::GoalStatus::PREEMPTING)\n                {\n                    ROS_INFO(\"Trajectory has started but goal was cancelled : stopping all movement.\");\n                    stop_all_movement();\n                }\n                // We should not have received that\n                else\n                {\n                    ROS_DEBUG(\"Notification mismatch : received ACTION_START but we are in %s\", actionServerStateNames[int(m_server_state)]);\n                }\n                break;\n\n            case Kinova::Api::Base::ActionEvent::ACTION_FEEDBACK:\n            {\n                // debug trace to indicate we've reached waypoints\n                for (unsigned int i = 0; i < notif.trajectory_info_size(); i++)\n                {\n                    auto info = notif.trajectory_info(i);\n                    if (info.trajectory_info_type() == Kinova::Api::Base::TrajectoryInfoType::WAYPOINT_REACHED)\n                    {\n                        ROS_DEBUG(\"Cartesian waypoint %d reached\", info.waypoint_index());\n                    }\n                }\n                break;\n            }\n\n            // The action was started in the arm, but it aborted\n            case Kinova::Api::Base::ActionEvent::ACTION_ABORT:\n                // The goal is still active, but we received a ABORT before starting, or during execution\n                if (m_goal.getGoalStatus().status == actionlib_msgs::GoalStatus::ACTIVE &&\n                    (m_server_state == ActionServerState::TRAJECTORY_EXECUTION_IN_PROGRESS ||\n                    m_server_state == ActionServerState::TRAJECTORY_EXECUTION_PENDING))\n                {\n                    ROS_ERROR(\"Trajectory has been aborted.\");\n\n                    result.error_code = result.PATH_TOLERANCE_VIOLATED;\n                    oss << \"Trajectory execution failed in the arm with sub error code \" << notif.abort_details() << std::endl;\n                    if (notif.abort_details() == Kinova::Api::SubErrorCodes::CONTROL_WRONG_STARTING_POINT)\n                    {\n                        oss << \"The starting point for the trajectory did not match the actual commanded cartesian pose.\" << std::endl;\n                    }\n                    else if (notif.abort_details() == Kinova::Api::SubErrorCodes::CONTROL_MANUAL_STOP)\n                    {\n                        oss << \"The speed while executing the trajectory was too damn high and caused the robot to stop.\" << std::endl;\n                    }\n                    result.error_string = oss.str();\n                    m_goal.setAborted(result);\n\n                    ROS_ERROR(\"%s\", oss.str().c_str());\n                    set_server_state(ActionServerState::IDLE);\n                }\n                // The goal was cancelled and we received a ACTION_ABORT : this means the trajectory was cancelled successfully in the arm\n                else if  (m_goal.getGoalStatus().status == actionlib_msgs::GoalStatus::PREEMPTING &&\n                        (m_server_state == ActionServerState::TRAJECTORY_EXECUTION_IN_PROGRESS ||\n                        m_server_state == ActionServerState::TRAJECTORY_EXECUTION_PENDING))\n                {\n                    ROS_INFO(\"Trajectory has been cancelled successfully in the arm.\");\n                    m_goal.setCanceled();\n                    set_server_state(ActionServerState::IDLE);\n                }\n                // We should not have received that\n                else\n                {\n                    ROS_DEBUG(\"Notification mismatch : received ACTION_ABORT but we are in %s\", actionServerStateNames[int(m_server_state)]);\n                }\n                break;\n\n            // The trajectory just ended\n            case Kinova::Api::Base::ActionEvent::ACTION_END:\n            {\n                // The trajectory was ongoing\n                if ((m_server_state == ActionServerState::TRAJECTORY_EXECUTION_IN_PROGRESS))\n                {\n                    result.error_code = result.SUCCESSFUL;\n                    ROS_INFO(\"Trajectory execution succeeded.\");\n                    m_goal.setSucceeded(result);\n\n                    set_server_state(ActionServerState::IDLE);\n                }\n                // We should not have received that\n                else\n                {\n                    ROS_DEBUG(\"Notification mismatch : received ACTION_END but we are in %s\", actionServerStateNames[int(m_server_state)]);\n                }\n                break;\n            }\n\n            case Kinova::Api::Base::ActionEvent::ACTION_PAUSE:\n                ROS_WARN(\"Action pause event was just received and this should never happen.\");\n                break;\n\n            default:\n                ROS_WARN(\"Unknown action event was just received and this should never happen.\");\n                break;\n            }\n        }\n\n\n    }\n    // Wrong action type. Rejecting the notification. Action server state unchanged.\n    else\n    {\n        return;\n    }\n\n    oss.flush();\n}\n\nbool CartesianTrajectoryActionServer::is_goal_acceptable(actionlib::ActionServer<kortex_driver::FollowCartesianTrajectoryAction>::GoalHandle goal_handle)\n{\n    // First check if goal is valid\n    if (!goal_handle.isValid())\n    {\n        ROS_ERROR(\"Invalid Cartesian goal.\");\n        return false;\n    }\n\n    // Retrieve the goal\n    kortex_driver::FollowCartesianTrajectoryGoalConstPtr goal = goal_handle.getGoal();\n\n    // Check if the trajectory contains at least 1 waypoint.\n    if (goal->trajectory.size() == 0)\n    {\n        ROS_ERROR(\"Empty Cartesian trajectory list.\");\n        return false;\n    }\n\n    return true;\n}\n\nvoid CartesianTrajectoryActionServer::stop_all_movement()\n{\n    ROS_INFO(\"Calling Stop on the robot.\");\n    try\n    {\n        m_base->Stop();\n    }\n    catch(const Kinova::Api::KBasicException& e)\n    {\n        ROS_WARN(\"Stop failed : %s\", e.what());\n    }\n}\n\nvoid CartesianTrajectoryActionServer::set_server_state(ActionServerState s)\n{\n    std::lock_guard<std::mutex> guard(m_server_state_lock);\n    ActionServerState old_state = m_server_state;\n    m_server_state = s;\n    ROS_INFO(\"State changed from %s to %s\\n\", actionServerStateNames[int(old_state)], actionServerStateNames[int(s)]);\n}",
    "file_path": "data\\preprocessed\\Kinovarobotics_ros_kortex__kortex_driver_src_non-generated_driver_cartesian_trajectory_action_server.cpp",
    "file_name": "Kinovarobotics_ros_kortex__kortex_driver_src_non-generated_driver_cartesian_trajectory_action_server.cpp",
    "language": "cpp"
  },
  {
    "text": "#include \"gfx/gfx.hpp\"\n#include \"gfx/Application.hpp\"\n#include \"en/World.hpp\"\n#include \"3d/RenderSystem.hpp\"\n#include \"3d/SceneSystem.hpp\"\n#include \"3d/Camera.hpp\"\n#include \"3d/BoxShape.hpp\"\n#include \"fs_local/FileSystemLocal.hpp\"\n#include \"io/FileSystem.hpp\"\n\nclass TexCubeApp : public ari::Application\n{\npublic:\n\n\t~TexCubeApp() = default;\n\n\tari::gfx::GfxSetup* GetGfxSetup() override\n\t{\n\t\treturn &m_setup;\n\t}\n\n\tvoid OnInit() override\n\t{\n\t\t// Add systems\n\t\tm_world.AddSystem(&m_renderer);\n\t\tm_world.AddSystem(&m_scene_mgr);\n\t\tari::io::RegisterFileSystem(\"file\", &m_file_system_local);\n\n\t\t// Create entity and add box and camera\n\t\tari::en::EntityHandle entity = m_world.CreateEntity();\n\t\tauto camera = m_world.CreateComponent<ari::en::Camera, ari::en::Node3D>();\n\t\tcamera.Component->Position.x = 3.f;\n\t\tcamera.Component->Position.y = 3.f;\n\t\tcamera.Component->Position.z = 3.f;\n\t\tcamera.Component->Target.z = 0.0f;\n\t\tm_world.AddDerivedComponent<ari::en::Camera, ari::en::Node3D>(entity, camera);\n\t\tauto box = m_world.CreateComponent<ari::en::BoxShape, ari::en::Node3D>();\n\t\tbox.Component->Texture = ari::gfx::LoadTexture(\"res:baboon.png\");\n\t\tm_pBox = box.Component;\n\t\tm_world.AddDerivedComponent<ari::en::BoxShape, ari::en::Node3D>(entity, box);\n\t}\n\n\tvoid OnFrame(float _elapsedTime) override\n\t{\n\t\tm_pBox->Rotation.x += 0.3f * _elapsedTime;\n\t\tm_pBox->Rotation.y += 0.3f * _elapsedTime;\n\t\tm_world.Update(_elapsedTime);\n\t}\n\n\tvoid OnCleanup() override\n\t{\n\n\t}\n\n\tvoid OnEvent(ari_event* event, ari::io::WindowHandle _window) override\n\t{\n\n\t}\n\nprivate:\n\n\tari::gfx::GfxSetup\t\t\tm_setup;\n\tari::en::World\t\t\t\tm_world;\n\tari::en::RenderSystem\t\tm_renderer;\n\tari::en::SceneSystem\t\tm_scene_mgr;\n\tari::io::FileSystemLocal\tm_file_system_local;\n\tari::en::BoxShape\t\t*\tm_pBox = nullptr;\n};\n\nARI_MAIN(TexCubeApp)\n",
    "file_path": "data\\preprocessed\\kochol_ariyana__tests_05-texcube_texcube.cpp",
    "file_name": "kochol_ariyana__tests_05-texcube_texcube.cpp",
    "language": "cpp"
  },
  {
    "text": "//\n// The MIT License (MIT)\n//\n// Copyright (c) 2019 Livox. All rights reserved.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n//\n// The above copyright notice and this permission notice shall be included in\n// all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n//\n\n#include <ros/ros.h>\n#include <livox_ros_driver/CustomMsg.h>\n#include <livox_ros_driver/CustomPoint.h>\n#include <pcl_ros/point_cloud.h>\n#include <sensor_msgs/PointCloud2.h>\n#include \"lddc.h\"\n\nusing namespace std;\nbool firstFlag = true;\nint firstID = 10;\nint hub_lidar_num;\nros::Time firstTime;\nbool sync_init = false;\nros::Publisher pubFullLaserCloud;\nstd::vector<Eigen::Matrix4f> extrinsicMatrix;\n\nbool loadExtrinsic(const std::string &filename, std::vector<Eigen::Matrix4f>& mat)\n{\n  FILE *fp=fopen(filename.c_str(),\"r\");\n  int nNum=0;\n  float roll,pitch,yaw,x,y,z;\n  Eigen::Matrix3f rotation_matrix;\n\n  while(!feof(fp))\n  {\n    if(nNum >= int(mat.size())){\n      break;\n    }\n    if(fscanf(fp,\"%f,%f,%f,%f,%f,%f,\\n\",&roll,&pitch,&yaw,&x,&y,&z) == 0){\n      return false;\n    }\n\n    rotation_matrix = Eigen::AngleAxisf(yaw,Eigen::Vector3f::UnitZ()) *\n                      Eigen::AngleAxisf(pitch,Eigen::Vector3f::UnitY()) *\n                      Eigen::AngleAxisf(roll,Eigen::Vector3f::UnitX());\n\n    mat[nNum] = Eigen::Matrix4f::Identity();\n    mat[nNum].topLeftCorner(3,3) = rotation_matrix;\n    mat[nNum].topRightCorner(3,1) = Eigen::Vector3f(x,y,z);\n    nNum++;\n  }\n  fclose(fp);\n  return true;\n}\n\nvoid pubPointCloud2(const pcl::PointCloud<pcl::PointXYZI>::Ptr& ptr){\n  sensor_msgs::PointCloud2 laserCloudMsg;\n  pcl::toROSMsg(*ptr, laserCloudMsg);\n  laserCloudMsg.header.stamp = ros::Time::now();\n  laserCloudMsg.header.frame_id = \"/livox_frame\";\n  pubFullLaserCloud.publish(laserCloudMsg);\n  cout << \"---------------------\" << endl;\n}\n\nvoid hubCallBack(const livox_ros_driver::CustomMsgConstPtr &msg){\n  static pcl::PointCloud<pcl::PointXYZI>::Ptr all_in_one_ptr(new pcl::PointCloud<pcl::PointXYZI>());\n  int lidar_id = int(msg->lidar_id) / 3;\n  if(lidar_id >= hub_lidar_num) return;\n  pcl::PointXYZI tmp;\n  Eigen::Vector3f eig_p;\n  if(abs(msg->header.stamp.toSec()-firstTime.toSec()) > 0.09 || lidar_id == firstID)firstFlag = true;\n  if(firstFlag)\n  {\n    if(!all_in_one_ptr->points.empty())\n    {\n      cout << \"all_in_one_ptr->points.size()=\" << all_in_one_ptr->points.size() << endl;\n      pubPointCloud2(all_in_one_ptr);\n      firstFlag = true;\n      all_in_one_ptr->clear();\n    }\n\n\n    firstFlag = false;\n    firstID = lidar_id;\n    firstTime = msg->header.stamp;\n    for(const auto & point : msg->points){\n      //if(point.x < 1.0) continue;\n      eig_p.x() = point.x;\n      eig_p.y() = point.y;\n      eig_p.z() = point.z;\n      eig_p = (extrinsicMatrix[lidar_id].topLeftCorner(3,3) * eig_p\n              + extrinsicMatrix[lidar_id].topRightCorner(3,1)).eval();\n      tmp.x = eig_p.x();\n      tmp.y = eig_p.y();\n      tmp.z = eig_p.z();\n      tmp.intensity = point.reflectivity;\n      all_in_one_ptr->push_back(tmp);\n    }\n    cout << \"first lidar id=\" << firstID << endl;\n    cout << \"lidar ID=\" << lidar_id << \"    timestamp=\" << msg->header.stamp << endl;\n  }\n\n\n  if(abs(msg->header.stamp.toSec() - firstTime.toSec()) <= 0.08 && lidar_id != firstID)\n  {\n    for(const auto & point : msg->points){\n      //if(point.x < 1.0) continue;\n      eig_p.x() = point.x;\n      eig_p.y() = point.y;\n      eig_p.z() = point.z;\n      eig_p = (extrinsicMatrix[lidar_id].topLeftCorner(3,3) * eig_p\n              + extrinsicMatrix[lidar_id].topRightCorner(3,1)).eval();\n      tmp.x = eig_p.x();\n      tmp.y = eig_p.y();\n      tmp.z = eig_p.z();\n      tmp.intensity = point.reflectivity;\n      all_in_one_ptr->push_back(tmp);\n    }\n    cout << \"not first flag\" << endl;\n    cout << \"lidar ID=\" << lidar_id << \"    timestamp=\" << msg->header.stamp << endl;\n  }\n\n\n}\n\nint main(int argc, char **argv) {\n  ros::init(argc, argv, \"livox_autoware_hub_node\");\n  ros::NodeHandle livox_node(\"~\");\n\n  firstFlag = true;\n  firstID = 10;\n  /** Init defualt system parameter */\n  int xfer_format = 0;\n   livox_node.getParam(\"/xfer_format\", xfer_format);\n   if(xfer_format != livox_ros::kLivoxCustomMsg){\n     ROS_WARN(\"NOTE: Request 'xfer_format = 1' !\");\n     return 1;\n   }\n\n   if(!livox_node.getParam(\"/hub_lidar_num\", hub_lidar_num)){\n     ROS_WARN(\"NOTE: Request 'hub_lidar_num' param!\");\n     return 1;\n   }\n\n   extrinsicMatrix.resize(hub_lidar_num, Eigen::Matrix4f::Identity());\n  //extrinsicMatrix.resize(hub_lidar_num, Eigen::Matrix4f::Identity());\n\n  std::string extrinsic_path;\n\n   if(!livox_node.getParam(\"/extrinsic_file\", extrinsic_path)){\n     ROS_WARN(\"NOTE: Request 'extrinsic_file' param!\");\n     return 1;\n   }\n\n  if(!loadExtrinsic(extrinsic_path, extrinsicMatrix)){\n    ROS_WARN(\"ERROR Load Extrinsic Matrix!\");\n    return 1;\n  }\n\n  std::cout<<\"Extrinsic Matrixs:\"<<std::endl;\n  for(int i=0; i<hub_lidar_num; ++i){\n    std::cout<<extrinsicMatrix[i]<<std::endl<<\"----------------------\"<<std::endl;\n  }\n\n\n  ros::Subscriber subFullCloud = livox_node.subscribe<livox_ros_driver::CustomMsg>(\"/livox/lidar\", 100, hubCallBack);\n  pubFullLaserCloud = livox_node.advertise<sensor_msgs::PointCloud2>(\"/points_raw\", 100);\n\n  ros::spin();\n\n  return 0;\n}\n\n",
    "file_path": "data\\preprocessed\\Livox-SDK_livox_autoware_driver__livox_ros_driver_livox_ros_driver_livox_autoware_hub_driver.cpp",
    "file_name": "Livox-SDK_livox_autoware_driver__livox_ros_driver_livox_ros_driver_livox_autoware_hub_driver.cpp",
    "language": "cpp"
  },
  {
    "text": "/*\n** Copyright (c) 2020 LunarG, Inc.\n**\n** Permission is hereby granted, free of charge, to any person obtaining a\n** copy of this software and associated documentation files (the \"Software\"),\n** to deal in the Software without restriction, including without limitation\n** the rights to use, copy, modify, merge, publish, distribute, sublicense,\n** and/or sell copies of the Software, and to permit persons to whom the\n** Software is furnished to do so, subject to the following conditions:\n**\n** The above copyright notice and this permission notice shall be included in\n** all copies or substantial portions of the Software.\n**\n** THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n** IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n** FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n** AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n** LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n** FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n** DEALINGS IN THE SOFTWARE.\n*/\n\n#include \"encode/dx12_dll_initializer.h\"\n#include \"encode/dxgi_dispatch_table.h\"\n#include \"util/defines.h\"\n#include \"util/file_path.h\"\n#include \"util/platform.h\"\n#include \"hook_dxgi.h\"\n\n#include <cassert>\n#include <array>\n#include <mutex>\n#include <string>\n#include <windows.h>\n\nconst char kSystemDllName[]             = \"dxgi.dll\";\nconst char kSystemDllNameRenamed[]      = \"dxgi_ms.dll\";\nconst char kCaptureDllName[]            = \"d3d12_capture.dll\";\nconst char kCaptureDllInitProcName[]    = \"InitializeDxgiCapture\";\nconst char kCaptureDllDestroyProcName[] = \"ReleaseDxgiCapture\";\n\nstatic gfxrecon::encode::DxDllInitializer<gfxrecon::encode::DxgiDispatchTable> dll_initializer;\n\ninline const gfxrecon::encode::DxgiDispatchTable& GetDispatchTable()\n{\n    return dll_initializer.GetDispatchTable();\n}\n\nGFXRECON_BEGIN_NAMESPACE(gfxrecon)\n\nstatic void LoadDxgiCaptureProcs(HMODULE system_dll, encode::DxgiDispatchTable* dispatch_table)\n{\n    if (system_dll != nullptr && dispatch_table != nullptr)\n    {\n        dispatch_table->CreateDXGIFactory =\n            reinterpret_cast<decltype(CreateDXGIFactory)*>(GetProcAddress(system_dll, \"CreateDXGIFactory\"));\n        dispatch_table->CreateDXGIFactory1 =\n            reinterpret_cast<decltype(CreateDXGIFactory1)*>(GetProcAddress(system_dll, \"CreateDXGIFactory1\"));\n        dispatch_table->CreateDXGIFactory2 =\n            reinterpret_cast<decltype(CreateDXGIFactory2)*>(GetProcAddress(system_dll, \"CreateDXGIFactory2\"));\n        dispatch_table->DXGIDeclareAdapterRemovalSupport =\n            reinterpret_cast<decltype(DXGIDeclareAdapterRemovalSupport)*>(\n                GetProcAddress(system_dll, \"DXGIDeclareAdapterRemovalSupport\"));\n        dispatch_table->DXGIGetDebugInterface1 =\n            reinterpret_cast<decltype(DXGIGetDebugInterface1)*>(GetProcAddress(system_dll, \"DXGIGetDebugInterface1\"));\n    }\n}\n\nstatic bool Initialize()\n{\n    static bool       initialized = false;\n    static std::mutex initialization_mutex;\n\n    // Check `initialized` before locking to avoid locking unnecessarily.\n    if (initialized == false)\n    {\n        std::unique_lock<std::mutex> initialization_lock(initialization_mutex);\n        if (initialized == false)\n        {\n            std::string module_path = gfxrecon::encode::SetupCaptureModule(kSystemDllName, kSystemDllNameRenamed);\n\n            initialized = dll_initializer.Initialize(\n                module_path.c_str(), kCaptureDllName, kCaptureDllInitProcName, LoadDxgiCaptureProcs);\n        }\n    }\n\n    return initialized;\n}\n\nstatic void Destroy()\n{\n    dll_initializer.Destroy(kCaptureDllDestroyProcName);\n}\n\nGFXRECON_END_NAMESPACE(gfxrecon)\n\nextern \"C\" __declspec(dllexport) void UpdateHooks()\n{\n    static bool hooked = false;\n\n    if (hooked == false)\n    {\n        Hook_DXGI::HookInterceptor(dll_initializer.IsCaptureEnabled());\n        hooked = true;\n    }\n}\n\nEXTERN_C HRESULT WINAPI gfxrecon_CreateDXGIFactory(REFIID riid, void** ppFactory)\n{\n    if (gfxrecon::Initialize())\n    {\n        return GetDispatchTable().CreateDXGIFactory(riid, ppFactory);\n    }\n\n    return E_FAIL;\n}\n\nEXTERN_C HRESULT WINAPI gfxrecon_CreateDXGIFactory1(REFIID riid, void** ppFactory)\n{\n    if (gfxrecon::Initialize())\n    {\n        return GetDispatchTable().CreateDXGIFactory1(riid, ppFactory);\n    }\n\n    return E_FAIL;\n}\n\nEXTERN_C HRESULT WINAPI gfxrecon_CreateDXGIFactory2(UINT Flags, REFIID riid, void** ppFactory)\n{\n    if (gfxrecon::Initialize())\n    {\n        return GetDispatchTable().CreateDXGIFactory2(Flags, riid, ppFactory);\n    }\n\n    return E_FAIL;\n}\n\nEXTERN_C HRESULT WINAPI gfxrecon_DXGIDeclareAdapterRemovalSupport()\n{\n    if (gfxrecon::Initialize())\n    {\n        return GetDispatchTable().DXGIDeclareAdapterRemovalSupport();\n    }\n\n    return E_FAIL;\n}\n\nEXTERN_C HRESULT WINAPI gfxrecon_DXGIGetDebugInterface1(UINT Flags, REFIID riid, void** ppDebug)\n{\n    if (gfxrecon::Initialize())\n    {\n        return GetDispatchTable().DXGIGetDebugInterface1(Flags, riid, ppDebug);\n    }\n\n    return E_FAIL;\n}\n\nBOOL WINAPI DllMain(HINSTANCE hinstDLL, DWORD fdwReason, LPVOID lpvReserved)\n{\n    switch (fdwReason)\n    {\n        case DLL_PROCESS_DETACH:\n            // Only cleanup if the process is not exiting.\n            if (lpvReserved == nullptr)\n            {\n                gfxrecon::Destroy();\n            }\n            break;\n        default:\n            break;\n    }\n\n    return TRUE;\n}\n",
    "file_path": "data\\preprocessed\\LunarG_gfxreconstruct__layer_dxgi_dll_main.cpp",
    "file_name": "LunarG_gfxreconstruct__layer_dxgi_dll_main.cpp",
    "language": "cpp"
  },
  {
    "text": "/*\n * Copyright (c) 2012-2020 MIRACL UK Ltd.\n *\n * This file is part of MIRACL Core\n * (see https://github.com/miracl/core).\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     https://example.com/path\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n#include \"arch.h\"\n#include \"fp_BLS48556.h\"\n\nnamespace BLS48556 {\n\n/* Curve BLS48556 - Pairing friendly BLS curve */\n\n#if CHUNK==16\n\n#error Not supported\n\n#endif\n\n#if CHUNK==32\n\nusing namespace B560_29;\n\n// Base Bits= 29\nconst BIG Modulus= {0x1CF6AC0B,0x17B7307F,0x19877E7B,0x12CE0134,0x14228402,0x1BD4C386,0x1DACBB04,0x40410D0,0x25A415,0x980B53E,0xDE6E250,0x15D9AAD6,0x5DA950,0x1029B7A,0x54AB351,0x14AD90CE,0x3729047,0x1FE7E2D9,0x145F610B,0x1F};\nconst BIG ROI= {0x1CF6AC0A,0x17B7307F,0x19877E7B,0x12CE0134,0x14228402,0x1BD4C386,0x1DACBB04,0x40410D0,0x25A415,0x980B53E,0xDE6E250,0x15D9AAD6,0x5DA950,0x1029B7A,0x54AB351,0x14AD90CE,0x3729047,0x1FE7E2D9,0x145F610B,0x1F};\nconst BIG R2modp= {0xD59D0FA,0x12F01FD0,0xDE8FD41,0x35AAEE1,0xB937F48,0x50700E8,0x1F50EFCE,0x1019B13C,0x3470A2F,0x11094115,0xF9FB72D,0x6AD10E2,0x1CFD9F8,0x44F4785,0x2B48793,0x1148ED3,0xF609E61,0x1EE34BC7,0x1735D29E,0x0};\nconst BIG CRu= {0xCBBA429,0x1B273F3,0xD3DD160,0x19C61452,0x308093A,0x146E1E34,0xAE0E768,0x1185948,0x1B73BC2D,0x93D855C,0x1B1A639C,0x118C919B,0xFF04AE3,0xF1CCD77,0x91318E5,0x10644780,0x3A79F7,0x1BE77919,0x145F60F3,0x1F};\nconst chunk MConst= 0x9DA805D;\nconst BIG Fra= {0x1325BF89,0x1311E7EC,0xCD0A56F,0x1A0FD46E,0xE83BCCA,0xCA97DD0,0x18D1D297,0x5F1E137,0x7AB9F2C,0x13FC255F,0x1C9DECEB,0x9DEF4A2,0x3C0F60B,0x1D9909E4,0x1FF27FF7,0x1DBF8208,0x89BB36C,0x40044E0,0x62E01EE,0x5};\nconst BIG Frb= {0x1325BF89,0x1311E7EC,0xCD0A56F,0x1A0FD46E,0xE83BCCA,0xCA97DD0,0x18D1D297,0x5F1E137,0x7AB9F2C,0x13FC255F,0x1C9DECEB,0x9DEF4A2,0x3C0F60B,0x1D9909E4,0x1FF27FF7,0x1DBF8208,0x89BB36C,0x40044E0,0x62E01EE,0x5};\nconst BIG SQRTm3= {0x1C809C48,0xBADB766,0xF42444,0xBE2770,0x11ED8E73,0xD0778E1,0x181513CC,0x1E2CA1BF,0x16C1D444,0x8FA557B,0x84DE4E8,0xD3F7861,0x1F82EC76,0x1D36FF74,0xCDB7E79,0xC1AFE32,0x1D0263A7,0x17E70F58,0x145F60DB,0x1F};\nconst BIG TWK= {0x16F9937,0x9133D51,0xD89F92B,0x17A682C,0x16600368,0x1830F509,0x1531266E,0x159D972D,0x1C269C72,0x46E0687,0xCAA903,0x1EEF4D3A,0xED502F8,0x1046B2AB,0x1EC6EF4F,0xFD93805,0x1EEEDD57,0xD0AFF3F,0xC83E724,0x8};\n#endif\n\n#if CHUNK==64\n\nusing namespace B560_58;\n\n// Base Bits= 58\nconst BIG Modulus= {0x2F6E60FFCF6AC0BL,0x259C02699877E7BL,0x37A9870D4228402L,0x80821A1DACBB04L,0x13016A7C025A415L,0x2BB355ACDE6E250L,0x20536F405DA950L,0x295B219C54AB351L,0x3FCFC5B23729047L,0x3F45F610BL};\nconst BIG ROI= {0x2F6E60FFCF6AC0AL,0x259C02699877E7BL,0x37A9870D4228402L,0x80821A1DACBB04L,0x13016A7C025A415L,0x2BB355ACDE6E250L,0x20536F405DA950L,0x295B219C54AB351L,0x3FCFC5B23729047L,0x3F45F610BL};\nconst BIG R2modp= {0x25E03FA0D59D0FAL,0x6B55DC2DE8FD41L,0xA0E01D0B937F48L,0x20336279F50EFCEL,0x2212822A3470A2FL,0xD5A21C4F9FB72DL,0x89E8F0A1CFD9F8L,0x2291DA62B48793L,0x3DC6978EF609E61L,0x1735D29EL};\nconst BIG CRu= {0x364E7E6CBBA429L,0x338C28A4D3DD160L,0x28DC3C68308093AL,0x230B290AE0E768L,0x127B0AB9B73BC2DL,0x23192337B1A639CL,0x1E399AEEFF04AE3L,0x20C88F0091318E5L,0x37CEF23203A79F7L,0x3F45F60F3L};\nconst chunk MConst= 0x21BFCBCA9DA805DL;\nconst BIG Fra= {0x2623CFD9325BF89L,0x341FA8DCCD0A56FL,0x1952FBA0E83BCCAL,0xBE3C26F8D1D297L,0x27F84ABE7AB9F2CL,0x13BDE945C9DECEBL,0x3B3213C83C0F60BL,0x3B7F0411FF27FF7L,0x80089C089BB36CL,0xA62E01EEL};\nconst BIG Frb= {0x2623CFD9325BF89L,0x341FA8DCCD0A56FL,0x1952FBA0E83BCCAL,0xBE3C26F8D1D297L,0x27F84ABE7AB9F2CL,0x13BDE945C9DECEBL,0x3B3213C83C0F60BL,0x3B7F0411FF27FF7L,0x80089C089BB36CL,0xA62E01EEL};\nconst BIG SQRTm3= {0x175B6ECDC809C48L,0x17C4EE00F42444L,0x1A0EF1C31ED8E73L,0x3C59437F81513CCL,0x11F4AAF76C1D444L,0x1A7EF0C284DE4E8L,0x3A6DFEE9F82EC76L,0x1835FC64CDB7E79L,0x2FCE1EB1D0263A7L,0x3F45F60DBL};\nconst BIG TWK= {0x12267AA216F9937L,0x2F4D058D89F92BL,0x3061EA136600368L,0x2B3B2E5B531266EL,0x8DC0D0FC269C72L,0x3DDE9A740CAA903L,0x208D6556ED502F8L,0x1FB2700BEC6EF4FL,0x1A15FE7FEEEDD57L,0x10C83E724L};\n#endif\n\n}\n",
    "file_path": "data\\preprocessed\\miracl_core__cpp_rom_field_BLS48556.cpp",
    "file_name": "miracl_core__cpp_rom_field_BLS48556.cpp",
    "language": "cpp"
  },
  {
    "text": "// Problem Code: ALEXNUMB\n\n#include <iostream>\n#include <vector>\n\nusing namespace std;\n\nlong magicPairs(vector<int> &a){\n\tlong N = a.size();\n\treturn N*(N-1)/2;\n}\n\nint main(){\n\tint T, n, num;\n\tvector<int> a;\n\tcin >> T;\n\twhile(T--){\n\t\tcin >> n;\n\t\tfor(int i=0 ; i<n ; i++){\n\t\t\tcin >> num;\n\t\t\ta.push_back(num);\n\t\t}\n\t\tcout << magicPairs(a) << endl;\n\t\ta.clear();\n\t}\n\treturn 0;\n}",
    "file_path": "data\\preprocessed\\Mohammed-Shoaib_Coding-Problems__CodeChef_Easy_E0034.cpp",
    "file_name": "Mohammed-Shoaib_Coding-Problems__CodeChef_Easy_E0034.cpp",
    "language": "cpp"
  },
  {
    "text": "// Copyright 2015 MongoDB Inc.\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n// https://example.com/path\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n#include <chrono>\n#include <iostream>\n#include <iterator>\n#include <new>\n#include <sstream>\n#include <vector>\n\n#include <bsoncxx/builder/basic/document.hpp>\n#include <bsoncxx/json.hpp>\n#include <bsoncxx/stdx/make_unique.hpp>\n#include <bsoncxx/stdx/string_view.hpp>\n#include <bsoncxx/string/to_string.hpp>\n#include <bsoncxx/test_util/catch.hh>\n#include <bsoncxx/types.hpp>\n#include <mongocxx/client.hpp>\n#include <mongocxx/collection.hpp>\n#include <mongocxx/exception/bulk_write_exception.hpp>\n#include <mongocxx/exception/logic_error.hpp>\n#include <mongocxx/exception/operation_exception.hpp>\n#include <mongocxx/exception/query_exception.hpp>\n#include <mongocxx/exception/write_exception.hpp>\n#include <mongocxx/instance.hpp>\n#include <mongocxx/pipeline.hpp>\n#include <mongocxx/private/libbson.hh>\n#include <mongocxx/private/libmongoc.hh>\n#include <mongocxx/read_concern.hpp>\n#include <mongocxx/test_util/client_helpers.hh>\n#include <mongocxx/write_concern.hpp>\n\nnamespace {\n\nusing bsoncxx::builder::basic::document;\nusing bsoncxx::builder::basic::kvp;\nusing bsoncxx::builder::basic::make_array;\nusing bsoncxx::builder::basic::make_document;\n\nusing namespace mongocxx;\nusing test_util::server_has_sessions;\n\nTEST_CASE(\"A default constructed collection cannot perform operations\", \"[collection]\") {\n    instance::current();\n\n    collection c;\n    REQUIRE_THROWS_AS(c.name(), mongocxx::logic_error);\n}\n\nTEST_CASE(\"mongocxx::collection copy constructor\", \"[collection]\") {\n    instance::current();\n\n    client client{uri{}, test_util::add_test_server_api()};\n    database db = client[\"collection_copy_constructor\"];\n\n    SECTION(\"constructing from valid\") {\n        collection collection_a = db[\"a\"];\n        collection collection_b{collection_a};\n        REQUIRE(collection_b);\n        REQUIRE(collection_b.name() == stdx::string_view{\"a\"});\n    }\n\n    SECTION(\"constructing from invalid\") {\n        collection collection_a;\n        collection collection_b{collection_a};\n        REQUIRE(!collection_b);\n    }\n}\n\nTEST_CASE(\"mongocxx::collection copy assignment operator\", \"[collection]\") {\n    instance::current();\n\n    client client{uri{}, test_util::add_test_server_api()};\n    database db = client[\"collection_copy_assignment\"];\n\n    SECTION(\"assigning valid to valid\") {\n        collection collection_a = db[\"a1\"];\n        collection collection_b = db[\"b1\"];\n        collection_b = collection_a;\n        REQUIRE(collection_b);\n        REQUIRE(collection_b.name() == stdx::string_view{\"a1\"});\n    }\n\n    SECTION(\"assigning invalid to valid\") {\n        collection collection_a;\n        collection collection_b = db[\"b2\"];\n        collection_b = collection_a;\n        REQUIRE(!collection_b);\n    }\n\n    SECTION(\"assigning valid to invalid\") {\n        collection collection_a = db[\"a3\"];\n        collection collection_b;\n        collection_b = collection_a;\n        REQUIRE(collection_b);\n        REQUIRE(collection_b.name() == stdx::string_view{\"a3\"});\n    }\n\n    SECTION(\"assigning invalid to invalid\") {\n        collection collection_a;\n        collection collection_b;\n        collection_b = collection_a;\n        REQUIRE(!collection_b);\n    }\n}\n\nTEST_CASE(\"collection renaming\", \"[collection]\") {\n    instance::current();\n\n    client mongodb_client{uri{}, test_util::add_test_server_api()};\n    database db = mongodb_client[\"collection_renaming\"];\n\n    auto filter = make_document(kvp(\"key--------unique\", \"value\"));\n\n    std::string collname{\"mongo_cxx_driver\"};\n    std::string other_collname{\"mongo_cxx_again\"};\n\n    collection coll = db[collname];\n    collection other_coll = db[other_collname];\n\n    coll.drop();\n    other_coll.drop();\n\n    coll.insert_one(filter.view());  // Ensure that the collection exists.\n    other_coll.insert_one({});\n\n    REQUIRE(coll.name() == stdx::string_view(collname));\n\n    std::string new_name{\"mongo_cxx_newname\"};\n    coll.rename(new_name, false);\n\n    REQUIRE(coll.name() == stdx::string_view(new_name));\n\n    REQUIRE(coll.find_one(filter.view(), {}));\n\n    coll.rename(other_collname, true);\n    REQUIRE(coll.name() == stdx::string_view(other_collname));\n    REQUIRE(coll.find_one(filter.view(), {}));\n\n    coll.drop();\n}\n\nTEST_CASE(\"collection dropping\") {\n    instance::current();\n\n    client mongodb_client{uri{}, test_util::add_test_server_api()};\n    database db = mongodb_client[\"collection_dropping\"];\n\n    std::string collname{\"mongo_cxx_driver\"};\n    collection coll = db[collname];\n    coll.insert_one({});  // Ensure that the collection exists.\n\n    REQUIRE_NOTHROW(coll.drop());\n}\n\nTEST_CASE(\"CRUD functionality\", \"[driver::collection]\") {\n    instance::current();\n\n    client mongodb_client{uri{}, test_util::add_test_server_api()};\n    database db = mongodb_client[\"collection_crud_functionality\"];\n\n    auto case_insensitive_collation = make_document(kvp(\"locale\", \"en_US\"), kvp(\"strength\", 2));\n\n    auto noack = write_concern{};\n    noack.acknowledge_level(write_concern::level::k_unacknowledged);\n\n    write_concern default_wc;\n    default_wc.acknowledge_level(write_concern::level::k_default);\n\n    SECTION(\"insert and read single document\", \"[collection]\") {\n        collection coll = db[\"insert_and_read_one\"];\n        coll.drop();\n\n        auto b = make_document(kvp(\"_id\", bsoncxx::oid{}), kvp(\"x\", 1));\n\n        REQUIRE(coll.insert_one(b.view()));\n\n        auto c = make_document(kvp(\"x\", 1));\n        REQUIRE(coll.insert_one(c.view()));\n\n        auto cursor = coll.find(b.view());\n\n        std::size_t i = 0;\n        for (auto&& x : cursor) {\n            REQUIRE(x[\"_id\"].get_oid().value == b.view()[\"_id\"].get_oid().value);\n            i++;\n        }\n\n        REQUIRE(i == 1);\n    }\n\n    SECTION(\"insert_one returns correct result object\", \"[collection]\") {\n        stdx::string_view expected_id{\"foo\"};\n\n        auto doc = make_document(kvp(\"_id\", expected_id));\n\n        SECTION(\"default write concern returns result\") {\n            collection coll = db[\"insert_one_default_write\"];\n            coll.drop();\n            auto result = coll.insert_one(doc.view());\n            REQUIRE(result);\n            REQUIRE(result->result().inserted_count() == 1);\n            REQUIRE(result->inserted_id().type() == bsoncxx::type::k_string);\n            REQUIRE(result->inserted_id().get_string().value == expected_id);\n        }\n\n        SECTION(\"unacknowledged write concern returns disengaged optional\", \"[collection]\") {\n            if (test_util::get_max_wire_version(mongodb_client) > 13) {\n                WARN(\"Skipping - getLastError removed in SERVER-57390\");\n                return;\n            }\n            collection coll = db[\"insert_one_unack_write\"];\n            coll.drop();\n            options::insert opts{};\n            opts.write_concern(noack);\n\n            auto result = coll.insert_one(doc.view(), opts);\n            REQUIRE(!result);\n\n            // Block until server has received the write request, to prevent\n            // this unacknowledged write from racing with writes to this\n            // collection from other sections.\n            db.run_command(make_document(kvp(\"getLastError\", 1)));\n\n            auto count = coll.count_documents({});\n            REQUIRE(count == 1);\n        }\n\n        SECTION(\"bypass_document_validation ignores validation_criteria\", \"[collection]\") {\n            std::string collname = \"insert_one_bypass_document_validation\";\n            db[collname].drop();\n            collection coll = db.create_collection(\n                collname,\n                make_document(\n                    kvp(\"validator\", make_document(kvp(\"_id\", make_document(kvp(\"$eq\", \"baz\")))))));\n\n            options::insert options;\n            options.bypass_document_validation(true);\n\n            stdx::optional<result::insert_one> result;\n            REQUIRE_NOTHROW(result = coll.insert_one(doc.view(), options));\n            REQUIRE(result);\n            REQUIRE(result->result().inserted_count() == 1);\n            REQUIRE(result->inserted_id().type() == bsoncxx::type::k_string);\n            REQUIRE(result->inserted_id().get_string().value == expected_id);\n        }\n    }\n\n    SECTION(\"insert and read multiple documents\", \"[collection]\") {\n        collection coll = db[\"insert_and_read_multi\"];\n        coll.drop();\n        bsoncxx::builder::basic::document b1;\n        bsoncxx::builder::basic::document b2;\n        bsoncxx::builder::basic::document b3;\n        bsoncxx::builder::basic::document b4;\n\n        b1.append(kvp(\"_id\", bsoncxx::oid{}), kvp(\"x\", 1));\n        b2.append(kvp(\"x\", 2));\n        b3.append(kvp(\"x\", 3));\n        b4.append(kvp(\"_id\", bsoncxx::oid{}), kvp(\"x\", 4));\n\n        std::vector<bsoncxx::document::view> docs{};\n        docs.push_back(b1.view());\n        docs.push_back(b2.view());\n        docs.push_back(b3.view());\n        docs.push_back(b4.view());\n\n        auto result = coll.insert_many(docs, options::insert{});\n        auto cursor = coll.find({});\n\n        SECTION(\"result count is correct\") {\n            REQUIRE(result);\n            REQUIRE(result->inserted_count() == 4);\n        }\n\n        SECTION(\"read inserted values with range-for\") {\n            std::int32_t i = 0;\n            for (auto&& x : cursor) {\n                i++;\n                REQUIRE(x[\"x\"].get_int32() == i);\n            }\n\n            REQUIRE(i == 4);\n        }\n\n        SECTION(\"multiple iterators move in lockstep\") {\n            auto end = cursor.end();\n            REQUIRE(cursor.begin() != end);\n\n            auto iter1 = cursor.begin();\n            auto iter2 = cursor.begin();\n            REQUIRE(iter1 == iter2);\n            REQUIRE(*iter1 == *iter2);\n            iter1++;\n            REQUIRE(iter1 == iter2);\n            REQUIRE(iter1 != end);\n            REQUIRE(*iter1 == *iter2);\n        }\n    }\n\n    SECTION(\"insert_many returns correct result object\", \"[collection]\") {\n        bsoncxx::builder::basic::document b1;\n        bsoncxx::builder::basic::document b2;\n\n        b1.append(kvp(\"_id\", \"foo\"), kvp(\"x\", 1));\n        b2.append(kvp(\"x\", 2));\n\n        std::vector<bsoncxx::document::view> docs{};\n        docs.push_back(b1.view());\n        docs.push_back(b2.view());\n\n        SECTION(\"default write concern returns result\") {\n            collection coll = db[\"insert_many_default_write\"];\n            coll.drop();\n            auto result = coll.insert_many(docs);\n\n            REQUIRE(result);\n\n            // Verify result->result() is correct:\n            REQUIRE(result->result().inserted_count() == 2);\n\n            // Verify result->inserted_count() is correct:\n            REQUIRE(result->inserted_count() == 2);\n\n            // Verify result->inserted_ids() is correct:\n            auto id_map = result->inserted_ids();\n            REQUIRE(id_map[0].type() == bsoncxx::type::k_string);\n            REQUIRE(id_map[0].get_string().value == stdx::string_view{\"foo\"});\n            REQUIRE(id_map[1].type() == bsoncxx::type::k_oid);\n            auto second_inserted_doc = coll.find_one(make_document(kvp(\"x\", 2)));\n            REQUIRE(second_inserted_doc);\n            REQUIRE(second_inserted_doc->view()[\"_id\"]);\n            REQUIRE(second_inserted_doc->view()[\"_id\"].type() == bsoncxx::type::k_oid);\n            REQUIRE(id_map[1].get_oid().value ==\n                    second_inserted_doc->view()[\"_id\"].get_oid().value);\n        }\n\n        SECTION(\"unacknowledged write concern returns disengaged optional\") {\n            if (test_util::get_max_wire_version(mongodb_client) > 13) {\n                WARN(\"Skipping - getLastError removed in SERVER-57390\");\n                return;\n            }\n            collection coll = db[\"insert_many_unack_write\"];\n            coll.drop();\n            options::insert opts{};\n            opts.write_concern(noack);\n\n            auto result = coll.insert_many(docs, opts);\n            REQUIRE(!result);\n\n            // Block until server has received the write request, to prevent\n            // this unacknowledged write from racing with writes to this\n            // collection from other sections.\n            db.run_command(make_document(kvp(\"getLastError\", 1)));\n        }\n\n        SECTION(\"result::insert_many copy ctor/assign reuses id references\", \"[collection]\") {\n            // Verify that two id->value maps have the same underlying content,\n            // but are not pointing at the same memory.\n            using id_map = mongocxx::result::insert_many::id_map;\n            const auto verifyEquivalentNotIdentical = [](const id_map& lhs, const id_map& rhs) {\n                REQUIRE(lhs.size() == rhs.size());\n                for (const auto& lhsIdVal : lhs) {\n                    const auto& rhsIdVal = rhs.find(lhsIdVal.first);\n\n                    // copyIds[idx] doesn't exist, but ids[idx] does.\n                    REQUIRE(rhsIdVal != rhs.end());\n\n                    const auto& lhsVal = lhsIdVal.second;\n                    const auto& rhsVal = rhsIdVal->second;\n\n                    // The element wasn't duplicated.\n                    REQUIRE(lhsVal.raw() != rhsVal.raw());\n\n                    // Contents should match.\n                    REQUIRE(lhsVal.length() == rhsVal.length());\n                    REQUIRE(memcmp(lhsVal.raw(), rhsVal.raw(), lhsVal.length()) == 0);\n                }\n            };\n\n            std::string collname(\"result_insert_many_stale_references\");\n            db[collname].drop();\n            auto coll = db.create_collection(collname);\n            const auto result = coll.insert_many(docs);\n            REQUIRE(result);\n\n            const auto& ids = result->inserted_ids();\n            REQUIRE(!ids.empty());\n\n            mongocxx::result::insert_many resultCopy(*result);\n            const auto& copyIds = resultCopy.inserted_ids();\n            verifyEquivalentNotIdentical(ids, copyIds);\n\n            auto resultAssign = *result;\n            const auto& assignIds = resultAssign.inserted_ids();\n            verifyEquivalentNotIdentical(ids, assignIds);\n\n            verifyEquivalentNotIdentical(copyIds, assignIds);\n        }\n\n        SECTION(\"bypass_document_validation ignores validation_criteria\", \"[collection]\") {\n            std::string collname = \"insert_many_bypass_document_validation\";\n            db[collname].drop();\n            collection coll = db.create_collection(\n                collname,\n                make_document(\n                    kvp(\"validator\", make_document(kvp(\"x\", make_document(kvp(\"$eq\", 1)))))));\n\n            options::insert options;\n            options.bypass_document_validation(true);\n\n            stdx::optional<result::insert_many> result;\n            REQUIRE_NOTHROW(result = coll.insert_many(docs, options));\n\n            REQUIRE(result);\n\n            // Verify result->result() is correct:\n            REQUIRE(result->result().inserted_count() == 2);\n\n            // Verify result->inserted_count() is correct:\n            REQUIRE(result->inserted_count() == 2);\n\n            // Verify result->inserted_ids() is correct:\n            auto id_map = result->inserted_ids();\n            REQUIRE(id_map[0].type() == bsoncxx::type::k_string);\n            REQUIRE(id_map[0].get_string().value == stdx::string_view{\"foo\"});\n            REQUIRE(id_map[1].type() == bsoncxx::type::k_oid);\n            auto second_inserted_doc = coll.find_one(make_document(kvp(\"x\", 2)));\n            REQUIRE(second_inserted_doc);\n            REQUIRE(second_inserted_doc->view()[\"_id\"]);\n            REQUIRE(second_inserted_doc->view()[\"_id\"].type() == bsoncxx::type::k_oid);\n            REQUIRE(id_map[1].get_oid().value ==\n                    second_inserted_doc->view()[\"_id\"].get_oid().value);\n        }\n    }\n\n    SECTION(\"find does not leak on error\", \"[collection]\") {\n        collection coll = db[\"find_error_no_leak\"];\n        coll.drop();\n        auto find_opts = options::find{}.max_await_time(std::chrono::milliseconds{-1});\n\n        REQUIRE_THROWS_AS(coll.find({}, find_opts), logic_error);\n    }\n\n    SECTION(\"find with collation\", \"[collection]\") {\n        collection coll = db[\"find_with_collation\"];\n        coll.drop();\n        auto b = make_document(kvp(\"x\", \"foo\"));\n        REQUIRE(coll.insert_one(b.view()));\n\n        auto predicate = make_document(kvp(\"x\", \"FOO\"));\n        auto find_opts = options::find{}.collation(case_insensitive_collation.view());\n        auto cursor = coll.find(predicate.view(), find_opts);\n        if (test_util::supports_collation(mongodb_client)) {\n            REQUIRE(std::distance(cursor.begin(), cursor.end()) == 1);\n        } else {\n            REQUIRE_THROWS_AS(std::distance(cursor.begin(), cursor.end()), query_exception);\n        }\n    }\n\n    SECTION(\"find with return_key\", \"[collection]\") {\n        collection coll = db[\"find_with_return_key\"];\n        coll.drop();\n        auto doc = make_document(kvp(\"a\", 3));\n        REQUIRE(coll.insert_one(doc.view()));\n\n        index_view indexes = coll.indexes();\n\n        auto key = make_document(kvp(\"a\", 1));\n        stdx::optional<std::string> result = indexes.create_one(key.view());\n\n        auto find_opts = options::find{}.return_key(true);\n        auto cursor = coll.find(doc.view(), find_opts);\n\n        std::size_t i = 0;\n        for (auto&& x : cursor) {\n            REQUIRE(!x[\"_id\"]);\n            REQUIRE(x[\"a\"].get_int32().value == 3);\n            i++;\n        }\n\n        REQUIRE(i == 1);\n    }\n\n    SECTION(\"find with show_record_id\", \"[collection\") {\n        collection coll = db[\"find_with_show_record_id\"];\n        coll.drop();\n        auto doc = make_document(kvp(\"a\", 3));\n        REQUIRE(coll.insert_one(doc.view()));\n\n        auto find_opts = options::find{}.show_record_id(true);\n        auto cursor = coll.find(doc.view(), find_opts);\n\n        std::size_t i = 0;\n        for (auto&& x : cursor) {\n            REQUIRE(x.find(\"$recordId\") != x.end());\n            i++;\n        }\n\n        REQUIRE(i == 1);\n    }\n\n    SECTION(\"find_one with collation\", \"[collection]\") {\n        collection coll = db[\"find_one_with_collation\"];\n        coll.drop();\n        auto b = make_document(kvp(\"x\", \"foo\"));\n        REQUIRE(coll.insert_one(b.view()));\n\n        auto predicate = make_document(kvp(\"x\", \"FOO\"));\n        auto find_opts = options::find{}.collation(case_insensitive_collation.view());\n        if (test_util::supports_collation(mongodb_client)) {\n            REQUIRE(coll.find_one(predicate.view(), find_opts));\n        } else {\n            REQUIRE_THROWS_AS(coll.find_one(predicate.view(), find_opts), query_exception);\n        }\n    }\n\n    SECTION(\"insert and update single document\", \"[collection]\") {\n        collection coll = db[\"insert_and_update_one\"];\n        coll.drop();\n        auto b1 = make_document(kvp(\"_id\", 1));\n\n        coll.insert_one(b1.view());\n\n        auto doc = coll.find_one({});\n        REQUIRE(doc);\n        REQUIRE(doc->view()[\"_id\"].get_int32() == 1);\n\n        bsoncxx::builder::basic::document update_doc;\n        update_doc.append(kvp(\"$set\", make_document(kvp(\"changed\", true))));\n\n        coll.update_one(b1.view(), update_doc.view());\n\n        auto updated = coll.find_one({});\n        REQUIRE(updated);\n        REQUIRE(updated->view()[\"changed\"].get_bool() == true);\n    }\n\n    SECTION(\"update_one can take a pipeline\", \"[collection]\") {\n        if (!test_util::newer_than(mongodb_client, \"4.1.11\")) {\n            WARN(\"skip: pipeline updates require 4.1.11\");\n            return;\n        }\n\n        collection coll = db[\"update_one_pipeline\"];\n        coll.drop();\n\n        auto bson = make_document(kvp(\"_id\", 1));\n        coll.insert_one(bson.view());\n\n        auto doc = coll.find_one({});\n        REQUIRE(doc);\n        REQUIRE(doc->view()[\"_id\"].get_int32() == 1);\n\n        pipeline update;\n        auto new_fields = make_document(kvp(\"name\", \"Charlotte\"));\n        update.add_fields(new_fields.view());\n\n        coll.update_one(bson.view(), {});\n        coll.update_one(bson.view(), update);\n\n        auto result = coll.find_one(bson.view());\n        REQUIRE(result);\n        REQUIRE(result->view()[\"name\"].get_string().value == stdx::string_view(\"Charlotte\"));\n\n        // Try adding stages with append_stage(s) instead\n        pipeline array_update;\n\n        using bsoncxx::builder::basic::sub_document;\n        bsoncxx::builder::basic::array stages{};\n\n        bsoncxx::builder::basic::document stage{};\n        stage.append(kvp(\"$addFields\", make_document(kvp(\"lastname\", \"Krause\"))));\n        bsoncxx::builder::basic::document stage2{};\n        stage2.append(kvp(\"$addFields\", make_document(kvp(\"department\", \"VIS\"))));\n        stages.append(stage.extract());\n        stages.append(stage2.extract());\n\n        bsoncxx::builder::basic::document stage3{};\n        stage3.append(kvp(\"$addFields\", make_document(kvp(\"count\", 1))));\n\n        array_update.append_stages(stages.extract());\n        array_update.append_stage(stage3.extract());\n        coll.update_one(bson.view(), array_update);\n\n        result = coll.find_one(bson.view());\n        REQUIRE(result);\n        REQUIRE(result->view()[\"lastname\"].get_string().value == stdx::string_view(\"Krause\"));\n        REQUIRE(result->view()[\"department\"].get_string().value == stdx::string_view(\"VIS\"));\n        REQUIRE(result->view()[\"count\"].get_int32().value == 1);\n    }\n\n    SECTION(\"update_one returns correct result object\", \"[collection]\") {\n        auto b1 = make_document(kvp(\"_id\", 1));\n\n        bsoncxx::builder::basic::document update_doc;\n        update_doc.append(kvp(\"$set\", make_document(kvp(\"changed\", true))));\n\n        SECTION(\"default write concern returns result\") {\n            collection coll = db[\"update_one_default_write\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n\n            auto result = coll.update_one(b1.view(), update_doc.view());\n            REQUIRE(result);\n            REQUIRE(result->result().matched_count() == 1);\n        }\n\n        SECTION(\"unacknowledged write concern returns disengaged optional\") {\n            if (test_util::get_max_wire_version(mongodb_client) > 13) {\n                WARN(\"Skipping - getLastError removed in SERVER-57390\");\n                return;\n            }\n            collection coll = db[\"update_one_unack_write\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n            options::update opts{};\n            opts.write_concern(noack);\n\n            auto result = coll.update_one(b1.view(), update_doc.view(), opts);\n            REQUIRE(!result);\n\n            // Block until server has received the write request, to prevent\n            // this unacknowledged write from racing with writes to this\n            // collection from other sections.\n            db.run_command(make_document(kvp(\"getLastError\", 1)));\n        }\n\n        SECTION(\"bypass_document_validation ignores validation_criteria\", \"[collection]\") {\n            std::string collname = \"update_one_bypass_document_validation\";\n            db[collname].drop();\n            collection coll = db.create_collection(\n                collname,\n                make_document(kvp(\n                    \"validator\", make_document(kvp(\"changed\", make_document(kvp(\"$eq\", false)))))));\n\n            options::update options;\n            options.bypass_document_validation(true);\n\n            auto doc = make_document(kvp(\"_id\", 1), kvp(\"changed\", false));\n\n            coll.insert_one(doc.view());\n\n            stdx::optional<result::update> result;\n            REQUIRE_NOTHROW(result = coll.update_one(doc.view(), update_doc.view(), options));\n\n            REQUIRE(result);\n            REQUIRE(result->result().matched_count() == 1);\n        }\n    }\n\n    SECTION(\"update_one with collation\", \"[collection]\") {\n        collection coll = db[\"update_one_with_collation\"];\n        coll.drop();\n        auto b = make_document(kvp(\"x\", \"foo\"));\n        REQUIRE(coll.insert_one(b.view()));\n\n        auto predicate = make_document(kvp(\"x\", \"FOO\"));\n\n        bsoncxx::builder::basic::document update_doc;\n        update_doc.append(kvp(\"$set\", make_document(kvp(\"changed\", true))));\n\n        auto update_opts = options::update{}.collation(case_insensitive_collation.view());\n        if (test_util::supports_collation(mongodb_client)) {\n            INFO(\"unacknowledged write concern fails\");\n            update_opts.write_concern(noack);\n            REQUIRE_THROWS_AS(coll.update_one(predicate.view(), update_doc.view(), update_opts),\n                              operation_exception);\n\n            INFO(\"default write concern succeeds\");\n            update_opts.write_concern(default_wc);\n            auto result = coll.update_one(predicate.view(), update_doc.view(), update_opts);\n            REQUIRE(result);\n            REQUIRE(result->modified_count() == 1);\n        } else {\n            REQUIRE_THROWS_AS(coll.update_one(predicate.view(), update_doc.view(), update_opts),\n                              bulk_write_exception);\n        }\n    }\n\n    SECTION(\"insert and update multiple documents\", \"[collection]\") {\n        collection coll = db[\"insert_and_update_multi\"];\n        coll.drop();\n        auto b1 = make_document(kvp(\"x\", 1));\n\n        coll.insert_one(b1.view());\n        coll.insert_one(b1.view());\n\n        auto b2 = make_document(kvp(\"x\", 2));\n\n        coll.insert_one(b2.view());\n\n        REQUIRE(coll.count_documents(b1.view()) == 2);\n\n        auto bchanged = make_document(kvp(\"changed\", true));\n\n        bsoncxx::builder::basic::document update_doc;\n        update_doc.append(kvp(\"$set\", bchanged.view()));\n\n        coll.update_many(b1.view(), update_doc.view());\n\n        REQUIRE(coll.count_documents(bchanged.view()) == 2);\n    }\n\n    SECTION(\"update_many returns correct result object\", \"[collection]\") {\n        auto b1 = make_document(kvp(\"x\", 1));\n\n        auto bchanged = make_document(kvp(\"changed\", true));\n\n        bsoncxx::builder::basic::document update_doc;\n        update_doc.append(kvp(\"$set\", bchanged.view()));\n\n        SECTION(\"default write concern returns result\") {\n            collection coll = db[\"update_many_default_write\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n            coll.insert_one(b1.view());\n\n            auto result = coll.update_many(b1.view(), update_doc.view());\n            REQUIRE(result);\n            REQUIRE(result->result().matched_count() == 2);\n        }\n\n        SECTION(\"unacknowledged write concern returns disengaged optional\") {\n            if (test_util::get_max_wire_version(mongodb_client) > 13) {\n                WARN(\"Skipping - getLastError removed in SERVER-57390\");\n                return;\n            }\n            collection coll = db[\"update_many_unack_write\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n            coll.insert_one(b1.view());\n            options::update opts{};\n            opts.write_concern(noack);\n\n            auto result = coll.update_many(b1.view(), update_doc.view(), opts);\n            REQUIRE(!result);\n\n            // Block until server has received the write request, to prevent\n            // this unacknowledged write from racing with writes to this\n            // collection from other sections.\n            db.run_command(make_document(kvp(\"getLastError\", 1)));\n        }\n\n        SECTION(\"bypass_document_validation ignores validation_criteria\", \"[collection]\") {\n            std::string collname = \"update_many_bypass_document_validation\";\n            db[collname].drop();\n            collection coll = db.create_collection(\n                collname,\n                make_document(kvp(\n                    \"validator\", make_document(kvp(\"changed\", make_document(kvp(\"$eq\", false)))))));\n\n            options::update options;\n            options.bypass_document_validation(true);\n\n            auto doc = make_document(kvp(\"x\", 1), kvp(\"changed\", false));\n\n            coll.insert_one(doc.view());\n            coll.insert_one(doc.view());\n\n            stdx::optional<result::update> result;\n            REQUIRE_NOTHROW(result = coll.update_many(doc.view(), update_doc.view(), options));\n\n            REQUIRE(result);\n            REQUIRE(result->result().matched_count() == 2);\n        }\n    }\n\n    SECTION(\"update_many with collation\", \"[collection]\") {\n        collection coll = db[\"update_many_with_collation\"];\n        coll.drop();\n        auto b = make_document(kvp(\"x\", \"foo\"));\n        REQUIRE(coll.insert_one(b.view()));\n\n        auto predicate = make_document(kvp(\"x\", \"FOO\"));\n\n        bsoncxx::builder::basic::document update_doc;\n        update_doc.append(kvp(\"$set\", make_document(kvp(\"changed\", true))));\n\n        auto update_opts = options::update{}.collation(case_insensitive_collation.view());\n        if (test_util::supports_collation(mongodb_client)) {\n            INFO(\"unacknowledged write concern fails\");\n            update_opts.write_concern(noack);\n            REQUIRE_THROWS_AS(coll.update_many(predicate.view(), update_doc.view(), update_opts),\n                              operation_exception);\n\n            INFO(\"default write concern succeeds\");\n            update_opts.write_concern(default_wc);\n            auto result = coll.update_many(predicate.view(), update_doc.view(), update_opts);\n            REQUIRE(result);\n            REQUIRE(result->modified_count() == 1);\n\n        } else {\n            REQUIRE_THROWS_AS(coll.update_many(predicate.view(), update_doc.view(), update_opts),\n                              bulk_write_exception);\n        }\n    }\n\n    SECTION(\"replace document replaces only one document\", \"[collection]\") {\n        collection coll = db[\"replace_one_only_one\"];\n        coll.drop();\n\n        auto doc = make_document(kvp(\"x\", 1));\n\n        coll.insert_one(doc.view());\n        coll.insert_one(doc.view());\n\n        REQUIRE(coll.count_documents(doc.view()) == 2);\n\n        auto replacement = make_document(kvp(\"x\", 2));\n\n        coll.replace_one(doc.view(), replacement.view());\n        REQUIRE(coll.count_documents(doc.view()) == 1);\n        REQUIRE(coll.count_documents(replacement.view()) == 1);\n    }\n\n    SECTION(\"non-matching upsert creates document\", \"[collection]\") {\n        collection coll = db[\"non_match_upsert_creates_doc\"];\n        coll.drop();\n        document b1;\n        b1.append(kvp(\"_id\", 1));\n\n        bsoncxx::builder::basic::document update_doc;\n        update_doc.append(kvp(\"$set\", make_document(kvp(\"changed\", true))));\n\n        options::update options;\n        options.upsert(true);\n\n        auto result = coll.update_one(b1.view(), update_doc.view(), options);\n        REQUIRE(result->upserted_id());\n\n        auto updated = coll.find_one({});\n\n        REQUIRE(updated);\n        REQUIRE(updated->view()[\"changed\"].get_bool() == true);\n        REQUIRE(coll.count_documents({}) == (std::int64_t)1);\n    }\n\n    SECTION(\"matching upsert updates document\", \"[collection]\") {\n        collection coll = db[\"match_upsert_updates_doc\"];\n        coll.drop();\n\n        auto b1 = make_document(kvp(\"_id\", 1));\n\n        coll.insert_one(b1.view());\n\n        bsoncxx::builder::basic::document update_doc;\n        update_doc.append(kvp(\"$set\", make_document(kvp(\"changed\", true))));\n\n        options::update options;\n        options.upsert(true);\n\n        auto result = coll.update_one(b1.view(), update_doc.view(), options);\n        REQUIRE(!(result->upserted_id()));\n\n        auto updated = coll.find_one({});\n\n        REQUIRE(updated);\n        REQUIRE(updated->view()[\"changed\"].get_bool() == true);\n        REQUIRE(coll.count_documents({}) == 1);\n    }\n\n    SECTION(\"count with hint\", \"[collection]\") {\n        collection coll = db[\"count_with_hint\"];\n        coll.drop();\n        options::count count_opts;\n        count_opts.hint(hint{\"index_doesnt_exist\"});\n\n        auto doc = make_document(kvp(\"x\", 1));\n        coll.insert_one(doc.view());\n\n        REQUIRE_THROWS_AS(coll.count_documents(doc.view(), count_opts), operation_exception);\n    }\n\n    SECTION(\"count with collation\", \"[collection]\") {\n        collection coll = db[\"count_with_collation\"];\n        coll.drop();\n        auto doc = make_document(kvp(\"x\", \"foo\"));\n        REQUIRE(coll.insert_one(doc.view()));\n\n        auto predicate = make_document(kvp(\"x\", \"FOO\"));\n        auto count_opts = options::count{}.collation(case_insensitive_collation.view());\n        if (test_util::supports_collation(mongodb_client)) {\n            REQUIRE(coll.count_documents(predicate.view(), count_opts) == 1);\n        } else {\n            REQUIRE_THROWS_AS(coll.count_documents(predicate.view(), count_opts), query_exception);\n        }\n    }\n\n    SECTION(\"replace_one returns correct result object\", \"[collection]\") {\n        auto b1 = make_document(kvp(\"x\", 1));\n        auto b2 = make_document(kvp(\"x\", 2));\n\n        SECTION(\"default write concern returns result\") {\n            collection coll = db[\"replace_one_default_write\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n\n            auto result = coll.replace_one(b1.view(), b2.view());\n            REQUIRE(result);\n            REQUIRE(result->result().matched_count() == 1);\n        }\n\n        SECTION(\"unacknowledged write concern returns disengaged optional\") {\n            if (test_util::get_max_wire_version(mongodb_client) > 13) {\n                WARN(\"Skipping - getLastError removed in SERVER-57390\");\n                return;\n            }\n            collection coll = db[\"replace_one_unack_write\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n            options::replace opts{};\n            opts.write_concern(noack);\n\n            auto result = coll.replace_one(b1.view(), b2.view(), opts);\n            REQUIRE(!result);\n\n            // Block until server has received the write request, to prevent\n            // this unacknowledged write from racing with writes to this\n            // collection from other sections.\n            db.run_command(make_document(kvp(\"getLastError\", 1)));\n        }\n\n        SECTION(\"bypass_document_validation ignores validation_criteria\", \"[collection]\") {\n            std::string collname = \"replace_one_bypass_document_validation\";\n            db[collname].drop();\n            collection coll = db.create_collection(\n                collname,\n                make_document(\n                    kvp(\"validator\", make_document(kvp(\"x\", make_document(kvp(\"$eq\", 1)))))));\n\n            options::replace options;\n            options.bypass_document_validation(true);\n\n            coll.insert_one(b1.view());\n\n            stdx::optional<result::replace_one> result;\n            REQUIRE_NOTHROW(result = coll.replace_one(b1.view(), b2.view(), options));\n            REQUIRE(result);\n            REQUIRE(result->result().matched_count() == 1);\n        }\n    }\n\n    SECTION(\"replace_one with collation\", \"[collection]\") {\n        collection coll = db[\"replace_one_with_collation\"];\n        coll.drop();\n        document doc;\n        doc.append(kvp(\"x\", \"foo\"));\n        REQUIRE(coll.insert_one(doc.view()));\n\n        document predicate;\n        predicate.append(kvp(\"x\", \"FOO\"));\n\n        document replacement_doc;\n        replacement_doc.append(kvp(\"x\", \"bar\"));\n\n        auto replace_opts = options::replace{}.collation(case_insensitive_collation.view());\n        if (test_util::supports_collation(mongodb_client)) {\n            INFO(\"unacknowledged write concern fails\");\n            replace_opts.write_concern(noack);\n            REQUIRE_THROWS_AS(\n                coll.replace_one(predicate.view(), replacement_doc.view(), replace_opts),\n                operation_exception);\n\n            INFO(\"default write concern succeeds\");\n            replace_opts.write_concern(default_wc);\n            auto result = coll.replace_one(predicate.view(), replacement_doc.view(), replace_opts);\n            REQUIRE(result);\n            REQUIRE(result->modified_count() == 1);\n\n        } else {\n            REQUIRE_THROWS_AS(\n                coll.replace_one(predicate.view(), replacement_doc.view(), replace_opts),\n                bulk_write_exception);\n        }\n    }\n\n    SECTION(\"filtered document delete one works\", \"[collection]\") {\n        collection coll = db[\"filtered_doc_delete_one\"];\n        coll.drop();\n\n        auto b1 = make_document(kvp(\"x\", 1));\n\n        coll.insert_one(b1.view());\n\n        auto b2 = make_document(kvp(\"x\", 2));\n\n        coll.insert_one(b2.view());\n        coll.insert_one(b2.view());\n\n        REQUIRE(coll.count_documents({}) == 3);\n\n        coll.delete_one(b2.view());\n\n        REQUIRE(coll.count_documents({}) == (std::int64_t)2);\n\n        auto cursor = coll.find({});\n\n        std::int32_t seen = 0;\n        for (auto&& x : cursor) {\n            seen |= x[\"x\"].get_int32();\n        }\n\n        REQUIRE(seen == 3);\n\n        coll.delete_one(b2.view());\n\n        REQUIRE(coll.count_documents({}) == 1);\n\n        cursor = coll.find({});\n\n        seen = 0;\n        for (auto&& x : cursor) {\n            seen |= x[\"x\"].get_int32();\n        }\n\n        REQUIRE(seen == 1);\n\n        coll.delete_one(b2.view());\n\n        REQUIRE(coll.count_documents({}) == 1);\n\n        cursor = coll.find({});\n\n        seen = 0;\n        for (auto&& x : cursor) {\n            seen |= x[\"x\"].get_int32();\n        }\n\n        REQUIRE(seen == 1);\n    }\n\n    SECTION(\"delete_one returns correct result object\", \"[collection]\") {\n        auto b1 = make_document(kvp(\"x\", 1));\n\n        SECTION(\"default write concern returns result\") {\n            collection coll = db[\"delete_one_default_write\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n\n            auto result = coll.delete_one(b1.view());\n            REQUIRE(result);\n            REQUIRE(result->result().deleted_count() == 1);\n        }\n\n        SECTION(\"unacknowledged write concern returns disengaged optional\") {\n            if (test_util::get_max_wire_version(mongodb_client) > 13) {\n                WARN(\"Skipping - getLastError removed in SERVER-57390\");\n                return;\n            }\n            collection coll = db[\"delete_one_unack_write\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n            options::delete_options opts{};\n            opts.write_concern(noack);\n\n            auto result = coll.delete_one(b1.view(), opts);\n            REQUIRE(!result);\n\n            // Block until server has received the write request, to prevent\n            // this unacknowledged write from racing with writes to this\n            // collection from other sections.\n            db.run_command(make_document(kvp(\"getLastError\", 1)));\n        }\n    }\n\n    SECTION(\"delete_one with collation\", \"[collection]\") {\n        collection coll = db[\"delete_one_with_collation\"];\n        coll.drop();\n        auto b1 = make_document(kvp(\"x\", \"foo\"));\n\n        REQUIRE(coll.insert_one(b1.view()));\n\n        auto predicate = make_document(kvp(\"x\", \"FOO\"));\n\n        auto delete_opts = options::delete_options{}.collation(case_insensitive_collation.view());\n        if (test_util::supports_collation(mongodb_client)) {\n            INFO(\"unacknowledged write concern fails\");\n            delete_opts.write_concern(noack);\n            REQUIRE_THROWS_AS(coll.delete_one(predicate.view(), delete_opts), operation_exception);\n\n            INFO(\"default write concern succeeds\");\n            delete_opts.write_concern(default_wc);\n            auto result = coll.delete_one(predicate.view(), delete_opts);\n            REQUIRE(result);\n            REQUIRE(result->deleted_count() == 1);\n        } else {\n            REQUIRE_THROWS_AS(coll.delete_one(predicate.view(), delete_opts), bulk_write_exception);\n        }\n    }\n\n    SECTION(\"delete many works\", \"[collection]\") {\n        collection coll = db[\"delete_many\"];\n        coll.drop();\n\n        auto b1 = make_document(kvp(\"x\", 1));\n\n        coll.insert_one(b1.view());\n\n        auto b2 = make_document(kvp(\"x\", 2));\n\n        coll.insert_one(b2.view());\n        coll.insert_one(b2.view());\n\n        REQUIRE(coll.count_documents({}) == 3);\n\n        coll.delete_many(b2.view());\n\n        REQUIRE(coll.count_documents({}) == 1);\n\n        auto cursor = coll.find({});\n\n        std::int32_t seen = 0;\n        for (auto&& x : cursor) {\n            seen |= x[\"x\"].get_int32();\n        }\n\n        REQUIRE(seen == 1);\n\n        coll.delete_many(b2.view());\n\n        REQUIRE(coll.count_documents({}) == 1);\n\n        cursor = coll.find({});\n\n        seen = 0;\n        for (auto&& x : cursor) {\n            seen |= x[\"x\"].get_int32();\n        }\n\n        REQUIRE(seen == 1);\n    }\n\n    SECTION(\"delete_many returns correct result object\", \"[collection]\") {\n        auto b1 = make_document(kvp(\"x\", 1));\n\n        SECTION(\"default write concern returns result\") {\n            collection coll = db[\"delete_many_default_write\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n            coll.insert_one(b1.view());\n            coll.insert_one(b1.view());\n\n            auto result = coll.delete_many(b1.view());\n            REQUIRE(result);\n            REQUIRE(result->result().deleted_count() > 1);\n        }\n\n        SECTION(\"unacknowledged write concern returns disengaged optional\") {\n            if (test_util::get_max_wire_version(mongodb_client) > 13) {\n                WARN(\"Skipping - getLastError removed in SERVER-57390\");\n                return;\n            }\n            collection coll = db[\"delete_many_unack_write\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n            coll.insert_one(b1.view());\n            coll.insert_one(b1.view());\n            options::delete_options opts{};\n            opts.write_concern(noack);\n\n            auto result = coll.delete_many(b1.view(), opts);\n            REQUIRE(!result);\n\n            // Block until server has received the write request, to prevent\n            // this unacknowledged write from racing with writes to this\n            // collection from other sections.\n            db.run_command(make_document(kvp(\"getLastError\", 1)));\n        }\n    }\n\n    SECTION(\"delete_many with collation\", \"[collection]\") {\n        collection coll = db[\"delete_many_with_collation\"];\n        coll.drop();\n        auto b1 = make_document(kvp(\"x\", \"foo\"));\n\n        REQUIRE(coll.insert_one(b1.view()));\n\n        auto predicate = make_document(kvp(\"x\", \"FOO\"));\n\n        auto delete_opts = options::delete_options{}.collation(case_insensitive_collation.view());\n        if (test_util::supports_collation(mongodb_client)) {\n            INFO(\"unacknowledged write concern fails\");\n            delete_opts.write_concern(noack);\n            REQUIRE_THROWS_AS(coll.delete_many(predicate.view(), delete_opts), operation_exception);\n\n            INFO(\"default write concern succeeds\");\n            delete_opts.write_concern(default_wc);\n            auto result = coll.delete_many(predicate.view(), delete_opts);\n            REQUIRE(result);\n            REQUIRE(result->deleted_count() == 1);\n        } else {\n            REQUIRE_THROWS_AS(coll.delete_many(predicate.view(), delete_opts),\n                              bulk_write_exception);\n        }\n    }\n\n    SECTION(\"find works with sort\", \"[collection]\") {\n        collection coll = db[\"find_with_sort\"];\n        coll.drop();\n\n        auto b1 = make_document(kvp(\"x\", 1));\n        auto b2 = make_document(kvp(\"x\", 2));\n        auto b3 = make_document(kvp(\"x\", 3));\n\n        coll.insert_one(b1.view());\n        coll.insert_one(b3.view());\n        coll.insert_one(b2.view());\n\n        SECTION(\"sort ascending\") {\n            auto sort = make_document(kvp(\"x\", 1));\n            options::find opts{};\n            opts.sort(sort.view());\n\n            auto cursor = coll.find({}, opts);\n\n            std::int32_t x = 1;\n            for (auto&& doc : cursor) {\n                REQUIRE(x == doc[\"x\"].get_int32());\n                x++;\n            }\n        }\n\n        SECTION(\"sort descending\") {\n            auto sort = make_document(kvp(\"x\", -1));\n            options::find opts{};\n            opts.sort(sort.view());\n\n            auto cursor = coll.find({}, opts);\n\n            std::int32_t x = 3;\n            for (auto&& doc : cursor) {\n                REQUIRE(x == doc[\"x\"].get_int32());\n                x--;\n            }\n        }\n    }\n\n    SECTION(\"find_one_and_replace works\", \"[collection]\") {\n        auto b1 = make_document(kvp(\"x\", \"foo\"));\n\n        auto criteria = make_document(kvp(\"x\", \"foo\"));\n        auto replacement = make_document(kvp(\"x\", \"bar\"));\n\n        SECTION(\"without return replacement returns original\") {\n            collection coll = db[\"find_one_and_replace_no_return\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n            coll.insert_one(b1.view());\n\n            REQUIRE(coll.count_documents({}) == 2);\n\n            auto doc = coll.find_one_and_replace(criteria.view(), replacement.view());\n            REQUIRE(doc);\n            REQUIRE(doc->view()[\"x\"].get_string().value == stdx::string_view{\"foo\"});\n        }\n\n        SECTION(\"with return replacement returns new\") {\n            collection coll = db[\"find_one_and_replace_return\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n            coll.insert_one(b1.view());\n\n            REQUIRE(coll.count_documents({}) == 2);\n\n            options::find_one_and_replace options;\n            options.return_document(options::return_document::k_after);\n            auto doc = coll.find_one_and_replace(criteria.view(), replacement.view(), options);\n            REQUIRE(doc);\n            REQUIRE(doc->view()[\"x\"].get_string().value == stdx::string_view{\"bar\"});\n        }\n\n        SECTION(\"with collation\") {\n            collection coll = db[\"find_one_and_replace_with_collation\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n            coll.insert_one(b1.view());\n\n            REQUIRE(coll.count_documents({}) == 2);\n\n            options::find_one_and_replace options;\n            options.collation(case_insensitive_collation.view());\n\n            auto collation_criteria = make_document(kvp(\"x\", \"FOO\"));\n\n            if (test_util::supports_collation(mongodb_client)) {\n                INFO(\"unacknowledged write concern fails\");\n                options.write_concern(noack);\n                REQUIRE_THROWS_AS(coll.find_one_and_replace(\n                                      collation_criteria.view(), replacement.view(), options),\n                                  logic_error);\n\n                INFO(\"default write concern succeeds\");\n                options.write_concern(default_wc);\n                auto doc = coll.find_one_and_replace(\n                    collation_criteria.view(), replacement.view(), options);\n                REQUIRE(doc);\n                REQUIRE(doc->view()[\"x\"].get_string().value == stdx::string_view{\"foo\"});\n            } else {\n                REQUIRE_THROWS_AS(coll.find_one_and_replace(\n                                      collation_criteria.view(), replacement.view(), options),\n                                  write_exception);\n            }\n        }\n\n        SECTION(\"bad criteria returns negative optional\") {\n            collection coll = db[\"find_one_and_replace_bad_criteria\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n            coll.insert_one(b1.view());\n\n            REQUIRE(coll.count_documents({}) == 2);\n\n            auto bad_criteria = make_document(kvp(\"x\", \"baz\"));\n\n            auto doc = coll.find_one_and_replace(bad_criteria.view(), replacement.view());\n\n            REQUIRE(!doc);\n        }\n\n        SECTION(\"bypass_document_validation ignores validation_criteria\", \"[collection]\") {\n            std::string collname = \"find_one_and_replace_bypass_document_validation\";\n            db[collname].drop();\n            collection coll = db.create_collection(\n                collname,\n                make_document(\n                    kvp(\"validator\", make_document(kvp(\"x\", make_document(kvp(\"$eq\", \"foo\")))))));\n\n            coll.insert_one(b1.view());\n\n            options::find_one_and_replace options;\n            options.return_document(options::return_document::k_after);\n            options.bypass_document_validation(true);\n\n            stdx::optional<bsoncxx::document::value> doc;\n            REQUIRE_NOTHROW(\n                doc = coll.find_one_and_replace(criteria.view(), replacement.view(), options));\n            REQUIRE(doc);\n            REQUIRE(doc->view()[\"x\"].get_string().value == stdx::string_view{\"bar\"});\n        }\n    }\n\n    SECTION(\"find_one_and_update works\", \"[collection]\") {\n        auto b1 = make_document(kvp(\"x\", \"foo\"));\n        auto criteria = make_document(kvp(\"x\", \"foo\"));\n        auto update = make_document(kvp(\"$set\", make_document(kvp(\"x\", \"bar\"))));\n\n        SECTION(\"without return update returns original\") {\n            collection coll = db[\"find_one_and_update_no_return\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n            coll.insert_one(b1.view());\n\n            REQUIRE(coll.count_documents({}) == 2);\n\n            auto doc = coll.find_one_and_update(criteria.view(), update.view());\n\n            REQUIRE(doc);\n\n            REQUIRE(doc->view()[\"x\"].get_string().value == stdx::string_view{\"foo\"});\n        }\n\n        SECTION(\"with return update returns new\") {\n            collection coll = db[\"find_one_and_update_return\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n            coll.insert_one(b1.view());\n\n            REQUIRE(coll.count_documents({}) == 2);\n\n            options::find_one_and_update options;\n            options.return_document(options::return_document::k_after);\n            auto doc = coll.find_one_and_update(criteria.view(), update.view(), options);\n            REQUIRE(doc);\n            REQUIRE(doc->view()[\"x\"].get_string().value == stdx::string_view{\"bar\"});\n        }\n\n        SECTION(\"with collation\") {\n            collection coll = db[\"find_one_and_update_with collation\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n            coll.insert_one(b1.view());\n\n            REQUIRE(coll.count_documents({}) == 2);\n\n            options::find_one_and_update options;\n            options.collation(case_insensitive_collation.view());\n\n            auto collation_criteria = make_document(kvp(\"x\", \"FOO\"));\n\n            if (test_util::supports_collation(mongodb_client)) {\n                INFO(\"unacknowledged write concern fails\");\n                options.write_concern(noack);\n                REQUIRE_THROWS_AS(\n                    coll.find_one_and_update(collation_criteria.view(), update.view(), options),\n                    logic_error);\n\n                INFO(\"default write concern succeeds\");\n                options.write_concern(default_wc);\n                auto doc =\n                    coll.find_one_and_update(collation_criteria.view(), update.view(), options);\n                REQUIRE(doc);\n                REQUIRE(doc->view()[\"x\"].get_string().value == stdx::string_view{\"foo\"});\n\n            } else {\n                REQUIRE_THROWS_AS(\n                    coll.find_one_and_update(collation_criteria.view(), update.view(), options),\n                    write_exception);\n            }\n        }\n\n        SECTION(\"bad criteria returns negative optional\") {\n            collection coll = db[\"find_one_and_update_bad_criteria\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n            coll.insert_one(b1.view());\n\n            REQUIRE(coll.count_documents({}) == 2);\n\n            auto bad_criteria = make_document(kvp(\"x\", \"baz\"));\n\n            auto doc = coll.find_one_and_update(bad_criteria.view(), update.view());\n\n            REQUIRE(!doc);\n        }\n\n        SECTION(\"bypass_document_validation ignores validation_criteria\", \"[collection]\") {\n            std::string collname = \"find_one_and_update_bypass_document_validation\";\n            db[collname].drop();\n            collection coll = db.create_collection(\n                collname,\n                make_document(\n                    kvp(\"validator\", make_document(kvp(\"x\", make_document(kvp(\"$eq\", \"foo\")))))));\n\n            coll.insert_one(b1.view());\n\n            options::find_one_and_update options;\n            options.return_document(options::return_document::k_after);\n            options.bypass_document_validation(true);\n\n            stdx::optional<bsoncxx::document::value> doc;\n            REQUIRE_NOTHROW(doc =\n                                coll.find_one_and_update(criteria.view(), update.view(), options));\n            REQUIRE(doc);\n            REQUIRE(doc->view()[\"x\"].get_string().value == stdx::string_view{\"bar\"});\n        }\n    }\n\n    SECTION(\"find_one_and_delete works\", \"[collection]\") {\n        auto b1 = make_document(kvp(\"x\", \"foo\"));\n        auto criteria = make_document(kvp(\"x\", \"foo\"));\n\n        SECTION(\"delete one deletes one and returns it\") {\n            collection coll = db[\"find_one_and_delete_one\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n            coll.insert_one(b1.view());\n\n            REQUIRE(coll.count_documents({}) == 2);\n\n            auto doc = coll.find_one_and_delete(criteria.view());\n\n            REQUIRE(doc);\n\n            REQUIRE(doc->view()[\"x\"].get_string().value == stdx::string_view{\"foo\"});\n            REQUIRE(coll.count_documents({}) == 1);\n        }\n\n        SECTION(\"with collation\") {\n            collection coll = db[\"find_one_and_delete_with_collation\"];\n            coll.drop();\n\n            coll.insert_one(b1.view());\n            coll.insert_one(b1.view());\n\n            REQUIRE(coll.count_documents({}) == 2);\n\n            options::find_one_and_delete options;\n            options.collation(case_insensitive_collation.view());\n\n            auto collation_criteria = make_document(kvp(\"x\", \"FOO\"));\n\n            if (test_util::supports_collation(mongodb_client)) {\n                INFO(\"unacknowledged write concern fails\");\n                options.write_concern(noack);\n                REQUIRE_THROWS_AS(coll.find_one_and_delete(collation_criteria.view(), options),\n                                  logic_error);\n\n                INFO(\"default write concern succeeds\");\n                options.write_concern(default_wc);\n                auto doc = coll.find_one_and_delete(collation_criteria.view(), options);\n                REQUIRE(doc);\n                REQUIRE(doc->view()[\"x\"].get_string().value == stdx::string_view{\"foo\"});\n\n            } else {\n                REQUIRE_THROWS_AS(coll.find_one_and_delete(collation_criteria.view(), options),\n                                  write_exception);\n            }\n        }\n    }\n\n    SECTION(\"aggregation\", \"[collection]\") {\n        pipeline pipeline;\n\n        auto get_results = [](cursor&& cursor) {\n            std::vector<bsoncxx::document::value> results;\n            std::transform(cursor.begin(),\n                           cursor.end(),\n                           std::back_inserter(results),\n                           [](bsoncxx::document::view v) { return bsoncxx::document::value{v}; });\n            return results;\n        };\n\n        SECTION(\"add_fields\") {\n            collection coll = db[\"aggregation_add_fields\"];\n            coll.drop();\n\n            coll.insert_one({});\n\n            pipeline.add_fields(make_document(kvp(\"x\", 1)));\n            auto cursor = coll.aggregate(pipeline);\n\n            if (test_util::get_max_wire_version(mongodb_client) >= 5) {\n                // The server supports add_fields().\n                auto results = get_results(std::move(cursor));\n                REQUIRE(results.size() == 1);\n                REQUIRE(results[0].view()[\"x\"].get_int32() == 1);\n            } else {\n                // The server does not support add_fields().\n                REQUIRE_THROWS_AS(get_results(std::move(cursor)), operation_exception);\n            }\n        }\n\n        SECTION(\"bucket\") {\n            collection coll = db[\"aggregation_bucket\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"x\", 1)));\n            coll.insert_one(make_document(kvp(\"x\", 3)));\n            coll.insert_one(make_document(kvp(\"x\", 5)));\n\n            pipeline.bucket(\n                make_document(kvp(\"groupBy\", \"$x\"), kvp(\"boundaries\", make_array(0, 2, 6))));\n            auto cursor = coll.aggregate(pipeline);\n\n            if (test_util::get_max_wire_version(mongodb_client) >= 5) {\n                // The server supports bucket().\n                auto results = get_results(std::move(cursor));\n                REQUIRE(results.size() == 2);\n\n                REQUIRE(results[0].view()[\"_id\"].get_int32() == 0);\n                REQUIRE(results[0].view()[\"count\"].get_int32() == 1);\n\n                REQUIRE(results[1].view()[\"_id\"].get_int32() == 2);\n                REQUIRE(results[1].view()[\"count\"].get_int32() == 2);\n            } else {\n                // The server does not support bucket().\n                REQUIRE_THROWS_AS(get_results(std::move(cursor)), operation_exception);\n            }\n        }\n\n        SECTION(\"bucket_auto\") {\n            collection coll = db[\"aggregation_bucket_auto\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"x\", 1)));\n            coll.insert_one(make_document(kvp(\"x\", 3)));\n            coll.insert_one(make_document(kvp(\"x\", 5)));\n\n            pipeline.bucket_auto(make_document(kvp(\"groupBy\", \"$x\"), kvp(\"buckets\", 2)));\n            auto cursor = coll.aggregate(pipeline);\n\n            if (test_util::get_max_wire_version(mongodb_client) >= 5) {\n                // The server supports bucket_auto().\n\n                auto results = get_results(std::move(cursor));\n                REQUIRE(results.size() == 2);\n                // We check that the \"count\" field exists here, but we don't assert the exact count,\n                // since the server doesn't guarantee what the exact boundaries (and thus the exact\n                // counts) will be.\n                REQUIRE(results[0].view()[\"count\"]);\n                REQUIRE(results[1].view()[\"count\"]);\n            } else {\n                // The server does not support bucket_auto().\n                REQUIRE_THROWS_AS(get_results(std::move(cursor)), operation_exception);\n            }\n        }\n\n        SECTION(\"coll_stats\") {\n            collection coll = db[\"aggregation_coll_stats\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"x\", 1)));\n\n            pipeline.coll_stats(make_document(kvp(\"latencyStats\", make_document())));\n            auto cursor = coll.aggregate(pipeline);\n\n            if (test_util::get_max_wire_version(mongodb_client) >= 5) {\n                // The server supports coll_stats().\n                auto results = get_results(std::move(cursor));\n                REQUIRE(results.size() == 1);\n                REQUIRE(results[0].view()[\"ns\"]);\n                REQUIRE(results[0].view()[\"latencyStats\"]);\n            } else {\n                // The server does not support coll_stats().\n                REQUIRE_THROWS_AS(get_results(std::move(cursor)), operation_exception);\n            }\n        }\n\n        SECTION(\"count\") {\n            collection coll = db[\"aggregation_count\"];\n            coll.drop();\n\n            coll.insert_one({});\n            coll.insert_one({});\n            coll.insert_one({});\n\n            pipeline.count(\"foo\");\n            auto cursor = coll.aggregate(pipeline);\n\n            if (test_util::get_max_wire_version(mongodb_client) >= 5) {\n                // The server supports count().\n                auto results = get_results(std::move(cursor));\n                REQUIRE(results.size() == 1);\n                REQUIRE(results[0].view()[\"foo\"].get_int32() == 3);\n            } else {\n                // The server does not support count().\n                REQUIRE_THROWS_AS(get_results(std::move(cursor)), operation_exception);\n            }\n        }\n\n        SECTION(\"facet\") {\n            collection coll = db[\"aggregation_facet\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"x\", 1)));\n            coll.insert_one(make_document(kvp(\"x\", 2)));\n            coll.insert_one(make_document(kvp(\"x\", 3)));\n\n            pipeline.facet(make_document(kvp(\"foo\", make_array(make_document(kvp(\"$limit\", 2))))));\n            auto cursor = coll.aggregate(pipeline);\n\n            if (test_util::get_max_wire_version(mongodb_client) >= 5) {\n                // The server supports facet().\n                auto results = get_results(std::move(cursor));\n                REQUIRE(results.size() == 1);\n                auto foo_array = results[0].view()[\"foo\"].get_array().value;\n                REQUIRE(std::distance(foo_array.begin(), foo_array.end()) == 2);\n            } else {\n                // The server does not support facet().\n                REQUIRE_THROWS_AS(get_results(std::move(cursor)), operation_exception);\n            }\n        }\n\n        SECTION(\"geo_near\") {\n            collection coll = db[\"aggregation_geo_near\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"_id\", 0), kvp(\"x\", make_array(0, 0))));\n            coll.insert_one(make_document(kvp(\"_id\", 1), kvp(\"x\", make_array(1, 1))));\n            coll.create_index(make_document(kvp(\"x\", \"2d\")));\n\n            pipeline.geo_near(\n                make_document(kvp(\"near\", make_array(0, 0)), kvp(\"distanceField\", \"d\")));\n            auto cursor = coll.aggregate(pipeline);\n\n            auto results = get_results(std::move(cursor));\n            REQUIRE(results.size() == 2);\n            REQUIRE(results[0].view()[\"d\"]);\n            REQUIRE(results[0].view()[\"_id\"].get_int32() == 0);\n            REQUIRE(results[1].view()[\"d\"]);\n            REQUIRE(results[1].view()[\"_id\"].get_int32() == 1);\n        }\n\n        SECTION(\"graph_lookup\") {\n            collection coll = db[\"aggregation_graph_lookup\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"x\", \"bar\")));\n            coll.insert_one(make_document(kvp(\"x\", \"foo\"), kvp(\"y\", \"bar\")));\n\n            pipeline.graph_lookup(make_document(kvp(\"from\", coll.name()),\n                                                kvp(\"startWith\", \"$y\"),\n                                                kvp(\"connectFromField\", \"y\"),\n                                                kvp(\"connectToField\", \"x\"),\n                                                kvp(\"as\", \"z\")));\n            // Add a sort to the pipeline, so below tests can make assumptions about result order.\n            pipeline.sort(make_document(kvp(\"x\", 1)));\n            auto cursor = coll.aggregate(pipeline);\n\n            if (test_util::get_max_wire_version(mongodb_client) >= 5) {\n                // The server supports graph_lookup().\n                auto results = get_results(std::move(cursor));\n                REQUIRE(results.size() == 2);\n                REQUIRE(results[0].view()[\"z\"].get_array().value.empty());\n                REQUIRE(!results[1].view()[\"z\"].get_array().value.empty());\n            } else {\n                // The server does not support graph_lookup().\n                REQUIRE_THROWS_AS(get_results(std::move(cursor)), operation_exception);\n            }\n        }\n\n        SECTION(\"group\") {\n            collection coll = db[\"aggregation_group\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"x\", 1)));\n            coll.insert_one(make_document(kvp(\"x\", 1)));\n            coll.insert_one(make_document(kvp(\"x\", 2)));\n\n            pipeline.group(make_document(kvp(\"_id\", \"$x\")));\n            // Add a sort to the pipeline, so below tests can make assumptions about result order.\n            pipeline.sort(make_document(kvp(\"_id\", 1)));\n            auto cursor = coll.aggregate(pipeline);\n\n            auto results = get_results(std::move(cursor));\n            REQUIRE(results.size() == 2);\n            REQUIRE(results[0].view()[\"_id\"].get_int32() == 1);\n            REQUIRE(results[1].view()[\"_id\"].get_int32() == 2);\n        }\n\n        SECTION(\"index_stats\") {\n            collection coll = db[\"aggregation_index_stats\"];\n            coll.drop();\n\n            coll.create_index(make_document(kvp(\"a\", 1)));\n            coll.create_index(make_document(kvp(\"b\", 1)));\n            coll.create_index(make_document(kvp(\"c\", 1)));\n\n            pipeline.index_stats();\n            auto cursor = coll.aggregate(pipeline);\n\n            if (test_util::get_max_wire_version(mongodb_client) >= 4) {\n                // The server supports index_stats().\n                auto results = get_results(std::move(cursor));\n                REQUIRE(results.size() == 4);\n            } else {\n                // The server does not support index_stats().\n                REQUIRE_THROWS_AS(get_results(std::move(cursor)), operation_exception);\n            }\n        }\n\n        SECTION(\"limit\") {\n            collection coll = db[\"aggregation_limit\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"x\", 1)));\n            coll.insert_one(make_document(kvp(\"x\", 2)));\n            coll.insert_one(make_document(kvp(\"x\", 3)));\n\n            // Add a sort to the pipeline, so below tests can make assumptions about result order.\n            pipeline.sort(make_document(kvp(\"x\", 1)));\n            pipeline.limit(2);\n            auto cursor = coll.aggregate(pipeline);\n\n            auto results = get_results(std::move(cursor));\n            REQUIRE(results.size() == 2);\n            REQUIRE(results[0].view()[\"x\"].get_int32() == 1);\n            REQUIRE(results[1].view()[\"x\"].get_int32() == 2);\n        }\n\n        SECTION(\"lookup\") {\n            collection coll = db[\"aggregation_lookup\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"x\", 0)));\n            coll.insert_one(make_document(kvp(\"x\", 1), kvp(\"y\", 0)));\n\n            pipeline.lookup(make_document(kvp(\"from\", coll.name()),\n                                          kvp(\"localField\", \"x\"),\n                                          kvp(\"foreignField\", \"y\"),\n                                          kvp(\"as\", \"z\")));\n            // Add a sort to the pipeline, so below tests can make assumptions about result order.\n            pipeline.sort(make_document(kvp(\"x\", 1)));\n            auto cursor = coll.aggregate(pipeline);\n\n            if (test_util::get_max_wire_version(mongodb_client) >= 4) {\n                // The server supports lookup().\n                auto results = get_results(std::move(cursor));\n                REQUIRE(results.size() == 2);\n                REQUIRE(!results[0].view()[\"z\"].get_array().value.empty());\n                REQUIRE(results[1].view()[\"z\"].get_array().value.empty());\n            } else {\n                // The server does not support lookup().\n                REQUIRE_THROWS_AS(get_results(std::move(cursor)), operation_exception);\n            }\n        }\n\n        SECTION(\"match\") {\n            collection coll = db[\"aggregation_match\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"x\", 1)));\n            coll.insert_one(make_document(kvp(\"x\", 1)));\n            coll.insert_one(make_document(kvp(\"x\", 2)));\n\n            pipeline.match(make_document(kvp(\"x\", 1)));\n            auto cursor = coll.aggregate(pipeline);\n\n            auto results = get_results(std::move(cursor));\n            REQUIRE(results.size() == 2);\n        }\n\n        SECTION(\"merge\") {\n            auto merge_version = \"4.1.11\";\n            auto server_version = test_util::get_server_version(mongodb_client);\n            if (test_util::compare_versions(server_version, merge_version) < 0) {\n                // The server does not support $merge.\n                return;\n            }\n\n            collection coll = db[\"aggregation_merge\"];\n            collection coll_out = db[\"aggregation_merge_out\"];\n            coll.drop();\n            coll_out.drop();\n\n            coll.insert_one(make_document(kvp(\"a\", 1)));\n\n            pipeline.match(make_document(kvp(\"a\", 1)));\n            pipeline.merge(make_document(kvp(\"into\", \"aggregation_merge_out\")));\n\n            auto cursor = coll.aggregate(pipeline);\n\n            auto results = get_results(std::move(cursor));\n            REQUIRE(results.empty());\n\n            auto doc = coll_out.find_one({});\n            REQUIRE(doc);\n        }\n\n        SECTION(\"out\") {\n            collection coll = db[\"aggregation_out\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"x\", 1), kvp(\"y\", 1)));\n\n            pipeline.project(make_document(kvp(\"x\", 1)));\n            pipeline.out(bsoncxx::string::to_string(coll.name()));\n            auto cursor = coll.aggregate(pipeline);\n\n            // The server supports out().\n            auto results = get_results(std::move(cursor));\n            REQUIRE(results.empty());\n\n            auto collection_contents = get_results(coll.find({}));\n            REQUIRE(collection_contents.size() == 1);\n            REQUIRE(collection_contents[0].view()[\"x\"].get_int32() == 1);\n            REQUIRE(!collection_contents[0].view()[\"y\"]);\n        }\n\n        SECTION(\"out with bypass_document_validation\", \"[collection]\") {\n            collection coll_in = db[\"aggregation_out_bypass_document_validation_in\"];\n            coll_in.drop();\n            coll_in.insert_one(make_document(kvp(\"x\", 1), kvp(\"y\", 1)));\n\n            std::string collname = \"aggregation_out_bypass_document_validation_out\";\n            db[collname].drop();\n            collection coll_out = db.create_collection(\n                collname,\n                make_document(\n                    kvp(\"validator\", make_document(kvp(\"x\", make_document(kvp(\"$eq\", 2)))))));\n\n            options::aggregate options;\n            options.bypass_document_validation(true);\n\n            pipeline.project(make_document(kvp(\"x\", 1)));\n            pipeline.out(bsoncxx::string::to_string(coll_out.name()));\n            stdx::optional<cursor> cursor;\n            REQUIRE_NOTHROW(cursor = coll_in.aggregate(pipeline, options));\n\n            if (test_util::get_max_wire_version(mongodb_client) >= 1) {\n                // The server supports out().\n                auto results = get_results(std::move(*cursor));\n                REQUIRE(results.empty());\n\n                auto collection_contents = get_results(coll_out.find({}));\n                REQUIRE(collection_contents.size() == 1);\n                REQUIRE(collection_contents[0].view()[\"x\"].get_int32() == 1);\n                REQUIRE(!collection_contents[0].view()[\"y\"]);\n            } else {\n                // The server does not support out().\n                REQUIRE_THROWS_AS(get_results(std::move(*cursor)), operation_exception);\n            }\n        }\n\n        SECTION(\"out fails when not last\") {\n            collection coll = db[\"aggregation_out_fails\"];\n            coll.insert_one(make_document(kvp(\"x\", 1)));\n\n            pipeline.project(make_document(kvp(\"x\", 1)));\n            pipeline.out(\"aggregation_out_fails\");\n            pipeline.sample(1);\n\n            auto cursor = coll.aggregate(pipeline);\n            REQUIRE_THROWS_AS(get_results(std::move(cursor)), operation_exception);\n        }\n\n        SECTION(\"project\") {\n            collection coll = db[\"aggregation_project\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"x\", 1), kvp(\"y\", 1)));\n\n            pipeline.project(make_document(kvp(\"x\", 1)));\n            auto cursor = coll.aggregate(pipeline);\n\n            auto results = get_results(std::move(cursor));\n            REQUIRE(results.size() == 1);\n            REQUIRE(results[0].view()[\"x\"].get_int32() == 1);\n            REQUIRE(!results[0].view()[\"y\"]);\n        }\n\n        SECTION(\"redact\") {\n            collection coll = db[\"aggregation_redact\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"x\", make_document(kvp(\"secret\", 1))), kvp(\"y\", 1)));\n\n            pipeline.redact(make_document(\n                kvp(\"$cond\",\n                    make_document(kvp(\"if\", make_document(kvp(\"$eq\", make_array(\"$secret\", 1)))),\n                                  kvp(\"then\", \"$$PRUNE\"),\n                                  kvp(\"else\", \"$$DESCEND\")))));\n            auto cursor = coll.aggregate(pipeline);\n\n            // The server supports redact().\n            auto results = get_results(std::move(cursor));\n            REQUIRE(results.size() == 1);\n            REQUIRE(!results[0].view()[\"x\"]);\n            REQUIRE(results[0].view()[\"y\"].get_int32() == 1);\n        }\n\n        SECTION(\"replace_root\") {\n            collection coll = db[\"aggregation_replace_root\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"x\", make_document(kvp(\"y\", 1)))));\n\n            pipeline.replace_root(make_document(kvp(\"newRoot\", \"$x\")));\n            auto cursor = coll.aggregate(pipeline);\n\n            if (test_util::get_max_wire_version(mongodb_client) >= 5) {\n                // The server supports replace_root().\n                auto results = get_results(std::move(cursor));\n                REQUIRE(results.size() == 1);\n                REQUIRE(results[0].view()[\"y\"]);\n            } else {\n                // The server does not support replace_root().\n                REQUIRE_THROWS_AS(get_results(std::move(cursor)), operation_exception);\n            }\n        }\n\n        SECTION(\"sample\") {\n            collection coll = db[\"aggregation_sample\"];\n            coll.drop();\n\n            coll.insert_one({});\n            coll.insert_one({});\n            coll.insert_one({});\n            coll.insert_one({});\n\n            pipeline.sample(3);\n            auto cursor = coll.aggregate(pipeline);\n\n            if (test_util::get_max_wire_version(mongodb_client) >= 4) {\n                // The server supports sample().\n                auto results = get_results(std::move(cursor));\n                REQUIRE(results.size() == 3);\n            } else {\n                // The server does not support sample().\n                REQUIRE_THROWS_AS(get_results(std::move(cursor)), operation_exception);\n            }\n        }\n\n        SECTION(\"skip\") {\n            collection coll = db[\"aggregation_skip\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"x\", 1)));\n            coll.insert_one(make_document(kvp(\"x\", 2)));\n            coll.insert_one(make_document(kvp(\"x\", 3)));\n\n            // Add a sort to the pipeline, so below tests can make assumptions about result order.\n            pipeline.sort(make_document(kvp(\"x\", 1)));\n            pipeline.skip(1);\n            auto cursor = coll.aggregate(pipeline);\n\n            auto results = get_results(std::move(cursor));\n            REQUIRE(results.size() == 2);\n            REQUIRE(results[0].view()[\"x\"].get_int32() == 2);\n            REQUIRE(results[1].view()[\"x\"].get_int32() == 3);\n        }\n\n        SECTION(\"sort\") {\n            collection coll = db[\"aggregation_sort\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"x\", 1)));\n            coll.insert_one(make_document(kvp(\"x\", 2)));\n            coll.insert_one(make_document(kvp(\"x\", 3)));\n\n            pipeline.sort(make_document(kvp(\"x\", -1)));\n            auto cursor = coll.aggregate(pipeline);\n\n            auto results = get_results(std::move(cursor));\n            REQUIRE(results.size() == 3);\n            REQUIRE(results[0].view()[\"x\"].get_int32() == 3);\n            REQUIRE(results[1].view()[\"x\"].get_int32() == 2);\n            REQUIRE(results[2].view()[\"x\"].get_int32() == 1);\n        }\n\n        SECTION(\"sort_by_count\") {\n            std::vector<bsoncxx::document::value> inserts{\n                make_document(kvp(\"x\", 1)), make_document(kvp(\"x\", 2)), make_document(kvp(\"x\", 2))};\n\n            SECTION(\"with string\") {\n                collection coll = db[\"aggregation_sort_by_count_with_string\"];\n                coll.drop();\n\n                coll.insert_many(inserts, options::insert{});\n\n                pipeline.sort_by_count(\"$x\");\n                auto cursor = coll.aggregate(pipeline);\n\n                if (test_util::get_max_wire_version(mongodb_client) >= 5) {\n                    // The server supports sort_by_count().\n                    auto results = get_results(std::move(cursor));\n                    REQUIRE(results.size() == 2);\n                    REQUIRE(results[0].view()[\"_id\"].get_int32() == 2);\n                    REQUIRE(results[1].view()[\"_id\"].get_int32() == 1);\n                } else {\n                    // The server does not support sort_by_count().\n                    REQUIRE_THROWS_AS(get_results(std::move(cursor)), operation_exception);\n                }\n            }\n\n            SECTION(\"with document\") {\n                collection coll = db[\"aggregation_sort_by_count_with_document\"];\n                coll.drop();\n\n                coll.insert_many(inserts, options::insert{});\n\n                pipeline.sort_by_count(make_document(kvp(\"$mod\", make_array(\"$x\", 2))));\n                auto cursor = coll.aggregate(pipeline);\n\n                if (test_util::get_max_wire_version(mongodb_client) >= 5) {\n                    // The server supports sort_by_count().\n                    auto results = get_results(std::move(cursor));\n                    REQUIRE(results.size() == 2);\n                    REQUIRE(results[0].view()[\"_id\"].get_int32() == 0);\n                    REQUIRE(results[1].view()[\"_id\"].get_int32() == 1);\n                } else {\n                    // The server does not support sort_by_count().\n                    REQUIRE_THROWS_AS(get_results(std::move(cursor)), operation_exception);\n                }\n            }\n        }\n\n        SECTION(\"unwind with string\") {\n            collection coll = db[\"aggregation_unwind_with_string\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"x\", make_array(1, 2, 3, 4, 5))));\n            pipeline.unwind(\"$x\");\n            auto cursor = coll.aggregate(pipeline);\n\n            auto results = get_results(std::move(cursor));\n            REQUIRE(results.size() == 5);\n        }\n\n        SECTION(\"unwind with document\") {\n            collection coll = db[\"aggregation_unwind_with_doc\"];\n            coll.drop();\n\n            coll.insert_one(make_document(kvp(\"x\", make_array(1, 2, 3, 4, 5))));\n\n            pipeline.unwind(make_document(kvp(\"path\", \"$x\")));\n            auto cursor = coll.aggregate(pipeline);\n\n            if (test_util::get_max_wire_version(mongodb_client) >= 4) {\n                // The server supports unwind() with a document.\n                auto results = get_results(std::move(cursor));\n                REQUIRE(results.size() == 5);\n            } else {\n                // The server does not support unwind() with a document.\n                REQUIRE_THROWS_AS(get_results(std::move(cursor)), operation_exception);\n            }\n        }\n    }\n\n    SECTION(\"aggregation with collation\", \"[collection]\") {\n        collection coll = db[\"aggregation_with_collation\"];\n        coll.drop();\n\n        auto b1 = make_document(kvp(\"x\", \"foo\"));\n\n        coll.insert_one(b1.view());\n\n        auto predicate = make_document(kvp(\"x\", \"FOO\"));\n\n        pipeline p;\n        p.match(predicate.view());\n\n        auto agg_opts = options::aggregate{}.collation(case_insensitive_collation.view());\n        auto results = coll.aggregate(p, agg_opts);\n\n        if (test_util::supports_collation(mongodb_client)) {\n            REQUIRE(std::distance(results.begin(), results.end()) == 1);\n        } else {\n            // The server does not support collation.\n            REQUIRE_THROWS_AS(std::distance(results.begin(), results.end()), operation_exception);\n        }\n    }\n\n    SECTION(\"bulk_write returns correct result object\") {\n        auto doc1 = make_document(kvp(\"foo\", 1));\n        auto doc2 = make_document(kvp(\"foo\", 2));\n\n        options::bulk_write bulk_opts;\n        bulk_opts.ordered(false);\n\n        SECTION(\"default write concern returns result\") {\n            collection coll = db[\"bulk_write_default_write\"];\n            coll.drop();\n\n            auto abulk = coll.create_bulk_write(bulk_opts);\n            abulk.append(model::insert_one{std::move(doc1)});\n            abulk.append(model::insert_one{std::move(doc2)});\n            auto result = abulk.execute();\n\n            REQUIRE(result);\n            REQUIRE(result->inserted_count() == 2);\n        }\n\n        SECTION(\"unacknowledged write concern returns disengaged optional\", \"[collection]\") {\n            if (test_util::get_max_wire_version(mongodb_client) > 13) {\n                WARN(\"Skipping - getLastError removed in SERVER-57390\");\n                return;\n            }\n            collection coll = db[\"bulk_write_unack_write\"];\n            coll.drop();\n\n            bulk_opts.write_concern(noack);\n            auto bbulk = coll.create_bulk_write(bulk_opts);\n            bbulk.append(model::insert_one{std::move(doc1)});\n            bbulk.append(model::insert_one{std::move(doc2)});\n            auto result = bbulk.execute();\n\n            REQUIRE(!result);\n\n            // Block until server has received the write request, to prevent\n            // this unacknowledged write from racing with writes to this\n            // collection from other sections.\n            db.run_command(make_document(kvp(\"getLastError\", 1)));\n        }\n\n        SECTION(\"write wrapper returns correct result\") {\n            collection coll = db[\"bulk_write_write_wrapper\"];\n            coll.drop();\n\n            auto doc3 = make_document(kvp(\"foo\", 3));\n            auto result = coll.write(model::insert_one{std::move(doc3)});\n            REQUIRE(result);\n            REQUIRE(result->inserted_count() == 1);\n        }\n\n        SECTION(\"fail if server has maxWireVersion < 5 and write has collation\") {\n            if (test_util::get_max_wire_version(mongodb_client) < 5) {\n                collection coll = db[\"bulk_write_collation\"];\n                coll.drop();\n\n                auto collation =\n                    make_document(kvp(\"collation\", make_document(kvp(\"locale\", \"en_US\"))));\n\n                model::delete_one first{std::move(doc1)};\n                model::delete_one second{std::move(doc2)};\n\n                second.collation(collation.view());\n\n                auto bulk = coll.create_bulk_write(bulk_opts);\n                bulk.append(first);\n                bulk.append(second);\n\n                REQUIRE_THROWS_AS(bulk.execute(), operation_exception);\n            }\n        }\n\n        SECTION(\"bypass_document_validation ignores validation_criteria\", \"[collection]\") {\n            std::string collname = \"bulk_write_bypass_document_validation\";\n            db[collname].drop();\n            collection coll = db.create_collection(\n                collname,\n                make_document(\n                    kvp(\"validator\", make_document(kvp(\"foo\", make_document(kvp(\"$eq\", 1)))))));\n\n            bulk_opts.bypass_document_validation(true);\n            auto cbulk = coll.create_bulk_write(bulk_opts);\n            cbulk.append(model::insert_one{std::move(doc1)});\n            cbulk.append(model::insert_one{std::move(doc2)});\n\n            stdx::optional<result::bulk_write> result;\n            REQUIRE_NOTHROW(result = cbulk.execute());\n\n            REQUIRE(result);\n            REQUIRE(result->inserted_count() == 2);\n        }\n    }\n\n    SECTION(\"distinct works\", \"[collection]\") {\n        collection coll = db[\"distinct\"];\n        coll.drop();\n        auto doc1 = make_document(kvp(\"foo\", \"baz\"), kvp(\"garply\", 1));\n        auto doc2 = make_document(kvp(\"foo\", \"bar\"), kvp(\"garply\", 2));\n        auto doc3 = make_document(kvp(\"foo\", \"baz\"), kvp(\"garply\", 2));\n        auto doc4 = make_document(kvp(\"foo\", \"quux\"), kvp(\"garply\", 9));\n\n        options::bulk_write bulk_opts;\n        bulk_opts.ordered(false);\n        auto bulk = coll.create_bulk_write(bulk_opts);\n\n        bulk.append(model::insert_one{std::move(doc1)});\n        bulk.append(model::insert_one{std::move(doc2)});\n        bulk.append(model::insert_one{std::move(doc3)});\n        bulk.append(model::insert_one{std::move(doc4)});\n\n        bulk.execute();\n\n        REQUIRE(coll.count_documents({}) == 4);\n\n        auto distinct_results = coll.distinct(\"foo\", {});\n\n        // copy into a vector.\n        std::vector<bsoncxx::document::value> results;\n        for (auto&& result : distinct_results) {\n            results.emplace_back(result);\n        }\n\n        REQUIRE(results.size() == std::size_t{1});\n\n        auto res_doc = results[0].view();\n        auto values_array = res_doc[\"values\"].get_array().value;\n\n        std::vector<stdx::string_view> distinct_values;\n        for (auto&& value : values_array) {\n            distinct_values.push_back(value.get_string().value);\n        }\n\n        const auto assert_contains_one = [&](stdx::string_view val) {\n            REQUIRE(std::count(distinct_values.begin(), distinct_values.end(), val) == 1);\n        };\n\n        assert_contains_one(\"baz\");\n        assert_contains_one(\"bar\");\n        assert_contains_one(\"quux\");\n    }\n\n    SECTION(\"distinct with collation\", \"[collection]\") {\n        collection coll = db[\"distinct_with_collation\"];\n        coll.drop();\n        auto doc = make_document(kvp(\"x\", \"foo\"));\n\n        coll.insert_one(doc.view());\n\n        auto predicate = make_document(kvp(\"x\", \"FOO\"));\n\n        auto distinct_opts = options::distinct{}.collation(case_insensitive_collation.view());\n\n        if (test_util::supports_collation(mongodb_client)) {\n            auto distinct_results = coll.distinct(\"x\", predicate.view(), distinct_opts);\n            auto iter = distinct_results.begin();\n            REQUIRE(iter != distinct_results.end());\n            auto result = *iter;\n            auto values = result[\"values\"].get_array().value;\n            REQUIRE(std::distance(values.begin(), values.end()) == 1);\n            REQUIRE(values[0].get_string().value == stdx::string_view{\"foo\"});\n        } else {\n            // The server does not support collation.\n            REQUIRE_THROWS_AS(coll.distinct(\"x\", predicate.view(), distinct_opts),\n                              operation_exception);\n        }\n    }\n}\n\nTEST_CASE(\"read_concern is inherited from parent\", \"[collection]\") {\n    client mongo_client{uri{}, test_util::add_test_server_api()};\n    database db = mongo_client[\"collection_read_concern_inheritance\"];\n\n    read_concern::level majority = read_concern::level::k_majority;\n    read_concern::level local = read_concern::level::k_local;\n\n    read_concern rc{};\n    rc.acknowledge_level(majority);\n    db.read_concern(rc);\n\n    SECTION(\"when parent is a database\") {\n        collection coll = db[\"database_parent\"];\n        REQUIRE(coll.read_concern().acknowledge_level() == read_concern::level::k_majority);\n    }\n\n    SECTION(\"except when read_concern is explicitly set\") {\n        collection coll = db[\"explicitly_set\"];\n        read_concern set_rc{};\n        set_rc.acknowledge_level(read_concern::level::k_local);\n        coll.read_concern(set_rc);\n\n        REQUIRE(coll.read_concern().acknowledge_level() == local);\n    }\n}\n\nvoid find_index_and_validate(collection& coll,\n                             stdx::string_view index_name,\n                             const std::function<void(bsoncxx::document::view)>& validate =\n                                 [](bsoncxx::document::view) {}) {\n    auto cursor = coll.list_indexes();\n\n    for (auto&& index : cursor) {\n        auto name_ele = index[\"name\"];\n        REQUIRE(name_ele);\n        REQUIRE(name_ele.type() == bsoncxx::type::k_string);\n\n        if (name_ele.get_string().value != index_name) {\n            continue;\n        }\n\n        validate(index);\n        return;\n    }\n    REQUIRE(false);  // index of given name not found\n}\n\nTEST_CASE(\"create_index tests\", \"[collection]\") {\n    using namespace bsoncxx;\n\n    instance::current();\n\n    client mongodb_client{uri{}, test_util::add_test_server_api()};\n    database db = mongodb_client[\"collection_create_index\"];\n\n    SECTION(\"returns index name\") {\n        collection coll = db[\"create_index_return_name\"];\n        coll.drop();\n        coll.insert_one({});  // Ensure that the collection exists.\n\n        bsoncxx::document::value index = make_document(kvp(\"a\", 1));\n\n        std::string indexName{\"myName\"};\n        options::index options{};\n        options.name(indexName);\n\n        auto response = coll.create_index(index.view(), options);\n        REQUIRE(response.view()[\"name\"].get_string().value ==\n                bsoncxx::stdx::string_view(indexName));\n\n        find_index_and_validate(coll, indexName);\n\n        bsoncxx::document::value index2 = make_document(kvp(\"b\", 1), kvp(\"c\", -1));\n\n        auto response2 = coll.create_index(index2.view(), options::index{});\n        REQUIRE(response2.view()[\"name\"].get_string().value ==\n                bsoncxx::stdx::string_view{\"b_1_c_-1\"});\n\n        find_index_and_validate(coll, \"b_1_c_-1\");\n    }\n\n    SECTION(\"with collation\") {\n        collection coll = db[\"create_index_with_collation\"];\n        coll.drop();\n        coll.insert_one({});  // Ensure that the collection exists.\n\n        bsoncxx::document::value keys = make_document(kvp(\"a\", 1));\n        auto collation = make_document(kvp(\"locale\", \"en_US\"));\n\n        options::index options{};\n        options.collation(collation.view());\n\n        coll.create_index(keys.view(), options);\n\n        auto validate = [](bsoncxx::document::view index) {\n            bsoncxx::types::bson_value::view locale{types::b_string{\"en_US\"}};\n            auto locale_ele = index[\"collation\"][\"locale\"];\n            REQUIRE(locale_ele);\n            REQUIRE(locale_ele.type() == type::k_string);\n            REQUIRE((locale_ele.get_string() == locale));\n        };\n\n        find_index_and_validate(coll, \"a_1\", validate);\n    }\n\n    SECTION(\"fails\") {\n        collection coll = db[\"create_index_fails\"];\n        coll.drop();\n        coll.insert_one({});  // Ensure that the collection exists.\n\n        bsoncxx::document::value keys1 = make_document(kvp(\"a\", 1));\n        bsoncxx::document::value keys2 = make_document(kvp(\"a\", -1));\n\n        options::index options{};\n        options.name(\"a\");\n\n        REQUIRE_NOTHROW(coll.create_index(keys1.view(), options));\n        REQUIRE_THROWS_AS(coll.create_index(keys2.view(), options), operation_exception);\n    }\n\n    SECTION(\"succeeds with options\") {\n        collection coll = db[\"create_index_with_options\"];\n        coll.drop();\n        coll.insert_one({});  // Ensure that the collection exists.\n\n        mongocxx::stdx::string_view index_name{\"succeeds_with_options\"};\n\n        bsoncxx::document::value keys = make_document(kvp(\"cccc\", 1));\n\n        options::index options{};\n        options.unique(true);\n        if (test_util::newer_than(mongodb_client, \"4.4\"))\n            options.hidden(true);\n        options.expire_after(std::chrono::seconds(500));\n        options.name(index_name);\n\n        REQUIRE_NOTHROW(coll.create_index(keys.view(), options));\n        auto validate = [&](bsoncxx::document::view index) {\n            auto expire_after = index[\"expireAfterSeconds\"];\n            REQUIRE(expire_after);\n            REQUIRE(expire_after.type() == type::k_int32);\n            REQUIRE(expire_after.get_int32().value == 500);\n\n            auto unique_ele = index[\"unique\"];\n            REQUIRE(unique_ele);\n            REQUIRE(unique_ele.type() == type::k_bool);\n            REQUIRE(unique_ele.get_bool() == options.unique().value());\n\n            if (test_util::newer_than(mongodb_client, \"4.4\")) {\n                auto hidden_ele = index[\"hidden\"];\n                REQUIRE(hidden_ele);\n                REQUIRE(hidden_ele.type() == type::k_bool);\n                REQUIRE(hidden_ele.get_bool() == options.hidden().value());\n            }\n        };\n\n        find_index_and_validate(coll, index_name, validate);\n    }\n\n    SECTION(\"fails with options\") {\n        collection coll = db[\"create_index_fails_with_options\"];\n        coll.drop();\n        coll.insert_one({});  // Ensure that the collection exists.\n\n        bsoncxx::document::value keys = make_document(kvp(\"c\", 1));\n        options::index options{};\n\n        auto expire_after =\n            std::chrono::seconds(static_cast<int64_t>(std::numeric_limits<int32_t>::max()) + 1);\n        options.expire_after(expire_after);\n        REQUIRE_THROWS_AS(coll.create_index(keys.view(), options), logic_error);\n\n        expire_after = std::chrono::seconds(-1);\n        options.expire_after(expire_after);\n        REQUIRE_THROWS_AS(coll.create_index(keys.view(), options), logic_error);\n    }\n\n    SECTION(\"succeeds with storage engine options\") {\n        collection coll = db[\"create_index_succeeds_with_storage_options\"];\n        coll.drop();\n        coll.insert_one({});  // Ensure that the collection exists.\n\n        bsoncxx::stdx::string_view index_name{\"storage_options_test\"};\n        bsoncxx::document::value keys = make_document(kvp(\"c\", 1));\n\n        options::index options{};\n        options.name(index_name);\n\n        std::unique_ptr<options::index::wiredtiger_storage_options> wt_options =\n            bsoncxx::stdx::make_unique<options::index::wiredtiger_storage_options>();\n        wt_options->config_string(\"block_allocation=first\");\n\n        REQUIRE_NOTHROW(options.storage_options(std::move(wt_options)));\n        REQUIRE_NOTHROW(coll.create_index(keys.view(), options));\n\n        auto validate = [](bsoncxx::document::view index) {\n            auto config_string_ele = index[\"storageEngine\"][\"wiredTiger\"][\"configString\"];\n            REQUIRE(config_string_ele);\n            REQUIRE(config_string_ele.type() == type::k_string);\n            REQUIRE(config_string_ele.get_string() == types::b_string{\"block_allocation=first\"});\n        };\n\n        find_index_and_validate(coll, index_name, validate);\n    }\n}\n\nTEST_CASE(\"list_indexes\", \"[collection]\") {\n    instance::current();\n\n    client mongodb_client{uri{}, test_util::add_test_server_api()};\n    database db = mongodb_client[\"collection_list_indexes\"];\n\n    collection coll = db[\"list_indexes_works\"];\n    coll.drop();\n    coll.insert_one({});  // Ensure that the collection exists.\n\n    options::index options{};\n    options.unique(true);\n\n    coll.create_index(make_document(kvp(\"a\", 1)), options);\n    coll.create_index(make_document(kvp(\"b\", 1), kvp(\"c\", -1)));\n    coll.create_index(make_document(kvp(\"c\", -1)));\n\n    auto cursor = coll.list_indexes();\n\n    std::vector<std::string> expected_names{\"a_1\", \"b_1_c_-1\", \"c_-1\"};\n    std::int8_t found = 0;\n\n    for (auto&& index : cursor) {\n        auto name = index[\"name\"].get_string();\n\n        for (auto&& expected : expected_names) {\n            if (bsoncxx::stdx::string_view(expected) == name.value) {\n                found++;\n                if (expected == \"a_1\") {\n                    REQUIRE(index[\"unique\"]);\n                } else {\n                    REQUIRE(!index[\"unique\"]);\n                }\n            }\n        }\n    }\n    REQUIRE(found == 3);\n}\n\n// We use a capped collection for this test case so we can\n// use it with all three cursor types.\nTEST_CASE(\"Cursor iteration\", \"[collection][cursor]\") {\n    instance::current();\n    client mongodb_client{uri{}, test_util::add_test_server_api()};\n    database db = mongodb_client[\"collection_cursor_iteration\"];\n\n    auto capped_name = std::string(\"mongo_cxx_driver_capped\");\n    collection coll = db[capped_name];\n\n    // Drop and (re)create the capped collection.\n    coll.drop();\n    db.create_collection(capped_name, make_document(kvp(\"capped\", true), kvp(\"size\", 1024 * 1024)));\n\n    // Tests will use all three cursor types.\n    options::find opts;\n    std::string type_str = \"no cursor type set\";\n\n    auto run_test = [&]() {\n        INFO(type_str);\n\n        // Insert 3 documents.\n        for (int32_t n : {1, 2, 3}) {\n            coll.insert_one(make_document(kvp(\"x\", n)));\n        }\n\n        auto cursor = coll.find({}, opts);\n        auto iter = cursor.begin();\n\n        REQUIRE(iter == cursor.begin());\n\n        // Check that the cursor finds three documents and that the iterator\n        // stays in lockstep.\n        auto expected = 1;\n\n        for (auto&& doc : cursor) {\n            REQUIRE(doc[\"x\"].get_int32() == expected);\n\n            // Lockstep requires that iter matches both the current document\n            // and cursor.begin() (current doc before cursor increment).\n            // It must not match cursor.end(), since a document exists.\n            REQUIRE(iter == cursor.begin());\n            REQUIRE(iter != cursor.end());\n            REQUIRE((*iter)[\"x\"].get_int32() == expected);\n\n            expected++;\n        }\n\n        // Check that iteration covered all three documents.\n        REQUIRE(expected == 4);\n\n        // As no document is available, iterator now must match cursor.end().\n        // We check both LHS and RHS for coverage.\n        REQUIRE(iter == cursor.end());\n        REQUIRE(cursor.end() == iter);\n\n        // Because there are no more documents available from this query,\n        // cursor.begin() must equal cursor.end().  Transitively, this means\n        // that iter must also match cursor.begin().\n        REQUIRE(cursor.begin() == cursor.end());\n        REQUIRE(iter == cursor.begin());\n\n        // For tailable cursors, if more documents are inserted, the next\n        // call to cursor.begin() should find more documents and the existing iterator\n        // should no longer be exhausted.\n        if (opts.cursor_type() != cursor::type::k_non_tailable) {\n            // Insert 3 more documents.\n            for (int32_t n : {4, 5, 6}) {\n                coll.insert_one(make_document(kvp(\"x\", n)));\n            }\n\n            // More documents are available, but until the next call to\n            // cursor.begin(), the existing iterator still appears exhausted.\n            REQUIRE(iter == cursor.end());\n\n            // After calling cursor.begin(), the existing iterator is revived.\n            cursor.begin();\n            REQUIRE(iter != cursor.end());\n            REQUIRE(iter == cursor.begin());\n\n            // Check that the cursor finds the next three documents and that the\n            // iterator stays in lockstep.\n            for (auto&& doc : cursor) {\n                REQUIRE(doc[\"x\"].get_int32() == expected);\n\n                REQUIRE(iter == cursor.begin());\n                REQUIRE(iter != cursor.end());\n                REQUIRE((*iter)[\"x\"].get_int32() == expected);\n\n                expected++;\n            }\n\n            // Check that iteration has covered all six documents.\n            REQUIRE(expected == 7);\n\n            // As before: iter, cursor.begin() and cursor.end() must all\n            // transitively agree that the cursor is currently exhausted.\n            REQUIRE(iter == cursor.end());\n            REQUIRE(cursor.begin() == cursor.end());\n            REQUIRE(iter == cursor.begin());\n        }\n    };\n\n    SECTION(\"k_non_tailable\") {\n        opts.cursor_type(cursor::type::k_non_tailable);\n        type_str = \"k_non_tailable\";\n        run_test();\n    }\n\n    SECTION(\"k_tailable\") {\n        opts.cursor_type(cursor::type::k_tailable);\n        type_str = \"k_tailable\";\n        run_test();\n    }\n\n    SECTION(\"k_tailable_await\") {\n        opts.cursor_type(cursor::type::k_tailable_await);\n        type_str = \"k_tailable_await\";\n\n        // Improve execution time by reducing the amount of time the server waits for new\n        // results for this cursor. Note: may cause flaky test failures if the duration is too\n        // short.\n        opts.max_await_time(std::chrono::milliseconds{10});\n\n        run_test();\n    }\n}\n\nTEST_CASE(\"regressions\", \"CXX-986\") {\n    instance::current();\n    mongocxx::uri mongo_uri{\"mongodb://non-existent-host.invalid/\"};\n    mongocxx::client client{mongo_uri, test_util::add_test_server_api()};\n    REQUIRE_THROWS(client.database(\"irrelevant\")[\"irrelevant\"].find_one_and_update(\n        make_document(kvp(\"irrelevant\", 1)), make_document(kvp(\"irrelevant\", 2))));\n}\n\nTEST_CASE(\"bulk_write with container\", \"[collection]\") {\n    instance::current();\n    mongocxx::client client{uri{}, test_util::add_test_server_api()};\n\n    std::vector<model::write> vec;\n    for (int32_t i = 0; i != 10; ++i) {\n        vec.emplace_back(model::insert_one{make_document(kvp(\"_id\", i))});\n    }\n\n    auto collection = client[\"bulk_write_container\"][\"collection\"];\n    collection.drop();\n    auto result = collection.bulk_write(vec);\n    // The optional result is engaged.\n    REQUIRE(static_cast<bool>(result));\n    REQUIRE(result->inserted_count() == 10);\n    REQUIRE(collection.count_documents({}) == 10);\n}\n\n/* Regression test for CXX-2028. */\nTEST_CASE(\"find_and_x operations append write concern correctly\", \"[collection]\") {\n    instance::current();\n    mongocxx::client client{uri{}, test_util::add_test_server_api()};\n    mongocxx::write_concern wc;\n    wc.acknowledge_level(mongocxx::write_concern::level::k_acknowledged);\n\n    auto collection = client[\"fam_wc\"][\"collection\"];\n    collection.drop();\n    collection.insert_one(make_document(kvp(\"x\", 1)));\n\n    stdx::optional<bsoncxx::document::value> doc;\n    /* 4.4. servers will reply with an error, causing an exception. */\n    /* find_one_and_update */\n    mongocxx::options::find_one_and_update find_one_and_update_opts;\n    find_one_and_update_opts.write_concern(wc);\n    doc = collection.find_one_and_update(\n        {}, make_document(kvp(\"$set\", make_document(kvp(\"x\", 2)))), find_one_and_update_opts);\n    REQUIRE(doc);\n\n    /* find_one_and_replace */\n    mongocxx::options::find_one_and_replace find_one_and_replace_opts;\n    find_one_and_replace_opts.write_concern(wc);\n    doc = collection.find_one_and_replace(\n        make_document(), make_document(kvp(\"x\", 2)), find_one_and_replace_opts);\n    REQUIRE(doc);\n\n    /* find_one_and_delete */\n    mongocxx::options::find_one_and_delete find_one_and_delete_opts;\n    find_one_and_delete_opts.write_concern(wc);\n    doc = collection.find_one_and_delete({}, find_one_and_delete_opts);\n    REQUIRE(doc);\n\n    /* < 4.4 servers will not return an error for unexpected fields. Add a visitor function to check\n     * manually. */\n    bool called = false;\n    auto visitor = libmongoc::find_and_modify_opts_append.create_instance();\n    visitor->visit([&](mongoc_find_and_modify_opts_t*, const bson_t* extra) {\n        bsoncxx::document::value expected =\n            make_document(kvp(\"writeConcern\", make_document(kvp(\"w\", 1))));\n        bsoncxx::document::view extra_view{bson_get_data(extra), extra->len};\n\n        called = true;\n        REQUIRE(extra_view == expected.view());\n    });\n\n    /* Insert a new document. */\n    collection.insert_one(make_document(kvp(\"x\", 1)));\n    doc = collection.find_one_and_delete({}, find_one_and_delete_opts);\n    REQUIRE(doc);\n    REQUIRE(called);\n}\n\nTEST_CASE(\"Ensure that the WriteConcernError 'errInfo' object is propagated\", \"[collection]\") {\n    using namespace bsoncxx;\n    instance::current();\n\n    client mongodb_client{uri{}, test_util::add_test_server_api()};\n\n    if (test_util::get_topology(mongodb_client) == \"sharded\" &&\n        test_util::compare_versions(test_util::get_server_version(mongodb_client), \"4.1.0\") < 0) {\n        WARN(\"Skipping - failCommand on mongos requires 4.1+\");\n        return;\n    }\n\n    using bsoncxx::builder::basic::sub_document;\n    auto err_info = builder::basic::document{};\n    err_info.append(kvp(\"writeConcern\", [](sub_document sub_doc) {\n        sub_doc.append(kvp(\"w\", types::b_int32{2}));\n        sub_doc.append(kvp(\"wtimeout\", types::b_int32{0}));\n        sub_doc.append(kvp(\"provenance\", \"clientSupplied\"));\n    }));\n\n    auto fail_point = builder::basic::document{};\n    fail_point.append(kvp(\"configureFailPoint\", \"failCommand\"));\n\n    using bsoncxx::builder::basic::sub_array;\n    fail_point.append(kvp(\"data\", [&err_info](sub_document sub_doc) {\n        sub_doc.append(kvp(\"failCommands\", [](sub_array sub_arr) { sub_arr.append(\"insert\"); }));\n        sub_doc.append(kvp(\"writeConcernError\", [&err_info](sub_document sub_doc) {\n            sub_doc.append(kvp(\"code\", types::b_int32{100}));\n            sub_doc.append(kvp(\"codeName\", \"UnsatisfiableWriteConcern\"));\n            sub_doc.append(kvp(\"errmsg\", \"Not enough data-bearing nodes\"));\n            sub_doc.append(kvp(\"errInfo\", types::b_document{err_info}));\n        }));\n    }));\n\n    fail_point.append(\n        kvp(\"mode\", [](sub_document sub_doc) { sub_doc.append(kvp(\"times\", types::b_int32{1})); }));\n\n    mongodb_client[\"admin\"].run_command(fail_point.view());\n    collection coll = mongodb_client[\"test\"][\"errInfo\"];\n\n    coll.drop();\n    auto doc = make_document(kvp(\"x\", types::b_int32{1}));\n\n    bool contains_err_info{false};\n    try {\n        coll.insert_one(doc.view());\n    } catch (const operation_exception& e) {\n        auto error = e.raw_server_error()->view();\n        auto result = error[\"writeConcernErrors\"][0][\"errInfo\"];\n        contains_err_info = (err_info == result.get_document().view());\n    }\n\n    REQUIRE(contains_err_info);\n}\n\nTEST_CASE(\"expose writeErrors[].errInfo\", \"[collection]\") {\n    // A helper for checking that an error document is well-formed according to our requirements:\n    auto writeErrors_well_formed = [](const bsoncxx::document::view& reply_view) -> bool {\n        if (!reply_view[\"writeErrors\"]) {\n            return false;\n        }\n\n        const auto& errdoc = reply_view[\"writeErrors\"][0];\n\n        auto error_code = errdoc[\"code\"].get_int32();\n\n        // The code should always be 121 (DocumentValidationFailure):\n        if (121 != error_code) {\n            std::ostringstream os;\n            os << \"writeErrors expected to have code 121, but had \" << error_code << \" instead\";\n            throw std::runtime_error(os.str());\n        }\n\n        // We require the \"details\" field be present:\n        if (!errdoc[\"errInfo\"][\"details\"]) {\n            throw std::runtime_error(\"no \\\"details\\\" field in \\\"writeErrors\\\"\");\n        }\n\n        return true;\n    };\n\n    // Set up our test environment:\n    instance::current();\n\n    mongocxx::options::apm apm_opts;\n\n    auto client_opts = test_util::add_test_server_api();\n\n    // We set this by side effect in on_command_succeeded to make sure the callback was actually\n    // triggered:\n    bool insert_succeeded = false;\n\n    // Listen to the insertion-failed event: we want to get a copy of the server's\n    // response so that we can compare it to the thrown exception later:\n    apm_opts.on_command_succeeded([&writeErrors_well_formed, &insert_succeeded](\n                                      const mongocxx::events::command_succeeded_event& ev) {\n        if (0 != ev.command_name().compare(\"insert\")) {\n            return;\n        }\n\n        REQUIRE(writeErrors_well_formed(ev.reply()));\n\n        // Make sure that \"we\" were actually called:\n        insert_succeeded = true;\n    });\n\n    client_opts.apm_opts(apm_opts);\n\n    auto mongodb_client = mongocxx::client(uri{}, client_opts);\n\n    if (!test_util::newer_than(mongodb_client, \"5.0\")) {\n        WARN(\"skip: test requires MongoDB server 5.0 or newer\");\n        return;\n    }\n\n    database db = mongodb_client[\"prose_test_expose_details\"];\n\n    const std::string collname{\"mongo_cxx_driver-expose_details\"};\n\n    // Drop the existing collection, if any:\n    db[collname].drop();\n\n    // Make a new collection with validation checking:\n    collection coll = db.create_collection(\n        collname,\n        make_document(kvp(\"validator\",\n                          make_document(kvp(\"field_x\", make_document(kvp(\"$type\", \"string\")))))));\n\n    SECTION(\"cause a type violation on insert\") {\n        bsoncxx::builder::basic::document entry;\n\n        entry.append(kvp(\"_id\", bsoncxx::oid()), kvp(\"field_x\", 42));\n\n        try {\n            coll.insert_one(entry.view());\n\n            // We should not make it here (i.e. this is an error):\n            CHECK(false);\n        } catch (const operation_exception& e) {\n            auto rse = e.raw_server_error();\n\n            // We have no has_value() check:\n            CHECK(rse);\n\n            CHECK(writeErrors_well_formed(*rse));\n        } catch (...) {\n            // An exception was thrown, but of the wrong type:\n            CHECK(false);\n        }\n\n        // Make sure that our callback was actually triggered and completed successfully:\n        REQUIRE(insert_succeeded);\n    }\n}\n\n}  // namespace\n",
    "file_path": "data\\preprocessed\\mongodb_mongo-cxx-driver__src_mongocxx_test_collection.cpp",
    "file_name": "mongodb_mongo-cxx-driver__src_mongocxx_test_collection.cpp",
    "language": "cpp"
  },
  {
    "text": "/*\n * Copyright (c) 2004-present, The University of Notre Dame. All rights\n * reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions are met:\n *\n * 1. Redistributions of source code must retain the above copyright notice,\n *    this list of conditions and the following disclaimer.\n *\n * 2. Redistributions in binary form must reproduce the above copyright notice,\n *    this list of conditions and the following disclaimer in the documentation\n *    and/or other materials provided with the distribution.\n *\n * 3. Neither the name of the copyright holder nor the names of its\n *    contributors may be used to endorse or promote products derived from\n *    this software without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n * LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n * INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n * CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n * ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n * POSSIBILITY OF SUCH DAMAGE.\n *\n * SUPPORT OPEN SCIENCE!  If you use OpenMD or its source code in your\n * research, please cite the appropriate papers when you publish your\n * work.  Good starting points are:\n *\n * [1] Meineke, et al., J. Comp. Chem. 26, 252-271 (2005).\n * [2] Fennell & Gezelter, J. Chem. Phys. 124, 234104 (2006).\n * [3] Sun, Lin & Gezelter, J. Chem. Phys. 128, 234107 (2008).\n * [4] Vardeman, Stocker & Gezelter, J. Chem. Theory Comput. 7, 834 (2011).\n * [5] Kuang & Gezelter, Mol. Phys., 110, 691-701 (2012).\n * [6] Lamichhane, Gezelter & Newman, J. Chem. Phys. 141, 134109 (2014).\n * [7] Lamichhane, Newman & Gezelter, J. Chem. Phys. 141, 134110 (2014).\n * [8] Bhattarai, Newman & Gezelter, Phys. Rev. B 99, 094106 (2019).\n */\n\n#include \"io/SectionParser.hpp\"\n\n#include \"utils/Trim.hpp\"\n\nnamespace OpenMD {\n\n  void SectionParser::parse(std::istream& input, ForceField& ff, int lineNo) {\n    const int bufferSize = 65535;\n    char buffer[bufferSize];\n    std::string line, filteredLine;\n    while (input.getline(buffer, bufferSize)) {\n      ++lineNo;\n      line = Utils::trimLeftCopy(buffer);\n      // a line begins with \"//\" is comment\n      // let's also call lines starting with # and ! as comments\n      if (isEndSection(line)) {\n        break;\n      } else if (line.empty() ||\n                 (line.size() >= 2 && line[0] == '/' && line[1] == '/') ||\n                 (line.size() >= 1 && line[0] == '#') ||\n                 (line.size() >= 1 && line[0] == '!')) {\n        continue;\n      } else {\n        filteredLine = stripComments(line);\n        parseLine(ff, filteredLine, lineNo);\n      }\n    }\n  }\n\n  std::string SectionParser::stripComments(const std::string& line) {\n    unsigned int n = line.length();\n    std::string res;\n\n    // Flags to indicate that single line and multpile line comments\n    // have started or not.\n    bool s_cmt = false;\n    bool m_cmt = false;\n\n    // Traverse the line\n    for (unsigned int i = 0; i < n; i++) {\n      // If single line comment flag is on, then check for end of it\n      if (s_cmt == true && line[i] == '\\n') s_cmt = false;\n\n      // If multiple line comment is on, then check for end of it\n      else if (m_cmt == true && line[i] == '*' && line[i + 1] == '/')\n        m_cmt = false, i++;\n\n      // If this character is in a comment, ignore it\n      else if (s_cmt || m_cmt)\n        continue;\n\n      // Check for beginning of comments and set the approproate flags\n      else if (line[i] == '/' && line[i + 1] == '/')\n        s_cmt = true, i++;\n      else if (line[i] == '/' && line[i + 1] == '*')\n        m_cmt = true, i++;\n\n      // If current character is a non-comment character, append it to res\n      else\n        res += line[i];\n    }\n    return res;\n  }\n\n  bool SectionParser::isEndSection(const std::string& line) {\n    StringTokenizer tokenizer(line);\n\n    if (tokenizer.countTokens() >= 2) {\n      std::string keyword = tokenizer.nextToken();\n\n      if (keyword != \"end\") { return false; }\n\n      std::string section = tokenizer.nextToken();\n      if (section == sectionName_) {\n        return true;\n      } else {\n        return false;\n      }\n\n    } else {\n      return false;\n    }\n  }\n\n}  // namespace OpenMD\n",
    "file_path": "data\\preprocessed\\OpenMD_OpenMD__src_io_SectionParser.cpp",
    "file_name": "OpenMD_OpenMD__src_io_SectionParser.cpp",
    "language": "cpp"
  },
  {
    "text": "#include \"testing/testing.hpp\"\n\n#include \"base/base.hpp\"\n#include \"base/exception.hpp\"\n#include \"base/logging.hpp\"\n\n\nUNIT_TEST(Assert_Smoke)\n{\n  int x = 5;\n  // to avoid warning in release\n#ifdef RELEASE\n  UNUSED_VALUE(x);\n#endif\n  ASSERT_EQUAL ( x, 5, () );\n  ASSERT_NOT_EQUAL ( x, 6, () );\n  //ASSERT_EQUAL ( x, 666, (\"Skip this to continue test\") );\n}\n\nUNIT_TEST(Check_Smoke)\n{\n  int x = 5;\n  CHECK_EQUAL ( x, 5, () );\n  CHECK_NOT_EQUAL ( x, 6, () );\n  //CHECK_EQUAL ( x, 666, (\"Skip this to continue test\") );\n}\n\nUNIT_TEST(Exception_Formatting)\n{\n  try\n  {\n    MYTHROW(RootException, (\"String1\", \"String2\", \"String3\"));\n  }\n  catch (RootException const & e)\n  {\n    LOG(LINFO, (\"Exception string: \", e.what()));\n  }\n}\n",
    "file_path": "data\\preprocessed\\organicmaps_organicmaps__base_base_tests_assert_test.cpp",
    "file_name": "organicmaps_organicmaps__base_base_tests_assert_test.cpp",
    "language": "cpp"
  },
  {
    "text": "#include \"EnvCubeComponent.h\"\n#include \"../../Entity.h\"\n\nusing namespace PaintsNow;\n\nEnvCubeComponent::EnvCubeComponent() : range(1.0f, 1.0f, 1.0f), strength(1.0f) {}\n\nEnvCubeComponent::~EnvCubeComponent() {}\n\nTiny::FLAG EnvCubeComponent::GetEntityFlagMask() const {\n\treturn Entity::ENTITY_HAS_RENDERCONTROL | RenderableComponent::GetEntityFlagMask();\n}\n\nuint32_t EnvCubeComponent::CollectDrawCalls(std::vector<OutputRenderData, DrawCallAllocator>& outputDrawCalls, const InputRenderData& inputRenderData, BytesCache& bytesCache, CollectOption option) {\n\treturn 0;\n}\n\nTObject<IReflect>& EnvCubeComponent::operator () (IReflect& reflect) {\n\tBaseClass::operator () (reflect);\n\n\tif (reflect.IsReflectProperty()) {\n\t\tReflectProperty(cubeMapTexture);\n\t}\n\n\treturn *this;\n}\n\nvoid EnvCubeComponent::UpdateBoundingBox(Engine& engine, Float3Pair& box, bool recursive) {\n\tMath::Union(box, Float3(-range));\n\tMath::Union(box, range);\n}\n",
    "file_path": "data\\preprocessed\\paintdream_PaintsNow__Source_Utility_MythForest_Component_EnvCube_EnvCubeComponent.cpp",
    "file_name": "paintdream_PaintsNow__Source_Utility_MythForest_Component_EnvCube_EnvCubeComponent.cpp",
    "language": "cpp"
  },
  {
    "text": "#include \"merge.h\"\n#include \"docwordspace.h\"\n#include <unordered_set>\n#include <text.h>\n\nvoid Trinity::MergeCandidatesCollection::commit() {\n        std::sort(candidates.begin(), candidates.end(), [](const auto &a, const auto &b) noexcept {\n                return b.gen < a.gen;\n        });\n\n        map.clear();\n        all.clear();\n\n        // For each candidate, we 'll track the base in all[]\n        // so that we 'll need to consider all masked products from [base, all.size())\n        // This makes sense because we have ordered by generation, and Trinity's generation order semantics\n        for (const auto &c : candidates) {\n                const auto &ud = c.maskedDocuments;\n\n                map.push_back({c, all.size()});\n                if (ud) {\n                        all.push_back(ud);\n                }\n        }\n}\n\nstd::unique_ptr<Trinity::masked_documents_registry> Trinity::MergeCandidatesCollection::scanner_registry_for(const uint16_t idx) {\n        const auto n = map[idx].second;\n\n\t// It's important that we masked_documents_registry::make() use_bf is set to false here\n\t// otherwise it's just too expensive to allocate/release the memory for the bloom filter\n\t// and because the BF size is large the allocator will fallback to mmap with subsequent madvise/munmap\n\t// which is expensive if it involves thousands of such calls\n        return masked_documents_registry::make(all.data(), n, false);\n}\n\n// Make sure you have commited first\n// Unlike with e.g SegmentIndexSession where the order of postlists in the index is based on our translation(term=>integer id) and the ascending order of that id\n// here the order will match the order the terms are found in `tersm`, because we perform a merge-sort and so we process terms in lexicograpphic order\nvoid Trinity::MergeCandidatesCollection::merge(Trinity::Codecs::IndexSession *                                is,\n                                               simple_allocator *                                             allocator,\n                                               std::vector<std::pair<str8_t, Trinity::term_index_ctx>> *const terms,\n                                               IndexSource::field_statistics *const                           defaultFieldStats,\n                                               const uint32_t                                                 flushFreq,\n                                               const bool   disableOptimizations) {\n        static constexpr bool trace{false};\n\n        struct tracked_candidate final {\n                uint16_t        idx;\n                merge_candidate candidate;\n        };\n\n        std::vector<tracked_candidate> all_;\n\n        if (trace) {\n                SLog(\"Merging \", candidates.size(), \" candidates\\n\");\n        }\n\n        EXPECT(candidates.size() < std::numeric_limits<uint16_t>::max());\n\n        for (uint16_t i{0}; i < candidates.size(); ++i) {\n                if (trace) {\n                        SLog(\"Candidate \", i, \" gen=\", candidates[i].gen, \" \", candidates[i].ap->codec_identifier(), \"\\n\");\n                }\n\n                if (i) {\n                        EXPECT(candidates[i].gen < candidates[i - 1].gen);\n                }\n\n                if (candidates[i].terms && false == candidates[i].terms->done() && candidates[i].ap) {\n                        // ap may be nullptr if we only wanted to e.g mask documents\n                        all_.push_back({i, candidates[i]});\n                }\n        }\n\n        if (all_.empty()) {\n                return;\n        }\n\n        auto   all = all_.data();\n        uint16_t   rem = all_.size();\n        uint16_t   toAdvance[rem];\n        const auto   isCODEC = is->codec_identifier();\n        DocWordsSpace                                                 dws{Limits::MaxPosition}; // dummy, for materialize_hits()\n        size_t   termHitsCapacity{0};\n        term_hit *   termHitsStorage{nullptr};\n        std::vector<Trinity::Codecs::IndexSession::merge_participant> mergeParticipants;\n        std::vector<std::pair<\n            std::pair<Trinity::Codecs::Decoder *, Trinity::Codecs::PostingsListIterator *>,\n            masked_documents_registry *>>\n            decodersV;\n        term_index_ctx                            tctx;\n        std::unique_ptr<Trinity::Codecs::Encoder> enc(is->new_encoder());\n        // Only if it's implemented by the codec's IndexSession\n        const bool haveAppendIndexChunk = (false == disableOptimizations) && (is->caps & unsigned(Codecs::IndexSession::Capabilities::AppendIndexChunk));\n        const bool haveMerge            = (false == disableOptimizations) && (is->caps & unsigned(Codecs::IndexSession::Capabilities::Merge));\n\n        DEFER(\n            {\n                    if (termHitsStorage)\n                            std::free(termHitsStorage);\n            });\n\n#if 0\n\tfor (unsigned i = 0; i < rem; ++i) {\n\t\tSLog(\"NOW:\", i, \" for \", candidates[i].gen, \"\\n\");\n\t\tif (candidates[i].gen != 1566292481019157) { continue; }\n\n                for (;;) {\n                        if (candidates[i].terms->done()) {\n                                break;\n                        }\n                        const auto p = candidates[i].terms->cur();\n\n#if 0\n                        if (p.first.Eq(_S(\"pid:555-000-0000\")) || p.first.Eq(_S(\"XBOX\"))) {\n                                SLog(\"For [\", p.first, \"] \", p.second.documents, \"\\n\");\n                        }\n#endif\n\t\t\tSLog(\"Got [\", p.first, \"]\\n\");\n                        candidates[i].terms->next();\n                }\n        }\n\tSLog(\"exiting\\n\"); exit(0);\n#endif\n\n        for (;;) {\n                uint8_t    toAdvanceCnt{1};\n                const auto pair = all[0].candidate.terms->cur();\n                auto       selected{pair};\n                auto       codec = all[0].candidate.ap->codec_identifier();\n                bool       sameCODEC{true};\n\n                toAdvance[0] = 0;\n                for (uint16_t i{1}; i < rem; ++i) {\n                        const auto pair = all[i].candidate.terms->cur();\n                        const auto r    = terms_cmp(pair.first.data(), pair.first.size(), selected.first.data(), selected.first.size());\n\n                        if (r < 0) {\n                                toAdvanceCnt = 1;\n                                toAdvance[0] = i;\n                                selected     = pair;\n                                sameCODEC    = true;\n                                codec        = all[i].candidate.ap->codec_identifier();\n                        } else if (r == 0) {\n                                if (sameCODEC) {\n                                        auto c = all[i].candidate.ap->codec_identifier();\n\n                                        if (c != codec) {\n                                                sameCODEC = false;\n                                        }\n                                }\n\n                                toAdvance[toAdvanceCnt++] = i;\n                        }\n                }\n\n                const str8_t                outTerm(allocator->CopyOf(selected.first.data(), selected.first.size()), selected.first.size());\n                [[maybe_unused]] const bool fastPath = sameCODEC && codec == isCODEC;\n                static constexpr bool       trace{false};\n\n                if (trace) {\n                        SLog(\"TERM [\", selected.first, \"], toAdvanceCnt = \", toAdvanceCnt, \", sameCODEC = \", sameCODEC, \", first = \", toAdvance[0], \", fastPath = \", fastPath, \"\\n\");\n                }\n\n                if (toAdvanceCnt == 1) {\n                        auto c             = all[toAdvance[0]].candidate;\n                        auto maskedDocsReg = scanner_registry_for(all[toAdvance[0]].idx);\n\n                        if (fastPath && maskedDocsReg->empty() && haveAppendIndexChunk) {\n                                if (likely(selected.second.documents)) {\n                                        // See comments below for why this is possible\n                                        const auto chunk = is->append_index_chunk(c.ap, selected.second);\n\n                                        terms->push_back({outTerm, {selected.second.documents, chunk}});\n\n                                        ++(defaultFieldStats->totalTerms);\n                                } else if (trace) {\n                                        SLog(\"No documents\\n\");\n                                }\n                        } else {\n                                if (unlikely(0 == selected.second.documents)) {\n                                        // It's possible, however unlikely (check your implementation)\n                                        // that you have e.g indexed a term, but indexed no documents for that term\n                                        // in which case, it will be 0 documents.\n                                        //\n                                        // We will just skip this here altogether(doing the same for other branches)\n                                        //\n                                        // Note that SegmentIndexSession and this merge() method explicitly drop terms with no documents associated with them, so\n                                        // the only real way to get a term with no document is to use the various Trinity segment constructs directly.\n                                        if (trace) {\n                                                Print(\"0 documents for TERM [\", selected.first, \"]\\n\");\n                                        }\n                                } else {\n                                        std::unique_ptr<Trinity::Codecs::Decoder>              dec(c.ap->new_decoder(selected.second));\n                                        std::unique_ptr<Trinity::Codecs::PostingsListIterator> it(dec->new_iterator());\n\n                                        it->next();\n                                        enc->begin_term();\n\n                                        do {\n                                                const auto docID = it->curDocument.id;\n                                                const auto freq  = it->freq;\n\n                                                EXPECT(docID != DocIDsEND); // sanity check\n\n                                                if (trace) {\n   SLog(\"docID = \", docID, \", masked = \", maskedDocsReg->test(docID), \"\\n\");\n                                                }\n\n                                                if (!maskedDocsReg->test(docID)) {\n   if (freq > termHitsCapacity) {\n   if (termHitsStorage) {\n   std::free(termHitsStorage);\n   }\n\n   termHitsCapacity = freq + 128;\n   termHitsStorage  = static_cast<term_hit *>(malloc(sizeof(term_hit) * termHitsCapacity));\n   }\n\n   enc->begin_document(docID);\n   it->materialize_hits(&dws /* dummy */, termHitsStorage);\n\n   ++(defaultFieldStats->sumTermsDocs);\n   defaultFieldStats->sumTermHits += freq;\n\n   for (uint32_t i{0}; i < freq; ++i) {\n   const auto &th    = termHitsStorage[i];\n   const auto  bytes = reinterpret_cast<const uint8_t *>(&th.payload);\n\n   enc->new_hit(th.pos, {bytes, th.payloadLen});\n   }\n\n   enc->end_document();\n                                                }\n\n                                        } while (it->next() != DocIDsEND);\n\n                                        enc->end_term(&tctx);\n\n                                        if (tctx.documents) {\n                                                // This means that we may end up e.g storing some meta-data specific to this term, and/or a skiplist\n                                                // in the index/other index session data files in between enc->begin_term() .. enc->end_term(), which could\n                                                // have been set even if no documents were indexed for this term.\n                                                // That's fine though -- will ignore them in a future merge op.\n                                                terms->push_back({outTerm, tctx});\n                                                ++(defaultFieldStats->totalTerms);\n                                        }\n\n                                        if (trace) {\n                                                SLog(\"Indexed Term\\n\");\n                                        }\n                                }\n                        }\n                } else {\n                        if (fastPath && haveMerge) {\n                                mergeParticipants.clear();\n\n                                for (uint16_t i{0}; i < toAdvanceCnt; ++i) {\n                                        const auto idx = toAdvance[i];\n\n                                        if (likely(all[idx].candidate.terms->cur().second.documents)) {\n                                                // See comments earliert for why this is possible\n\n                                                mergeParticipants.push_back(\n   {all[idx].candidate.ap,\n   all[idx].candidate.terms->cur().second,\n   scanner_registry_for(all[idx].idx).release()});\n                                        } else if (trace) {\n                                                SLog(\"No documents for candidate \", i, \"\\n\");\n                                        }\n                                }\n\n                                if (mergeParticipants.size()) {\n                                        enc->begin_term();\n                                        is->merge(mergeParticipants.data(), mergeParticipants.size(), enc.get());\n                                        enc->end_term(&tctx);\n\n                                        if (tctx.documents) {\n                                                terms->push_back({outTerm, tctx});\n                                                ++(defaultFieldStats->totalTerms);\n                                        }\n\n                                        for (uint16_t i{0}; i < mergeParticipants.size(); ++i) {\n                                                delete mergeParticipants[i].maskedDocsReg;\n                                        }\n                                }\n                        } else {\n                                // we got to merge-sort across different codecs and output to an encoder of a different, potentially, codec\n                                for (uint16_t i{0}; i < toAdvanceCnt; ++i) {\n                                        const auto idx = toAdvance[i];\n\n                                        if (likely(all[idx].candidate.terms->cur().second.documents)) {\n                                                // see earlier comments for why this is possible\n                                                auto ap  = all[idx].candidate.ap;\n                                                auto dec = ap->new_decoder(all[idx].candidate.terms->cur().second);\n                                                auto it  = dec->new_iterator();\n                                                auto reg = scanner_registry_for(all[idx].idx).release();\n\n                                                EXPECT(reg);\n                                                it->next();\n                                                decodersV.push_back({{dec, it}, reg});\n                                        } else if (trace) {\n                                                SLog(\"No documents for candidate \", i, \"\\n\");\n                                        }\n                                }\n\n                                if (uint16_t rem = decodersV.size()) {\n                                        auto     decoders = decodersV.data();\n                                        uint16_t toAdvance[128];\n\n                                        EXPECT(sizeof_array(toAdvance) >= decodersV.size());\n\n                                        // TODO: just use a Switch::priority_queue<>\n                                        enc->begin_term();\n                                        for (;;) {\n                                                uint16_t toAdvanceCnt{1};\n                                                auto     lowestDID = decoders[0].first.second->curDocument.id;\n\n                                                toAdvance[0] = 0;\n                                                for (uint16_t i{1}; i < rem; ++i) {\n   const auto id = decoders[i].first.second->curDocument.id;\n\n   if (id < lowestDID) {\n   lowestDID    = id;\n   toAdvanceCnt = 1;\n   toAdvance[0] = i;\n   } else if (id == lowestDID) {\n   toAdvance[toAdvanceCnt++] = i;\n   }\n                                                }\n\n                                                // always choose the first because they are always sorted by gen DESC\n\n                                                if (trace) {\n   SLog(\"Lowest = \", lowestDID, \", masked = \", decoders[toAdvance[0]].second->test(lowestDID), \"\\n\");\n                                                }\n\n                                                if (!decoders[toAdvance[0]].second->test(lowestDID)) {\n   auto       it   = decoders[toAdvance[0]].first.second;\n   const auto freq = it->freq;\n\n   if (freq > termHitsCapacity) {\n   if (termHitsStorage) {\n   std::free(termHitsStorage);\n   }\n\n   termHitsCapacity = freq + 128;\n   termHitsStorage  = (term_hit *)malloc(sizeof(term_hit) * termHitsCapacity);\n   }\n\n   enc->begin_document(lowestDID);\n   it->materialize_hits(&dws /* dummy */, termHitsStorage);\n\n   for (uint32_t i{0}; i < freq; ++i) {\n   const auto &th    = termHitsStorage[i];\n   const auto  bytes = (uint8_t *)&th.payload;\n\n   enc->new_hit(th.pos, {bytes, th.payloadLen});\n   }\n   enc->end_document();\n\n   ++(defaultFieldStats->sumTermsDocs);\n   defaultFieldStats->sumTermHits += freq;\n                                                }\n\n                                                do {\n   const auto idx = toAdvance[--toAdvanceCnt];\n   auto       it  = decoders[idx].first.second;\n\n   if (it->next() == DocIDsEND) {\n   delete it;\n   delete decoders[idx].first.first;\n   delete decoders[idx].second;\n\n   if (!--rem) {\n   goto l10;\n   }\n\n   memmove(decoders + idx, decoders + idx + 1, (rem - idx) * sizeof(decoders[0]));\n   }\n                                                } while (toAdvanceCnt);\n                                        }\n\n                                l10:\n                                        decodersV.clear();\n                                        enc->end_term(&tctx);\n\n                                        if (tctx.documents) {\n                                                terms->push_back({outTerm, tctx});\n                                                ++(defaultFieldStats->totalTerms);\n                                        }\n                                }\n                        }\n                }\n\n                if (flushFreq && is->indexOut.size() > flushFreq) {\n                        // TODO: support pending\n                }\n\n                do {\n                        const auto idx   = toAdvance[--toAdvanceCnt];\n                        auto       terms = all[idx].candidate.terms;\n\n                        terms->next();\n                        if (terms->done()) {\n                                if (!--rem) {\n                                        goto l1;\n                                }\n\n                                memmove(all + idx, all + idx + 1, (rem - idx) * sizeof(all[0]));\n                        }\n                } while (toAdvanceCnt);\n        }\nl1:;\n}\n\nstd::vector<std::pair<uint64_t, Trinity::MergeCandidatesCollection::IndexSourceRetention>>\nTrinity::MergeCandidatesCollection::consider_tracked_sources(std::vector<uint64_t> trackedSources) {\n        std::unordered_set<uint64_t>                           candidatesGens;\n        std::vector<std::pair<uint64_t, IndexSourceRetention>> res;\n        const auto                                             cnt = trackedSources.size();\n        uint32_t                                               lastNotCandidateIdx{UINT32_MAX};\n\n        std::sort(trackedSources.begin(), trackedSources.end());\n\n        for (const auto &it : candidates) {\n                candidatesGens.insert(it.gen);\n\t}\n\n        for (uint32_t i{0}; i < cnt; ++i) {\n                const auto gen = trackedSources[i];\n\n                if (!candidatesGens.count(gen)) {\n                        lastNotCandidateIdx = i;\n                        res.push_back({gen, IndexSourceRetention::RetainAll});\n                        continue;\n                } else if (lastNotCandidateIdx < i) {\n                        // if there is 1+ other tracked sources, and any of those sources is NOT in candidatesGens, we need to retain the updated documentIDs\n                        res.push_back({gen, IndexSourceRetention::RetainDocumentIDsUpdates});\n                } else {\n                        res.push_back({gen, IndexSourceRetention::Delete});\n\t\t}\n        }\n\n        return res;\n}\n",
    "file_path": "data\\preprocessed\\phaistos-networks_Trinity__merge.cpp",
    "file_name": "phaistos-networks_Trinity__merge.cpp",
    "language": "cpp"
  },
  {
    "text": "// Copyright (c) 2015 The Bitcoin Core developers\n// Distributed under the MIT software license, see the accompanying\n// file COPYING or https://example.com/path\n\n#include <vector>\n#include \"prevector.h\"\n#include \"random.h\"\n\n#include \"serialize.h\"\n#include \"streams.h\"\n\n#include \"test/test_pivx.h\"\n\n#include <boost/test/unit_test.hpp>\n\nBOOST_FIXTURE_TEST_SUITE(PrevectorTests, TestingSetup)\n\ntemplate<unsigned int N, typename T>\nclass prevector_tester {\n    typedef std::vector<T> realtype;\n    realtype real_vector;\n    realtype real_vector_alt;\n\n    typedef prevector<N, T> pretype;\n    pretype pre_vector;\n    pretype pre_vector_alt;\n\n    typedef typename pretype::size_type Size;\n\n    void test() {\n        const pretype& const_pre_vector = pre_vector;\n        BOOST_CHECK_EQUAL(real_vector.size(), pre_vector.size());\n        BOOST_CHECK_EQUAL(real_vector.empty(), pre_vector.empty());\n        for (Size s = 0; s < real_vector.size(); s++) {\n             BOOST_CHECK(real_vector[s] == pre_vector[s]);\n             BOOST_CHECK(&(pre_vector[s]) == &(pre_vector.begin()[s]));\n             BOOST_CHECK(&(pre_vector[s]) == &*(pre_vector.begin() + s));\n             BOOST_CHECK(&(pre_vector[s]) == &*((pre_vector.end() + s) - real_vector.size()));\n        }\n        // BOOST_CHECK(realtype(pre_vector) == real_vector);\n        BOOST_CHECK(pretype(real_vector.begin(), real_vector.end()) == pre_vector);\n        BOOST_CHECK(pretype(pre_vector.begin(), pre_vector.end()) == pre_vector);\n        size_t pos = 0;\n        for (const T& v  : pre_vector) {\n             BOOST_CHECK(v == real_vector[pos++]);\n        }\n        pos = 0;\n        for (const T& v : const_pre_vector) {\n             BOOST_CHECK(v == real_vector[pos++]);\n        }\n\n        CDataStream ss1(SER_DISK, 0);\n        CDataStream ss2(SER_DISK, 0);\n        ss1 << real_vector;\n        ss2 << pre_vector;\n        BOOST_CHECK_EQUAL(ss1.size(), ss2.size());\n        for (Size s = 0; s < ss1.size(); s++) {\n            BOOST_CHECK_EQUAL(ss1[s], ss2[s]);\n        }\n    }\n\npublic:\n    void resize(Size s) {\n        real_vector.resize(s);\n        BOOST_CHECK_EQUAL(real_vector.size(), s);\n        pre_vector.resize(s);\n        BOOST_CHECK_EQUAL(pre_vector.size(), s);\n        test();\n    }\n\n    void reserve(Size s) {\n        real_vector.reserve(s);\n        BOOST_CHECK(real_vector.capacity() >= s);\n        pre_vector.reserve(s);\n        BOOST_CHECK(pre_vector.capacity() >= s);\n        test();\n    }\n\n    void insert(Size position, const T& value) {\n        real_vector.insert(real_vector.begin() + position, value);\n        pre_vector.insert(pre_vector.begin() + position, value);\n        test();\n    }\n\n    void insert(Size position, Size count, const T& value) {\n        real_vector.insert(real_vector.begin() + position, count, value);\n        pre_vector.insert(pre_vector.begin() + position, count, value);\n        test();\n    }\n\n    template<typename I>\n    void insert_range(Size position, I first, I last) {\n        real_vector.insert(real_vector.begin() + position, first, last);\n        pre_vector.insert(pre_vector.begin() + position, first, last);\n        test();\n    }\n\n    void erase(Size position) {\n        real_vector.erase(real_vector.begin() + position);\n        pre_vector.erase(pre_vector.begin() + position);\n        test();\n    }\n\n    void erase(Size first, Size last) {\n        real_vector.erase(real_vector.begin() + first, real_vector.begin() + last);\n        pre_vector.erase(pre_vector.begin() + first, pre_vector.begin() + last);\n        test();\n    }\n\n    void update(Size pos, const T& value) {\n        real_vector[pos] = value;\n        pre_vector[pos] = value;\n        test();\n    }\n\n    void push_back(const T& value) {\n        real_vector.push_back(value);\n        pre_vector.push_back(value);\n        test();\n    }\n\n    void pop_back() {\n        real_vector.pop_back();\n        pre_vector.pop_back();\n        test();\n    }\n\n    void clear() {\n        real_vector.clear();\n        pre_vector.clear();\n    }\n\n    void assign(Size n, const T& value) {\n        real_vector.assign(n, value);\n        pre_vector.assign(n, value);\n    }\n\n    Size size() {\n        return real_vector.size();\n    }\n\n    Size capacity() {\n        return pre_vector.capacity();\n    }\n\n    void shrink_to_fit() {\n        pre_vector.shrink_to_fit();\n        test();\n    }\n\n    void swap() {\n        real_vector.swap(real_vector_alt);\n        pre_vector.swap(pre_vector_alt);\n        test();\n    }\n\n    void move() {\n        real_vector = std::move(real_vector_alt);\n        real_vector_alt.clear();\n        pre_vector = std::move(pre_vector_alt);\n        pre_vector_alt.clear();\n    }\n\n    void copy() {\n        real_vector = real_vector_alt;\n        pre_vector = pre_vector_alt;\n    }\n};\n\nBOOST_AUTO_TEST_CASE(PrevectorTestInt)\n{\n    for (int j = 0; j < 64; j++) {\n        prevector_tester<8, int> test;\n        for (int i = 0; i < 2048; i++) {\n            int r = InsecureRand32();\n            if ((r % 4) == 0) {\n                test.insert(InsecureRand32() % (test.size() + 1), InsecureRand32());\n            }\n            if (test.size() > 0 && ((r >> 2) % 4) == 1) {\n                test.erase(InsecureRand32() % test.size());\n            }\n            if (((r >> 4) % 8) == 2) {\n                int new_size = std::max<int>(0, std::min<int>(30, test.size() + (InsecureRand32() % 5) - 2));\n                test.resize(new_size);\n            }\n            if (((r >> 7) % 8) == 3) {\n                test.insert(InsecureRand32() % (test.size() + 1), 1 + (InsecureRand32() % 2), InsecureRand32());\n            }\n            if (((r >> 10) % 8) == 4) {\n                int del = std::min<int>(test.size(), 1 + (InsecureRand32() % 2));\n                int beg = InsecureRand32() % (test.size() + 1 - del);\n                test.erase(beg, beg + del);\n            }\n            if (((r >> 13) % 16) == 5) {\n                test.push_back(InsecureRand32());\n            }\n            if (test.size() > 0 && ((r >> 17) % 16) == 6) {\n                test.pop_back();\n            }\n            if (((r >> 21) % 32) == 7) {\n                int values[4];\n                int num = 1 + (InsecureRand32() % 4);\n                for (int i = 0; i < num; i++) {\n                    values[i] = InsecureRand32();\n                }\n                test.insert_range(InsecureRand32() % (test.size() + 1), values, values + num);\n            }\n            if (((r >> 26) % 32) == 8) {\n                int del = std::min<int>(test.size(), 1 + (InsecureRand32() % 4));\n                int beg = InsecureRand32() % (test.size() + 1 - del);\n                test.erase(beg, beg + del);\n            }\n            r = InsecureRand32();\n            if (r % 32 == 9) {\n                test.reserve(InsecureRand32() % 32);\n            }\n            if ((r >> 5) % 64 == 10) {\n                test.shrink_to_fit();\n            }\n            if (test.size() > 0) {\n                test.update(InsecureRand32() % test.size(), InsecureRand32());\n            }\n            if (((r >> 11) % 1024) == 11) {\n                test.clear();\n            }\n            if (((r >> 21) % 512) == 12) {\n                test.assign(InsecureRand32() % 32, InsecureRand32());\n            }\n            if (((r >> 15) % 8) == 3) {\n                test.swap();\n            }\n            if (((r >> 15) % 16) == 8) {\n                test.copy();\n            }\n            if (((r >> 15) % 32) == 18) {\n                test.move();\n            }\n        }\n    }\n}\n\nBOOST_AUTO_TEST_SUITE_END()\n",
    "file_path": "data\\preprocessed\\RapidsOfficial_Rapids__src_test_prevector_tests.cpp",
    "file_name": "RapidsOfficial_Rapids__src_test_prevector_tests.cpp",
    "language": "cpp"
  },
  {
    "text": "//\n//  q5.cpp\n//  Algorithm\n//\n//  Created by Mohd Shoaib Rayeen on 05/11/18.\n//  Copyright  2018 Shoaib Rayeen. All rights reserved.\n//\n\n#include <bits/stdc++.h>\nusing namespace std;\n\ndouble diff( double n , double mid ) {\n    if (n > (mid*mid*mid)) {\n        return (n-(mid*mid*mid));\n    }\n    else {\n        return ((mid*mid*mid) - n);\n    }\n}\n\ndouble cubicRoot(double n) {\n    double start = 0, end = n;\n    double e = 0.0000001;\n    while (true)\n    {\n        double mid = (start + end)/2;\n        double error = diff(n, mid);\n        if (error <= e) {\n            return mid;\n        }\n        if ((mid*mid*mid) > n) {\n            end = mid;\n        }\n        else {\n            start = mid;\n        }\n    }\n}\n\nint main() {\n    double num;\n    cout << \"\\nEnter Number\\t:\\t\";\n    cin >> num;\n    cout << \"\\nCubic Root\\t:\\t\" << cubicRoot(num);\n    return 0;\n}\n",
    "file_path": "data\\preprocessed\\shoaibrayeen_Data-Structures-and-Algorithms__Cubic_Root_of_A_Number_code_1.cpp",
    "file_name": "shoaibrayeen_Data-Structures-and-Algorithms__Cubic_Root_of_A_Number_code_1.cpp",
    "language": "cpp"
  },
  {
    "text": "#include <iostream>\n\nusing namespace std;\n\nint sumByFormula(int n)\n{\n    int sum = 0;\n    sum = ((n + 1) * (n + 2)) / 2;\n    return sum;\n}\n\nint sumByAdding(int a[], int n)\n{\n    int i, sum = 0;\n    for (i = 0; i < n; i++)\n        sum = sum + a[i];\n    return sum;\n}\nint main()\n{\n    int n, i, sum1, sum2 = 0;\n    cout << \"enter no. of terms\";\n    cin >> n;\n    int a[n];\n\n    //input terms of an array\n    for (i = 0; i < n; i++)\n        cin >> a[i];\n\n    //sum by formula\n    sum1 = sumByFormula(n);\n\n    //sum by adding\n    sum2 = sumByAdding(a, n);\n\n    cout << \"missing number = \" << sum1 - sum2;\n    return 0;\n}\n",
    "file_path": "data\\preprocessed\\shoaibrayeen_Programmers-Community__Data_Structure_Array_Or_Vector_Find_the_Missing_Number_SolutionByPushpneet.cpp",
    "file_name": "shoaibrayeen_Programmers-Community__Data_Structure_Array_Or_Vector_Find_the_Missing_Number_SolutionByPushpneet.cpp",
    "language": "cpp"
  },
  {
    "text": "#include \"stdafx.h\"\n#include \"unzip.h\"\n\n\n// THIS FILE is almost entirely based upon code by Jean-loup Gailly\n// and Mark Adler. It has been modified by Lucian Wischik.\n// The modifications were: incorporate the bugfixes of 1.1.4, allow\n// unzipping to/from handles/pipes/files/memory, encryption, unicode,\n// a windowsish api, and putting everything into a single .cpp file.\n// The original code may be found at https://example.com/path\n// The original copyright text follows.\n//\n//\n//\n// zlib.h -- interface of the 'zlib' general purpose compression library\n//  version 1.1.3, July 9th, 1998\n//\n//  Copyright (C) 1995-1998 Jean-loup Gailly and Mark Adler\n//\n//  This software is provided 'as-is', without any express or implied\n//  warranty.  In no event will the authors be held liable for any damages\n//  arising from the use of this software.\n//\n//  Permission is granted to anyone to use this software for any purpose,\n//  including commercial applications, and to alter it and redistribute it\n//  freely, subject to the following restrictions:\n//\n//  1. The origin of this software must not be misrepresented; you must not\n//     claim that you wrote the original software. If you use this software\n//     in a product, an acknowledgment in the product documentation would be\n//     appreciated but is not required.\n//  2. Altered source versions must be plainly marked as such, and must not be\n//     misrepresented as being the original software.\n//  3. This notice may not be removed or altered from any source distribution.\n//\n//  Jean-loup Gailly        Mark Adler\n//  user@example.com          madler@alumni.caltech.edu\n//\n//\n//  The data format used by the zlib library is described by RFCs (Request for\n//  Comments) 1950 to 1952 in the files https://example.com/path\n//  (zlib format), rfc1951.txt (deflate format) and rfc1952.txt (gzip format).\n//\n//\n//     The 'zlib' compression library provides in-memory compression and\n//  decompression functions, including integrity checks of the uncompressed\n//  data.  This version of the library supports only one compression method\n//  (deflation) but other algorithms will be added later and will have the same\n//  stream interface.\n//\n//     Compression can be done in a single step if the buffers are large\n//  enough (for example if an input file is mmap'ed), or can be done by\n//  repeated calls of the compression function.  In the latter case, the\n//  application must provide more input and/or consume the output\n//  (providing more output space) before each call.\n//\n//     The library also supports reading and writing files in gzip (.gz) format\n//  with an interface similar to that of stdio.\n//\n//     The library does not install any signal handler. The decoder checks\n//  the consistency of the compressed data, so the library should never\n//  crash even in case of corrupted input.\n//\n// for more info about .ZIP format, see https://example.com/path\n//   PkWare has also a specification at https://example.com/path\n\n#define ZIP_HANDLE   1\n#define ZIP_FILENAME 2\n#define ZIP_MEMORY   3\n\n\n#define zmalloc(len) malloc(len)\n\n#define zfree(p) free(p)\n\n/*\nvoid *zmalloc(unsigned int len)\n{ char *buf = new char[len+32];\n  for (int i=0; i<16; i++)\n  { buf[i]=i;\n    buf[len+31-i]=i;\n  }\n  *((unsigned int*)buf) = len;\n  char c[1000]; wsprintf(c,\"malloc 0x%lx  - %lu\",buf+16,len);\n  OutputDebugString(c);\n  return buf+16;\n}\n\nvoid zfree(void *buf)\n{ char c[1000]; wsprintf(c,\"free   0x%lx\",buf);\n  OutputDebugString(c);\n  char *p = ((char*)buf)-16;\n  unsigned int len = *((unsigned int*)p);\n  bool blown=false;\n  for (int i=0; i<16; i++)\n  { char lo = p[i];\n    char hi = p[len+31-i];\n    if (hi!=i || (lo!=i && i>4)) blown=true;\n  }\n  if (blown)\n  { OutputDebugString(\"BLOWN!!!\");\n  }\n  delete[] p;\n}\n*/\n\n\ntypedef struct tm_unz_s\n{ unsigned int tm_sec;            // seconds after the minute - [0,59]\n  unsigned int tm_min;            // minutes after the hour - [0,59]\n  unsigned int tm_hour;           // hours since midnight - [0,23]\n  unsigned int tm_mday;           // day of the month - [1,31]\n  unsigned int tm_mon;            // months since January - [0,11]\n  unsigned int tm_year;           // years - [1980..2044]\n} tm_unz;\n\n\n// unz_global_info structure contain global data about the ZIPfile\ntypedef struct unz_global_info_s\n{ unsigned long number_entry;         // total number of entries in the central dir on this disk\n  unsigned long size_comment;         // size of the global comment of the zipfile\n} unz_global_info;\n\n// unz_file_info contain information about a file in the zipfile\ntypedef struct unz_file_info_s\n{ unsigned long version;              // version made by                 2 bytes\n  unsigned long version_needed;       // version needed to extract       2 bytes\n  unsigned long flag;                 // general purpose bit flag        2 bytes\n  unsigned long compression_method;   // compression method              2 bytes\n  unsigned long dosDate;              // last mod file date in Dos fmt   4 bytes\n  unsigned long crc;                  // crc-32                          4 bytes\n  unsigned long compressed_size;      // compressed size                 4 bytes\n  unsigned long uncompressed_size;    // uncompressed size               4 bytes\n  unsigned long size_filename;        // filename length                 2 bytes\n  unsigned long size_file_extra;      // extra field length              2 bytes\n  unsigned long size_file_comment;    // file comment length             2 bytes\n  unsigned long disk_num_start;       // disk number start               2 bytes\n  unsigned long internal_fa;          // internal file attributes        2 bytes\n  unsigned long external_fa;          // external file attributes        4 bytes\n  tm_unz tmu_date;\n} unz_file_info;\n\n\n#define UNZ_OK                  (0)\n#define UNZ_END_OF_LIST_OF_FILE (-100)\n#define UNZ_ERRNO               (Z_ERRNO)\n#define UNZ_EOF                 (0)\n#define UNZ_PARAMERROR          (-102)\n#define UNZ_BADZIPFILE          (-103)\n#define UNZ_INTERNALERROR       (-104)\n#define UNZ_CRCERROR            (-105)\n#define UNZ_PASSWORD            (-106)\n\n\n#define ZLIB_VERSION \"1.1.3\"\n\n\n// Allowed flush values; see deflate() for details\n#define Z_NO_FLUSH      0\n#define Z_SYNC_FLUSH    2\n#define Z_FULL_FLUSH    3\n#define Z_FINISH        4\n\n\n// compression levels\n#define Z_NO_COMPRESSION         0\n#define Z_BEST_SPEED             1\n#define Z_BEST_COMPRESSION       9\n#define Z_DEFAULT_COMPRESSION  (-1)\n\n// compression strategy; see deflateInit2() for details\n#define Z_FILTERED            1\n#define Z_HUFFMAN_ONLY        2\n#define Z_DEFAULT_STRATEGY    0\n\n// Possible values of the data_type field\n#define Z_BINARY   0\n#define Z_ASCII    1\n#define Z_UNKNOWN  2\n\n// The deflate compression method (the only one supported in this version)\n#define Z_DEFLATED   8\n\n// for initializing zalloc, zfree, opaque\n#define Z_NULL  0\n\n// case sensitivity when searching for filenames\n#define CASE_SENSITIVE 1\n#define CASE_INSENSITIVE 2\n\n\n// Return codes for the compression/decompression functions. Negative\n// values are errors, positive values are used for special but normal events.\n#define Z_OK            0\n#define Z_STREAM_END    1\n#define Z_NEED_DICT     2\n#define Z_ERRNO        (-1)\n#define Z_STREAM_ERROR (-2)\n#define Z_DATA_ERROR   (-3)\n#define Z_MEM_ERROR    (-4)\n#define Z_BUF_ERROR    (-5)\n#define Z_VERSION_ERROR (-6)\n\n\n// Basic data types\ntypedef unsigned char  Byte;  // 8 bits\ntypedef unsigned int   uInt;  // 16 bits or more\ntypedef unsigned long  uLong; // 32 bits or more\ntypedef void *voidpf;\ntypedef void     *voidp;\ntypedef long z_off_t;\n\n\ntypedef voidpf (*alloc_func) (voidpf opaque, uInt items, uInt size);\ntypedef void   (*free_func)  (voidpf opaque, voidpf address);\n\nstruct internal_state;\n\ntypedef struct z_stream_s {\n    Byte    *next_in;  // next input byte\n    uInt     avail_in;  // number of bytes available at next_in\n    uLong    total_in;  // total nb of input bytes read so far\n\n    Byte    *next_out; // next output byte should be put there\n    uInt     avail_out; // remaining free space at next_out\n    uLong    total_out; // total nb of bytes output so far\n\n    char     *msg;      // last error message, NULL if no error\n    struct internal_state *state; // not visible by applications\n\n    alloc_func zalloc;  // used to allocate the internal state\n    free_func  zfree;   // used to free the internal state\n    voidpf     opaque;  // private data object passed to zalloc and zfree\n\n    int     data_type;  // best guess about the data type: ascii or binary\n    uLong   adler;      // adler32 value of the uncompressed data\n    uLong   reserved;   // reserved for future use\n} z_stream;\n\ntypedef z_stream *z_streamp;\n\n\n//   The application must update next_in and avail_in when avail_in has\n//   dropped to zero. It must update next_out and avail_out when avail_out\n//   has dropped to zero. The application must initialize zalloc, zfree and\n//   opaque before calling the init function. All other fields are set by the\n//   compression library and must not be updated by the application.\n//\n//   The opaque value provided by the application will be passed as the first\n//   parameter for calls of zalloc and zfree. This can be useful for custom\n//   memory management. The compression library attaches no meaning to the\n//   opaque value.\n//\n//   zalloc must return Z_NULL if there is not enough memory for the object.\n//   If zlib is used in a multi-threaded application, zalloc and zfree must be\n//   thread safe.\n//\n//   The fields total_in and total_out can be used for statistics or\n//   progress reports. After compression, total_in holds the total size of\n//   the uncompressed data and may be saved for use in the decompressor\n//   (particularly if the decompressor wants to decompress everything in\n//   a single step).\n//\n\n\n// basic functions\n\nconst char *zlibVersion ();\n// The application can compare zlibVersion and ZLIB_VERSION for consistency.\n// If the first character differs, the library code actually used is\n// not compatible with the zlib.h header file used by the application.\n// This check is automatically made by inflateInit.\n\n\nint inflate (z_streamp strm, int flush);\n//\n//    inflate decompresses as much data as possible, and stops when the input\n//  buffer becomes empty or the output buffer becomes full. It may some\n//  introduce some output latency (reading input without producing any output)\n//  except when forced to flush.\n//\n//  The detailed semantics are as follows. inflate performs one or both of the\n//  following actions:\n//\n//  - Decompress more input starting at next_in and update next_in and avail_in\n//    accordingly. If not all input can be processed (because there is not\n//    enough room in the output buffer), next_in is updated and processing\n//    will resume at this point for the next call of inflate().\n//\n//  - Provide more output starting at next_out and update next_out and avail_out\n//    accordingly.  inflate() provides as much output as possible, until there\n//    is no more input data or no more space in the output buffer (see below\n//    about the flush parameter).\n//\n//  Before the call of inflate(), the application should ensure that at least\n//  one of the actions is possible, by providing more input and/or consuming\n//  more output, and updating the next_* and avail_* values accordingly.\n//  The application can consume the uncompressed output when it wants, for\n//  example when the output buffer is full (avail_out == 0), or after each\n//  call of inflate(). If inflate returns Z_OK and with zero avail_out, it\n//  must be called again after making room in the output buffer because there\n//  might be more output pending.\n//\n//    If the parameter flush is set to Z_SYNC_FLUSH, inflate flushes as much\n//  output as possible to the output buffer. The flushing behavior of inflate is\n//  not specified for values of the flush parameter other than Z_SYNC_FLUSH\n//  and Z_FINISH, but the current implementation actually flushes as much output\n//  as possible anyway.\n//\n//    inflate() should normally be called until it returns Z_STREAM_END or an\n//  error. However if all decompression is to be performed in a single step\n//  (a single call of inflate), the parameter flush should be set to\n//  Z_FINISH. In this case all pending input is processed and all pending\n//  output is flushed; avail_out must be large enough to hold all the\n//  uncompressed data. (The size of the uncompressed data may have been saved\n//  by the compressor for this purpose.) The next operation on this stream must\n//  be inflateEnd to deallocate the decompression state. The use of Z_FINISH\n//  is never required, but can be used to inform inflate that a faster routine\n//  may be used for the single inflate() call.\n//\n//     If a preset dictionary is needed at this point (see inflateSetDictionary\n//  below), inflate sets strm-adler to the adler32 checksum of the\n//  dictionary chosen by the compressor and returns Z_NEED_DICT; otherwise\n//  it sets strm->adler to the adler32 checksum of all output produced\n//  so far (that is, total_out bytes) and returns Z_OK, Z_STREAM_END or\n//  an error code as described below. At the end of the stream, inflate()\n//  checks that its computed adler32 checksum is equal to that saved by the\n//  compressor and returns Z_STREAM_END only if the checksum is correct.\n//\n//    inflate() returns Z_OK if some progress has been made (more input processed\n//  or more output produced), Z_STREAM_END if the end of the compressed data has\n//  been reached and all uncompressed output has been produced, Z_NEED_DICT if a\n//  preset dictionary is needed at this point, Z_DATA_ERROR if the input data was\n//  corrupted (input stream not conforming to the zlib format or incorrect\n//  adler32 checksum), Z_STREAM_ERROR if the stream structure was inconsistent\n//  (for example if next_in or next_out was NULL), Z_MEM_ERROR if there was not\n//  enough memory, Z_BUF_ERROR if no progress is possible or if there was not\n//  enough room in the output buffer when Z_FINISH is used. In the Z_DATA_ERROR\n//  case, the application may then call inflateSync to look for a good\n//  compression block.\n//\n\n\nint inflateEnd (z_streamp strm);\n//\n//     All dynamically allocated data structures for this stream are freed.\n//   This function discards any unprocessed input and does not flush any\n//   pending output.\n//\n//     inflateEnd returns Z_OK if success, Z_STREAM_ERROR if the stream state\n//   was inconsistent. In the error case, msg may be set but then points to a\n//   static string (which must not be deallocated).\n\n                        // Advanced functions\n\n//  The following functions are needed only in some special applications.\n\n\nint inflateSetDictionary (z_streamp strm,\n                                             const Byte *dictionary,\n                                             uInt  dictLength);\n//\n//     Initializes the decompression dictionary from the given uncompressed byte\n//   sequence. This function must be called immediately after a call of inflate\n//   if this call returned Z_NEED_DICT. The dictionary chosen by the compressor\n//   can be determined from the Adler32 value returned by this call of\n//   inflate. The compressor and decompressor must use exactly the same\n//   dictionary.\n//\n//     inflateSetDictionary returns Z_OK if success, Z_STREAM_ERROR if a\n//   parameter is invalid (such as NULL dictionary) or the stream state is\n//   inconsistent, Z_DATA_ERROR if the given dictionary doesn't match the\n//   expected one (incorrect Adler32 value). inflateSetDictionary does not\n//   perform any decompression: this will be done by subsequent calls of\n//   inflate().\n\n\nint inflateSync (z_streamp strm);\n//\n//    Skips invalid compressed data until a full flush point can be found, or until all\n//  available input is skipped. No output is provided.\n//\n//    inflateSync returns Z_OK if a full flush point has been found, Z_BUF_ERROR\n//  if no more input was provided, Z_DATA_ERROR if no flush point has been found,\n//  or Z_STREAM_ERROR if the stream structure was inconsistent. In the success\n//  case, the application may save the current current value of total_in which\n//  indicates where valid compressed data was found. In the error case, the\n//  application may repeatedly call inflateSync, providing more input each time,\n//  until success or end of the input data.\n\n\nint inflateReset (z_streamp strm);\n//     This function is equivalent to inflateEnd followed by inflateInit,\n//   but does not free and reallocate all the internal decompression state.\n//   The stream will keep attributes that may have been set by inflateInit2.\n//\n//      inflateReset returns Z_OK if success, or Z_STREAM_ERROR if the source\n//   stream state was inconsistent (such as zalloc or state being NULL).\n//\n\n\n// checksum functions\n// These functions are not related to compression but are exported\n// anyway because they might be useful in applications using the\n// compression library.\n\nuLong adler32 (uLong adler, const Byte *buf, uInt len);\n//     Update a running Adler-32 checksum with the bytes buf[0..len-1] and\n//   return the updated checksum. If buf is NULL, this function returns\n//   the required initial value for the checksum.\n//   An Adler-32 checksum is almost as reliable as a CRC32 but can be computed\n//   much faster. Usage example:\n//\n//     uLong adler = adler32(0L, Z_NULL, 0);\n//\n//     while (read_buffer(buffer, length) != EOF) {\n//       adler = adler32(adler, buffer, length);\n//     }\n//     if (adler != original_adler) error();\n\nuLong ucrc32   (uLong crc, const Byte *buf, uInt len);\n//     Update a running crc with the bytes buf[0..len-1] and return the updated\n//   crc. If buf is NULL, this function returns the required initial value\n//   for the crc. Pre- and post-conditioning (one's complement) is performed\n//   within this function so it shouldn't be done by the application.\n//   Usage example:\n//\n//     uLong crc = crc32(0L, Z_NULL, 0);\n//\n//     while (read_buffer(buffer, length) != EOF) {\n//       crc = crc32(crc, buffer, length);\n//     }\n//     if (crc != original_crc) error();\n\n\nconst char   *zError           (int err);\nint           inflateSyncPoint (z_streamp z);\nconst uLong *get_crc_table    (void);\n\n\ntypedef unsigned char  uch;\ntypedef uch uchf;\ntypedef unsigned short ush;\ntypedef ush ushf;\ntypedef unsigned long  ulg;\n\n\nconst char * const z_errmsg[10] = { // indexed by 2-zlib_error\n\"need dictionary\",     // Z_NEED_DICT       2\n\"stream end\",          // Z_STREAM_END      1\n\"\",                    // Z_OK              0\n\"file error\",          // Z_ERRNO         (-1)\n\"stream error\",        // Z_STREAM_ERROR  (-2)\n\"data error\",          // Z_DATA_ERROR    (-3)\n\"insufficient memory\", // Z_MEM_ERROR     (-4)\n\"buffer error\",        // Z_BUF_ERROR     (-5)\n\"incompatible version\",// Z_VERSION_ERROR (-6)\n\"\"};\n\n\n#define ERR_MSG(err) z_errmsg[Z_NEED_DICT-(err)]\n\n#define ERR_RETURN(strm,err) \\\n  return (strm->msg = (char*)ERR_MSG(err), (err))\n// To be used only when the state is known to be valid\n\n        // common constants\n\n\n#define STORED_BLOCK 0\n#define STATIC_TREES 1\n#define DYN_TREES    2\n// The three kinds of block type\n\n#define MIN_MATCH  3\n#define MAX_MATCH  258\n// The minimum and maximum match lengths\n\n#define PRESET_DICT 0x20 // preset dictionary flag in zlib header\n\n        // target dependencies\n\n#define OS_CODE  0x0b  // Window 95 & Windows NT\n\n\n         // functions\n\n#define zmemzero(dest, len) memset(dest, 0, len)\n\n// Diagnostic functions\n#define LuAssert(cond,msg)\n#define LuTrace(x)\n#define LuTracev(x)\n#define LuTracevv(x)\n#define LuTracec(c,x)\n#define LuTracecv(c,x)\n\n\ntypedef uLong (*check_func) (uLong check, const Byte *buf, uInt len);\nvoidpf zcalloc (voidpf opaque, unsigned items, unsigned size);\nvoid   zcfree  (voidpf opaque, voidpf ptr);\n\n#define ZALLOC(strm, items, size) \\\n           (*((strm)->zalloc))((strm)->opaque, (items), (size))\n#define ZFREE(strm, addr)  (*((strm)->zfree))((strm)->opaque, (voidpf)(addr))\n\n//void ZFREE(z_streamp strm,voidpf addr)\n//{ *((strm)->zfree))((strm)->opaque, addr);\n//}\n\n#define TRY_FREE(s, p) {if (p) ZFREE(s, p);}\n\n\n// Huffman code lookup table entry--this entry is four bytes for machines\n// that have 16-bit pointers (e.g. PC's in the small or medium model).\n\n\ntypedef struct inflate_huft_s inflate_huft;\n\nstruct inflate_huft_s {\n  union {\n    struct {\n      Byte Exop;        // number of extra bits or operation\n      Byte Bits;        // number of bits in this code or subcode\n    } what;\n    uInt pad;           // pad structure to a power of 2 (4 bytes for\n  } word;               //  16-bit, 8 bytes for 32-bit int's)\n  uInt base;            // literal, length base, distance base, or table offset\n};\n\n// Maximum size of dynamic tree.  The maximum found in a long but non-\n//   exhaustive search was 1004 huft structures (850 for length/literals\n//   and 154 for distances, the latter actually the result of an\n//   exhaustive search).  The actual maximum is not known, but the\n//   value below is more than safe.\n#define MANY 1440\n\nint inflate_trees_bits (\n    uInt *,                    // 19 code lengths\n    uInt *,                    // bits tree desired/actual depth\n    inflate_huft * *,       // bits tree result\n    inflate_huft *,             // space for trees\n    z_streamp);                // for messages\n\nint inflate_trees_dynamic (\n    uInt,                       // number of literal/length codes\n    uInt,                       // number of distance codes\n    uInt *,                    // that many (total) code lengths\n    uInt *,                    // literal desired/actual bit depth\n    uInt *,                    // distance desired/actual bit depth\n    inflate_huft * *,       // literal/length tree result\n    inflate_huft * *,       // distance tree result\n    inflate_huft *,             // space for trees\n    z_streamp);                // for messages\n\nint inflate_trees_fixed (\n    uInt *,                    // literal desired/actual bit depth\n    uInt *,                    // distance desired/actual bit depth\n    const inflate_huft * *,       // literal/length tree result\n    const inflate_huft * *,       // distance tree result\n    z_streamp);                // for memory allocation\n\n\nstruct inflate_blocks_state;\ntypedef struct inflate_blocks_state inflate_blocks_statef;\n\ninflate_blocks_statef * inflate_blocks_new (\n    z_streamp z,\n    check_func c,               // check function\n    uInt w);                   // window size\n\nint inflate_blocks (\n    inflate_blocks_statef *,\n    z_streamp ,\n    int);                      // initial return code\n\nvoid inflate_blocks_reset (\n    inflate_blocks_statef *,\n    z_streamp ,\n    uLong *);                  // check value on output\n\nint inflate_blocks_free (\n    inflate_blocks_statef *,\n    z_streamp);\n\nvoid inflate_set_dictionary (\n    inflate_blocks_statef *s,\n    const Byte *d,  // dictionary\n    uInt  n);       // dictionary length\n\nint inflate_blocks_sync_point (\n    inflate_blocks_statef *s);\n\n\nstruct inflate_codes_state;\ntypedef struct inflate_codes_state inflate_codes_statef;\n\ninflate_codes_statef *inflate_codes_new (\n    uInt, uInt,\n    const inflate_huft *, const inflate_huft *,\n    z_streamp );\n\nint inflate_codes (\n    inflate_blocks_statef *,\n    z_streamp ,\n    int);\n\nvoid inflate_codes_free (\n    inflate_codes_statef *,\n    z_streamp );\n\n\ntypedef enum {\n      IBM_TYPE,     // get type bits (3, including end bit)\n      IBM_LENS,     // get lengths for stored\n      IBM_STORED,   // processing stored block\n      IBM_TABLE,    // get table lengths\n      IBM_BTREE,    // get bit lengths tree for a dynamic block\n      IBM_DTREE,    // get length, distance trees for a dynamic block\n      IBM_CODES,    // processing fixed or dynamic block\n      IBM_DRY,      // output remaining window bytes\n      IBM_DONE,     // finished last block, done\n      IBM_BAD}      // got a data error--stuck here\ninflate_block_mode;\n\n// inflate blocks semi-private state\nstruct inflate_blocks_state {\n\n  // mode\n  inflate_block_mode  mode;     // current inflate_block mode\n\n  // mode dependent information\n  union {\n    uInt left;          // if STORED, bytes left to copy\n    struct {\n      uInt table;               // table lengths (14 bits)\n      uInt index;               // index into blens (or border)\n      uInt *blens;             // bit lengths of codes\n      uInt bb;                  // bit length tree depth\n      inflate_huft *tb;         // bit length decoding tree\n    } trees;            // if DTREE, decoding info for trees\n    struct {\n      inflate_codes_statef\n         *codes;\n    } decode;           // if CODES, current state\n  } sub;                // submode\n  uInt last;            // true if this block is the last block\n\n  // mode independent information\n  uInt bitk;            // bits in bit buffer\n  uLong bitb;           // bit buffer\n  inflate_huft *hufts;  // single malloc for tree space\n  Byte *window;        // sliding window\n  Byte *end;           // one byte after sliding window\n  Byte *read;          // window read pointer\n  Byte *write;         // window write pointer\n  check_func checkfn;   // check function\n  uLong check;          // check on output\n\n};\n\n\n// defines for inflate input/output\n//   update pointers and return\n#define UPDBITS {s->bitb=b;s->bitk=k;}\n#define UPDIN {z->avail_in=n;z->total_in+=(uLong)(p-z->next_in);z->next_in=p;}\n#define UPDOUT {s->write=q;}\n#define UPDATE {UPDBITS UPDIN UPDOUT}\n#define LEAVE {UPDATE return inflate_flush(s,z,r);}\n//   get bytes and bits\n#define LOADIN {p=z->next_in;n=z->avail_in;b=s->bitb;k=s->bitk;}\n#define NEEDBYTE {if(n)r=Z_OK;else LEAVE}\n#define NEXTBYTE (n--,*p++)\n#define NEEDBITS(j) {while(k<(j)){NEEDBYTE;b|=((uLong)NEXTBYTE)<<k;k+=8;}}\n#define DUMPBITS(j) {b>>=(j);k-=(j);}\n//   output bytes\n#define WAVAIL (uInt)(q<s->read?s->read-q-1:s->end-q)\n#define LOADOUT {q=s->write;m=(uInt)WAVAIL;m;}\n#define WRAP {if(q==s->end&&s->read!=s->window){q=s->window;m=(uInt)WAVAIL;}}\n#define FLUSH {UPDOUT r=inflate_flush(s,z,r); LOADOUT}\n#define NEEDOUT {if(m==0){WRAP if(m==0){FLUSH WRAP if(m==0) LEAVE}}r=Z_OK;}\n#define OUTBYTE(a) {*q++=(Byte)(a);m--;}\n//   load local pointers\n#define LOAD {LOADIN LOADOUT}\n\n// masks for lower bits (size given to avoid silly warnings with Visual C++)\n// And'ing with mask[n] masks the lower n bits\nconst uInt inflate_mask[17] = {\n    0x0000,\n    0x0001, 0x0003, 0x0007, 0x000f, 0x001f, 0x003f, 0x007f, 0x00ff,\n    0x01ff, 0x03ff, 0x07ff, 0x0fff, 0x1fff, 0x3fff, 0x7fff, 0xffff\n};\n\n// copy as much as possible from the sliding window to the output area\nint inflate_flush (inflate_blocks_statef *, z_streamp, int);\n\nint inflate_fast (uInt, uInt, const inflate_huft *, const inflate_huft *, inflate_blocks_statef *, z_streamp );\n\n\nconst uInt fixed_bl = 9;\nconst uInt fixed_bd = 5;\nconst inflate_huft fixed_tl[] = {\n    {{{96,7}},256}, {{{0,8}},80}, {{{0,8}},16}, {{{84,8}},115},\n    {{{82,7}},31}, {{{0,8}},112}, {{{0,8}},48}, {{{0,9}},192},\n    {{{80,7}},10}, {{{0,8}},96}, {{{0,8}},32}, {{{0,9}},160},\n    {{{0,8}},0}, {{{0,8}},128}, {{{0,8}},64}, {{{0,9}},224},\n    {{{80,7}},6}, {{{0,8}},88}, {{{0,8}},24}, {{{0,9}},144},\n    {{{83,7}},59}, {{{0,8}},120}, {{{0,8}},56}, {{{0,9}},208},\n    {{{81,7}},17}, {{{0,8}},104}, {{{0,8}},40}, {{{0,9}},176},\n    {{{0,8}},8}, {{{0,8}},136}, {{{0,8}},72}, {{{0,9}},240},\n    {{{80,7}},4}, {{{0,8}},84}, {{{0,8}},20}, {{{85,8}},227},\n    {{{83,7}},43}, {{{0,8}},116}, {{{0,8}},52}, {{{0,9}},200},\n    {{{81,7}},13}, {{{0,8}},100}, {{{0,8}},36}, {{{0,9}},168},\n    {{{0,8}},4}, {{{0,8}},132}, {{{0,8}},68}, {{{0,9}},232},\n    {{{80,7}},8}, {{{0,8}},92}, {{{0,8}},28}, {{{0,9}},152},\n    {{{84,7}},83}, {{{0,8}},124}, {{{0,8}},60}, {{{0,9}},216},\n    {{{82,7}},23}, {{{0,8}},108}, {{{0,8}},44}, {{{0,9}},184},\n    {{{0,8}},12}, {{{0,8}},140}, {{{0,8}},76}, {{{0,9}},248},\n    {{{80,7}},3}, {{{0,8}},82}, {{{0,8}},18}, {{{85,8}},163},\n    {{{83,7}},35}, {{{0,8}},114}, {{{0,8}},50}, {{{0,9}},196},\n    {{{81,7}},11}, {{{0,8}},98}, {{{0,8}},34}, {{{0,9}},164},\n    {{{0,8}},2}, {{{0,8}},130}, {{{0,8}},66}, {{{0,9}},228},\n    {{{80,7}},7}, {{{0,8}},90}, {{{0,8}},26}, {{{0,9}},148},\n    {{{84,7}},67}, {{{0,8}},122}, {{{0,8}},58}, {{{0,9}},212},\n    {{{82,7}},19}, {{{0,8}},106}, {{{0,8}},42}, {{{0,9}},180},\n    {{{0,8}},10}, {{{0,8}},138}, {{{0,8}},74}, {{{0,9}},244},\n    {{{80,7}},5}, {{{0,8}},86}, {{{0,8}},22}, {{{192,8}},0},\n    {{{83,7}},51}, {{{0,8}},118}, {{{0,8}},54}, {{{0,9}},204},\n    {{{81,7}},15}, {{{0,8}},102}, {{{0,8}},38}, {{{0,9}},172},\n    {{{0,8}},6}, {{{0,8}},134}, {{{0,8}},70}, {{{0,9}},236},\n    {{{80,7}},9}, {{{0,8}},94}, {{{0,8}},30}, {{{0,9}},156},\n    {{{84,7}},99}, {{{0,8}},126}, {{{0,8}},62}, {{{0,9}},220},\n    {{{82,7}},27}, {{{0,8}},110}, {{{0,8}},46}, {{{0,9}},188},\n    {{{0,8}},14}, {{{0,8}},142}, {{{0,8}},78}, {{{0,9}},252},\n    {{{96,7}},256}, {{{0,8}},81}, {{{0,8}},17}, {{{85,8}},131},\n    {{{82,7}},31}, {{{0,8}},113}, {{{0,8}},49}, {{{0,9}},194},\n    {{{80,7}},10}, {{{0,8}},97}, {{{0,8}},33}, {{{0,9}},162},\n    {{{0,8}},1}, {{{0,8}},129}, {{{0,8}},65}, {{{0,9}},226},\n    {{{80,7}},6}, {{{0,8}},89}, {{{0,8}},25}, {{{0,9}},146},\n    {{{83,7}},59}, {{{0,8}},121}, {{{0,8}},57}, {{{0,9}},210},\n    {{{81,7}},17}, {{{0,8}},105}, {{{0,8}},41}, {{{0,9}},178},\n    {{{0,8}},9}, {{{0,8}},137}, {{{0,8}},73}, {{{0,9}},242},\n    {{{80,7}},4}, {{{0,8}},85}, {{{0,8}},21}, {{{80,8}},258},\n    {{{83,7}},43}, {{{0,8}},117}, {{{0,8}},53}, {{{0,9}},202},\n    {{{81,7}},13}, {{{0,8}},101}, {{{0,8}},37}, {{{0,9}},170},\n    {{{0,8}},5}, {{{0,8}},133}, {{{0,8}},69}, {{{0,9}},234},\n    {{{80,7}},8}, {{{0,8}},93}, {{{0,8}},29}, {{{0,9}},154},\n    {{{84,7}},83}, {{{0,8}},125}, {{{0,8}},61}, {{{0,9}},218},\n    {{{82,7}},23}, {{{0,8}},109}, {{{0,8}},45}, {{{0,9}},186},\n    {{{0,8}},13}, {{{0,8}},141}, {{{0,8}},77}, {{{0,9}},250},\n    {{{80,7}},3}, {{{0,8}},83}, {{{0,8}},19}, {{{85,8}},195},\n    {{{83,7}},35}, {{{0,8}},115}, {{{0,8}},51}, {{{0,9}},198},\n    {{{81,7}},11}, {{{0,8}},99}, {{{0,8}},35}, {{{0,9}},166},\n    {{{0,8}},3}, {{{0,8}},131}, {{{0,8}},67}, {{{0,9}},230},\n    {{{80,7}},7}, {{{0,8}},91}, {{{0,8}},27}, {{{0,9}},150},\n    {{{84,7}},67}, {{{0,8}},123}, {{{0,8}},59}, {{{0,9}},214},\n    {{{82,7}},19}, {{{0,8}},107}, {{{0,8}},43}, {{{0,9}},182},\n    {{{0,8}},11}, {{{0,8}},139}, {{{0,8}},75}, {{{0,9}},246},\n    {{{80,7}},5}, {{{0,8}},87}, {{{0,8}},23}, {{{192,8}},0},\n    {{{83,7}},51}, {{{0,8}},119}, {{{0,8}},55}, {{{0,9}},206},\n    {{{81,7}},15}, {{{0,8}},103}, {{{0,8}},39}, {{{0,9}},174},\n    {{{0,8}},7}, {{{0,8}},135}, {{{0,8}},71}, {{{0,9}},238},\n    {{{80,7}},9}, {{{0,8}},95}, {{{0,8}},31}, {{{0,9}},158},\n    {{{84,7}},99}, {{{0,8}},127}, {{{0,8}},63}, {{{0,9}},222},\n    {{{82,7}},27}, {{{0,8}},111}, {{{0,8}},47}, {{{0,9}},190},\n    {{{0,8}},15}, {{{0,8}},143}, {{{0,8}},79}, {{{0,9}},254},\n    {{{96,7}},256}, {{{0,8}},80}, {{{0,8}},16}, {{{84,8}},115},\n    {{{82,7}},31}, {{{0,8}},112}, {{{0,8}},48}, {{{0,9}},193},\n    {{{80,7}},10}, {{{0,8}},96}, {{{0,8}},32}, {{{0,9}},161},\n    {{{0,8}},0}, {{{0,8}},128}, {{{0,8}},64}, {{{0,9}},225},\n    {{{80,7}},6}, {{{0,8}},88}, {{{0,8}},24}, {{{0,9}},145},\n    {{{83,7}},59}, {{{0,8}},120}, {{{0,8}},56}, {{{0,9}},209},\n    {{{81,7}},17}, {{{0,8}},104}, {{{0,8}},40}, {{{0,9}},177},\n    {{{0,8}},8}, {{{0,8}},136}, {{{0,8}},72}, {{{0,9}},241},\n    {{{80,7}},4}, {{{0,8}},84}, {{{0,8}},20}, {{{85,8}},227},\n    {{{83,7}},43}, {{{0,8}},116}, {{{0,8}},52}, {{{0,9}},201},\n    {{{81,7}},13}, {{{0,8}},100}, {{{0,8}},36}, {{{0,9}},169},\n    {{{0,8}},4}, {{{0,8}},132}, {{{0,8}},68}, {{{0,9}},233},\n    {{{80,7}},8}, {{{0,8}},92}, {{{0,8}},28}, {{{0,9}},153},\n    {{{84,7}},83}, {{{0,8}},124}, {{{0,8}},60}, {{{0,9}},217},\n    {{{82,7}},23}, {{{0,8}},108}, {{{0,8}},44}, {{{0,9}},185},\n    {{{0,8}},12}, {{{0,8}},140}, {{{0,8}},76}, {{{0,9}},249},\n    {{{80,7}},3}, {{{0,8}},82}, {{{0,8}},18}, {{{85,8}},163},\n    {{{83,7}},35}, {{{0,8}},114}, {{{0,8}},50}, {{{0,9}},197},\n    {{{81,7}},11}, {{{0,8}},98}, {{{0,8}},34}, {{{0,9}},165},\n    {{{0,8}},2}, {{{0,8}},130}, {{{0,8}},66}, {{{0,9}},229},\n    {{{80,7}},7}, {{{0,8}},90}, {{{0,8}},26}, {{{0,9}},149},\n    {{{84,7}},67}, {{{0,8}},122}, {{{0,8}},58}, {{{0,9}},213},\n    {{{82,7}},19}, {{{0,8}},106}, {{{0,8}},42}, {{{0,9}},181},\n    {{{0,8}},10}, {{{0,8}},138}, {{{0,8}},74}, {{{0,9}},245},\n    {{{80,7}},5}, {{{0,8}},86}, {{{0,8}},22}, {{{192,8}},0},\n    {{{83,7}},51}, {{{0,8}},118}, {{{0,8}},54}, {{{0,9}},205},\n    {{{81,7}},15}, {{{0,8}},102}, {{{0,8}},38}, {{{0,9}},173},\n    {{{0,8}},6}, {{{0,8}},134}, {{{0,8}},70}, {{{0,9}},237},\n    {{{80,7}},9}, {{{0,8}},94}, {{{0,8}},30}, {{{0,9}},157},\n    {{{84,7}},99}, {{{0,8}},126}, {{{0,8}},62}, {{{0,9}},221},\n    {{{82,7}},27}, {{{0,8}},110}, {{{0,8}},46}, {{{0,9}},189},\n    {{{0,8}},14}, {{{0,8}},142}, {{{0,8}},78}, {{{0,9}},253},\n    {{{96,7}},256}, {{{0,8}},81}, {{{0,8}},17}, {{{85,8}},131},\n    {{{82,7}},31}, {{{0,8}},113}, {{{0,8}},49}, {{{0,9}},195},\n    {{{80,7}},10}, {{{0,8}},97}, {{{0,8}},33}, {{{0,9}},163},\n    {{{0,8}},1}, {{{0,8}},129}, {{{0,8}},65}, {{{0,9}},227},\n    {{{80,7}},6}, {{{0,8}},89}, {{{0,8}},25}, {{{0,9}},147},\n    {{{83,7}},59}, {{{0,8}},121}, {{{0,8}},57}, {{{0,9}},211},\n    {{{81,7}},17}, {{{0,8}},105}, {{{0,8}},41}, {{{0,9}},179},\n    {{{0,8}},9}, {{{0,8}},137}, {{{0,8}},73}, {{{0,9}},243},\n    {{{80,7}},4}, {{{0,8}},85}, {{{0,8}},21}, {{{80,8}},258},\n    {{{83,7}},43}, {{{0,8}},117}, {{{0,8}},53}, {{{0,9}},203},\n    {{{81,7}},13}, {{{0,8}},101}, {{{0,8}},37}, {{{0,9}},171},\n    {{{0,8}},5}, {{{0,8}},133}, {{{0,8}},69}, {{{0,9}},235},\n    {{{80,7}},8}, {{{0,8}},93}, {{{0,8}},29}, {{{0,9}},155},\n    {{{84,7}},83}, {{{0,8}},125}, {{{0,8}},61}, {{{0,9}},219},\n    {{{82,7}},23}, {{{0,8}},109}, {{{0,8}},45}, {{{0,9}},187},\n    {{{0,8}},13}, {{{0,8}},141}, {{{0,8}},77}, {{{0,9}},251},\n    {{{80,7}},3}, {{{0,8}},83}, {{{0,8}},19}, {{{85,8}},195},\n    {{{83,7}},35}, {{{0,8}},115}, {{{0,8}},51}, {{{0,9}},199},\n    {{{81,7}},11}, {{{0,8}},99}, {{{0,8}},35}, {{{0,9}},167},\n    {{{0,8}},3}, {{{0,8}},131}, {{{0,8}},67}, {{{0,9}},231},\n    {{{80,7}},7}, {{{0,8}},91}, {{{0,8}},27}, {{{0,9}},151},\n    {{{84,7}},67}, {{{0,8}},123}, {{{0,8}},59}, {{{0,9}},215},\n    {{{82,7}},19}, {{{0,8}},107}, {{{0,8}},43}, {{{0,9}},183},\n    {{{0,8}},11}, {{{0,8}},139}, {{{0,8}},75}, {{{0,9}},247},\n    {{{80,7}},5}, {{{0,8}},87}, {{{0,8}},23}, {{{192,8}},0},\n    {{{83,7}},51}, {{{0,8}},119}, {{{0,8}},55}, {{{0,9}},207},\n    {{{81,7}},15}, {{{0,8}},103}, {{{0,8}},39}, {{{0,9}},175},\n    {{{0,8}},7}, {{{0,8}},135}, {{{0,8}},71}, {{{0,9}},239},\n    {{{80,7}},9}, {{{0,8}},95}, {{{0,8}},31}, {{{0,9}},159},\n    {{{84,7}},99}, {{{0,8}},127}, {{{0,8}},63}, {{{0,9}},223},\n    {{{82,7}},27}, {{{0,8}},111}, {{{0,8}},47}, {{{0,9}},191},\n    {{{0,8}},15}, {{{0,8}},143}, {{{0,8}},79}, {{{0,9}},255}\n  };\nconst inflate_huft fixed_td[] = {\n    {{{80,5}},1}, {{{87,5}},257}, {{{83,5}},17}, {{{91,5}},4097},\n    {{{81,5}},5}, {{{89,5}},1025}, {{{85,5}},65}, {{{93,5}},16385},\n    {{{80,5}},3}, {{{88,5}},513}, {{{84,5}},33}, {{{92,5}},8193},\n    {{{82,5}},9}, {{{90,5}},2049}, {{{86,5}},129}, {{{192,5}},24577},\n    {{{80,5}},2}, {{{87,5}},385}, {{{83,5}},25}, {{{91,5}},6145},\n    {{{81,5}},7}, {{{89,5}},1537}, {{{85,5}},97}, {{{93,5}},24577},\n    {{{80,5}},4}, {{{88,5}},769}, {{{84,5}},49}, {{{92,5}},12289},\n    {{{82,5}},13}, {{{90,5}},3073}, {{{86,5}},193}, {{{192,5}},24577}\n  };\n\n\n// copy as much as possible from the sliding window to the output area\nint inflate_flush(inflate_blocks_statef *s,z_streamp z,int r)\n{\n  uInt n;\n  Byte *p;\n  Byte *q;\n\n  // local copies of source and destination pointers\n  p = z->next_out;\n  q = s->read;\n\n  // compute number of bytes to copy as far as end of window\n  n = (uInt)((q <= s->write ? s->write : s->end) - q);\n  if (n > z->avail_out) n = z->avail_out;\n  if (n && r == Z_BUF_ERROR) r = Z_OK;\n\n  // update counters\n  z->avail_out -= n;\n  z->total_out += n;\n\n  // update check information\n  if (s->checkfn != Z_NULL)\n    z->adler = s->check = (*s->checkfn)(s->check, q, n);\n\n  // copy as far as end of window\n  if (n!=0)          // check for n!=0 to avoid waking up CodeGuard\n  { memcpy(p, q, n);\n    p += n;\n    q += n;\n  }\n\n  // see if more to copy at beginning of window\n  if (q == s->end)\n  {\n    // wrap pointers\n    q = s->window;\n    if (s->write == s->end)\n      s->write = s->window;\n\n    // compute bytes to copy\n    n = (uInt)(s->write - q);\n    if (n > z->avail_out) n = z->avail_out;\n    if (n && r == Z_BUF_ERROR) r = Z_OK;\n\n    // update counters\n    z->avail_out -= n;\n    z->total_out += n;\n\n    // update check information\n    if (s->checkfn != Z_NULL)\n      z->adler = s->check = (*s->checkfn)(s->check, q, n);\n\n    // copy\n    if (n!=0) {memcpy(p,q,n); p+=n; q+=n;}\n  }\n\n  // update pointers\n  z->next_out = p;\n  s->read = q;\n\n  // done\n  return r;\n}\n\n\n// simplify the use of the inflate_huft type with some defines\n#define exop word.what.Exop\n#define bits word.what.Bits\n\ntypedef enum {        // waiting for \"i:\"=input, \"o:\"=output, \"x:\"=nothing\n      START,    // x: set up for LEN\n      LEN,      // i: get length/literal/eob next\n      LENEXT,   // i: getting length extra (have base)\n      DIST,     // i: get distance next\n      DISTEXT,  // i: getting distance extra\n      COPY,     // o: copying bytes in window, waiting for space\n      LIT,      // o: got literal, waiting for output space\n      WASH,     // o: got eob, possibly still output waiting\n      END,      // x: got eob and all data flushed\n      BADCODE}  // x: got error\ninflate_codes_mode;\n\n// inflate codes private state\nstruct inflate_codes_state {\n\n  // mode\n  inflate_codes_mode mode;      // current inflate_codes mode\n\n  // mode dependent information\n  uInt len;\n  union {\n    struct {\n      const inflate_huft *tree;       // pointer into tree\n      uInt need;                // bits needed\n    } code;             // if LEN or DIST, where in tree\n    uInt lit;           // if LIT, literal\n    struct {\n      uInt get;                 // bits to get for extra\n      uInt dist;                // distance back to copy from\n    } copy;             // if EXT or COPY, where and how much\n  } sub;                // submode\n\n  // mode independent information\n  Byte lbits;           // ltree bits decoded per branch\n  Byte dbits;           // dtree bits decoder per branch\n  const inflate_huft *ltree;          // literal/length/eob tree\n  const inflate_huft *dtree;          // distance tree\n\n};\n\n\ninflate_codes_statef *inflate_codes_new(\nuInt bl, uInt bd,\nconst inflate_huft *tl,\nconst inflate_huft *td, // need separate declaration for Borland C++\nz_streamp z)\n{\n  inflate_codes_statef *c;\n\n  if ((c = (inflate_codes_statef *)\n       ZALLOC(z,1,sizeof(struct inflate_codes_state))) != Z_NULL)\n  {\n    c->mode = START;\n    c->lbits = (Byte)bl;\n    c->dbits = (Byte)bd;\n    c->ltree = tl;\n    c->dtree = td;\n    LuTracev((stderr, \"inflate:       codes new\\n\"));\n  }\n  return c;\n}\n\n\nint inflate_codes(inflate_blocks_statef *s, z_streamp z, int r)\n{\n  uInt j;               // temporary storage\n  const inflate_huft *t;      // temporary pointer\n  uInt e;               // extra bits or operation\n  uLong b;              // bit buffer\n  uInt k;               // bits in bit buffer\n  Byte *p;             // input data pointer\n  uInt n;               // bytes available there\n  Byte *q;             // output window write pointer\n  uInt m;               // bytes to end of window or read pointer\n  Byte *f;             // pointer to copy strings from\n  inflate_codes_statef *c = s->sub.decode.codes;  // codes state\n\n  // copy input/output information to locals (UPDATE macro restores)\n  LOAD\n\n  // process input and output based on current state\n  for(;;) switch (c->mode)\n  {             // waiting for \"i:\"=input, \"o:\"=output, \"x:\"=nothing\n    case START:         // x: set up for LEN\n#ifndef SLOW\n      if (m >= 258 && n >= 10)\n      {\n        UPDATE\n        r = inflate_fast(c->lbits, c->dbits, c->ltree, c->dtree, s, z);\n        LOAD\n        if (r != Z_OK)\n        {\n          c->mode = r == Z_STREAM_END ? WASH : BADCODE;\n          break;\n        }\n      }\n#endif // !SLOW\n      c->sub.code.need = c->lbits;\n      c->sub.code.tree = c->ltree;\n      c->mode = LEN;\n    case LEN:           // i: get length/literal/eob next\n      j = c->sub.code.need;\n      NEEDBITS(j)\n      t = c->sub.code.tree + ((uInt)b & inflate_mask[j]);\n      DUMPBITS(t->bits)\n      e = (uInt)(t->exop);\n      if (e == 0)               // literal\n      {\n        c->sub.lit = t->base;\n        LuTracevv((stderr, t->base >= 0x20 && t->base < 0x7f ?\n                 \"inflate:         literal '%c'\\n\" :\n                 \"inflate:         literal 0x%02x\\n\", t->base));\n        c->mode = LIT;\n        break;\n      }\n      if (e & 16)               // length\n      {\n        c->sub.copy.get = e & 15;\n        c->len = t->base;\n        c->mode = LENEXT;\n        break;\n      }\n      if ((e & 64) == 0)        // next table\n      {\n        c->sub.code.need = e;\n        c->sub.code.tree = t + t->base;\n        break;\n      }\n      if (e & 32)               // end of block\n      {\n        LuTracevv((stderr, \"inflate:         end of block\\n\"));\n        c->mode = WASH;\n        break;\n      }\n      c->mode = BADCODE;        // invalid code\n      z->msg = (char*)\"invalid literal/length code\";\n      r = Z_DATA_ERROR;\n      LEAVE\n    case LENEXT:        // i: getting length extra (have base)\n      j = c->sub.copy.get;\n      NEEDBITS(j)\n      c->len += (uInt)b & inflate_mask[j];\n      DUMPBITS(j)\n      c->sub.code.need = c->dbits;\n      c->sub.code.tree = c->dtree;\n      LuTracevv((stderr, \"inflate:         length %u\\n\", c->len));\n      c->mode = DIST;\n    case DIST:          // i: get distance next\n      j = c->sub.code.need;\n      NEEDBITS(j)\n      t = c->sub.code.tree + ((uInt)b & inflate_mask[j]);\n      DUMPBITS(t->bits)\n      e = (uInt)(t->exop);\n      if (e & 16)               // distance\n      {\n        c->sub.copy.get = e & 15;\n        c->sub.copy.dist = t->base;\n        c->mode = DISTEXT;\n        break;\n      }\n      if ((e & 64) == 0)        // next table\n      {\n        c->sub.code.need = e;\n        c->sub.code.tree = t + t->base;\n        break;\n      }\n      c->mode = BADCODE;        // invalid code\n      z->msg = (char*)\"invalid distance code\";\n      r = Z_DATA_ERROR;\n      LEAVE\n    case DISTEXT:       // i: getting distance extra\n      j = c->sub.copy.get;\n      NEEDBITS(j)\n      c->sub.copy.dist += (uInt)b & inflate_mask[j];\n      DUMPBITS(j)\n      LuTracevv((stderr, \"inflate:         distance %u\\n\", c->sub.copy.dist));\n      c->mode = COPY;\n    case COPY:          // o: copying bytes in window, waiting for space\n      f = q - c->sub.copy.dist;\n      while (f < s->window)             // modulo window size-\"while\" instead\n        f += s->end - s->window;        // of \"if\" handles invalid distances\n      while (c->len)\n      {\n        NEEDOUT\n        OUTBYTE(*f++)\n        if (f == s->end)\n          f = s->window;\n        c->len--;\n      }\n      c->mode = START;\n      break;\n    case LIT:           // o: got literal, waiting for output space\n      NEEDOUT\n      OUTBYTE(c->sub.lit)\n      c->mode = START;\n      break;\n    case WASH:          // o: got eob, possibly more output\n      if (k > 7)        // return unused byte, if any\n      {\n        //Assert(k < 16, \"inflate_codes grabbed too many bytes\")\n        k -= 8;\n        n++;\n        p--;            // can always return one\n      }\n      FLUSH\n      if (s->read != s->write)\n        LEAVE\n      c->mode = END;\n    case END:\n      r = Z_STREAM_END;\n      LEAVE\n    case BADCODE:       // x: got error\n      r = Z_DATA_ERROR;\n      LEAVE\n    default:\n      r = Z_STREAM_ERROR;\n      LEAVE\n  }\n}\n\n\nvoid inflate_codes_free(inflate_codes_statef *c,z_streamp z)\n{ ZFREE(z, c);\n  LuTracev((stderr, \"inflate:       codes free\\n\"));\n}\n\n\n// infblock.c -- interpret and process block types to last block\n// Copyright (C) 1995-1998 Mark Adler\n// For conditions of distribution and use, see copyright notice in zlib.h\n\n//struct inflate_codes_state {int dummy;}; // for buggy compilers\n\n\n// Table for deflate from PKZIP's appnote.txt.\nconst uInt border[] = { // Order of the bit length code lengths\n        16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15};\n\n//\n// Notes beyond the 1.93a appnote.txt:\n//\n// 1. Distance pointers never point before the beginning of the output stream.\n// 2. Distance pointers can point back across blocks, up to 32k away.\n// 3. There is an implied maximum of 7 bits for the bit length table and\n//    15 bits for the actual data.\n// 4. If only one code exists, then it is encoded using one bit.  (Zero\n//    would be more efficient, but perhaps a little confusing.)  If two\n//    codes exist, they are coded using one bit each (0 and 1).\n// 5. There is no way of sending zero distance codes--a dummy must be\n//    sent if there are none.  (History: a pre 2.0 version of PKZIP would\n//    store blocks with no distance codes, but this was discovered to be\n//    too harsh a criterion.)  Valid only for 1.93a.  2.04c does allow\n//    zero distance codes, which is sent as one code of zero bits in\n//    length.\n// 6. There are up to 286 literal/length codes.  Code 256 represents the\n//    end-of-block.  Note however that the static length tree defines\n//    288 codes just to fill out the Huffman codes.  Codes 286 and 287\n//    cannot be used though, since there is no length base or extra bits\n//    defined for them.  Similarily, there are up to 30 distance codes.\n//    However, static trees define 32 codes (all 5 bits) to fill out the\n//    Huffman codes, but the last two had better not show up in the data.\n// 7. Unzip can check dynamic Huffman blocks for complete code sets.\n//    The exception is that a single code would not be complete (see #4).\n// 8. The five bits following the block type is really the number of\n//    literal codes sent minus 257.\n// 9. Length codes 8,16,16 are interpreted as 13 length codes of 8 bits\n//    (1+6+6).  Therefore, to output three times the length, you output\n//    three codes (1+1+1), whereas to output four times the same length,\n//    you only need two codes (1+3).  Hmm.\n//10. In the tree reconstruction algorithm, Code = Code + Increment\n//    only if BitLength(i) is not zero.  (Pretty obvious.)\n//11. Correction: 4 Bits: # of Bit Length codes - 4     (4 - 19)\n//12. Note: length code 284 can represent 227-258, but length code 285\n//    really is 258.  The last length deserves its own, short code\n//    since it gets used a lot in very redundant files.  The length\n//    258 is special since 258 - 3 (the min match length) is 255.\n//13. The literal/length and distance code bit lengths are read as a\n//    single stream of lengths.  It is possible (and advantageous) for\n//    a repeat code (16, 17, or 18) to go across the boundary between\n//    the two sets of lengths.\n\n\nvoid inflate_blocks_reset(inflate_blocks_statef *s, z_streamp z, uLong *c)\n{\n  if (c != Z_NULL)\n    *c = s->check;\n  if (s->mode == IBM_BTREE || s->mode == IBM_DTREE)\n    ZFREE(z, s->sub.trees.blens);\n  if (s->mode == IBM_CODES)\n    inflate_codes_free(s->sub.decode.codes, z);\n  s->mode = IBM_TYPE;\n  s->bitk = 0;\n  s->bitb = 0;\n  s->read = s->write = s->window;\n  if (s->checkfn != Z_NULL)\n    z->adler = s->check = (*s->checkfn)(0L, (const Byte *)Z_NULL, 0);\n  LuTracev((stderr, \"inflate:   blocks reset\\n\"));\n}\n\n\ninflate_blocks_statef *inflate_blocks_new(z_streamp z, check_func c, uInt w)\n{\n  inflate_blocks_statef *s;\n\n  if ((s = (inflate_blocks_statef *)ZALLOC\n       (z,1,sizeof(struct inflate_blocks_state))) == Z_NULL)\n    return s;\n  if ((s->hufts =\n       (inflate_huft *)ZALLOC(z, sizeof(inflate_huft), MANY)) == Z_NULL)\n  {\n    ZFREE(z, s);\n    return Z_NULL;\n  }\n  if ((s->window = (Byte *)ZALLOC(z, 1, w)) == Z_NULL)\n  {\n    ZFREE(z, s->hufts);\n    ZFREE(z, s);\n    return Z_NULL;\n  }\n  s->end = s->window + w;\n  s->checkfn = c;\n  s->mode = IBM_TYPE;\n  LuTracev((stderr, \"inflate:   blocks allocated\\n\"));\n  inflate_blocks_reset(s, z, Z_NULL);\n  return s;\n}\n\n\nint inflate_blocks(inflate_blocks_statef *s, z_streamp z, int r)\n{\n  uInt t;               // temporary storage\n  uLong b;              // bit buffer\n  uInt k;               // bits in bit buffer\n  Byte *p;             // input data pointer\n  uInt n;               // bytes available there\n  Byte *q;             // output window write pointer\n  uInt m;               // bytes to end of window or read pointer\n\n  // copy input/output information to locals (UPDATE macro restores)\n  LOAD\n\n  // process input based on current state\n  for(;;) switch (s->mode)\n  {\n    case IBM_TYPE:\n      NEEDBITS(3)\n      t = (uInt)b & 7;\n      s->last = t & 1;\n      switch (t >> 1)\n      {\n        case 0:                         // stored\n          LuTracev((stderr, \"inflate:     stored block%s\\n\",\n                 s->last ? \" (last)\" : \"\"));\n          DUMPBITS(3)\n          t = k & 7;                    // go to byte boundary\n          DUMPBITS(t)\n          s->mode = IBM_LENS;               // get length of stored block\n          break;\n        case 1:                         // fixed\n          LuTracev((stderr, \"inflate:     fixed codes block%s\\n\",\n                 s->last ? \" (last)\" : \"\"));\n          {\n            uInt bl, bd;\n            const inflate_huft *tl, *td;\n\n            inflate_trees_fixed(&bl, &bd, &tl, &td, z);\n            s->sub.decode.codes = inflate_codes_new(bl, bd, tl, td, z);\n            if (s->sub.decode.codes == Z_NULL)\n            {\n              r = Z_MEM_ERROR;\n              LEAVE\n            }\n          }\n          DUMPBITS(3)\n          s->mode = IBM_CODES;\n          break;\n        case 2:                         // dynamic\n          LuTracev((stderr, \"inflate:     dynamic codes block%s\\n\",\n                 s->last ? \" (last)\" : \"\"));\n          DUMPBITS(3)\n          s->mode = IBM_TABLE;\n          break;\n        case 3:                         // illegal\n          DUMPBITS(3)\n          s->mode = IBM_BAD;\n          z->msg = (char*)\"invalid block type\";\n          r = Z_DATA_ERROR;\n          LEAVE\n      }\n      break;\n    case IBM_LENS:\n      NEEDBITS(32)\n      if ((((~b) >> 16) & 0xffff) != (b & 0xffff))\n      {\n        s->mode = IBM_BAD;\n        z->msg = (char*)\"invalid stored block lengths\";\n        r = Z_DATA_ERROR;\n        LEAVE\n      }\n      s->sub.left = (uInt)b & 0xffff;\n      b = k = 0;                      // dump bits\n      LuTracev((stderr, \"inflate:       stored length %u\\n\", s->sub.left));\n      s->mode = s->sub.left ? IBM_STORED : (s->last ? IBM_DRY : IBM_TYPE);\n      break;\n    case IBM_STORED:\n      if (n == 0)\n        LEAVE\n      NEEDOUT\n      t = s->sub.left;\n      if (t > n) t = n;\n      if (t > m) t = m;\n      memcpy(q, p, t);\n      p += t;  n -= t;\n      q += t;  m -= t;\n      if ((s->sub.left -= t) != 0)\n        break;\n      LuTracev((stderr, \"inflate:       stored end, %lu total out\\n\",\n              z->total_out + (q >= s->read ? q - s->read :\n              (s->end - s->read) + (q - s->window))));\n      s->mode = s->last ? IBM_DRY : IBM_TYPE;\n      break;\n    case IBM_TABLE:\n      NEEDBITS(14)\n      s->sub.trees.table = t = (uInt)b & 0x3fff;\n      // remove this section to workaround bug in pkzip\n      if ((t & 0x1f) > 29 || ((t >> 5) & 0x1f) > 29)\n      {\n        s->mode = IBM_BAD;\n        z->msg = (char*)\"too many length or distance symbols\";\n        r = Z_DATA_ERROR;\n        LEAVE\n      }\n      // end remove\n      t = 258 + (t & 0x1f) + ((t >> 5) & 0x1f);\n      if ((s->sub.trees.blens = (uInt*)ZALLOC(z, t, sizeof(uInt))) == Z_NULL)\n      {\n        r = Z_MEM_ERROR;\n        LEAVE\n      }\n      DUMPBITS(14)\n      s->sub.trees.index = 0;\n      LuTracev((stderr, \"inflate:       table sizes ok\\n\"));\n      s->mode = IBM_BTREE;\n    case IBM_BTREE:\n      while (s->sub.trees.index < 4 + (s->sub.trees.table >> 10))\n      {\n        NEEDBITS(3)\n        s->sub.trees.blens[border[s->sub.trees.index++]] = (uInt)b & 7;\n        DUMPBITS(3)\n      }\n      while (s->sub.trees.index < 19)\n        s->sub.trees.blens[border[s->sub.trees.index++]] = 0;\n      s->sub.trees.bb = 7;\n      t = inflate_trees_bits(s->sub.trees.blens, &s->sub.trees.bb,\n                             &s->sub.trees.tb, s->hufts, z);\n      if (t != Z_OK)\n      {\n        r = t;\n        if (r == Z_DATA_ERROR)\n        {\n          ZFREE(z, s->sub.trees.blens);\n          s->mode = IBM_BAD;\n        }\n        LEAVE\n      }\n      s->sub.trees.index = 0;\n      LuTracev((stderr, \"inflate:       bits tree ok\\n\"));\n      s->mode = IBM_DTREE;\n    case IBM_DTREE:\n      while (t = s->sub.trees.table,\n             s->sub.trees.index < 258 + (t & 0x1f) + ((t >> 5) & 0x1f))\n      {\n        inflate_huft *h;\n        uInt i, j, c;\n\n        t = s->sub.trees.bb;\n        NEEDBITS(t)\n        h = s->sub.trees.tb + ((uInt)b & inflate_mask[t]);\n        t = h->bits;\n        c = h->base;\n        if (c < 16)\n        {\n          DUMPBITS(t)\n          s->sub.trees.blens[s->sub.trees.index++] = c;\n        }\n        else // c == 16..18\n        {\n          i = c == 18 ? 7 : c - 14;\n          j = c == 18 ? 11 : 3;\n          NEEDBITS(t + i)\n          DUMPBITS(t)\n          j += (uInt)b & inflate_mask[i];\n          DUMPBITS(i)\n          i = s->sub.trees.index;\n          t = s->sub.trees.table;\n          if (i + j > 258 + (t & 0x1f) + ((t >> 5) & 0x1f) ||\n              (c == 16 && i < 1))\n          {\n            ZFREE(z, s->sub.trees.blens);\n            s->mode = IBM_BAD;\n            z->msg = (char*)\"invalid bit length repeat\";\n            r = Z_DATA_ERROR;\n            LEAVE\n          }\n          c = c == 16 ? s->sub.trees.blens[i - 1] : 0;\n          do {\n            s->sub.trees.blens[i++] = c;\n          } while (--j);\n          s->sub.trees.index = i;\n        }\n      }\n      s->sub.trees.tb = Z_NULL;\n      {\n        uInt bl, bd;\n        inflate_huft *tl, *td;\n        inflate_codes_statef *c;\n\n        bl = 9;         // must be <= 9 for lookahead assumptions\n        bd = 6;         // must be <= 9 for lookahead assumptions\n        t = s->sub.trees.table;\n        t = inflate_trees_dynamic(257 + (t & 0x1f), 1 + ((t >> 5) & 0x1f),\n                                  s->sub.trees.blens, &bl, &bd, &tl, &td,\n                                  s->hufts, z);\n        if (t != Z_OK)\n        {\n          if (t == (uInt)Z_DATA_ERROR)\n          {\n            ZFREE(z, s->sub.trees.blens);\n            s->mode = IBM_BAD;\n          }\n          r = t;\n          LEAVE\n        }\n        LuTracev((stderr, \"inflate:       trees ok\\n\"));\n        if ((c = inflate_codes_new(bl, bd, tl, td, z)) == Z_NULL)\n        {\n          r = Z_MEM_ERROR;\n          LEAVE\n        }\n        s->sub.decode.codes = c;\n      }\n      ZFREE(z, s->sub.trees.blens);\n      s->mode = IBM_CODES;\n    case IBM_CODES:\n      UPDATE\n      if ((r = inflate_codes(s, z, r)) != Z_STREAM_END)\n        return inflate_flush(s, z, r);\n      r = Z_OK;\n      inflate_codes_free(s->sub.decode.codes, z);\n      LOAD\n      LuTracev((stderr, \"inflate:       codes end, %lu total out\\n\",\n              z->total_out + (q >= s->read ? q - s->read :\n              (s->end - s->read) + (q - s->window))));\n      if (!s->last)\n      {\n        s->mode = IBM_TYPE;\n        break;\n      }\n      s->mode = IBM_DRY;\n    case IBM_DRY:\n      FLUSH\n      if (s->read != s->write)\n        LEAVE\n      s->mode = IBM_DONE;\n    case IBM_DONE:\n      r = Z_STREAM_END;\n      LEAVE\n    case IBM_BAD:\n      r = Z_DATA_ERROR;\n      LEAVE\n    default:\n      r = Z_STREAM_ERROR;\n      LEAVE\n  }\n}\n\n\nint inflate_blocks_free(inflate_blocks_statef *s, z_streamp z)\n{\n  inflate_blocks_reset(s, z, Z_NULL);\n  ZFREE(z, s->window);\n  ZFREE(z, s->hufts);\n  ZFREE(z, s);\n  LuTracev((stderr, \"inflate:   blocks freed\\n\"));\n  return Z_OK;\n}\n\n\n// inftrees.c -- generate Huffman trees for efficient decoding\n// Copyright (C) 1995-1998 Mark Adler\n// For conditions of distribution and use, see copyright notice in zlib.h\n//\n\n\nextern const char inflate_copyright[] =\n   \" inflate 1.1.3 Copyright 1995-1998 Mark Adler \";\n// If you use the zlib library in a product, an acknowledgment is welcome\n// in the documentation of your product. If for some reason you cannot\n// include such an acknowledgment, I would appreciate that you keep this\n// copyright string in the executable of your product.\n\n\nint huft_build (\n    uInt *,            // code lengths in bits\n    uInt,               // number of codes\n    uInt,               // number of \"simple\" codes\n    const uInt *,      // list of base values for non-simple codes\n    const uInt *,      // list of extra bits for non-simple codes\n    inflate_huft **,// result: starting table\n    uInt *,            // maximum lookup bits (returns actual)\n    inflate_huft *,     // space for trees\n    uInt *,             // hufts used in space\n    uInt * );         // space for values\n\n// Tables for deflate from PKZIP's appnote.txt.\nconst uInt cplens[31] = { // Copy lengths for literal codes 257..285\n        3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31,\n        35, 43, 51, 59, 67, 83, 99, 115, 131, 163, 195, 227, 258, 0, 0};\n        // see note #13 above about 258\nconst uInt cplext[31] = { // Extra bits for literal codes 257..285\n        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2,\n        3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 0, 112, 112}; // 112==invalid\nconst uInt cpdist[30] = { // Copy offsets for distance codes 0..29\n        1, 2, 3, 4, 5, 7, 9, 13, 17, 25, 33, 49, 65, 97, 129, 193,\n        257, 385, 513, 769, 1025, 1537, 2049, 3073, 4097, 6145,\n        8193, 12289, 16385, 24577};\nconst uInt cpdext[30] = { // Extra bits for distance codes\n        0, 0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6,\n        7, 7, 8, 8, 9, 9, 10, 10, 11, 11,\n        12, 12, 13, 13};\n\n//\n//   Huffman code decoding is performed using a multi-level table lookup.\n//   The fastest way to decode is to simply build a lookup table whose\n//   size is determined by the longest code.  However, the time it takes\n//   to build this table can also be a factor if the data being decoded\n//   is not very long.  The most common codes are necessarily the\n//   shortest codes, so those codes dominate the decoding time, and hence\n//   the speed.  The idea is you can have a shorter table that decodes the\n//   shorter, more probable codes, and then point to subsidiary tables for\n//   the longer codes.  The time it costs to decode the longer codes is\n//   then traded against the time it takes to make longer tables.\n//\n//   This results of this trade are in the variables lbits and dbits\n//   below.  lbits is the number of bits the first level table for literal/\n//   length codes can decode in one step, and dbits is the same thing for\n//   the distance codes.  Subsequent tables are also less than or equal to\n//   those sizes.  These values may be adjusted either when all of the\n//   codes are shorter than that, in which case the longest code length in\n//   bits is used, or when the shortest code is *longer* than the requested\n//   table size, in which case the length of the shortest code in bits is\n//   used.\n//\n//   There are two different values for the two tables, since they code a\n//   different number of possibilities each.  The literal/length table\n//   codes 286 possible values, or in a flat code, a little over eight\n//   bits.  The distance table codes 30 possible values, or a little less\n//   than five bits, flat.  The optimum values for speed end up being\n//   about one bit more than those, so lbits is 8+1 and dbits is 5+1.\n//   The optimum values may differ though from machine to machine, and\n//   possibly even between compilers.  Your mileage may vary.\n//\n\n\n// If BMAX needs to be larger than 16, then h and x[] should be uLong.\n#define BMAX 15         // maximum bit length of any code\n\nint huft_build(\nuInt *b,               // code lengths in bits (all assumed <= BMAX)\nuInt n,                 // number of codes (assumed <= 288)\nuInt s,                 // number of simple-valued codes (0..s-1)\nconst uInt *d,         // list of base values for non-simple codes\nconst uInt *e,         // list of extra bits for non-simple codes\ninflate_huft * *t,  // result: starting table\nuInt *m,               // maximum lookup bits, returns actual\ninflate_huft *hp,       // space for trees\nuInt *hn,               // hufts used in space\nuInt *v)               // working area: values in order of bit length\n// Given a list of code lengths and a maximum table size, make a set of\n// tables to decode that set of codes.  Return Z_OK on success, Z_BUF_ERROR\n// if the given code set is incomplete (the tables are still built in this\n// case), or Z_DATA_ERROR if the input is invalid.\n{\n\n  uInt a;                       // counter for codes of length k\n  uInt c[BMAX+1];               // bit length count table\n  uInt f;                       // i repeats in table every f entries\n  int g;                        // maximum code length\n  int h;                        // table level\n  register uInt i;              // counter, current code\n  register uInt j;              // counter\n  register int k;               // number of bits in current code\n  int l;                        // bits per table (returned in m)\n  uInt mask;                    // (1 << w) - 1, to avoid cc -O bug on HP\n  register uInt *p;            // pointer into c[], b[], or v[]\n  inflate_huft *q;              // points to current table\n  struct inflate_huft_s r;      // table entry for structure assignment\n  inflate_huft *u[BMAX];        // table stack\n  register int w;               // bits before this table == (l * h)\n  uInt x[BMAX+1];               // bit offsets, then code stack\n  uInt *xp;                    // pointer into x\n  int y;                        // number of dummy codes added\n  uInt z;                       // number of entries in current table\n\n\n  // Generate counts for each bit length\n  p = c;\n#define C0 *p++ = 0;\n#define C2 C0 C0 C0 C0\n#define C4 C2 C2 C2 C2\n  C4; p;                          // clear c[]--assume BMAX+1 is 16\n  p = b;  i = n;\n  do {\n    c[*p++]++;                  // assume all entries <= BMAX\n  } while (--i);\n  if (c[0] == n)                // null input--all zero length codes\n  {\n    *t = (inflate_huft *)Z_NULL;\n    *m = 0;\n    return Z_OK;\n  }\n\n\n  // Find minimum and maximum length, bound *m by those\n  l = *m;\n  for (j = 1; j <= BMAX; j++)\n    if (c[j])\n      break;\n  k = j;                        // minimum code length\n  if ((uInt)l < j)\n    l = j;\n  for (i = BMAX; i; i--)\n    if (c[i])\n      break;\n  g = i;                        // maximum code length\n  if ((uInt)l > i)\n    l = i;\n  *m = l;\n\n\n  // Adjust last length count to fill out codes, if needed\n  for (y = 1 << j; j < i; j++, y <<= 1)\n    if ((y -= c[j]) < 0)\n      return Z_DATA_ERROR;\n  if ((y -= c[i]) < 0)\n    return Z_DATA_ERROR;\n  c[i] += y;\n\n\n  // Generate starting offsets into the value table for each length\n  x[1] = j = 0;\n  p = c + 1;  xp = x + 2;\n  while (--i) {                 // note that i == g from above\n    *xp++ = (j += *p++);\n  }\n\n\n  // Make a table of values in order of bit lengths\n  p = b;  i = 0;\n  do {\n    if ((j = *p++) != 0)\n      v[x[j]++] = i;\n  } while (++i < n);\n  n = x[g];                     // set n to length of v\n\n\n  // Generate the Huffman codes and for each, make the table entries\n  x[0] = i = 0;                 // first Huffman code is zero\n  p = v;                        // grab values in bit order\n  h = -1;                       // no tables yet--level -1\n  w = -l;                       // bits decoded == (l * h)\n  u[0] = (inflate_huft *)Z_NULL;        // just to keep compilers happy\n  q = (inflate_huft *)Z_NULL;   // ditto\n  z = 0;                        // ditto\n\n  // go through the bit lengths (k already is bits in shortest code)\n  for (; k <= g; k++)\n  {\n    a = c[k];\n    while (a--)\n    {\n      // here i is the Huffman code of length k bits for value *p\n      // make tables up to required level\n      while (k > w + l)\n      {\n        h++;\n        w += l;                 // previous table always l bits\n\n        // compute minimum size table less than or equal to l bits\n        z = g - w;\n        z = z > (uInt)l ? l : z;        // table size upper limit\n        if ((f = 1 << (j = k - w)) > a + 1)     // try a k-w bit table\n        {                       // too few codes for k-w bit table\n          f -= a + 1;           // deduct codes from patterns left\n          xp = c + k;\n          if (j < z)\n            while (++j < z)     // try smaller tables up to z bits\n            {\n              if ((f <<= 1) <= *++xp)\n                break;          // enough codes to use up j bits\n              f -= *xp;         // else deduct codes from patterns\n            }\n        }\n        z = 1 << j;             // table entries for j-bit table\n\n        // allocate new table\n        if (*hn + z > MANY)     // (note: doesn't matter for fixed)\n          return Z_DATA_ERROR;  // overflow of MANY\n        u[h] = q = hp + *hn;\n        *hn += z;\n\n        // connect to last table, if there is one\n        if (h)\n        {\n          x[h] = i;             // save pattern for backing up\n          r.bits = (Byte)l;     // bits to dump before this table\n          r.exop = (Byte)j;     // bits in this table\n          j = i >> (w - l);\n          r.base = (uInt)(q - u[h-1] - j);   // offset to this table\n          u[h-1][j] = r;        // connect to last table\n        }\n        else\n          *t = q;               // first table is returned result\n      }\n\n      // set up table entry in r\n      r.bits = (Byte)(k - w);\n      if (p >= v + n)\n        r.exop = 128 + 64;      // out of values--invalid code\n      else if (*p < s)\n      {\n        r.exop = (Byte)(*p < 256 ? 0 : 32 + 64);     // 256 is end-of-block\n        r.base = *p++;          // simple code is just the value\n      }\n      else\n      {\n        r.exop = (Byte)(e[*p - s] + 16 + 64);// non-simple--look up in lists\n        r.base = d[*p++ - s];\n      }\n\n      // fill code-like entries with r\n      f = 1 << (k - w);\n      for (j = i >> w; j < z; j += f)\n        q[j] = r;\n\n      // backwards increment the k-bit code i\n      for (j = 1 << (k - 1); i & j; j >>= 1)\n        i ^= j;\n      i ^= j;\n\n      // backup over finished tables\n      mask = (1 << w) - 1;      // needed on HP, cc -O bug\n      while ((i & mask) != x[h])\n      {\n        h--;                    // don't need to update q\n        w -= l;\n        mask = (1 << w) - 1;\n      }\n    }\n  }\n\n\n  // Return Z_BUF_ERROR if we were given an incomplete table\n  return y != 0 && g != 1 ? Z_BUF_ERROR : Z_OK;\n}\n\n\nint inflate_trees_bits(\nuInt *c,               // 19 code lengths\nuInt *bb,              // bits tree desired/actual depth\ninflate_huft * *tb, // bits tree result\ninflate_huft *hp,       // space for trees\nz_streamp z)            // for messages\n{\n  int r;\n  uInt hn = 0;          // hufts used in space\n  uInt *v;             // work area for huft_build\n\n  if ((v = (uInt*)ZALLOC(z, 19, sizeof(uInt))) == Z_NULL)\n    return Z_MEM_ERROR;\n  r = huft_build(c, 19, 19, (uInt*)Z_NULL, (uInt*)Z_NULL,\n                 tb, bb, hp, &hn, v);\n  if (r == Z_DATA_ERROR)\n    z->msg = (char*)\"oversubscribed dynamic bit lengths tree\";\n  else if (r == Z_BUF_ERROR || *bb == 0)\n  {\n    z->msg = (char*)\"incomplete dynamic bit lengths tree\";\n    r = Z_DATA_ERROR;\n  }\n  ZFREE(z, v);\n  return r;\n}\n\n\nint inflate_trees_dynamic(\nuInt nl,                // number of literal/length codes\nuInt nd,                // number of distance codes\nuInt *c,               // that many (total) code lengths\nuInt *bl,              // literal desired/actual bit depth\nuInt *bd,              // distance desired/actual bit depth\ninflate_huft * *tl, // literal/length tree result\ninflate_huft * *td, // distance tree result\ninflate_huft *hp,       // space for trees\nz_streamp z)            // for messages\n{\n  int r;\n  uInt hn = 0;          // hufts used in space\n  uInt *v;             // work area for huft_build\n\n  // allocate work area\n  if ((v = (uInt*)ZALLOC(z, 288, sizeof(uInt))) == Z_NULL)\n    return Z_MEM_ERROR;\n\n  // build literal/length tree\n  r = huft_build(c, nl, 257, cplens, cplext, tl, bl, hp, &hn, v);\n  if (r != Z_OK || *bl == 0)\n  {\n    if (r == Z_DATA_ERROR)\n      z->msg = (char*)\"oversubscribed literal/length tree\";\n    else if (r != Z_MEM_ERROR)\n    {\n      z->msg = (char*)\"incomplete literal/length tree\";\n      r = Z_DATA_ERROR;\n    }\n    ZFREE(z, v);\n    return r;\n  }\n\n  // build distance tree\n  r = huft_build(c + nl, nd, 0, cpdist, cpdext, td, bd, hp, &hn, v);\n  if (r != Z_OK || (*bd == 0 && nl > 257))\n  {\n    if (r == Z_DATA_ERROR)\n      z->msg = (char*)\"oversubscribed distance tree\";\n    else if (r == Z_BUF_ERROR) {\n      z->msg = (char*)\"incomplete distance tree\";\n      r = Z_DATA_ERROR;\n    }\n    else if (r != Z_MEM_ERROR)\n    {\n      z->msg = (char*)\"empty distance tree with lengths\";\n      r = Z_DATA_ERROR;\n    }\n    ZFREE(z, v);\n    return r;\n  }\n\n  // done\n  ZFREE(z, v);\n  return Z_OK;\n}\n\n\nint inflate_trees_fixed(\nuInt *bl,               // literal desired/actual bit depth\nuInt *bd,               // distance desired/actual bit depth\nconst inflate_huft * * tl,     // literal/length tree result\nconst inflate_huft * *td,     // distance tree result\nz_streamp )             // for memory allocation\n{\n  *bl = fixed_bl;\n  *bd = fixed_bd;\n  *tl = fixed_tl;\n  *td = fixed_td;\n  return Z_OK;\n}\n\n\n// inffast.c -- process literals and length/distance pairs fast\n// Copyright (C) 1995-1998 Mark Adler\n// For conditions of distribution and use, see copyright notice in zlib.h\n//\n\n\n//struct inflate_codes_state {int dummy;}; // for buggy compilers\n\n\n// macros for bit input with no checking and for returning unused bytes\n#define GRABBITS(j) {while(k<(j)){b|=((uLong)NEXTBYTE)<<k;k+=8;}}\n#define UNGRAB {c=z->avail_in-n;c=(k>>3)<c?k>>3:c;n+=c;p-=c;k-=c<<3;}\n\n// Called with number of bytes left to write in window at least 258\n// (the maximum string length) and number of input bytes available\n// at least ten.  The ten bytes are six bytes for the longest length/\n// distance pair plus four bytes for overloading the bit buffer.\n\nint inflate_fast(\nuInt bl, uInt bd,\nconst inflate_huft *tl,\nconst inflate_huft *td, // need separate declaration for Borland C++\ninflate_blocks_statef *s,\nz_streamp z)\n{\n  const inflate_huft *t;      // temporary pointer\n  uInt e;               // extra bits or operation\n  uLong b;              // bit buffer\n  uInt k;               // bits in bit buffer\n  Byte *p;             // input data pointer\n  uInt n;               // bytes available there\n  Byte *q;             // output window write pointer\n  uInt m;               // bytes to end of window or read pointer\n  uInt ml;              // mask for literal/length tree\n  uInt md;              // mask for distance tree\n  uInt c;               // bytes to copy\n  uInt d;               // distance back to copy from\n  Byte *r;             // copy source pointer\n\n  // load input, output, bit values\n  LOAD\n\n  // initialize masks\n  ml = inflate_mask[bl];\n  md = inflate_mask[bd];\n\n  // do until not enough input or output space for fast loop\n  do {                          // assume called with m >= 258 && n >= 10\n    // get literal/length code\n    GRABBITS(20)                // max bits for literal/length code\n    if ((e = (t = tl + ((uInt)b & ml))->exop) == 0)\n    {\n      DUMPBITS(t->bits)\n      LuTracevv((stderr, t->base >= 0x20 && t->base < 0x7f ?\n                \"inflate:         * literal '%c'\\n\" :\n                \"inflate:         * literal 0x%02x\\n\", t->base));\n      *q++ = (Byte)t->base;\n      m--;\n      continue;\n    }\n    for (;;) {\n      DUMPBITS(t->bits)\n      if (e & 16)\n      {\n        // get extra bits for length\n        e &= 15;\n        c = t->base + ((uInt)b & inflate_mask[e]);\n        DUMPBITS(e)\n        LuTracevv((stderr, \"inflate:         * length %u\\n\", c));\n\n        // decode distance base of block to copy\n        GRABBITS(15);           // max bits for distance code\n        e = (t = td + ((uInt)b & md))->exop;\n        for (;;) {\n          DUMPBITS(t->bits)\n          if (e & 16)\n          {\n            // get extra bits to add to distance base\n            e &= 15;\n            GRABBITS(e)         // get extra bits (up to 13)\n            d = t->base + ((uInt)b & inflate_mask[e]);\n            DUMPBITS(e)\n            LuTracevv((stderr, \"inflate:         * distance %u\\n\", d));\n\n            // do the copy\n            m -= c;\n            r = q - d;\n            if (r < s->window)                  // wrap if needed\n            {\n              do {\n                r += s->end - s->window;        // force pointer in window\n              } while (r < s->window);          // covers invalid distances\n              e = (uInt) (s->end - r);\n              if (c > e)\n              {\n                c -= e;                         // wrapped copy\n                do {\n                    *q++ = *r++;\n                } while (--e);\n                r = s->window;\n                do {\n                    *q++ = *r++;\n                } while (--c);\n              }\n              else                              // normal copy\n              {\n                *q++ = *r++;  c--;\n                *q++ = *r++;  c--;\n                do {\n                    *q++ = *r++;\n                } while (--c);\n              }\n            }\n            else                                /* normal copy */\n            {\n              *q++ = *r++;  c--;\n              *q++ = *r++;  c--;\n              do {\n                *q++ = *r++;\n              } while (--c);\n            }\n            break;\n          }\n          else if ((e & 64) == 0)\n          {\n            t += t->base;\n            e = (t += ((uInt)b & inflate_mask[e]))->exop;\n          }\n          else\n          {\n            z->msg = (char*)\"invalid distance code\";\n            UNGRAB\n            UPDATE\n            return Z_DATA_ERROR;\n          }\n        };\n        break;\n      }\n      if ((e & 64) == 0)\n      {\n        t += t->base;\n        if ((e = (t += ((uInt)b & inflate_mask[e]))->exop) == 0)\n        {\n          DUMPBITS(t->bits)\n          LuTracevv((stderr, t->base >= 0x20 && t->base < 0x7f ?\n                    \"inflate:         * literal '%c'\\n\" :\n                    \"inflate:         * literal 0x%02x\\n\", t->base));\n          *q++ = (Byte)t->base;\n          m--;\n          break;\n        }\n      }\n      else if (e & 32)\n      {\n        LuTracevv((stderr, \"inflate:         * end of block\\n\"));\n        UNGRAB\n        UPDATE\n        return Z_STREAM_END;\n      }\n      else\n      {\n        z->msg = (char*)\"invalid literal/length code\";\n        UNGRAB\n        UPDATE\n        return Z_DATA_ERROR;\n      }\n    };\n  } while (m >= 258 && n >= 10);\n\n  // not enough input or output--restore pointers and return\n  UNGRAB\n  UPDATE\n  return Z_OK;\n}\n\n\n// crc32.c -- compute the CRC-32 of a data stream\n// Copyright (C) 1995-1998 Mark Adler\n// For conditions of distribution and use, see copyright notice in zlib.h\n\n// @(#) $Id$\n\n\n// Table of CRC-32's of all single-byte values (made by make_crc_table)\nconst uLong crc_table[256] = {\n  0x00000000L, 0x77073096L, 0xee0e612cL, 0x990951baL, 0x076dc419L,\n  0x706af48fL, 0xe963a535L, 0x9e6495a3L, 0x0edb8832L, 0x79dcb8a4L,\n  0xe0d5e91eL, 0x97d2d988L, 0x09b64c2bL, 0x7eb17cbdL, 0xe7b82d07L,\n  0x90bf1d91L, 0x1db71064L, 0x6ab020f2L, 0xf3b97148L, 0x84be41deL,\n  0x1adad47dL, 0x6ddde4ebL, 0xf4d4b551L, 0x83d385c7L, 0x136c9856L,\n  0x646ba8c0L, 0xfd62f97aL, 0x8a65c9ecL, 0x14015c4fL, 0x63066cd9L,\n  0xfa0f3d63L, 0x8d080df5L, 0x3b6e20c8L, 0x4c69105eL, 0xd56041e4L,\n  0xa2677172L, 0x3c03e4d1L, 0x4b04d447L, 0xd20d85fdL, 0xa50ab56bL,\n  0x35b5a8faL, 0x42b2986cL, 0xdbbbc9d6L, 0xacbcf940L, 0x32d86ce3L,\n  0x45df5c75L, 0xdcd60dcfL, 0xabd13d59L, 0x26d930acL, 0x51de003aL,\n  0xc8d75180L, 0xbfd06116L, 0x21b4f4b5L, 0x56b3c423L, 0xcfba9599L,\n  0xb8bda50fL, 0x2802b89eL, 0x5f058808L, 0xc60cd9b2L, 0xb10be924L,\n  0x2f6f7c87L, 0x58684c11L, 0xc1611dabL, 0xb6662d3dL, 0x76dc4190L,\n  0x01db7106L, 0x98d220bcL, 0xefd5102aL, 0x71b18589L, 0x06b6b51fL,\n  0x9fbfe4a5L, 0xe8b8d433L, 0x7807c9a2L, 0x0f00f934L, 0x9609a88eL,\n  0xe10e9818L, 0x7f6a0dbbL, 0x086d3d2dL, 0x91646c97L, 0xe6635c01L,\n  0x6b6b51f4L, 0x1c6c6162L, 0x856530d8L, 0xf262004eL, 0x6c0695edL,\n  0x1b01a57bL, 0x8208f4c1L, 0xf50fc457L, 0x65b0d9c6L, 0x12b7e950L,\n  0x8bbeb8eaL, 0xfcb9887cL, 0x62dd1ddfL, 0x15da2d49L, 0x8cd37cf3L,\n  0xfbd44c65L, 0x4db26158L, 0x3ab551ceL, 0xa3bc0074L, 0xd4bb30e2L,\n  0x4adfa541L, 0x3dd895d7L, 0xa4d1c46dL, 0xd3d6f4fbL, 0x4369e96aL,\n  0x346ed9fcL, 0xad678846L, 0xda60b8d0L, 0x44042d73L, 0x33031de5L,\n  0xaa0a4c5fL, 0xdd0d7cc9L, 0x5005713cL, 0x270241aaL, 0xbe0b1010L,\n  0xc90c2086L, 0x5768b525L, 0x206f85b3L, 0xb966d409L, 0xce61e49fL,\n  0x5edef90eL, 0x29d9c998L, 0xb0d09822L, 0xc7d7a8b4L, 0x59b33d17L,\n  0x2eb40d81L, 0xb7bd5c3bL, 0xc0ba6cadL, 0xedb88320L, 0x9abfb3b6L,\n  0x03b6e20cL, 0x74b1d29aL, 0xead54739L, 0x9dd277afL, 0x04db2615L,\n  0x73dc1683L, 0xe3630b12L, 0x94643b84L, 0x0d6d6a3eL, 0x7a6a5aa8L,\n  0xe40ecf0bL, 0x9309ff9dL, 0x0a00ae27L, 0x7d079eb1L, 0xf00f9344L,\n  0x8708a3d2L, 0x1e01f268L, 0x6906c2feL, 0xf762575dL, 0x806567cbL,\n  0x196c3671L, 0x6e6b06e7L, 0xfed41b76L, 0x89d32be0L, 0x10da7a5aL,\n  0x67dd4accL, 0xf9b9df6fL, 0x8ebeeff9L, 0x17b7be43L, 0x60b08ed5L,\n  0xd6d6a3e8L, 0xa1d1937eL, 0x38d8c2c4L, 0x4fdff252L, 0xd1bb67f1L,\n  0xa6bc5767L, 0x3fb506ddL, 0x48b2364bL, 0xd80d2bdaL, 0xaf0a1b4cL,\n  0x36034af6L, 0x41047a60L, 0xdf60efc3L, 0xa867df55L, 0x316e8eefL,\n  0x4669be79L, 0xcb61b38cL, 0xbc66831aL, 0x256fd2a0L, 0x5268e236L,\n  0xcc0c7795L, 0xbb0b4703L, 0x220216b9L, 0x5505262fL, 0xc5ba3bbeL,\n  0xb2bd0b28L, 0x2bb45a92L, 0x5cb36a04L, 0xc2d7ffa7L, 0xb5d0cf31L,\n  0x2cd99e8bL, 0x5bdeae1dL, 0x9b64c2b0L, 0xec63f226L, 0x756aa39cL,\n  0x026d930aL, 0x9c0906a9L, 0xeb0e363fL, 0x72076785L, 0x05005713L,\n  0x95bf4a82L, 0xe2b87a14L, 0x7bb12baeL, 0x0cb61b38L, 0x92d28e9bL,\n  0xe5d5be0dL, 0x7cdcefb7L, 0x0bdbdf21L, 0x86d3d2d4L, 0xf1d4e242L,\n  0x68ddb3f8L, 0x1fda836eL, 0x81be16cdL, 0xf6b9265bL, 0x6fb077e1L,\n  0x18b74777L, 0x88085ae6L, 0xff0f6a70L, 0x66063bcaL, 0x11010b5cL,\n  0x8f659effL, 0xf862ae69L, 0x616bffd3L, 0x166ccf45L, 0xa00ae278L,\n  0xd70dd2eeL, 0x4e048354L, 0x3903b3c2L, 0xa7672661L, 0xd06016f7L,\n  0x4969474dL, 0x3e6e77dbL, 0xaed16a4aL, 0xd9d65adcL, 0x40df0b66L,\n  0x37d83bf0L, 0xa9bcae53L, 0xdebb9ec5L, 0x47b2cf7fL, 0x30b5ffe9L,\n  0xbdbdf21cL, 0xcabac28aL, 0x53b39330L, 0x24b4a3a6L, 0xbad03605L,\n  0xcdd70693L, 0x54de5729L, 0x23d967bfL, 0xb3667a2eL, 0xc4614ab8L,\n  0x5d681b02L, 0x2a6f2b94L, 0xb40bbe37L, 0xc30c8ea1L, 0x5a05df1bL,\n  0x2d02ef8dL\n};\n\nconst uLong * get_crc_table()\n{ return (const uLong *)crc_table;\n}\n\n#define CRC_DO1(buf) crc = crc_table[((int)crc ^ (*buf++)) & 0xff] ^ (crc >> 8);\n#define CRC_DO2(buf)  CRC_DO1(buf); CRC_DO1(buf);\n#define CRC_DO4(buf)  CRC_DO2(buf); CRC_DO2(buf);\n#define CRC_DO8(buf)  CRC_DO4(buf); CRC_DO4(buf);\n\nuLong ucrc32(uLong crc, const Byte *buf, uInt len)\n{ if (buf == Z_NULL) return 0L;\n  crc = crc ^ 0xffffffffL;\n  while (len >= 8)  {CRC_DO8(buf); len -= 8;}\n  if (len) do {CRC_DO1(buf);} while (--len);\n  return crc ^ 0xffffffffL;\n}\n\n\n// ===\n// some decryption routines\n#define CRC32(c, b) (crc_table[((int)(c)^(b))&0xff]^((c)>>8))\nvoid Uupdate_keys(unsigned long *keys, char c)\n{ keys[0] = CRC32(keys[0],c);\n  keys[1] += keys[0] & 0xFF;\n  keys[1] = keys[1]*134775813L +1;\n  keys[2] = CRC32(keys[2], keys[1] >> 24);\n}\nchar Udecrypt_byte(unsigned long *keys)\n{ unsigned temp = ((unsigned)keys[2] & 0xffff) | 2;\n  return (char)(((temp * (temp ^ 1)) >> 8) & 0xff);\n}\nchar zdecode(unsigned long *keys, char c)\n{ c^=Udecrypt_byte(keys);\n  Uupdate_keys(keys,c);\n  return c;\n}\n\n\n// adler32.c -- compute the Adler-32 checksum of a data stream\n// Copyright (C) 1995-1998 Mark Adler\n// For conditions of distribution and use, see copyright notice in zlib.h\n\n// @(#) $Id$\n\n\n#define BASE 65521L // largest prime smaller than 65536\n#define NMAX 5552\n// NMAX is the largest n such that 255n(n+1)/2 + (n+1)(BASE-1) <= 2^32-1\n\n#define AD_DO1(buf,i)  {s1 += buf[i]; s2 += s1;}\n#define AD_DO2(buf,i)  AD_DO1(buf,i); AD_DO1(buf,i+1);\n#define AD_DO4(buf,i)  AD_DO2(buf,i); AD_DO2(buf,i+2);\n#define AD_DO8(buf,i)  AD_DO4(buf,i); AD_DO4(buf,i+4);\n#define AD_DO16(buf)   AD_DO8(buf,0); AD_DO8(buf,8);\n\n// ===\nuLong adler32(uLong adler, const Byte *buf, uInt len)\n{\n    unsigned long s1 = adler & 0xffff;\n    unsigned long s2 = (adler >> 16) & 0xffff;\n    int k;\n\n    if (buf == Z_NULL) return 1L;\n\n    while (len > 0) {\n        k = len < NMAX ? len : NMAX;\n        len -= k;\n        while (k >= 16) {\n            AD_DO16(buf);\n\t    buf += 16;\n            k -= 16;\n        }\n        if (k != 0) do {\n            s1 += *buf++;\n\t    s2 += s1;\n        } while (--k);\n        s1 %= BASE;\n        s2 %= BASE;\n    }\n    return (s2 << 16) | s1;\n}\n\n\n// zutil.c -- target dependent utility functions for the compression library\n// Copyright (C) 1995-1998 Jean-loup Gailly.\n// For conditions of distribution and use, see copyright notice in zlib.h\n// @(#) $Id$\n\n\nconst char * zlibVersion()\n{\n    return ZLIB_VERSION;\n}\n\n// exported to allow conversion of error code to string for compress() and\n// uncompress()\nconst char * zError(int err)\n{ return ERR_MSG(err);\n}\n\n\nvoidpf zcalloc (voidpf opaque, unsigned items, unsigned size)\n{\n    if (opaque) items += size - size; // make compiler happy\n    return (voidpf)calloc(items, size);\n}\n\nvoid  zcfree (voidpf opaque, voidpf ptr)\n{\n    zfree(ptr);\n    if (opaque) return; // make compiler happy\n}\n\n\n// inflate.c -- zlib interface to inflate modules\n// Copyright (C) 1995-1998 Mark Adler\n// For conditions of distribution and use, see copyright notice in zlib.h\n\n//struct inflate_blocks_state {int dummy;}; // for buggy compilers\n\ntypedef enum {\n      IM_METHOD,   // waiting for method byte\n      IM_FLAG,     // waiting for flag byte\n      IM_DICT4,    // four dictionary check bytes to go\n      IM_DICT3,    // three dictionary check bytes to go\n      IM_DICT2,    // two dictionary check bytes to go\n      IM_DICT1,    // one dictionary check byte to go\n      IM_DICT0,    // waiting for inflateSetDictionary\n      IM_BLOCKS,   // decompressing blocks\n      IM_CHECK4,   // four check bytes to go\n      IM_CHECK3,   // three check bytes to go\n      IM_CHECK2,   // two check bytes to go\n      IM_CHECK1,   // one check byte to go\n      IM_DONE,     // finished check, done\n      IM_BAD}      // got an error--stay here\ninflate_mode;\n\n// inflate private state\nstruct internal_state {\n\n  // mode\n  inflate_mode  mode;   // current inflate mode\n\n  // mode dependent information\n  union {\n    uInt method;        // if IM_FLAGS, method byte\n    struct {\n      uLong was;                // computed check value\n      uLong need;               // stream check value\n    } check;            // if CHECK, check values to compare\n    uInt marker;        // if IM_BAD, inflateSync's marker bytes count\n  } sub;        // submode\n\n  // mode independent information\n  int  nowrap;          // flag for no wrapper\n  uInt wbits;           // log2(window size)  (8..15, defaults to 15)\n  inflate_blocks_statef\n    *blocks;            // current inflate_blocks state\n\n};\n\nint inflateReset(z_streamp z)\n{\n  if (z == Z_NULL || z->state == Z_NULL)\n    return Z_STREAM_ERROR;\n  z->total_in = z->total_out = 0;\n  z->msg = Z_NULL;\n  z->state->mode = z->state->nowrap ? IM_BLOCKS : IM_METHOD;\n  inflate_blocks_reset(z->state->blocks, z, Z_NULL);\n  LuTracev((stderr, \"inflate: reset\\n\"));\n  return Z_OK;\n}\n\nint inflateEnd(z_streamp z)\n{\n  if (z == Z_NULL || z->state == Z_NULL || z->zfree == Z_NULL)\n    return Z_STREAM_ERROR;\n  if (z->state->blocks != Z_NULL)\n    inflate_blocks_free(z->state->blocks, z);\n  ZFREE(z, z->state);\n  z->state = Z_NULL;\n  LuTracev((stderr, \"inflate: end\\n\"));\n  return Z_OK;\n}\n\n\nint inflateInit2(z_streamp z)\n{ const char *version = ZLIB_VERSION; int stream_size = sizeof(z_stream);\n  if (version == Z_NULL || version[0] != ZLIB_VERSION[0] || stream_size != sizeof(z_stream)) return Z_VERSION_ERROR;\n\n  int w = -15; // MAX_WBITS: 32K LZ77 window.\n  // Warning: reducing MAX_WBITS makes minigzip unable to extract .gz files created by gzip.\n  // The memory requirements for deflate are (in bytes):\n  //            (1 << (windowBits+2)) +  (1 << (memLevel+9))\n  // that is: 128K for windowBits=15  +  128K for memLevel = 8  (default values)\n  // plus a few kilobytes for small objects. For example, if you want to reduce\n  // the default memory requirements from 256K to 128K, compile with\n  //     make CFLAGS=\"-O -DMAX_WBITS=14 -DMAX_MEM_LEVEL=7\"\n  // Of course this will generally degrade compression (there's no free lunch).\n  //\n  //   The memory requirements for inflate are (in bytes) 1 << windowBits\n  // that is, 32K for windowBits=15 (default value) plus a few kilobytes\n  // for small objects.\n\n  // initialize state\n  if (z == Z_NULL) return Z_STREAM_ERROR;\n  z->msg = Z_NULL;\n  if (z->zalloc == Z_NULL)\n  {\n    z->zalloc = zcalloc;\n    z->opaque = (voidpf)0;\n  }\n  if (z->zfree == Z_NULL) z->zfree = zcfree;\n  if ((z->state = (struct internal_state *)\n       ZALLOC(z,1,sizeof(struct internal_state))) == Z_NULL)\n    return Z_MEM_ERROR;\n  z->state->blocks = Z_NULL;\n\n  // handle undocumented nowrap option (no zlib header or check)\n  z->state->nowrap = 0;\n  if (w < 0)\n  {\n    w = - w;\n    z->state->nowrap = 1;\n  }\n\n  // set window size\n  if (w < 8 || w > 15)\n  {\n    inflateEnd(z);\n    return Z_STREAM_ERROR;\n  }\n  z->state->wbits = (uInt)w;\n\n  // create inflate_blocks state\n  if ((z->state->blocks =\n      inflate_blocks_new(z, z->state->nowrap ? Z_NULL : adler32, (uInt)1 << w))\n      == Z_NULL)\n  {\n    inflateEnd(z);\n    return Z_MEM_ERROR;\n  }\n  LuTracev((stderr, \"inflate: allocated\\n\"));\n\n  // reset state\n  inflateReset(z);\n  return Z_OK;\n}\n\n\n#define IM_NEEDBYTE {if(z->avail_in==0)return r;r=f;}\n#define IM_NEXTBYTE (z->avail_in--,z->total_in++,*z->next_in++)\n\nint inflate(z_streamp z, int f)\n{\n  int r;\n  uInt b;\n\n  if (z == Z_NULL || z->state == Z_NULL || z->next_in == Z_NULL)\n    return Z_STREAM_ERROR;\n  f = f == Z_FINISH ? Z_BUF_ERROR : Z_OK;\n  r = Z_BUF_ERROR;\n  for (;;) switch (z->state->mode)\n  {\n    case IM_METHOD:\n      IM_NEEDBYTE\n      if (((z->state->sub.method = IM_NEXTBYTE) & 0xf) != Z_DEFLATED)\n      {\n        z->state->mode = IM_BAD;\n        z->msg = (char*)\"unknown compression method\";\n        z->state->sub.marker = 5;       // can't try inflateSync\n        break;\n      }\n      if ((z->state->sub.method >> 4) + 8 > z->state->wbits)\n      {\n        z->state->mode = IM_BAD;\n        z->msg = (char*)\"invalid window size\";\n        z->state->sub.marker = 5;       // can't try inflateSync\n        break;\n      }\n      z->state->mode = IM_FLAG;\n    case IM_FLAG:\n      IM_NEEDBYTE\n      b = IM_NEXTBYTE;\n      if (((z->state->sub.method << 8) + b) % 31)\n      {\n        z->state->mode = IM_BAD;\n        z->msg = (char*)\"incorrect header check\";\n        z->state->sub.marker = 5;       // can't try inflateSync\n        break;\n      }\n      LuTracev((stderr, \"inflate: zlib header ok\\n\"));\n      if (!(b & PRESET_DICT))\n      {\n        z->state->mode = IM_BLOCKS;\n        break;\n      }\n      z->state->mode = IM_DICT4;\n    case IM_DICT4:\n      IM_NEEDBYTE\n      z->state->sub.check.need = (uLong)IM_NEXTBYTE << 24;\n      z->state->mode = IM_DICT3;\n    case IM_DICT3:\n      IM_NEEDBYTE\n      z->state->sub.check.need += (uLong)IM_NEXTBYTE << 16;\n      z->state->mode = IM_DICT2;\n    case IM_DICT2:\n      IM_NEEDBYTE\n      z->state->sub.check.need += (uLong)IM_NEXTBYTE << 8;\n      z->state->mode = IM_DICT1;\n    case IM_DICT1:\n      IM_NEEDBYTE; r;\n      z->state->sub.check.need += (uLong)IM_NEXTBYTE;\n      z->adler = z->state->sub.check.need;\n      z->state->mode = IM_DICT0;\n      return Z_NEED_DICT;\n    case IM_DICT0:\n      z->state->mode = IM_BAD;\n      z->msg = (char*)\"need dictionary\";\n      z->state->sub.marker = 0;       // can try inflateSync\n      return Z_STREAM_ERROR;\n    case IM_BLOCKS:\n      r = inflate_blocks(z->state->blocks, z, r);\n      if (r == Z_DATA_ERROR)\n      {\n        z->state->mode = IM_BAD;\n        z->state->sub.marker = 0;       // can try inflateSync\n        break;\n      }\n      if (r == Z_OK)\n        r = f;\n      if (r != Z_STREAM_END)\n        return r;\n      r = f;\n      inflate_blocks_reset(z->state->blocks, z, &z->state->sub.check.was);\n      if (z->state->nowrap)\n      {\n        z->state->mode = IM_DONE;\n        break;\n      }\n      z->state->mode = IM_CHECK4;\n    case IM_CHECK4:\n      IM_NEEDBYTE\n      z->state->sub.check.need = (uLong)IM_NEXTBYTE << 24;\n      z->state->mode = IM_CHECK3;\n    case IM_CHECK3:\n      IM_NEEDBYTE\n      z->state->sub.check.need += (uLong)IM_NEXTBYTE << 16;\n      z->state->mode = IM_CHECK2;\n    case IM_CHECK2:\n      IM_NEEDBYTE\n      z->state->sub.check.need += (uLong)IM_NEXTBYTE << 8;\n      z->state->mode = IM_CHECK1;\n    case IM_CHECK1:\n      IM_NEEDBYTE\n      z->state->sub.check.need += (uLong)IM_NEXTBYTE;\n\n      if (z->state->sub.check.was != z->state->sub.check.need)\n      {\n        z->state->mode = IM_BAD;\n        z->msg = (char*)\"incorrect data check\";\n        z->state->sub.marker = 5;       // can't try inflateSync\n        break;\n      }\n      LuTracev((stderr, \"inflate: zlib check ok\\n\"));\n      z->state->mode = IM_DONE;\n    case IM_DONE:\n      return Z_STREAM_END;\n    case IM_BAD:\n      return Z_DATA_ERROR;\n    default:\n      return Z_STREAM_ERROR;\n  }\n}\n\n\n// unzip.c -- IO on .zip files using zlib\n// Version 0.15 beta, Mar 19th, 1998,\n// Read unzip.h for more info\n\n\n#define UNZ_BUFSIZE (16384)\n#define UNZ_MAXFILENAMEINZIP (256)\n#define SIZECENTRALDIRITEM (0x2e)\n#define SIZEZIPLOCALHEADER (0x1e)\n\n\nconst char unz_copyright[] = \" unzip 0.15 Copyright 1998 Gilles Vollant \";\n\n// unz_file_info_interntal contain internal info about a file in zipfile\ntypedef struct unz_file_info_internal_s\n{\n    uLong offset_curfile;// relative offset of local header 4 bytes\n} unz_file_info_internal;\n\n\ntypedef struct\n{ bool is_handle; // either a handle or memory\n  bool canseek;\n  // for handles:\n  HANDLE h; bool herr; unsigned long initial_offset; bool mustclosehandle;\n  // for memory:\n  void *buf; unsigned int len,pos; // if it's a memory block\n} LUFILE;\n\n\nLUFILE *lufopen(void *z,unsigned int len,DWORD flags,ZRESULT *err)\n{ if (flags!=ZIP_HANDLE && flags!=ZIP_FILENAME && flags!=ZIP_MEMORY) {*err=ZR_ARGS; return NULL;}\n  //\n  HANDLE h=0; bool canseek=false; *err=ZR_OK;\n  bool mustclosehandle=false;\n  if (flags==ZIP_HANDLE||flags==ZIP_FILENAME)\n  { if (flags==ZIP_HANDLE)\n    { HANDLE hf = z;\n      h=hf; mustclosehandle=false;\n#ifdef DuplicateHandle\n      BOOL res = DuplicateHandle(GetCurrentProcess(),hf,GetCurrentProcess(),&h,0,FALSE,DUPLICATE_SAME_ACCESS);\n      if (!res) mustclosehandle=true;\n#endif\n    }\n    else\n    { h=CreateFile((const TCHAR*)z,GENERIC_READ,FILE_SHARE_READ,NULL,OPEN_EXISTING,FILE_ATTRIBUTE_NORMAL,NULL);\n      if (h==INVALID_HANDLE_VALUE) {*err=ZR_NOFILE; return NULL;}\n      mustclosehandle=true;\n    }\n    // test if we can seek on it. We can't use GetFileType(h)==FILE_TYPE_DISK since it's not on CE.\n    DWORD res = SetFilePointer(h,0,0,FILE_CURRENT);\n    canseek = (res!=0xFFFFFFFF);\n  }\n  LUFILE *lf = new LUFILE;\n  if (flags==ZIP_HANDLE||flags==ZIP_FILENAME)\n  { lf->is_handle=true; lf->mustclosehandle=mustclosehandle;\n    lf->canseek=canseek;\n    lf->h=h; lf->herr=false;\n    lf->initial_offset=0;\n    if (canseek) lf->initial_offset = SetFilePointer(h,0,NULL,FILE_CURRENT);\n  }\n  else\n  { lf->is_handle=false;\n    lf->canseek=true;\n    lf->mustclosehandle=false;\n    lf->buf=z; lf->len=len; lf->pos=0; lf->initial_offset=0;\n  }\n  *err=ZR_OK;\n  return lf;\n}\n\n\nint lufclose(LUFILE *stream)\n{ if (stream==NULL) return EOF;\n  if (stream->mustclosehandle) CloseHandle(stream->h);\n  delete stream;\n  return 0;\n}\n\nint luferror(LUFILE *stream)\n{ if (stream->is_handle && stream->herr) return 1;\n  else return 0;\n}\n\nlong int luftell(LUFILE *stream)\n{ if (stream->is_handle && stream->canseek) return SetFilePointer(stream->h,0,NULL,FILE_CURRENT)-stream->initial_offset;\n  else if (stream->is_handle) return 0;\n  else return stream->pos;\n}\n\nint lufseek(LUFILE *stream, long offset, int whence)\n{ if (stream->is_handle && stream->canseek)\n  { if (whence==SEEK_SET) SetFilePointer(stream->h,stream->initial_offset+offset,0,FILE_BEGIN);\n    else if (whence==SEEK_CUR) SetFilePointer(stream->h,offset,NULL,FILE_CURRENT);\n    else if (whence==SEEK_END) SetFilePointer(stream->h,offset,NULL,FILE_END);\n    else return 19; // EINVAL\n    return 0;\n  }\n  else if (stream->is_handle) return 29; // ESPIPE\n  else\n  { if (whence==SEEK_SET) stream->pos=offset;\n    else if (whence==SEEK_CUR) stream->pos+=offset;\n    else if (whence==SEEK_END) stream->pos=stream->len+offset;\n    return 0;\n  }\n}\n\n\nsize_t lufread(void *ptr,size_t size,size_t n,LUFILE *stream)\n{ unsigned int toread = (unsigned int)(size*n);\n  if (stream->is_handle)\n  { DWORD red; BOOL res = ReadFile(stream->h,ptr,toread,&red,NULL);\n    if (!res) stream->herr=true;\n    return red/size;\n  }\n  if (stream->pos+toread > stream->len) toread = stream->len-stream->pos;\n  memcpy(ptr, (char*)stream->buf + stream->pos, toread); DWORD red = toread;\n  stream->pos += red;\n  return red/size;\n}\n\n\n// file_in_zip_read_info_s contain internal information about a file in zipfile,\n//  when reading and decompress it\ntypedef struct\n{\n\tchar  *read_buffer;         // internal buffer for compressed data\n\tz_stream stream;            // zLib stream structure for inflate\n\n\tuLong pos_in_zipfile;       // position in byte on the zipfile, for fseek\n\tuLong stream_initialised;   // flag set if stream structure is initialised\n\n\tuLong offset_local_extrafield;// offset of the local extra field\n\tuInt  size_local_extrafield;// size of the local extra field\n\tuLong pos_local_extrafield;   // position in the local extra field in read\n\n\tuLong crc32;                // crc32 of all data uncompressed\n\tuLong crc32_wait;           // crc32 we must obtain after decompress all\n\tuLong rest_read_compressed; // number of byte to be decompressed\n\tuLong rest_read_uncompressed;//number of byte to be obtained after decomp\n\tLUFILE* file;                 // io structore of the zipfile\n\tuLong compression_method;   // compression method (0==store)\n\tuLong byte_before_the_zipfile;// byte before the zipfile, (>0 for sfx)\n  bool encrypted;               // is it encrypted?\n  unsigned long keys[3];        // decryption keys, initialized by unzOpenCurrentFile\n  int encheadleft;              // the first call(s) to unzReadCurrentFile will read this many encryption-header bytes first\n  char crcenctest;              // if encrypted, we'll check the encryption buffer against this\n} file_in_zip_read_info_s;\n\n\n// unz_s contain internal information about the zipfile\ntypedef struct\n{\n\tLUFILE* file;               // io structore of the zipfile\n\tunz_global_info gi;         // public global information\n\tuLong byte_before_the_zipfile;// byte before the zipfile, (>0 for sfx)\n\tuLong num_file;             // number of the current file in the zipfile\n\tuLong pos_in_central_dir;   // pos of the current file in the central dir\n\tuLong current_file_ok;      // flag about the usability of the current file\n\tuLong central_pos;          // position of the beginning of the central dir\n\n\tuLong size_central_dir;     // size of the central directory\n\tuLong offset_central_dir;   // offset of start of central directory with respect to the starting disk number\n\n\tunz_file_info cur_file_info; // public info about the current file in zip\n\tunz_file_info_internal cur_file_info_internal; // private info about it\n    file_in_zip_read_info_s* pfile_in_zip_read; // structure about the current file if we are decompressing it\n} unz_s, *unzFile;\n\n\nint unzStringFileNameCompare (const char* fileName1,const char* fileName2,int iCaseSensitivity);\n//   Compare two filename (fileName1,fileName2).\n\nz_off_t unztell (unzFile file);\n//  Give the current position in uncompressed data\n\nint unzeof (unzFile file);\n//  return 1 if the end of file was reached, 0 elsewhere\n\nint unzGetLocalExtrafield (unzFile file, voidp buf, unsigned len);\n//  Read extra field from the current file (opened by unzOpenCurrentFile)\n//  This is the local-header version of the extra field (sometimes, there is\n//    more info in the local-header version than in the central-header)\n//\n//  if buf==NULL, it return the size of the local extra field\n//\n//  if buf!=NULL, len is the size of the buffer, the extra header is copied in\n//\tbuf.\n//  the return value is the number of bytes copied in buf, or (if <0)\n//\tthe error code\n\n\n// ===\n//   Read a byte from a gz_stream; update next_in and avail_in. Return EOF\n// for end of file.\n// IN assertion: the stream s has been sucessfully opened for reading.\n\nint unzlocal_getByte(LUFILE *fin,int *pi)\n{ unsigned char c;\n  int err = (int)lufread(&c, 1, 1, fin);\n  if (err==1)\n  { *pi = (int)c;\n    return UNZ_OK;\n  }\n  else\n  { if (luferror(fin)) return UNZ_ERRNO;\n    else return UNZ_EOF;\n  }\n}\n\n\n// ===\n// Reads a long in LSB order from the given gz_stream. Sets\nint unzlocal_getShort (LUFILE *fin,uLong *pX)\n{\n    uLong x ;\n    int i;\n    int err;\n\n    err = unzlocal_getByte(fin,&i);\n    x = (uLong)i;\n\n    if (err==UNZ_OK)\n        err = unzlocal_getByte(fin,&i);\n    x += ((uLong)i)<<8;\n\n    if (err==UNZ_OK)\n        *pX = x;\n    else\n        *pX = 0;\n    return err;\n}\n\nint unzlocal_getLong (LUFILE *fin,uLong *pX)\n{\n    uLong x ;\n    int i;\n    int err;\n\n    err = unzlocal_getByte(fin,&i);\n    x = (uLong)i;\n\n    if (err==UNZ_OK)\n        err = unzlocal_getByte(fin,&i);\n    x += ((uLong)i)<<8;\n\n    if (err==UNZ_OK)\n        err = unzlocal_getByte(fin,&i);\n    x += ((uLong)i)<<16;\n\n    if (err==UNZ_OK)\n        err = unzlocal_getByte(fin,&i);\n    x += ((uLong)i)<<24;\n\n    if (err==UNZ_OK)\n        *pX = x;\n    else\n        *pX = 0;\n    return err;\n}\n\n\n// My own strcmpi / strcasecmp\nint strcmpcasenosensitive_internal (const char* fileName1,const char *fileName2)\n{\n\tfor (;;)\n\t{\n\t\tchar c1=*(fileName1++);\n\t\tchar c2=*(fileName2++);\n\t\tif ((c1>='a') && (c1<='z'))\n\t\t\tc1 -= (char)0x20;\n\t\tif ((c2>='a') && (c2<='z'))\n\t\t\tc2 -= (char)0x20;\n\t\tif (c1=='\\0')\n\t\t\treturn ((c2=='\\0') ? 0 : -1);\n\t\tif (c2=='\\0')\n\t\t\treturn 1;\n\t\tif (c1<c2)\n\t\t\treturn -1;\n\t\tif (c1>c2)\n\t\t\treturn 1;\n\t}\n}\n\n\n//\n// Compare two filename (fileName1,fileName2).\n// If iCaseSenisivity = 1, comparision is case sensitivity (like strcmp)\n// If iCaseSenisivity = 2, comparision is not case sensitivity (like strcmpi or strcasecmp)\n//\nint unzStringFileNameCompare (const char*fileName1,const char*fileName2,int iCaseSensitivity)\n{ if (iCaseSensitivity==1) return strcmp(fileName1,fileName2);\n  else return strcmpcasenosensitive_internal(fileName1,fileName2);\n}\n\n#define BUFREADCOMMENT (0x400)\n\n\n//  Locate the Central directory of a zipfile (at the end, just before\n// the global comment). Lu bugfix 2005.07.26 - returns 0xFFFFFFFF if not found,\n// rather than 0, since 0 is a valid central-dir-location for an empty zipfile.\nuLong unzlocal_SearchCentralDir(LUFILE *fin)\n{ if (lufseek(fin,0,SEEK_END) != 0) return 0xFFFFFFFF;\n  uLong uSizeFile = luftell(fin);\n\n  uLong uMaxBack=0xffff; // maximum size of global comment\n  if (uMaxBack>uSizeFile) uMaxBack = uSizeFile;\n\n  unsigned char *buf = (unsigned char*)zmalloc(BUFREADCOMMENT+4);\n  if (buf==NULL) return 0xFFFFFFFF;\n  uLong uPosFound=0xFFFFFFFF;\n\n  uLong uBackRead = 4;\n  while (uBackRead<uMaxBack)\n  { uLong uReadSize,uReadPos ;\n    int i;\n    if (uBackRead+BUFREADCOMMENT>uMaxBack) uBackRead = uMaxBack;\n    else uBackRead+=BUFREADCOMMENT;\n    uReadPos = uSizeFile-uBackRead ;\n    uReadSize = ((BUFREADCOMMENT+4) < (uSizeFile-uReadPos)) ? (BUFREADCOMMENT+4) : (uSizeFile-uReadPos);\n    if (lufseek(fin,uReadPos,SEEK_SET)!=0) break;\n    if (lufread(buf,(uInt)uReadSize,1,fin)!=1) break;\n    for (i=(int)uReadSize-3; (i--)>=0;)\n    { if (((*(buf+i))==0x50) && ((*(buf+i+1))==0x4b) &&\t((*(buf+i+2))==0x05) && ((*(buf+i+3))==0x06))\n      { uPosFound = uReadPos+i;\tbreak;\n      }\n    }\n    if (uPosFound!=0) break;\n  }\n  if (buf) zfree(buf);\n  return uPosFound;\n}\n\n\nint unzGoToFirstFile (unzFile file);\nint unzCloseCurrentFile (unzFile file);\n\n// Open a Zip file.\n// If the zipfile cannot be opened (file don't exist or in not valid), return NULL.\n// Otherwise, the return value is a unzFile Handle, usable with other unzip functions\nunzFile unzOpenInternal(LUFILE *fin)\n{ if (fin==NULL) return NULL;\n  if (unz_copyright[0]!=' ') {lufclose(fin); return NULL;}\n\n  int err=UNZ_OK;\n  unz_s us;\n  uLong central_pos,uL;\n  central_pos = unzlocal_SearchCentralDir(fin);\n  if (central_pos==0xFFFFFFFF) err=UNZ_ERRNO;\n  if (lufseek(fin,central_pos,SEEK_SET)!=0) err=UNZ_ERRNO;\n  // the signature, already checked\n  if (unzlocal_getLong(fin,&uL)!=UNZ_OK) err=UNZ_ERRNO;\n  // number of this disk\n  uLong number_disk;          // number of the current dist, used for spanning ZIP, unsupported, always 0\n  if (unzlocal_getShort(fin,&number_disk)!=UNZ_OK) err=UNZ_ERRNO;\n  // number of the disk with the start of the central directory\n  uLong number_disk_with_CD;  // number the the disk with central dir, used for spaning ZIP, unsupported, always 0\n  if (unzlocal_getShort(fin,&number_disk_with_CD)!=UNZ_OK) err=UNZ_ERRNO;\n  // total number of entries in the central dir on this disk\n  if (unzlocal_getShort(fin,&us.gi.number_entry)!=UNZ_OK) err=UNZ_ERRNO;\n  // total number of entries in the central dir\n  uLong number_entry_CD;      // total number of entries in the central dir (same than number_entry on nospan)\n  if (unzlocal_getShort(fin,&number_entry_CD)!=UNZ_OK) err=UNZ_ERRNO;\n  if ((number_entry_CD!=us.gi.number_entry) || (number_disk_with_CD!=0) || (number_disk!=0)) err=UNZ_BADZIPFILE;\n  // size of the central directory\n  if (unzlocal_getLong(fin,&us.size_central_dir)!=UNZ_OK) err=UNZ_ERRNO;\n  // offset of start of central directory with respect to the starting disk number\n  if (unzlocal_getLong(fin,&us.offset_central_dir)!=UNZ_OK) err=UNZ_ERRNO;\n  // zipfile comment length\n  if (unzlocal_getShort(fin,&us.gi.size_comment)!=UNZ_OK) err=UNZ_ERRNO;\n  if ((central_pos+fin->initial_offset<us.offset_central_dir+us.size_central_dir) && (err==UNZ_OK)) err=UNZ_BADZIPFILE;\n  if (err!=UNZ_OK) {lufclose(fin);return NULL;}\n\n  us.file=fin;\n  us.byte_before_the_zipfile = central_pos+fin->initial_offset - (us.offset_central_dir+us.size_central_dir);\n  us.central_pos = central_pos;\n  us.pfile_in_zip_read = NULL;\n  fin->initial_offset = 0; // since the zipfile itself is expected to handle this\n\n  unz_s *s = (unz_s*)zmalloc(sizeof(unz_s));\n  *s=us;\n  unzGoToFirstFile((unzFile)s);\n  return (unzFile)s;\n}\n\n\n//  Close a ZipFile opened with unzipOpen.\n//  If there is files inside the .Zip opened with unzipOpenCurrentFile (see later),\n//    these files MUST be closed with unzipCloseCurrentFile before call unzipClose.\n//  return UNZ_OK if there is no problem.\nint unzClose (unzFile file)\n{\n\tunz_s* s;\n\tif (file==NULL)\n\t\treturn UNZ_PARAMERROR;\n\ts=(unz_s*)file;\n\n    if (s->pfile_in_zip_read!=NULL)\n        unzCloseCurrentFile(file);\n\n\tlufclose(s->file);\n\tif (s) zfree(s); // unused s=0;\n\treturn UNZ_OK;\n}\n\n\n//  Write info about the ZipFile in the *pglobal_info structure.\n//  No preparation of the structure is needed\n//  return UNZ_OK if there is no problem.\nint unzGetGlobalInfo (unzFile file,unz_global_info *pglobal_info)\n{\n\tunz_s* s;\n\tif (file==NULL)\n\t\treturn UNZ_PARAMERROR;\n\ts=(unz_s*)file;\n\t*pglobal_info=s->gi;\n\treturn UNZ_OK;\n}\n\n\n//   Translate date/time from Dos format to tm_unz (readable more easilty)\nvoid unzlocal_DosDateToTmuDate (uLong ulDosDate, tm_unz* ptm)\n{\n    uLong uDate;\n    uDate = (uLong)(ulDosDate>>16);\n    ptm->tm_mday = (uInt)(uDate&0x1f) ;\n    ptm->tm_mon =  (uInt)((((uDate)&0x1E0)/0x20)-1) ;\n    ptm->tm_year = (uInt)(((uDate&0x0FE00)/0x0200)+1980) ;\n\n    ptm->tm_hour = (uInt) ((ulDosDate &0xF800)/0x800);\n    ptm->tm_min =  (uInt) ((ulDosDate&0x7E0)/0x20) ;\n    ptm->tm_sec =  (uInt) (2*(ulDosDate&0x1f)) ;\n}\n\n//  Get Info about the current file in the zipfile, with internal only info\nint unzlocal_GetCurrentFileInfoInternal (unzFile file,\n                                                  unz_file_info *pfile_info,\n                                                  unz_file_info_internal\n                                                  *pfile_info_internal,\n                                                  char *szFileName,\n\t\t\t\t\t\t\t\t\t\t\t\t  uLong fileNameBufferSize,\n                                                  void *extraField,\n\t\t\t\t\t\t\t\t\t\t\t\t  uLong extraFieldBufferSize,\n                                                  char *szComment,\n\t\t\t\t\t\t\t\t\t\t\t\t  uLong commentBufferSize);\n\nint unzlocal_GetCurrentFileInfoInternal (unzFile file, unz_file_info *pfile_info,\n   unz_file_info_internal *pfile_info_internal, char *szFileName,\n   uLong fileNameBufferSize, void *extraField, uLong extraFieldBufferSize,\n   char *szComment, uLong commentBufferSize)\n{\n\tunz_s* s;\n\tunz_file_info file_info;\n\tunz_file_info_internal file_info_internal;\n\tint err=UNZ_OK;\n\tuLong uMagic;\n\tlong lSeek=0;\n\n\tif (file==NULL)\n\t\treturn UNZ_PARAMERROR;\n\ts=(unz_s*)file;\n\tif (lufseek(s->file,s->pos_in_central_dir+s->byte_before_the_zipfile,SEEK_SET)!=0)\n\t\terr=UNZ_ERRNO;\n\n\n\t// we check the magic\n\tif (err==UNZ_OK)\n\t\tif (unzlocal_getLong(s->file,&uMagic) != UNZ_OK)\n\t\t\terr=UNZ_ERRNO;\n\t\telse if (uMagic!=0x02014b50)\n\t\t\terr=UNZ_BADZIPFILE;\n\n\tif (unzlocal_getShort(s->file,&file_info.version) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\n\tif (unzlocal_getShort(s->file,&file_info.version_needed) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\n\tif (unzlocal_getShort(s->file,&file_info.flag) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\n\tif (unzlocal_getShort(s->file,&file_info.compression_method) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\n\tif (unzlocal_getLong(s->file,&file_info.dosDate) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\n    unzlocal_DosDateToTmuDate(file_info.dosDate,&file_info.tmu_date);\n\n\tif (unzlocal_getLong(s->file,&file_info.crc) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\n\tif (unzlocal_getLong(s->file,&file_info.compressed_size) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\n\tif (unzlocal_getLong(s->file,&file_info.uncompressed_size) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\n\tif (unzlocal_getShort(s->file,&file_info.size_filename) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\n\tif (unzlocal_getShort(s->file,&file_info.size_file_extra) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\n\tif (unzlocal_getShort(s->file,&file_info.size_file_comment) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\n\tif (unzlocal_getShort(s->file,&file_info.disk_num_start) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\n\tif (unzlocal_getShort(s->file,&file_info.internal_fa) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\n\tif (unzlocal_getLong(s->file,&file_info.external_fa) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\n\tif (unzlocal_getLong(s->file,&file_info_internal.offset_curfile) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\n\tlSeek+=file_info.size_filename;\n\tif ((err==UNZ_OK) && (szFileName!=NULL))\n\t{\n\t\tuLong uSizeRead ;\n\t\tif (file_info.size_filename<fileNameBufferSize)\n\t\t{\n\t\t\t*(szFileName+file_info.size_filename)='\\0';\n\t\t\tuSizeRead = file_info.size_filename;\n\t\t}\n\t\telse\n\t\t\tuSizeRead = fileNameBufferSize;\n\n\t\tif ((file_info.size_filename>0) && (fileNameBufferSize>0))\n\t\t\tif (lufread(szFileName,(uInt)uSizeRead,1,s->file)!=1)\n\t\t\t\terr=UNZ_ERRNO;\n\t\tlSeek -= uSizeRead;\n\t}\n\n\n\tif ((err==UNZ_OK) && (extraField!=NULL))\n\t{\n\t\tuLong uSizeRead ;\n\t\tif (file_info.size_file_extra<extraFieldBufferSize)\n\t\t\tuSizeRead = file_info.size_file_extra;\n\t\telse\n\t\t\tuSizeRead = extraFieldBufferSize;\n\n\t\tif (lSeek!=0)\n\t\t\tif (lufseek(s->file,lSeek,SEEK_CUR)==0)\n\t\t\t\tlSeek=0;\n\t\t\telse\n\t\t\t\terr=UNZ_ERRNO;\n\t\tif ((file_info.size_file_extra>0) && (extraFieldBufferSize>0))\n\t\t\tif (lufread(extraField,(uInt)uSizeRead,1,s->file)!=1)\n\t\t\t\terr=UNZ_ERRNO;\n\t\tlSeek += file_info.size_file_extra - uSizeRead;\n\t}\n\telse\n\t\tlSeek+=file_info.size_file_extra;\n\n\n\tif ((err==UNZ_OK) && (szComment!=NULL))\n\t{\n\t\tuLong uSizeRead ;\n\t\tif (file_info.size_file_comment<commentBufferSize)\n\t\t{\n\t\t\t*(szComment+file_info.size_file_comment)='\\0';\n\t\t\tuSizeRead = file_info.size_file_comment;\n\t\t}\n\t\telse\n\t\t\tuSizeRead = commentBufferSize;\n\n\t\tif (lSeek!=0)\n\t\t\tif (lufseek(s->file,lSeek,SEEK_CUR)==0)\n\t\t\t\t{} // unused lSeek=0;\n\t\t\telse\n\t\t\t\terr=UNZ_ERRNO;\n\t\tif ((file_info.size_file_comment>0) && (commentBufferSize>0))\n\t\t\tif (lufread(szComment,(uInt)uSizeRead,1,s->file)!=1)\n\t\t\t\terr=UNZ_ERRNO;\n\t\t//unused lSeek+=file_info.size_file_comment - uSizeRead;\n\t}\n\telse {} //unused lSeek+=file_info.size_file_comment;\n\n\tif ((err==UNZ_OK) && (pfile_info!=NULL))\n\t\t*pfile_info=file_info;\n\n\tif ((err==UNZ_OK) && (pfile_info_internal!=NULL))\n\t\t*pfile_info_internal=file_info_internal;\n\n\treturn err;\n}\n\n\n//  Write info about the ZipFile in the *pglobal_info structure.\n//  No preparation of the structure is needed\n//  return UNZ_OK if there is no problem.\nint unzGetCurrentFileInfo (unzFile file, unz_file_info *pfile_info,\n  char *szFileName, uLong fileNameBufferSize, void *extraField, uLong extraFieldBufferSize,\n  char *szComment, uLong commentBufferSize)\n{ return unzlocal_GetCurrentFileInfoInternal(file,pfile_info,NULL,szFileName,fileNameBufferSize,\n      extraField,extraFieldBufferSize, szComment,commentBufferSize);\n}\n\n\n//  Set the current file of the zipfile to the first file.\n//  return UNZ_OK if there is no problem\nint unzGoToFirstFile (unzFile file)\n{\n\tint err;\n\tunz_s* s;\n\tif (file==NULL) return UNZ_PARAMERROR;\n\ts=(unz_s*)file;\n\ts->pos_in_central_dir=s->offset_central_dir;\n\ts->num_file=0;\n\terr=unzlocal_GetCurrentFileInfoInternal(file,&s->cur_file_info,\n\t\t\t\t\t\t\t\t\t\t\t &s->cur_file_info_internal,\n\t\t\t\t\t\t\t\t\t\t\t NULL,0,NULL,0,NULL,0);\n\ts->current_file_ok = (err == UNZ_OK);\n\treturn err;\n}\n\n\n//  Set the current file of the zipfile to the next file.\n//  return UNZ_OK if there is no problem\n//  return UNZ_END_OF_LIST_OF_FILE if the actual file was the latest.\nint unzGoToNextFile (unzFile file)\n{\n\tunz_s* s;\n\tint err;\n\n\tif (file==NULL)\n\t\treturn UNZ_PARAMERROR;\n\ts=(unz_s*)file;\n\tif (!s->current_file_ok)\n\t\treturn UNZ_END_OF_LIST_OF_FILE;\n\tif (s->num_file+1==s->gi.number_entry)\n\t\treturn UNZ_END_OF_LIST_OF_FILE;\n\n\ts->pos_in_central_dir += SIZECENTRALDIRITEM + s->cur_file_info.size_filename +\n\t\t\ts->cur_file_info.size_file_extra + s->cur_file_info.size_file_comment ;\n\ts->num_file++;\n\terr = unzlocal_GetCurrentFileInfoInternal(file,&s->cur_file_info,\n\t\t\t\t\t\t\t\t\t\t\t   &s->cur_file_info_internal,\n\t\t\t\t\t\t\t\t\t\t\t   NULL,0,NULL,0,NULL,0);\n\ts->current_file_ok = (err == UNZ_OK);\n\treturn err;\n}\n\n\n//  Try locate the file szFileName in the zipfile.\n//  For the iCaseSensitivity signification, see unzStringFileNameCompare\n//  return value :\n//  UNZ_OK if the file is found. It becomes the current file.\n//  UNZ_END_OF_LIST_OF_FILE if the file is not found\nint unzLocateFile (unzFile file, const char *szFileName, int iCaseSensitivity)\n{\n\tunz_s* s;\n\tint err;\n\n\n\tuLong num_fileSaved;\n\tuLong pos_in_central_dirSaved;\n\n\n\tif (file==NULL)\n\t\treturn UNZ_PARAMERROR;\n\n    if (strlen(szFileName)>=UNZ_MAXFILENAMEINZIP)\n        return UNZ_PARAMERROR;\n\n\ts=(unz_s*)file;\n\tif (!s->current_file_ok)\n\t\treturn UNZ_END_OF_LIST_OF_FILE;\n\n\tnum_fileSaved = s->num_file;\n\tpos_in_central_dirSaved = s->pos_in_central_dir;\n\n\terr = unzGoToFirstFile(file);\n\n\twhile (err == UNZ_OK)\n\t{\n\t\tchar szCurrentFileName[UNZ_MAXFILENAMEINZIP+1];\n\t\tunzGetCurrentFileInfo(file,NULL,\n\t\t\t\t\t\t\t\tszCurrentFileName,sizeof(szCurrentFileName)-1,\n\t\t\t\t\t\t\t\tNULL,0,NULL,0);\n\t\tif (unzStringFileNameCompare(szCurrentFileName,szFileName,iCaseSensitivity)==0)\n\t\t\treturn UNZ_OK;\n\t\terr = unzGoToNextFile(file);\n\t}\n\n\ts->num_file = num_fileSaved ;\n\ts->pos_in_central_dir = pos_in_central_dirSaved ;\n\treturn err;\n}\n\n\n//  Read the local header of the current zipfile\n//  Check the coherency of the local header and info in the end of central\n//        directory about this file\n//  store in *piSizeVar the size of extra info in local header\n//        (filename and size of extra field data)\nint unzlocal_CheckCurrentFileCoherencyHeader (unz_s *s,uInt *piSizeVar,\n  uLong *poffset_local_extrafield, uInt  *psize_local_extrafield)\n{\n\tuLong uMagic,uData,uFlags;\n\tuLong size_filename;\n\tuLong size_extra_field;\n\tint err=UNZ_OK;\n\n\t*piSizeVar = 0;\n\t*poffset_local_extrafield = 0;\n\t*psize_local_extrafield = 0;\n\n\tif (lufseek(s->file,s->cur_file_info_internal.offset_curfile + s->byte_before_the_zipfile,SEEK_SET)!=0)\n\t\treturn UNZ_ERRNO;\n\n\n\tif (err==UNZ_OK)\n\t\tif (unzlocal_getLong(s->file,&uMagic) != UNZ_OK)\n\t\t\terr=UNZ_ERRNO;\n\t\telse if (uMagic!=0x04034b50)\n\t\t\terr=UNZ_BADZIPFILE;\n\n\tif (unzlocal_getShort(s->file,&uData) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n//\telse if ((err==UNZ_OK) && (uData!=s->cur_file_info.wVersion))\n//\t\terr=UNZ_BADZIPFILE;\n\tif (unzlocal_getShort(s->file,&uFlags) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\n\tif (unzlocal_getShort(s->file,&uData) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\telse if ((err==UNZ_OK) && (uData!=s->cur_file_info.compression_method))\n\t\terr=UNZ_BADZIPFILE;\n\n    if ((err==UNZ_OK) && (s->cur_file_info.compression_method!=0) &&\n                         (s->cur_file_info.compression_method!=Z_DEFLATED))\n        err=UNZ_BADZIPFILE;\n\n\tif (unzlocal_getLong(s->file,&uData) != UNZ_OK) // date/time\n\t\terr=UNZ_ERRNO;\n\n\tif (unzlocal_getLong(s->file,&uData) != UNZ_OK) // crc\n\t\terr=UNZ_ERRNO;\n\telse if ((err==UNZ_OK) && (uData!=s->cur_file_info.crc) &&\n\t\t                      ((uFlags & 8)==0))\n\t\terr=UNZ_BADZIPFILE;\n\n\tif (unzlocal_getLong(s->file,&uData) != UNZ_OK) // size compr\n\t\terr=UNZ_ERRNO;\n\telse if ((err==UNZ_OK) && (uData!=s->cur_file_info.compressed_size) &&\n\t\t\t\t\t\t\t  ((uFlags & 8)==0))\n\t\terr=UNZ_BADZIPFILE;\n\n\tif (unzlocal_getLong(s->file,&uData) != UNZ_OK) // size uncompr\n\t\terr=UNZ_ERRNO;\n\telse if ((err==UNZ_OK) && (uData!=s->cur_file_info.uncompressed_size) &&\n\t\t\t\t\t\t\t  ((uFlags & 8)==0))\n\t\terr=UNZ_BADZIPFILE;\n\n\n\tif (unzlocal_getShort(s->file,&size_filename) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\telse if ((err==UNZ_OK) && (size_filename!=s->cur_file_info.size_filename))\n\t\terr=UNZ_BADZIPFILE;\n\n\t*piSizeVar += (uInt)size_filename;\n\n\tif (unzlocal_getShort(s->file,&size_extra_field) != UNZ_OK)\n\t\terr=UNZ_ERRNO;\n\t*poffset_local_extrafield= s->cur_file_info_internal.offset_curfile +\n\t\t\t\t\t\t\t\t\tSIZEZIPLOCALHEADER + size_filename;\n\t*psize_local_extrafield = (uInt)size_extra_field;\n\n\t*piSizeVar += (uInt)size_extra_field;\n\n\treturn err;\n}\n\n\n//  Open for reading data the current file in the zipfile.\n//  If there is no error and the file is opened, the return value is UNZ_OK.\nint unzOpenCurrentFile (unzFile file, const char *password)\n{\n\tint err;\n\tint Store;\n\tuInt iSizeVar;\n\tunz_s* s;\n\tfile_in_zip_read_info_s* pfile_in_zip_read_info;\n\tuLong offset_local_extrafield;  // offset of the local extra field\n\tuInt  size_local_extrafield;    // size of the local extra field\n\n\tif (file==NULL)\n\t\treturn UNZ_PARAMERROR;\n\ts=(unz_s*)file;\n\tif (!s->current_file_ok)\n\t\treturn UNZ_PARAMERROR;\n\n    if (s->pfile_in_zip_read != NULL)\n        unzCloseCurrentFile(file);\n\n\tif (unzlocal_CheckCurrentFileCoherencyHeader(s,&iSizeVar,\n\t\t\t\t&offset_local_extrafield,&size_local_extrafield)!=UNZ_OK)\n\t\treturn UNZ_BADZIPFILE;\n\n\tpfile_in_zip_read_info = (file_in_zip_read_info_s*)zmalloc(sizeof(file_in_zip_read_info_s));\n\tif (pfile_in_zip_read_info==NULL)\n\t\treturn UNZ_INTERNALERROR;\n\n\tpfile_in_zip_read_info->read_buffer=(char*)zmalloc(UNZ_BUFSIZE);\n\tpfile_in_zip_read_info->offset_local_extrafield = offset_local_extrafield;\n\tpfile_in_zip_read_info->size_local_extrafield = size_local_extrafield;\n\tpfile_in_zip_read_info->pos_local_extrafield=0;\n\n\tif (pfile_in_zip_read_info->read_buffer==NULL)\n\t{\n\t\tif (pfile_in_zip_read_info!=0) zfree(pfile_in_zip_read_info); //unused pfile_in_zip_read_info=0;\n\t\treturn UNZ_INTERNALERROR;\n\t}\n\n\tpfile_in_zip_read_info->stream_initialised=0;\n\n\tif ((s->cur_file_info.compression_method!=0) && (s->cur_file_info.compression_method!=Z_DEFLATED))\n        { // unused err=UNZ_BADZIPFILE;\n        }\n\tStore = s->cur_file_info.compression_method==0;\n\n\tpfile_in_zip_read_info->crc32_wait=s->cur_file_info.crc;\n\tpfile_in_zip_read_info->crc32=0;\n\tpfile_in_zip_read_info->compression_method = s->cur_file_info.compression_method;\n\tpfile_in_zip_read_info->file=s->file;\n\tpfile_in_zip_read_info->byte_before_the_zipfile=s->byte_before_the_zipfile;\n\n    pfile_in_zip_read_info->stream.total_out = 0;\n\n\tif (!Store)\n\t{\n\t  pfile_in_zip_read_info->stream.zalloc = (alloc_func)0;\n\t  pfile_in_zip_read_info->stream.zfree = (free_func)0;\n\t  pfile_in_zip_read_info->stream.opaque = (voidpf)0;\n\n          err=inflateInit2(&pfile_in_zip_read_info->stream);\n\t  if (err == Z_OK)\n\t    pfile_in_zip_read_info->stream_initialised=1;\n        // windowBits is passed < 0 to tell that there is no zlib header.\n        // Note that in this case inflate *requires* an extra \"dummy\" byte\n        // after the compressed stream in order to complete decompression and\n        // return Z_STREAM_END.\n        // In unzip, i don't wait absolutely Z_STREAM_END because I known the\n        // size of both compressed and uncompressed data\n\t}\n\tpfile_in_zip_read_info->rest_read_compressed = s->cur_file_info.compressed_size ;\n\tpfile_in_zip_read_info->rest_read_uncompressed = s->cur_file_info.uncompressed_size ;\n  pfile_in_zip_read_info->encrypted = (s->cur_file_info.flag&1)!=0;\n  bool extlochead = (s->cur_file_info.flag&8)!=0;\n  if (extlochead) pfile_in_zip_read_info->crcenctest = (char)((s->cur_file_info.dosDate>>8)&0xff);\n  else pfile_in_zip_read_info->crcenctest = (char)(s->cur_file_info.crc >> 24);\n  pfile_in_zip_read_info->encheadleft = (pfile_in_zip_read_info->encrypted?12:0);\n  pfile_in_zip_read_info->keys[0] = 305419896L;\n  pfile_in_zip_read_info->keys[1] = 591751049L;\n  pfile_in_zip_read_info->keys[2] = 878082192L;\n  for (const char *cp=password; cp!=0 && *cp!=0; cp++) Uupdate_keys(pfile_in_zip_read_info->keys,*cp);\n\n\tpfile_in_zip_read_info->pos_in_zipfile =\n            s->cur_file_info_internal.offset_curfile + SIZEZIPLOCALHEADER +\n\t\t\t  iSizeVar;\n\n\tpfile_in_zip_read_info->stream.avail_in = (uInt)0;\n\n\ts->pfile_in_zip_read = pfile_in_zip_read_info;\n\n  return UNZ_OK;\n}\n\n\n//  Read bytes from the current file.\n//  buf contain buffer where data must be copied\n//  len the size of buf.\n//  return the number of byte copied if somes bytes are copied (and also sets *reached_eof)\n//  return 0 if the end of file was reached. (and also sets *reached_eof).\n//  return <0 with error code if there is an error. (in which case *reached_eof is meaningless)\n//    (UNZ_ERRNO for IO error, or zLib error for uncompress error)\nint unzReadCurrentFile  (unzFile file, voidp buf, unsigned len, bool *reached_eof)\n{ int err=UNZ_OK;\n  uInt iRead = 0;\n  if (reached_eof!=0) *reached_eof=false;\n\n  unz_s *s = (unz_s*)file;\n  if (s==NULL) return UNZ_PARAMERROR;\n\n  file_in_zip_read_info_s* pfile_in_zip_read_info = s->pfile_in_zip_read;\n  if (pfile_in_zip_read_info==NULL) return UNZ_PARAMERROR;\n  if ((pfile_in_zip_read_info->read_buffer == NULL)) return UNZ_END_OF_LIST_OF_FILE;\n  if (len==0) return 0;\n\n  pfile_in_zip_read_info->stream.next_out = (Byte*)buf;\n  pfile_in_zip_read_info->stream.avail_out = (uInt)len;\n\n  if (len>pfile_in_zip_read_info->rest_read_uncompressed)\n  { pfile_in_zip_read_info->stream.avail_out = (uInt)pfile_in_zip_read_info->rest_read_uncompressed;\n  }\n\n  while (pfile_in_zip_read_info->stream.avail_out>0)\n  { if ((pfile_in_zip_read_info->stream.avail_in==0) && (pfile_in_zip_read_info->rest_read_compressed>0))\n    { uInt uReadThis = UNZ_BUFSIZE;\n      if (pfile_in_zip_read_info->rest_read_compressed<uReadThis) uReadThis = (uInt)pfile_in_zip_read_info->rest_read_compressed;\n      if (uReadThis == 0) {if (reached_eof!=0) *reached_eof=true; return UNZ_EOF;}\n      if (lufseek(pfile_in_zip_read_info->file, pfile_in_zip_read_info->pos_in_zipfile + pfile_in_zip_read_info->byte_before_the_zipfile,SEEK_SET)!=0) return UNZ_ERRNO;\n      if (lufread(pfile_in_zip_read_info->read_buffer,uReadThis,1,pfile_in_zip_read_info->file)!=1) return UNZ_ERRNO;\n      pfile_in_zip_read_info->pos_in_zipfile += uReadThis;\n      pfile_in_zip_read_info->rest_read_compressed-=uReadThis;\n      pfile_in_zip_read_info->stream.next_in = (Byte*)pfile_in_zip_read_info->read_buffer;\n      pfile_in_zip_read_info->stream.avail_in = (uInt)uReadThis;\n      //\n      if (pfile_in_zip_read_info->encrypted)\n      { char *buf = (char*)pfile_in_zip_read_info->stream.next_in;\n        for (unsigned int i=0; i<uReadThis; i++) buf[i]=zdecode(pfile_in_zip_read_info->keys,buf[i]);\n      }\n    }\n\n    unsigned int uDoEncHead = pfile_in_zip_read_info->encheadleft;\n    if (uDoEncHead>pfile_in_zip_read_info->stream.avail_in) uDoEncHead=pfile_in_zip_read_info->stream.avail_in;\n    if (uDoEncHead>0)\n    { char bufcrc=pfile_in_zip_read_info->stream.next_in[uDoEncHead-1];\n      pfile_in_zip_read_info->rest_read_uncompressed-=uDoEncHead;\n      pfile_in_zip_read_info->stream.avail_in -= uDoEncHead;\n      pfile_in_zip_read_info->stream.next_in += uDoEncHead;\n      pfile_in_zip_read_info->encheadleft -= uDoEncHead;\n      if (pfile_in_zip_read_info->encheadleft==0)\n      { if (bufcrc!=pfile_in_zip_read_info->crcenctest) return UNZ_PASSWORD;\n      }\n    }\n\n    if (pfile_in_zip_read_info->compression_method==0)\n    { uInt uDoCopy,i ;\n      if (pfile_in_zip_read_info->stream.avail_out < pfile_in_zip_read_info->stream.avail_in)\n      { uDoCopy = pfile_in_zip_read_info->stream.avail_out ;\n      }\n      else\n      { uDoCopy = pfile_in_zip_read_info->stream.avail_in ;\n      }\n      for (i=0;i<uDoCopy;i++) *(pfile_in_zip_read_info->stream.next_out+i) = *(pfile_in_zip_read_info->stream.next_in+i);\n      pfile_in_zip_read_info->crc32 = ucrc32(pfile_in_zip_read_info->crc32,pfile_in_zip_read_info->stream.next_out,uDoCopy);\n      pfile_in_zip_read_info->rest_read_uncompressed-=uDoCopy;\n      pfile_in_zip_read_info->stream.avail_in -= uDoCopy;\n      pfile_in_zip_read_info->stream.avail_out -= uDoCopy;\n      pfile_in_zip_read_info->stream.next_out += uDoCopy;\n      pfile_in_zip_read_info->stream.next_in += uDoCopy;\n      pfile_in_zip_read_info->stream.total_out += uDoCopy;\n      iRead += uDoCopy;\n      if (pfile_in_zip_read_info->rest_read_uncompressed==0) {if (reached_eof!=0) *reached_eof=true;}\n    }\n    else\n    { uLong uTotalOutBefore,uTotalOutAfter;\n      const Byte *bufBefore;\n      uLong uOutThis;\n      int flush=Z_SYNC_FLUSH;\n      uTotalOutBefore = pfile_in_zip_read_info->stream.total_out;\n      bufBefore = pfile_in_zip_read_info->stream.next_out;\n      //\n      err=inflate(&pfile_in_zip_read_info->stream,flush);\n      //\n      uTotalOutAfter = pfile_in_zip_read_info->stream.total_out;\n      uOutThis = uTotalOutAfter-uTotalOutBefore;\n      pfile_in_zip_read_info->crc32 = ucrc32(pfile_in_zip_read_info->crc32,bufBefore,(uInt)(uOutThis));\n      pfile_in_zip_read_info->rest_read_uncompressed -= uOutThis;\n      iRead += (uInt)(uTotalOutAfter - uTotalOutBefore);\n      if (err==Z_STREAM_END || pfile_in_zip_read_info->rest_read_uncompressed==0)\n      { if (reached_eof!=0) *reached_eof=true;\n        return iRead;\n      }\n      if (err!=Z_OK) break;\n    }\n  }\n\n  if (err==Z_OK) return iRead;\n  return err;\n}\n\n\n//  Give the current position in uncompressed data\nz_off_t unztell (unzFile file)\n{\n\tunz_s* s;\n\tfile_in_zip_read_info_s* pfile_in_zip_read_info;\n\tif (file==NULL)\n\t\treturn UNZ_PARAMERROR;\n\ts=(unz_s*)file;\n    pfile_in_zip_read_info=s->pfile_in_zip_read;\n\n\tif (pfile_in_zip_read_info==NULL)\n\t\treturn UNZ_PARAMERROR;\n\n\treturn (z_off_t)pfile_in_zip_read_info->stream.total_out;\n}\n\n\n//  return 1 if the end of file was reached, 0 elsewhere\nint unzeof (unzFile file)\n{\n\tunz_s* s;\n\tfile_in_zip_read_info_s* pfile_in_zip_read_info;\n\tif (file==NULL)\n\t\treturn UNZ_PARAMERROR;\n\ts=(unz_s*)file;\n    pfile_in_zip_read_info=s->pfile_in_zip_read;\n\n\tif (pfile_in_zip_read_info==NULL)\n\t\treturn UNZ_PARAMERROR;\n\n\tif (pfile_in_zip_read_info->rest_read_uncompressed == 0)\n\t\treturn 1;\n\telse\n\t\treturn 0;\n}\n\n\n//  Read extra field from the current file (opened by unzOpenCurrentFile)\n//  This is the local-header version of the extra field (sometimes, there is\n//    more info in the local-header version than in the central-header)\n//  if buf==NULL, it return the size of the local extra field that can be read\n//  if buf!=NULL, len is the size of the buffer, the extra header is copied in buf.\n//  the return value is the number of bytes copied in buf, or (if <0) the error code\nint unzGetLocalExtrafield (unzFile file,voidp buf,unsigned len)\n{\n\tunz_s* s;\n\tfile_in_zip_read_info_s* pfile_in_zip_read_info;\n\tuInt read_now;\n\tuLong size_to_read;\n\n\tif (file==NULL)\n\t\treturn UNZ_PARAMERROR;\n\ts=(unz_s*)file;\n    pfile_in_zip_read_info=s->pfile_in_zip_read;\n\n\tif (pfile_in_zip_read_info==NULL)\n\t\treturn UNZ_PARAMERROR;\n\n\tsize_to_read = (pfile_in_zip_read_info->size_local_extrafield -\n\t\t\t\tpfile_in_zip_read_info->pos_local_extrafield);\n\n\tif (buf==NULL)\n\t\treturn (int)size_to_read;\n\n\tif (len>size_to_read)\n\t\tread_now = (uInt)size_to_read;\n\telse\n\t\tread_now = (uInt)len ;\n\n\tif (read_now==0)\n\t\treturn 0;\n\n\tif (lufseek(pfile_in_zip_read_info->file, pfile_in_zip_read_info->offset_local_extrafield +  pfile_in_zip_read_info->pos_local_extrafield,SEEK_SET)!=0)\n\t\treturn UNZ_ERRNO;\n\n\tif (lufread(buf,(uInt)size_to_read,1,pfile_in_zip_read_info->file)!=1)\n\t\treturn UNZ_ERRNO;\n\n\treturn (int)read_now;\n}\n\n//  Close the file in zip opened with unzipOpenCurrentFile\n//  Return UNZ_CRCERROR if all the file was read but the CRC is not good\nint unzCloseCurrentFile (unzFile file)\n{\n\tint err=UNZ_OK;\n\n\tunz_s* s;\n\tfile_in_zip_read_info_s* pfile_in_zip_read_info;\n\tif (file==NULL)\n\t\treturn UNZ_PARAMERROR;\n\ts=(unz_s*)file;\n    pfile_in_zip_read_info=s->pfile_in_zip_read;\n\n\tif (pfile_in_zip_read_info==NULL)\n\t\treturn UNZ_PARAMERROR;\n\n\n\tif (pfile_in_zip_read_info->rest_read_uncompressed == 0)\n\t{\n\t\tif (pfile_in_zip_read_info->crc32 != pfile_in_zip_read_info->crc32_wait)\n\t\t\terr=UNZ_CRCERROR;\n\t}\n\n\n\tif (pfile_in_zip_read_info->read_buffer!=0)\n        { void *buf = pfile_in_zip_read_info->read_buffer;\n          zfree(buf);\n          pfile_in_zip_read_info->read_buffer=0;\n        }\n\tpfile_in_zip_read_info->read_buffer = NULL;\n\tif (pfile_in_zip_read_info->stream_initialised)\n\t\tinflateEnd(&pfile_in_zip_read_info->stream);\n\n\tpfile_in_zip_read_info->stream_initialised = 0;\n        if (pfile_in_zip_read_info!=0) zfree(pfile_in_zip_read_info); // unused pfile_in_zip_read_info=0;\n\n    s->pfile_in_zip_read=NULL;\n\n\treturn err;\n}\n\n\n//  Get the global comment string of the ZipFile, in the szComment buffer.\n//  uSizeBuf is the size of the szComment buffer.\n//  return the number of byte copied or an error code <0\nint unzGetGlobalComment (unzFile file, char *szComment, uLong uSizeBuf)\n{ //int err=UNZ_OK;\n  unz_s* s;\n  uLong uReadThis ;\n  if (file==NULL) return UNZ_PARAMERROR;\n  s=(unz_s*)file;\n  uReadThis = uSizeBuf;\n  if (uReadThis>s->gi.size_comment) uReadThis = s->gi.size_comment;\n  if (lufseek(s->file,s->central_pos+22,SEEK_SET)!=0) return UNZ_ERRNO;\n  if (uReadThis>0)\n  { *szComment='\\0';\n    if (lufread(szComment,(uInt)uReadThis,1,s->file)!=1) return UNZ_ERRNO;\n  }\n  if ((szComment != NULL) && (uSizeBuf > s->gi.size_comment)) *(szComment+s->gi.size_comment)='\\0';\n  return (int)uReadThis;\n}\n\n\nint unzOpenCurrentFile (unzFile file, const char *password);\nint unzReadCurrentFile (unzFile file, void *buf, unsigned len);\nint unzCloseCurrentFile (unzFile file);\n\n\ntypedef unsigned __int32 lutime_t;       // define it ourselves since we don't include time.h\n\nFILETIME timet2filetime(const lutime_t t)\n{ LONGLONG i = Int32x32To64(t,10000000) + 116444736000000000;\n  FILETIME ft;\n  ft.dwLowDateTime = (DWORD) i;\n  ft.dwHighDateTime = (DWORD)(i >>32);\n  return ft;\n}\n\nFILETIME dosdatetime2filetime(WORD dosdate,WORD dostime)\n{ // date: bits 0-4 are day of month 1-31. Bits 5-8 are month 1..12. Bits 9-15 are year-1980\n  // time: bits 0-4 are seconds/2, bits 5-10 are minute 0..59. Bits 11-15 are hour 0..23\n  SYSTEMTIME st;\n  st.wYear = (WORD)(((dosdate>>9)&0x7f) + 1980);\n  st.wMonth = (WORD)((dosdate>>5)&0xf);\n  st.wDay = (WORD)(dosdate&0x1f);\n  st.wHour = (WORD)((dostime>>11)&0x1f);\n  st.wMinute = (WORD)((dostime>>5)&0x3f);\n  st.wSecond = (WORD)((dostime&0x1f)*2);\n  st.wMilliseconds = 0;\n  FILETIME ft; SystemTimeToFileTime(&st,&ft);\n  return ft;\n}\n\n\nclass TUnzip\n{ public:\n  TUnzip(const char *pwd) : uf(0), unzbuf(0), currentfile(-1), czei(-1), password(0) {if (pwd!=0) {password=new char[strlen(pwd)+1]; strcpy_s(password,MAX_PATH,pwd);}}\n  ~TUnzip() {if (password!=0) delete[] password; password=0; if (unzbuf!=0) delete[] unzbuf; unzbuf=0;}\n\n  unzFile uf; int currentfile; ZIPENTRY cze; int czei;\n  char *password;\n  char *unzbuf;            // lazily created and destroyed, used by Unzip\n  TCHAR rootdir[MAX_PATH]; // includes a trailing slash\n\n  ZRESULT Open(void *z,unsigned int len,DWORD flags);\n  ZRESULT Get(int index,ZIPENTRY *ze);\n  ZRESULT Find(const TCHAR *name,bool ic,int *index,ZIPENTRY *ze);\n  ZRESULT Unzip(int index,void *dst,unsigned int len,DWORD flags);\n  ZRESULT SetUnzipBaseDir(const TCHAR *dir);\n  ZRESULT Close();\n};\n\n\nZRESULT TUnzip::Open(void *z,unsigned int len,DWORD flags)\n{ if (uf!=0 || currentfile!=-1) return ZR_NOTINITED;\n  //\n#ifdef GetCurrentDirectory\n  GetCurrentDirectory(MAX_PATH,rootdir);\n#else\n  _tcscpy(rootdir,_T(\"\\\\\"));\n#endif\n  TCHAR lastchar = rootdir[_tcslen(rootdir)-1];\n  if (lastchar!='\\\\' && lastchar!='/') _tcscat_s(rootdir,_T(\"\\\\\"));\n  //\n  if (flags==ZIP_HANDLE)\n  { // test if we can seek on it. We can't use GetFileType(h)==FILE_TYPE_DISK since it's not on CE.\n    DWORD res = SetFilePointer(z,0,0,FILE_CURRENT);\n    bool canseek = (res!=0xFFFFFFFF);\n    if (!canseek) return ZR_SEEK;\n  }\n  ZRESULT e; LUFILE *f = lufopen(z,len,flags,&e);\n  if (f==NULL) return e;\n  uf = unzOpenInternal(f);\n  if (uf==0) return ZR_NOFILE;\n  return ZR_OK;\n}\n\nZRESULT TUnzip::SetUnzipBaseDir(const TCHAR *dir)\n{\n  _tcscpy_s(rootdir, MAX_PATH, dir);\n  TCHAR lastchar = rootdir[_tcslen(rootdir)-1];\n  if (lastchar!='\\\\' && lastchar!='/') _tcscat_s(rootdir,_T(\"\\\\\"));\n  return ZR_OK;\n}\n\nZRESULT TUnzip::Get(int index,ZIPENTRY *ze)\n{ if (index<-1 || index>=(int)uf->gi.number_entry) return ZR_ARGS;\n  if (currentfile!=-1) unzCloseCurrentFile(uf); currentfile=-1;\n  if (index==czei && index!=-1) {memcpy(ze,&cze,sizeof(ZIPENTRY)); return ZR_OK;}\n  if (index==-1)\n  { ze->index = uf->gi.number_entry;\n    ze->name[0]=0;\n    ze->attr=0;\n    ze->atime.dwLowDateTime=0; ze->atime.dwHighDateTime=0;\n    ze->ctime.dwLowDateTime=0; ze->ctime.dwHighDateTime=0;\n    ze->mtime.dwLowDateTime=0; ze->mtime.dwHighDateTime=0;\n    ze->comp_size=0;\n    ze->unc_size=0;\n    return ZR_OK;\n  }\n  if (index<(int)uf->num_file) unzGoToFirstFile(uf);\n  while ((int)uf->num_file<index) unzGoToNextFile(uf);\n  unz_file_info ufi; char fn[MAX_PATH];\n  unzGetCurrentFileInfo(uf,&ufi,fn,MAX_PATH,NULL,0,NULL,0);\n  // now get the extra header. We do this ourselves, instead of\n  // calling unzOpenCurrentFile &c., to avoid allocating more than necessary.\n  unsigned int extralen,iSizeVar; unsigned long offset;\n  int res = unzlocal_CheckCurrentFileCoherencyHeader(uf,&iSizeVar,&offset,&extralen);\n  if (res!=UNZ_OK) return ZR_CORRUPT;\n  if (lufseek(uf->file,offset,SEEK_SET)!=0) return ZR_READ;\n  unsigned char *extra = new unsigned char[extralen];\n  if (lufread(extra,1,(uInt)extralen,uf->file)!=extralen) {delete[] extra; return ZR_READ;}\n  //\n  ze->index=uf->num_file;\n  TCHAR tfn[MAX_PATH];\n#ifdef UNICODE\n  MultiByteToWideChar(CP_UTF8,0,fn,-1,tfn,MAX_PATH);\n#else\n  strcpy(tfn,fn);\n#endif\n  // As a safety feature: if the zip filename had sneaky stuff\n  // like \"c:\\windows\\file.txt\" or \"\\windows\\file.txt\" or \"fred\\..\\..\\..\\windows\\file.txt\"\n  // then we get rid of them all. That way, when the programmer does UnzipItem(hz,i,ze.name),\n  // it won't be a problem. (If the programmer really did want to get the full evil information,\n  // then they can edit out this security feature from here).\n  // In particular, we chop off any prefixes that are \"c:\\\" or \"\\\" or \"/\" or \"[stuff]\\..\" or \"[stuff]/..\"\n  const TCHAR *sfn=tfn;\n  for (;;)\n  { if (sfn[0]!=0 && sfn[1]==':') {sfn+=2; continue;}\n    if (sfn[0]=='\\\\') {sfn++; continue;}\n    if (sfn[0]=='/') {sfn++; continue;}\n    const TCHAR *c;\n    c=_tcsstr(sfn,_T(\"\\\\..\\\\\")); if (c!=0) {sfn=c+4; continue;}\n    c=_tcsstr(sfn,_T(\"\\\\../\")); if (c!=0) {sfn=c+4; continue;}\n    c=_tcsstr(sfn,_T(\"/../\")); if (c!=0) {sfn=c+4; continue;}\n    c=_tcsstr(sfn,_T(\"/..\\\\\")); if (c!=0) {sfn=c+4; continue;}\n    break;\n  }\n  _tcscpy_s(ze->name, MAX_PATH, sfn);\n\n\n  // zip has an 'attribute' 32bit value. Its lower half is windows stuff\n  // its upper half is standard unix stat.st_mode. We'll start trying\n  // to read it in unix mode\n  unsigned long a = ufi.external_fa;\n  bool isdir  =   (a&0x40000000)!=0;\n  bool readonly=  (a&0x00800000)==0;\n  //bool readable=  (a&0x01000000)!=0; // unused\n  //bool executable=(a&0x00400000)!=0; // unused\n  bool hidden=false, system=false, archive=true;\n  // but in normal hostmodes these are overridden by the lower half...\n  int host = ufi.version>>8;\n  if (host==0 || host==7 || host==11 || host==14)\n  { readonly=  (a&0x00000001)!=0;\n    hidden=    (a&0x00000002)!=0;\n    system=    (a&0x00000004)!=0;\n    isdir=     (a&0x00000010)!=0;\n    archive=   (a&0x00000020)!=0;\n  }\n  ze->attr=0;\n  if (isdir) ze->attr |= FILE_ATTRIBUTE_DIRECTORY;\n  if (archive) ze->attr|=FILE_ATTRIBUTE_ARCHIVE;\n  if (hidden) ze->attr|=FILE_ATTRIBUTE_HIDDEN;\n  if (readonly) ze->attr|=FILE_ATTRIBUTE_READONLY;\n  if (system) ze->attr|=FILE_ATTRIBUTE_SYSTEM;\n  ze->comp_size = ufi.compressed_size;\n  ze->unc_size = ufi.uncompressed_size;\n  //\n  WORD dostime = (WORD)(ufi.dosDate&0xFFFF);\n  WORD dosdate = (WORD)((ufi.dosDate>>16)&0xFFFF);\n  FILETIME ftd = dosdatetime2filetime(dosdate,dostime);\n  FILETIME ft; LocalFileTimeToFileTime(&ftd,&ft);\n  ze->atime=ft; ze->ctime=ft; ze->mtime=ft;\n  // the zip will always have at least that dostime. But if it also has\n  // an extra header, then we'll instead get the info from that.\n  unsigned int epos=0;\n  while (epos+4<extralen)\n  { char etype[3]; etype[0]=extra[epos+0]; etype[1]=extra[epos+1]; etype[2]=0;\n    int size = extra[epos+2];\n    if (strcmp(etype,\"UT\")!=0) {epos += 4+size; continue;}\n    int flags = extra[epos+4];\n    bool hasmtime = (flags&1)!=0;\n    bool hasatime = (flags&2)!=0;\n    bool hasctime = (flags&4)!=0;\n    epos+=5;\n    if (hasmtime)\n    { lutime_t mtime = ((extra[epos+0])<<0) | ((extra[epos+1])<<8) |((extra[epos+2])<<16) | ((extra[epos+3])<<24);\n\t  epos+=4;\n      ze->mtime = timet2filetime(mtime);\n    }\n    if (hasatime)\n    { lutime_t atime = ((extra[epos+0])<<0) | ((extra[epos+1])<<8) |((extra[epos+2])<<16) | ((extra[epos+3])<<24);\n      epos+=4;\n      ze->atime = timet2filetime(atime);\n    }\n    if (hasctime)\n    { lutime_t ctime = ((extra[epos+0])<<0) | ((extra[epos+1])<<8) |((extra[epos+2])<<16) | ((extra[epos+3])<<24);\n      epos+=4;\n      ze->ctime = timet2filetime(ctime);\n    }\n    break;\n  }\n  //\n  if (extra!=0) delete[] extra;\n  memcpy(&cze,ze,sizeof(ZIPENTRY)); czei=index;\n  return ZR_OK;\n}\n\nZRESULT TUnzip::Find(const TCHAR *tname,bool ic,int *index,ZIPENTRY *ze)\n{ char name[MAX_PATH];\n#ifdef UNICODE\n  WideCharToMultiByte(CP_UTF8,0,tname,-1,name,MAX_PATH,0,0);\n#else\n  strcpy(name,tname);\n#endif\n  int res = unzLocateFile(uf,name,ic?CASE_INSENSITIVE:CASE_SENSITIVE);\n  if (res!=UNZ_OK)\n  { if (index!=0) *index=-1;\n    if (ze!=NULL) {ZeroMemory(ze,sizeof(ZIPENTRY)); ze->index=-1;}\n    return ZR_NOTFOUND;\n  }\n  if (currentfile!=-1) unzCloseCurrentFile(uf); currentfile=-1;\n  int i = (int)uf->num_file;\n  if (index!=NULL) *index=i;\n  if (ze!=NULL)\n  { ZRESULT zres = Get(i,ze);\n    if (zres!=ZR_OK) return zres;\n  }\n  return ZR_OK;\n}\n\nvoid EnsureDirectory(const TCHAR *rootdir, const TCHAR *dir)\n{ if (rootdir!=0 && GetFileAttributes(rootdir)==0xFFFFFFFF) CreateDirectory(rootdir,0);\n  if (*dir==0) return;\n  const TCHAR *lastslash=dir, *c=lastslash;\n  while (*c!=0) {if (*c=='/' || *c=='\\\\') lastslash=c; c++;}\n  const TCHAR *name=lastslash;\n  if (lastslash!=dir)\n  { TCHAR tmp[MAX_PATH]; memcpy(tmp,dir,sizeof(TCHAR)*(lastslash-dir));\n    tmp[lastslash-dir]=0;\n    EnsureDirectory(rootdir,tmp);\n    name++;\n  }\n  TCHAR cd[MAX_PATH]; *cd=0; if (rootdir!=0) _tcscpy_s(cd, MAX_PATH, rootdir); _tcscat_s(cd,dir);\n  if (GetFileAttributes(cd)==0xFFFFFFFF) CreateDirectory(cd,NULL);\n}\n\n\nZRESULT TUnzip::Unzip(int index,void *dst,unsigned int len,DWORD flags)\n{ if (flags!=ZIP_MEMORY && flags!=ZIP_FILENAME && flags!=ZIP_HANDLE) return ZR_ARGS;\n  if (flags==ZIP_MEMORY)\n  { if (index!=currentfile)\n    { if (currentfile!=-1) unzCloseCurrentFile(uf); currentfile=-1;\n      if (index>=(int)uf->gi.number_entry) return ZR_ARGS;\n      if (index<(int)uf->num_file) unzGoToFirstFile(uf);\n      while ((int)uf->num_file<index) unzGoToNextFile(uf);\n      unzOpenCurrentFile(uf,password); currentfile=index;\n    }\n    bool reached_eof;\n    int res = unzReadCurrentFile(uf,dst,len,&reached_eof);\n    if (res<=0) {unzCloseCurrentFile(uf); currentfile=-1;}\n    if (reached_eof) return ZR_OK;\n    if (res>0) return ZR_MORE;\n    if (res==UNZ_PASSWORD) return ZR_PASSWORD;\n    return ZR_FLATE;\n  }\n  // otherwise we're writing to a handle or a file\n  if (currentfile!=-1) unzCloseCurrentFile(uf); currentfile=-1;\n  if (index>=(int)uf->gi.number_entry) return ZR_ARGS;\n  if (index<(int)uf->num_file) unzGoToFirstFile(uf);\n  while ((int)uf->num_file<index) unzGoToNextFile(uf);\n  ZIPENTRY ze; Get(index,&ze);\n  // zipentry=directory is handled specially\n  if ((ze.attr&FILE_ATTRIBUTE_DIRECTORY)!=0)\n  { if (flags==ZIP_HANDLE) return ZR_OK; // don't do anything\n    const TCHAR *dir = (const TCHAR*)dst;\n    bool isabsolute = (dir[0]=='/' || dir[0]=='\\\\' || (dir[0]!=0 && dir[1]==':'));\n    if (isabsolute) EnsureDirectory(0,dir); else EnsureDirectory(rootdir,dir);\n    return ZR_OK;\n  }\n  // otherwise, we write the zipentry to a file/handle\n  HANDLE h;\n  if (flags==ZIP_HANDLE) h=dst;\n  else\n  { const TCHAR *ufn = (const TCHAR*)dst;\n    // We'll qualify all relative names to our root dir, and leave absolute names as they are\n    // ufn=\"zipfile.txt\"  dir=\"\"  name=\"zipfile.txt\"  fn=\"c:\\\\currentdir\\\\zipfile.txt\"\n    // ufn=\"dir1/dir2/subfile.txt\"  dir=\"dir1/dir2/\"  name=\"subfile.txt\"  fn=\"c:\\\\currentdir\\\\dir1/dir2/subfiles.txt\"\n    // ufn=\"\\z\\file.txt\"  dir=\"\\z\\\"  name=\"file.txt\"  fn=\"\\z\\file.txt\"\n    // This might be a security risk, in the case where we just use the zipentry's name as \"ufn\", where\n    // a malicious zip could unzip itself into c:\\windows. Our solution is that GetZipItem (which\n    // is how the user retrieve's the file's name within the zip) never returns absolute paths.\n    const TCHAR *name=ufn; const TCHAR *c=name; while (*c!=0) {if (*c=='/' || *c=='\\\\') name=c+1; c++;}\n    TCHAR dir[MAX_PATH]; _tcscpy_s(dir, MAX_PATH, ufn); if (name==ufn) *dir=0; else dir[name-ufn]=0;\n    TCHAR fn[MAX_PATH];\n    bool isabsolute = (dir[0]=='/' || dir[0]=='\\\\' || (dir[0]!=0 && dir[1]==':'));\n    if (isabsolute) {wsprintf(fn,_T(\"%s%s\"),dir,name); EnsureDirectory(0,dir);}\n    else {wsprintf(fn,_T(\"%s%s%s\"),rootdir,dir,name); EnsureDirectory(rootdir,dir);}\n    //\n    h = CreateFile(fn,GENERIC_WRITE,0,NULL,CREATE_ALWAYS,ze.attr,NULL);\n  }\n  if (h==INVALID_HANDLE_VALUE) return ZR_NOFILE;\n  unzOpenCurrentFile(uf,password);\n  if (unzbuf==0) unzbuf=new char[16384]; DWORD haderr=0;\n  //\n\n  for (; haderr==0;)\n  { bool reached_eof;\n    int res = unzReadCurrentFile(uf,unzbuf,16384,&reached_eof);\n    if (res==UNZ_PASSWORD) {haderr=ZR_PASSWORD; break;}\n    if (res<0) {haderr=ZR_FLATE; break;}\n    if (res>0) {DWORD writ; BOOL bres=WriteFile(h,unzbuf,res,&writ,NULL); if (!bres) {haderr=ZR_WRITE; break;}}\n    if (reached_eof) break;\n    if (res==0) {haderr=ZR_FLATE; break;}\n  }\n  if (!haderr) SetFileTime(h,&ze.ctime,&ze.atime,&ze.mtime); // may fail if it was a pipe\n  if (flags!=ZIP_HANDLE) CloseHandle(h);\n  unzCloseCurrentFile(uf);\n  if (haderr!=0) return haderr;\n  return ZR_OK;\n}\n\nZRESULT TUnzip::Close()\n{ if (currentfile!=-1) unzCloseCurrentFile(uf); currentfile=-1;\n  if (uf!=0) unzClose(uf); uf=0;\n  return ZR_OK;\n}\n\n\nZRESULT lasterrorU=ZR_OK;\n\nunsigned int FormatZipMessageU(ZRESULT code, TCHAR *buf,unsigned int len)\n{ if (code==ZR_RECENT) code=lasterrorU;\n  const TCHAR *msg=_T(\"unknown zip result code\");\n  switch (code)\n  { case ZR_OK: msg=_T(\"Success\"); break;\n    case ZR_NODUPH: msg=_T(\"Culdn't duplicate handle\"); break;\n    case ZR_NOFILE: msg=_T(\"Couldn't create/open file\"); break;\n    case ZR_NOALLOC: msg=_T(\"Failed to allocate memory\"); break;\n    case ZR_WRITE: msg=_T(\"Error writing to file\"); break;\n    case ZR_NOTFOUND: msg=_T(\"File not found in the zipfile\"); break;\n    case ZR_MORE: msg=_T(\"Still more data to unzip\"); break;\n    case ZR_CORRUPT: msg=_T(\"Zipfile is corrupt or not a zipfile\"); break;\n    case ZR_READ: msg=_T(\"Error reading file\"); break;\n    case ZR_PASSWORD: msg=_T(\"Correct password required\"); break;\n    case ZR_ARGS: msg=_T(\"Caller: faulty arguments\"); break;\n    case ZR_PARTIALUNZ: msg=_T(\"Caller: the file had already been partially unzipped\"); break;\n    case ZR_NOTMMAP: msg=_T(\"Caller: can only get memory of a memory zipfile\"); break;\n    case ZR_MEMSIZE: msg=_T(\"Caller: not enough space allocated for memory zipfile\"); break;\n    case ZR_FAILED: msg=_T(\"Caller: there was a previous error\"); break;\n    case ZR_ENDED: msg=_T(\"Caller: additions to the zip have already been ended\"); break;\n    case ZR_ZMODE: msg=_T(\"Caller: mixing creation and opening of zip\"); break;\n    case ZR_NOTINITED: msg=_T(\"Zip-bug: internal initialisation not completed\"); break;\n    case ZR_SEEK: msg=_T(\"Zip-bug: trying to seek the unseekable\"); break;\n    case ZR_MISSIZE: msg=_T(\"Zip-bug: the anticipated size turned out wrong\"); break;\n    case ZR_NOCHANGE: msg=_T(\"Zip-bug: tried to change mind, but not allowed\"); break;\n    case ZR_FLATE: msg=_T(\"Zip-bug: an internal error during flation\"); break;\n  }\n  unsigned int mlen=(unsigned int)_tcslen(msg);\n  if (buf==0 || len==0) return mlen;\n  unsigned int n=mlen; if (n+1>len) n=len-1;\n  _tcsncpy_s(buf,MAX_PATH,msg,n); buf[n]=0;\n  return mlen;\n}\n\n\ntypedef struct\n{ DWORD flag;\n  TUnzip *unz;\n} TUnzipHandleData;\n\nHZIP OpenZipInternal(void *z,unsigned int len,DWORD flags, const char *password)\n{ TUnzip *unz = new TUnzip(password);\n  lasterrorU = unz->Open(z,len,flags);\n  if (lasterrorU!=ZR_OK) {delete unz; return 0;}\n  TUnzipHandleData *han = new TUnzipHandleData;\n  han->flag=1; han->unz=unz; return (HZIP)han;\n}\nHZIP OpenZipHandle(HANDLE h, const char *password) {return OpenZipInternal((void*)h,0,ZIP_HANDLE,password);}\nHZIP OpenZip(const TCHAR *fn, const char *password) {return OpenZipInternal((void*)fn,0,ZIP_FILENAME,password);}\nHZIP OpenZip(void *z,unsigned int len, const char *password) {return OpenZipInternal(z,len,ZIP_MEMORY,password);}\n\n\nZRESULT GetZipItem(HZIP hz, int index, ZIPENTRY *ze)\n{ ze->index=0; *ze->name=0; ze->unc_size=0;\n  if (hz==0) {lasterrorU=ZR_ARGS;return ZR_ARGS;}\n  TUnzipHandleData *han = (TUnzipHandleData*)hz;\n  if (han->flag!=1) {lasterrorU=ZR_ZMODE;return ZR_ZMODE;}\n  TUnzip *unz = han->unz;\n  lasterrorU = unz->Get(index,ze);\n  return lasterrorU;\n}\n\nZRESULT FindZipItem(HZIP hz, const TCHAR *name, bool ic, int *index, ZIPENTRY *ze)\n{ if (hz==0) {lasterrorU=ZR_ARGS;return ZR_ARGS;}\n  TUnzipHandleData *han = (TUnzipHandleData*)hz;\n  if (han->flag!=1) {lasterrorU=ZR_ZMODE;return ZR_ZMODE;}\n  TUnzip *unz = han->unz;\n  lasterrorU = unz->Find(name,ic,index,ze);\n  return lasterrorU;\n}\n\nZRESULT UnzipItemInternal(HZIP hz, int index, void *dst, unsigned int len, DWORD flags)\n{ if (hz==0) {lasterrorU=ZR_ARGS;return ZR_ARGS;}\n  TUnzipHandleData *han = (TUnzipHandleData*)hz;\n  if (han->flag!=1) {lasterrorU=ZR_ZMODE;return ZR_ZMODE;}\n  TUnzip *unz = han->unz;\n  lasterrorU = unz->Unzip(index,dst,len,flags);\n  return lasterrorU;\n}\nZRESULT UnzipItemHandle(HZIP hz, int index, HANDLE h) {return UnzipItemInternal(hz,index,(void*)h,0,ZIP_HANDLE);}\nZRESULT UnzipItem(HZIP hz, int index, const TCHAR *fn) {return UnzipItemInternal(hz,index,(void*)fn,0,ZIP_FILENAME);}\nZRESULT UnzipItem(HZIP hz, int index, void *z,unsigned int len) {return UnzipItemInternal(hz,index,z,len,ZIP_MEMORY);}\n\nZRESULT SetUnzipBaseDir(HZIP hz, const TCHAR *dir)\n{ if (hz==0) {lasterrorU=ZR_ARGS;return ZR_ARGS;}\n  TUnzipHandleData *han = (TUnzipHandleData*)hz;\n  if (han->flag!=1) {lasterrorU=ZR_ZMODE;return ZR_ZMODE;}\n  TUnzip *unz = han->unz;\n  lasterrorU = unz->SetUnzipBaseDir(dir);\n  return lasterrorU;\n}\n\n\nZRESULT CloseZipU(HZIP hz)\n{ if (hz==0) {lasterrorU=ZR_ARGS;return ZR_ARGS;}\n  TUnzipHandleData *han = (TUnzipHandleData*)hz;\n  if (han->flag!=1) {lasterrorU=ZR_ZMODE;return ZR_ZMODE;}\n  TUnzip *unz = han->unz;\n  lasterrorU = unz->Close();\n  delete unz;\n  delete han;\n  return lasterrorU;\n}\n\nbool IsZipHandleU(HZIP hz)\n{ if (hz==0) return false;\n  TUnzipHandleData *han = (TUnzipHandleData*)hz;\n  return (han->flag==1);\n}",
    "file_path": "data\\preprocessed\\Squirrel_Squirrel.Windows__src_Setup_unzip.cpp",
    "file_name": "Squirrel_Squirrel.Windows__src_Setup_unzip.cpp",
    "language": "cpp"
  },
  {
    "text": "// The MIT License (MIT)\n\n// Copyright (c) 2016 nabijaczleweli\n\n// Permission is hereby granted, free of charge, to any person obtaining a copy of\n// this software and associated documentation files (the \"Software\"), to deal in\n// the Software without restriction, including without limitation the rights to\n// use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n// the Software, and to permit persons to whom the Software is furnished to do so,\n// subject to the following conditions:\n\n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n// FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n// COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n// IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n// CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n#include \"whereami++.hpp\"\n#include \"whereami.h\"\n#include <utility>\n\n\n// wai_get*Path returns an incorrect length on Windows (1 more than required)\n#ifdef _WIN32\n#define WHEREAMI_CPP_MISPADDING 1\n#else\n#define WHEREAMI_CPP_MISPADDING 0\n#endif\n\n\nusing whereami_func_t = int (*)(char * out, int capacity, int * dirname_length);\n\n\nstatic std::string whereami_path(whereami_func_t whereami_func) {\n\tconst auto length = whereami_func(nullptr, 0, nullptr);\n\tif(length == -1)\n\t\treturn \"\";\n\n\tstd::string ret(length - WHEREAMI_CPP_MISPADDING, '\\0');\n\twhereami_func(&ret[0], length - WHEREAMI_CPP_MISPADDING, nullptr);\n\treturn ret;\n}\n\nstatic std::pair<std::string, std::string> whereami_segmented(whereami_func_t whereami_func) {\n\tconst auto length = whereami_func(nullptr, 0, nullptr);\n\tif(length == -1)\n\t\treturn {\"\", \"\"};\n\n\t// Mispadding correction breaks libcode here and is unnecessary because we're constructing via C-string anyway\n\tint path_length;\n\tstd::string buf(length, '\\0');\n\twhereami_func(&buf[0], length, &path_length);\n\treturn {{buf.c_str(), static_cast<std::size_t>(path_length)}, &buf[path_length + 1]};\n}\n\n\nstd::string whereami::executable_path() {\n\treturn whereami_path(wai_getExecutablePath);\n}\n\nstd::string whereami::module_path() {\n\treturn whereami_path(wai_getModulePath);\n}\n\nstd::string whereami::executable_name() {\n\treturn whereami_segmented(wai_getExecutablePath).second;\n}\n\nstd::string whereami::module_name() {\n\treturn whereami_segmented(wai_getModulePath).second;\n}\n\nstd::string whereami::executable_dir() {\n\treturn whereami_segmented(wai_getExecutablePath).first;\n}\n\nstd::string whereami::module_dir() {\n\treturn whereami_segmented(wai_getModulePath).first;\n}\n",
    "file_path": "data\\preprocessed\\Stepland_jujube__include_whereami_whereami++.cpp",
    "file_name": "Stepland_jujube__include_whereami_whereami++.cpp",
    "language": "cpp"
  },
  {
    "text": "class MyHashSet {\n\n    vector<vector<bool>> bucket;\n\npublic:\n    /** Initialize your data structure here. */\n    MyHashSet() {\n        bucket.resize(1001, vector<bool>());\n    }\n\n    void add(int key) {\n        int keyHash = key / 1000;\n        if (bucket[keyHash].empty()) bucket[keyHash].resize(1000, false);\n        bucket[keyHash][key % 1000] = true;\n    }\n\n    void remove(int key) {\n        int keyHash = key / 1000;\n        if (bucket[keyHash].empty()) return;\n        bucket[keyHash][key % 1000] = false;\n    }\n\n    /** Returns true if this set contains the specified element */\n    bool contains(int key) {\n        int keyHash = key / 1000;\n        if (bucket[keyHash].empty()) return false;\n        return bucket[keyHash][key % 1000];\n    }\n};\n\n/**\n * Your MyHashSet object will be instantiated and called as such:\n * MyHashSet* obj = new MyHashSet();\n * obj->add(key);\n * obj->remove(key);\n * bool param_3 = obj->contains(key);\n */",
    "file_path": "data\\preprocessed\\sunnysetia93_competitive-coding-problems__LeetCode_Tag_Hash-Table_cpp_705.design-hashset.cpp",
    "file_name": "sunnysetia93_competitive-coding-problems__LeetCode_Tag_Hash-Table_cpp_705.design-hashset.cpp",
    "language": "cpp"
  },
  {
    "text": "class Solution {\npublic:\n    int computeArea(int ax1, int ay1, int ax2, int ay2, int bx1, int by1, int bx2, int by2) {\n        int com = max(min(ax2, bx2) - max(ax1, bx1), 0) * max(min(ay2, by2) - max(ay1, by1), 0);\n        return (ax2 - ax1) * (ay2 - ay1) + (bx2 - bx1) * (by2 - by1) - com;\n    }\n};\n",
    "file_path": "data\\preprocessed\\tangjz_acm-icpc__leetcode_1-1000_223-rectangle-area.cpp",
    "file_name": "tangjz_acm-icpc__leetcode_1-1000_223-rectangle-area.cpp",
    "language": "cpp"
  },
  {
    "text": "/*\n * Copyright (c) 2017-2019 THL A29 Limited, a Tencent company. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *    https://example.com/path\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n#include <tencentcloud/bmvpc/v20180625/model/DeleteVpcPeerConnectionRequest.h>\n#include <tencentcloud/core/utils/rapidjson/document.h>\n#include <tencentcloud/core/utils/rapidjson/writer.h>\n#include <tencentcloud/core/utils/rapidjson/stringbuffer.h>\n\nusing namespace TencentCloud::Bmvpc::V20180625::Model;\nusing namespace std;\n\nDeleteVpcPeerConnectionRequest::DeleteVpcPeerConnectionRequest() :\n    m_vpcPeerConnectionIdHasBeenSet(false)\n{\n}\n\nstring DeleteVpcPeerConnectionRequest::ToJsonString() const\n{\n    rapidjson::Document d;\n    d.SetObject();\n    rapidjson::Document::AllocatorType& allocator = d.GetAllocator();\n\n\n    if (m_vpcPeerConnectionIdHasBeenSet)\n    {\n        rapidjson::Value iKey(rapidjson::kStringType);\n        string key = \"VpcPeerConnectionId\";\n        iKey.SetString(key.c_str(), allocator);\n        d.AddMember(iKey, rapidjson::Value(m_vpcPeerConnectionId.c_str(), allocator).Move(), allocator);\n    }\n\n\n    rapidjson::StringBuffer buffer;\n    rapidjson::Writer<rapidjson::StringBuffer> writer(buffer);\n    d.Accept(writer);\n    return buffer.GetString();\n}\n\n\nstring DeleteVpcPeerConnectionRequest::GetVpcPeerConnectionId() const\n{\n    return m_vpcPeerConnectionId;\n}\n\nvoid DeleteVpcPeerConnectionRequest::SetVpcPeerConnectionId(const string& _vpcPeerConnectionId)\n{\n    m_vpcPeerConnectionId = _vpcPeerConnectionId;\n    m_vpcPeerConnectionIdHasBeenSet = true;\n}\n\nbool DeleteVpcPeerConnectionRequest::VpcPeerConnectionIdHasBeenSet() const\n{\n    return m_vpcPeerConnectionIdHasBeenSet;\n}\n\n",
    "file_path": "data\\preprocessed\\TencentCloud_tencentcloud-sdk-cpp__bmvpc_src_v20180625_model_DeleteVpcPeerConnectionRequest.cpp",
    "file_name": "TencentCloud_tencentcloud-sdk-cpp__bmvpc_src_v20180625_model_DeleteVpcPeerConnectionRequest.cpp",
    "language": "cpp"
  },
  {
    "text": "/*\n * Copyright (c) 2017-2019 THL A29 Limited, a Tencent company. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *    https://example.com/path\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n#include <tencentcloud/tcss/v20201101/model/OpenTcssTrialResponse.h>\n#include <tencentcloud/core/utils/rapidjson/document.h>\n#include <tencentcloud/core/utils/rapidjson/writer.h>\n#include <tencentcloud/core/utils/rapidjson/stringbuffer.h>\n\nusing TencentCloud::CoreInternalOutcome;\nusing namespace TencentCloud::Tcss::V20201101::Model;\nusing namespace std;\n\nOpenTcssTrialResponse::OpenTcssTrialResponse() :\n    m_endTimeHasBeenSet(false),\n    m_startTimeHasBeenSet(false)\n{\n}\n\nCoreInternalOutcome OpenTcssTrialResponse::Deserialize(const string &payload)\n{\n    rapidjson::Document d;\n    d.Parse(payload.c_str());\n    if (d.HasParseError() || !d.IsObject())\n    {\n        return CoreInternalOutcome(Core::Error(\"response not json format\"));\n    }\n    if (!d.HasMember(\"Response\") || !d[\"Response\"].IsObject())\n    {\n        return CoreInternalOutcome(Core::Error(\"response `Response` is null or not object\"));\n    }\n    rapidjson::Value &rsp = d[\"Response\"];\n    if (!rsp.HasMember(\"RequestId\") || !rsp[\"RequestId\"].IsString())\n    {\n        return CoreInternalOutcome(Core::Error(\"response `Response.RequestId` is null or not string\"));\n    }\n    string requestId(rsp[\"RequestId\"].GetString());\n    SetRequestId(requestId);\n\n    if (rsp.HasMember(\"Error\"))\n    {\n        if (!rsp[\"Error\"].IsObject() ||\n            !rsp[\"Error\"].HasMember(\"Code\") || !rsp[\"Error\"][\"Code\"].IsString() ||\n            !rsp[\"Error\"].HasMember(\"Message\") || !rsp[\"Error\"][\"Message\"].IsString())\n        {\n            return CoreInternalOutcome(Core::Error(\"response `Response.Error` format error\").SetRequestId(requestId));\n        }\n        string errorCode(rsp[\"Error\"][\"Code\"].GetString());\n        string errorMsg(rsp[\"Error\"][\"Message\"].GetString());\n        return CoreInternalOutcome(Core::Error(errorCode, errorMsg).SetRequestId(requestId));\n    }\n\n\n    if (rsp.HasMember(\"EndTime\") && !rsp[\"EndTime\"].IsNull())\n    {\n        if (!rsp[\"EndTime\"].IsString())\n        {\n            return CoreInternalOutcome(Core::Error(\"response `EndTime` IsString=false incorrectly\").SetRequestId(requestId));\n        }\n        m_endTime = string(rsp[\"EndTime\"].GetString());\n        m_endTimeHasBeenSet = true;\n    }\n\n    if (rsp.HasMember(\"StartTime\") && !rsp[\"StartTime\"].IsNull())\n    {\n        if (!rsp[\"StartTime\"].IsString())\n        {\n            return CoreInternalOutcome(Core::Error(\"response `StartTime` IsString=false incorrectly\").SetRequestId(requestId));\n        }\n        m_startTime = string(rsp[\"StartTime\"].GetString());\n        m_startTimeHasBeenSet = true;\n    }\n\n\n    return CoreInternalOutcome(true);\n}\n\nstring OpenTcssTrialResponse::ToJsonString() const\n{\n    rapidjson::Document value;\n    value.SetObject();\n    rapidjson::Document::AllocatorType& allocator = value.GetAllocator();\n\n    if (m_endTimeHasBeenSet)\n    {\n        rapidjson::Value iKey(rapidjson::kStringType);\n        string key = \"EndTime\";\n        iKey.SetString(key.c_str(), allocator);\n        value.AddMember(iKey, rapidjson::Value(m_endTime.c_str(), allocator).Move(), allocator);\n    }\n\n    if (m_startTimeHasBeenSet)\n    {\n        rapidjson::Value iKey(rapidjson::kStringType);\n        string key = \"StartTime\";\n        iKey.SetString(key.c_str(), allocator);\n        value.AddMember(iKey, rapidjson::Value(m_startTime.c_str(), allocator).Move(), allocator);\n    }\n\n    rapidjson::Value iKey(rapidjson::kStringType);\n    string key = \"RequestId\";\n    iKey.SetString(key.c_str(), allocator);\n    value.AddMember(iKey, rapidjson::Value().SetString(GetRequestId().c_str(), allocator), allocator);\n\n    rapidjson::StringBuffer buffer;\n    rapidjson::Writer<rapidjson::StringBuffer> writer(buffer);\n    value.Accept(writer);\n    return buffer.GetString();\n}\n\n\nstring OpenTcssTrialResponse::GetEndTime() const\n{\n    return m_endTime;\n}\n\nbool OpenTcssTrialResponse::EndTimeHasBeenSet() const\n{\n    return m_endTimeHasBeenSet;\n}\n\nstring OpenTcssTrialResponse::GetStartTime() const\n{\n    return m_startTime;\n}\n\nbool OpenTcssTrialResponse::StartTimeHasBeenSet() const\n{\n    return m_startTimeHasBeenSet;\n}\n\n",
    "file_path": "data\\preprocessed\\TencentCloud_tencentcloud-sdk-cpp__tcss_src_v20201101_model_OpenTcssTrialResponse.cpp",
    "file_name": "TencentCloud_tencentcloud-sdk-cpp__tcss_src_v20201101_model_OpenTcssTrialResponse.cpp",
    "language": "cpp"
  },
  {
    "text": "//\n// Redistribution and use in source and binary forms, with or without\n// modification, are permitted provided that the following conditions\n// are met:\n//  * Redistributions of source code must retain the above copyright\n//    notice, this list of conditions and the following disclaimer.\n//  * Redistributions in binary form must reproduce the above copyright\n//    notice, this list of conditions and the following disclaimer in the\n//    documentation and/or other materials provided with the distribution.\n//  * Neither the name of NVIDIA CORPORATION nor the names of its\n//    contributors may be used to endorse or promote products derived\n//    from this software without specific prior written permission.\n//\n// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY\n// EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR\n// PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR\n// CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n// EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n// PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY\n// OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n//\n// Copyright (c) 2008-2018 NVIDIA Corporation. All rights reserved.\n// Copyright (c) 2004-2008 AGEIA Technologies, Inc. All rights reserved.\n// Copyright (c) 2001-2004 NovodeX AG. All rights reserved.\n\n#include \"PxsDefaultMemoryManager.h\"\n\nnamespace physx\n{\n\n\tPxsDefaultMemoryManager::~PxsDefaultMemoryManager()\n\t{\n\t\tfor (PxU32 i = 0; i < mAllocators.size(); ++i)\n\t\t{\n\t\t\tmAllocators[i]->~VirtualAllocatorCallback();\n\t\t\tPX_FREE(mAllocators[i]);\n\t\t}\n\t}\n\n\tPs::VirtualAllocatorCallback* PxsDefaultMemoryManager::createHostMemoryAllocator(const PxU32 gpuComputeVersion)\n\t{\n\t\tPX_UNUSED(gpuComputeVersion);\n\t\tPs::VirtualAllocatorCallback* allocator = PX_PLACEMENT_NEW(PX_ALLOC(sizeof(PxsDefaultMemoryAllocator), \"PxsDefaultMemoryAllocator\"), PxsDefaultMemoryAllocator());\n\t\tmAllocators.pushBack(allocator);\n\t\treturn allocator;\n\t}\n\n\t//this is an empty stub\n\tPs::VirtualAllocatorCallback* PxsDefaultMemoryManager::createDeviceMemoryAllocator(const PxU32 gpuComputeVersion)\n\t{\n\t\tPX_UNUSED(gpuComputeVersion);\n\t\treturn NULL;\n\t}\n\n\tvoid PxsDefaultMemoryManager::destroyMemoryAllocator()\n\t{\n\t\tfor (PxU32 i = 0; i < mAllocators.size(); ++i)\n\t\t{\n\t\t\tmAllocators[i]->~VirtualAllocatorCallback();\n\t\t\tPX_FREE(mAllocators[i]);\n\t\t}\n\t}\n\n\n\tPxsMemoryManager* createMemoryManager()\n\t{\n\t\treturn PX_PLACEMENT_NEW(PX_ALLOC(sizeof(PxsDefaultMemoryManager), PX_DEBUG_EXP(\"PxsDefaultMemoryManager\")), PxsDefaultMemoryManager());\n\t}\n\n}\n",
    "file_path": "data\\preprocessed\\timi-liuliang_echo__thirdparty_physx_physx_source_lowlevel_software_src_PxsDefaultMemoryManager.cpp",
    "file_name": "timi-liuliang_echo__thirdparty_physx_physx_source_lowlevel_software_src_PxsDefaultMemoryManager.cpp",
    "language": "cpp"
  },
  {
    "text": "/*\nOpen Asset Import Library (assimp)\n---\n\nCopyright (c) 2006-2022, assimp team\n\n\nAll rights reserved.\n\nRedistribution and use of this software in source and binary forms,\nwith or without modification, are permitted provided that the\nfollowing conditions are met:\n\n* Redistributions of source code must retain the above\n  copyright notice, this list of conditions and the\n  following disclaimer.\n\n* Redistributions in binary form must reproduce the above\n  copyright notice, this list of conditions and the\n  following disclaimer in the documentation and/or other\n  materials provided with the distribution.\n\n* Neither the name of the assimp team, nor the names of its\n  contributors may be used to endorse or promote products\n  derived from this software without specific prior\n  written permission of the assimp team.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n\"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\nLIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\nA PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\nOWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\nSPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\nLIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\nDATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\nTHEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\nOF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n---\n*/\n\n/** Implementation of the LimitBoneWeightsProcess post processing step */\n\n\n#include \"LimitBoneWeightsProcess.h\"\n#include <assimp/SmallVector.h>\n#include <assimp/StringUtils.h>\n#include <assimp/postprocess.h>\n#include <assimp/DefaultLogger.hpp>\n#include <assimp/scene.h>\n#include <stdio.h>\n\nusing namespace Assimp;\n\n// ---\n// Constructor to be privately used by Importer\nLimitBoneWeightsProcess::LimitBoneWeightsProcess()\n{\n    mMaxWeights = AI_LMW_MAX_WEIGHTS;\n}\n\n// ---\n// Destructor, private as well\nLimitBoneWeightsProcess::~LimitBoneWeightsProcess() = default;\n\n// ---\n// Returns whether the processing step is present in the given flag field.\nbool LimitBoneWeightsProcess::IsActive( unsigned int pFlags) const\n{\n    return (pFlags & aiProcess_LimitBoneWeights) != 0;\n}\n\n// ---\n// Executes the post processing step on the given imported data.\nvoid LimitBoneWeightsProcess::Execute( aiScene* pScene)\n{\n    ASSIMP_LOG_DEBUG(\"LimitBoneWeightsProcess begin\");\n\n    for (unsigned int m = 0; m < pScene->mNumMeshes; ++m) {\n        ProcessMesh(pScene->mMeshes[m]);\n    }\n\n    ASSIMP_LOG_DEBUG(\"LimitBoneWeightsProcess end\");\n}\n\n// ---\n// Executes the post processing step on the given imported data.\nvoid LimitBoneWeightsProcess::SetupProperties(const Importer* pImp)\n{\n    // get the current value of the property\n    this->mMaxWeights = pImp->GetPropertyInteger(AI_CONFIG_PP_LBW_MAX_WEIGHTS,AI_LMW_MAX_WEIGHTS);\n}\n\n// ---\n// Unites identical vertices in the given mesh\nvoid LimitBoneWeightsProcess::ProcessMesh(aiMesh* pMesh)\n{\n    if (!pMesh->HasBones())\n        return;\n\n    // collect all bone weights per vertex\n    typedef SmallVector<Weight,8> VertexWeightArray;\n    typedef std::vector<VertexWeightArray> WeightsPerVertex;\n    WeightsPerVertex vertexWeights(pMesh->mNumVertices);\n    size_t maxVertexWeights = 0;\n\n    for (unsigned int b = 0; b < pMesh->mNumBones; ++b)\n    {\n        const aiBone* bone = pMesh->mBones[b];\n        for (unsigned int w = 0; w < bone->mNumWeights; ++w)\n        {\n            const aiVertexWeight& vw = bone->mWeights[w];\n\n            if (vertexWeights.size() <= vw.mVertexId)\n                continue;\n\n            vertexWeights[vw.mVertexId].push_back(Weight(b, vw.mWeight));\n            maxVertexWeights = std::max(maxVertexWeights, vertexWeights[vw.mVertexId].size());\n        }\n    }\n\n    if (maxVertexWeights <= mMaxWeights)\n        return;\n\n    unsigned int removed = 0, old_bones = pMesh->mNumBones;\n\n    // now cut the weight count if it exceeds the maximum\n    for (WeightsPerVertex::iterator vit = vertexWeights.begin(); vit != vertexWeights.end(); ++vit)\n    {\n        if (vit->size() <= mMaxWeights)\n            continue;\n\n        // more than the defined maximum -> first sort by weight in descending order. That's\n        // why we defined the < operator in such a weird way.\n        std::sort(vit->begin(), vit->end());\n\n        // now kill everything beyond the maximum count\n        unsigned int m = static_cast<unsigned int>(vit->size());\n        vit->resize(mMaxWeights);\n        removed += static_cast<unsigned int>(m - vit->size());\n\n        // and renormalize the weights\n        float sum = 0.0f;\n        for(const Weight* it = vit->begin(); it != vit->end(); ++it) {\n            sum += it->mWeight;\n        }\n        if (0.0f != sum) {\n            const float invSum = 1.0f / sum;\n            for(Weight* it = vit->begin(); it != vit->end(); ++it) {\n                it->mWeight *= invSum;\n            }\n        }\n    }\n\n    // clear weight count for all bone\n    for (unsigned int a = 0; a < pMesh->mNumBones; ++a)\n    {\n        pMesh->mBones[a]->mNumWeights = 0;\n    }\n\n    // rebuild the vertex weight array for all bones\n    for (unsigned int a = 0; a < vertexWeights.size(); ++a)\n    {\n        const VertexWeightArray& vw = vertexWeights[a];\n        for (const Weight* it = vw.begin(); it != vw.end(); ++it)\n        {\n            aiBone* bone = pMesh->mBones[it->mBone];\n            bone->mWeights[bone->mNumWeights++] = aiVertexWeight(a, it->mWeight);\n        }\n    }\n\n    // remove empty bones\n    unsigned int writeBone = 0;\n\n    for (unsigned int readBone = 0; readBone< pMesh->mNumBones; ++readBone)\n    {\n        aiBone* bone = pMesh->mBones[readBone];\n        if (bone->mNumWeights > 0)\n        {\n            pMesh->mBones[writeBone++] = bone;\n        }\n        else\n        {\n            delete bone;\n        }\n    }\n    pMesh->mNumBones = writeBone;\n\n    if (!DefaultLogger::isNullLogger()) {\n        ASSIMP_LOG_INFO(\"Removed \", removed, \" weights. Input bones: \", old_bones, \". Output bones: \", pMesh->mNumBones);\n    }\n}\n",
    "file_path": "data\\preprocessed\\TorqueGameEngines_Torque3D__Engine_lib_assimp_code_PostProcessing_LimitBoneWeightsProcess.cpp",
    "file_name": "TorqueGameEngines_Torque3D__Engine_lib_assimp_code_PostProcessing_LimitBoneWeightsProcess.cpp",
    "language": "cpp"
  },
  {
    "text": "//===\n// Copyright (c) 2013-2020 Baptiste Wicht.\n// Distributed under the terms of the MIT License.\n// (See accompanying file LICENSE or copy at\n//  https://example.com/path\n//===\n\n#include <utility>\n\n#include \"config.hpp\"\n#include \"compute.hpp\"\n#include \"expenses.hpp\"\n#include \"earnings.hpp\"\n#include \"accounts.hpp\"\n#include \"incomes.hpp\"\n#include \"data_cache.hpp\"\n\nbudget::status budget::compute_year_status(data_cache & cache) {\n    auto today = budget::local_day();\n    return compute_year_status(cache, today.year(), today.month());\n}\n\nbudget::status budget::compute_year_status(data_cache & cache, year year) {\n    return compute_year_status(cache, year, 12);\n}\n\nbudget::status budget::compute_year_status(data_cache & cache, year year, month month) {\n    budget::status status;\n\n    auto sm = start_month(cache, year);\n\n    status.expenses = fold_left_auto(all_expenses_between(cache, year, sm, month) | to_amount);\n    status.earnings = fold_left_auto(all_earnings_between(cache, year, sm, month) | to_amount);\n\n    for (unsigned short i = sm; i <= month; ++i) {\n        status.budget += fold_left_auto(all_accounts(cache, year, i) | to_amount);\n        status.base_income += get_base_income(cache, budget::date(year, i, 1));\n    }\n\n    status.balance = status.budget + status.earnings - status.expenses;\n    status.income  = status.base_income + status.earnings;\n    status.savings = status.income - status.expenses;\n\n    status.taxes = 0;\n\n    if (has_taxes_account()) {\n        auto account_id = taxes_account().id;\n\n        status.taxes = fold_left_auto(all_expenses_between(cache, account_id, year, sm, month) | to_amount);\n    }\n\n    return status;\n}\n\nbudget::status budget::compute_month_status(data_cache & cache) {\n    auto today = budget::local_day();\n    return compute_month_status(cache, today.year(), today.month());\n}\n\nbudget::status budget::compute_month_status(data_cache & cache, month month) {\n    auto today = budget::local_day();\n    return compute_month_status(cache, today.year(), month);\n}\n\nbudget::status budget::compute_month_status(data_cache & cache, year year, month month) {\n    budget::status status;\n\n    status.expenses    = fold_left_auto(all_expenses_month(cache, year, month) | to_amount);\n    status.earnings    = fold_left_auto(all_earnings_month(cache, year, month) | to_amount);\n    status.budget      = fold_left_auto(all_accounts(cache, year, month) | to_amount);\n    status.balance     = status.budget + status.earnings - status.expenses;\n    status.base_income = get_base_income(cache, budget::date(year, month, 1));\n    status.income      = status.base_income + status.earnings;\n    status.savings     = status.income - status.expenses;\n\n    status.taxes = 0;\n\n    if (has_taxes_account()) {\n        auto account_id = taxes_account().id;\n\n        status.taxes = fold_left_auto(all_expenses_month(cache, account_id, year, month) | to_amount);\n    }\n\n    return status;\n}\n\nbudget::status budget::compute_avg_month_status(data_cache & cache) {\n    auto today = budget::local_day();\n    return compute_avg_month_status(cache, today.year(), today.month());\n}\n\nbudget::status budget::compute_avg_month_status(data_cache & cache, month month) {\n    auto today = budget::local_day();\n    return compute_avg_month_status(cache, today.year(), month);\n}\n\nbudget::status budget::compute_avg_month_status(data_cache & cache, year year, month month) {\n    budget::status avg_status;\n\n    for (budget::month m = 1; m < month; m = m + 1) {\n        auto status = compute_month_status(cache, year, m);\n\n        avg_status.expenses += status.expenses;\n        avg_status.earnings += status.earnings;\n        avg_status.budget += status.budget;\n        avg_status.balance += status.balance;\n        avg_status.taxes += status.taxes;\n        avg_status.savings += status.savings;\n    }\n\n    if (month.value > 1) {\n        avg_status.expenses /= month.value - 1;\n        avg_status.taxes /= month.value - 1;\n        avg_status.earnings /= month.value - 1;\n        avg_status.budget /= month.value - 1;\n        avg_status.balance /= month.value - 1;\n        avg_status.savings /= month.value - 1;\n    }\n\n    return avg_status;\n}\n",
    "file_path": "data\\preprocessed\\wichtounet_budgetwarrior__src_compute.cpp",
    "file_name": "wichtounet_budgetwarrior__src_compute.cpp",
    "language": "cpp"
  },
  {
    "text": "#include \"testlib.h\"\n#include \"params.h\"\n#include <set>\n#include <utility>\n\nint main() {\n\tregisterValidation();\n\n\tint N = inf.readInt(N_MIN, N_MAX);\n\tinf.readSpace();\n\tint M = inf.readInt(M_MIN, M_MAX);\n\tinf.readChar('\\n');\n\n\tfor(int i=0; i<M; i++) {\n\t\tint u = inf.readInt(0, N-1);\n\t\tinf.readSpace();\n\t\tint v = inf.readInt(0, N-1);\n\t\tinf.readChar('\\n');\n\t\tensure(u != v);\n\t}\n\tinf.readEof();\n\treturn 0;\n}\n",
    "file_path": "data\\preprocessed\\yosupo06_library-checker-problems__graph_cycle_detection_verifier.cpp",
    "file_name": "yosupo06_library-checker-problems__graph_cycle_detection_verifier.cpp",
    "language": "cpp"
  }
]