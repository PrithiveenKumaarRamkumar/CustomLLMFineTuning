<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="0" failures="3" skipped="0" tests="52" time="25.531" timestamp="2025-10-28T22:23:58.464788" hostname="ITSLOAN27102157"><testcase classname="tests.test_Acquisition.TestDataAcquisition" name="test_requirements_file_exists" time="0.002" /><testcase classname="tests.test_Acquisition.TestDataAcquisition" name="test_config_file_exists" time="0.001" /><testcase classname="tests.test_Acquisition.TestDataAcquisition" name="test_config_file_loads" time="0.026" /><testcase classname="tests.test_Acquisition.TestDataAcquisition" name="test_languages_configured" time="0.004" /><testcase classname="tests.test_Acquisition.TestDataAcquisition" name="test_output_directories_exist" time="0.002" /><testcase classname="tests.test_Acquisition.TestDataAcquisition" name="test_metadata_files_exist" time="0.001" /><testcase classname="tests.test_Acquisition.TestDataAcquisition" name="test_metadata_files_valid_json" time="0.095" /><testcase classname="tests.test_Acquisition.TestDataAcquisition" name="test_metadata_entries_have_required_fields" time="0.004" /><testcase classname="tests.test_Acquisition.TestDataAcquisition" name="test_downloaded_files_exist" time="0.004" /><testcase classname="tests.test_Acquisition.TestDataAcquisition" name="test_downloaded_files_not_empty" time="0.003" /><testcase classname="tests.test_Acquisition.TestDataAcquisition" name="test_filter_criteria_in_config" time="0.012" /><testcase classname="tests.test_Acquisition.TestRequirements" name="test_required_packages_in_requirements" time="0.002" /><testcase classname="tests.test_dataset_filter" name="test_organize_and_filter_basic" time="0.052" /><testcase classname="tests.test_pipeline_basics" name="test_pipeline_initialization" time="2.678" /><testcase classname="tests.test_preprocessing.TestPIIRemoval" name="test_api_key_removal" time="0.001" /><testcase classname="tests.test_preprocessing.TestPIIRemoval" name="test_email_removal" time="0.001" /><testcase classname="tests.test_preprocessing.TestPIIRemoval" name="test_github_token_removal" time="0.001" /><testcase classname="tests.test_preprocessing.TestPIIRemoval" name="test_ip_address_removal" time="0.001" /><testcase classname="tests.test_preprocessing.TestPIIRemoval" name="test_process_file" time="0.041" /><testcase classname="tests.test_preprocessing.TestPIIRemoval" name="test_url_removal" time="0.001" /><testcase classname="tests.test_preprocessing.TestPIIRemoval" name="test_whitelist_preservation" time="0.001" /><testcase classname="tests.test_preprocessing.TestDeduplication" name="test_code_normalization" time="0.001" /><testcase classname="tests.test_preprocessing.TestDeduplication" name="test_exact_hash_calculation" time="0.001" /><testcase classname="tests.test_preprocessing.TestDeduplication" name="test_find_exact_duplicates" time="0.001" /><testcase classname="tests.test_preprocessing.TestDeduplication" name="test_process_directory" time="0.039" /><testcase classname="tests.test_preprocessing.TestDeduplication" name="test_similarity_calculation" time="0.001" /><testcase classname="tests.test_preprocessing.TestPreprocessingPipeline" name="test_tokenization_with_mock" time="0.572" /><testcase classname="tests.test_preprocessing.TestIntegration" name="test_full_pipeline_integration" time="0.406" /><testcase classname="tests.test_simple" name="test_simple" time="0.001" /><testcase classname="tests.anomaly.test_bias_analysis.TestBiasAnalysis" name="test_language_distribution" time="0.002" /><testcase classname="tests.anomaly.test_bias_analysis.TestBiasAnalysis" name="test_complexity_bias" time="0.006" /><testcase classname="tests.anomaly.test_bias_analysis.TestBiasAnalysis" name="test_license_fairness" time="0.002" /><testcase classname="tests.anomaly.test_bias_analysis.TestBiasAnalysis" name="test_fairness_metrics" time="0.002" /><testcase classname="tests.anomaly.test_bias_analysis.TestBiasAnalysis" name="test_complexity_thresholds" time="0.002"><failure message="KeyError: 'complexity_threshold'">self = &lt;test_bias_analysis.TestBiasAnalysis object at 0x0000020F49A722A0&gt;
test_config = {'test_data_dir': 'C:\\Users\\ramkumar.pri\\Desktop\\github\\CustomLLMFineTuning\\tests\\test_data', 'thresholds': {'complexity_max': 15, 'doc_ratio_min': 0.05, 'duplicate_threshold': 0.2, 'file_size_max': 10000000, ...}}

    def test_complexity_thresholds(self, test_config):
        """Test complexity threshold fairness across languages."""
        complexities = {
            "python_file.py": 12,
            "java_file.java": 14,
            "cpp_file.cpp": 13,
            "js_file.js": 11
        }
    
        distribution = analyze_complexity_distribution(complexities)
    
        # Check if any language is unfairly penalized
&gt;       assert distribution["mean"] &lt;= test_config["thresholds"]["complexity_threshold"]
E       KeyError: 'complexity_threshold'

tests\anomaly\test_bias_analysis.py:108: KeyError</failure></testcase><testcase classname="tests.anomaly.test_bias_analysis.TestBiasAnalysis" name="test_statistical_significance" time="0.005" /><testcase classname="tests.anomaly.test_bias_analysis.TestBiasAnalysis" name="test_bias_mitigation_impact" time="0.003" /><testcase classname="tests.anomaly.test_data_quality.TestAnomalyDetection" name="test_file_size_anomalies" time="0.002" /><testcase classname="tests.anomaly.test_data_quality.TestAnomalyDetection" name="test_complexity_anomalies" time="0.001" /><testcase classname="tests.anomaly.test_data_quality.TestAnomalyDetection" name="test_duplicate_detection" time="0.001" /><testcase classname="tests.anomaly.test_data_quality.TestAnomalyDetection" name="test_statistical_anomalies" time="0.001" /><testcase classname="tests.anomaly.test_data_quality.TestAnomalyDetection" name="test_pii_pattern_detection" time="0.002" /><testcase classname="tests.anomaly.test_data_quality.TestAnomalyDetection" name="test_language_distribution_bias" time="0.001" /><testcase classname="tests.integration.test_pipeline_integration.TestPipelineIntegration" name="test_end_to_end_pipeline" time="0.265"><failure message="TypeError: Expected object of type bytes or bytearray, got: &lt;class 'tuple'&gt;">self = &lt;test_pipeline_integration.TestPipelineIntegration object at 0x0000020F49A737A0&gt;
sample_code_data = {'java_sample': '\npublic class Hello {\n    public static void main(String[] args) {\n        System.out.println("Hello, World!");\n    }\n}\n        ', 'python_sample': '\ndef hello_world():\n    print("Hello, World!")\n        '}

    def test_end_to_end_pipeline(self, sample_code_data):
        """Test complete data pipeline integration"""
        # Step 1: Data Acquisition
        download_result = self.data_acquisition.download_dataset(
            bucket="test-bucket",
            prefix="test-prefix"
        )
        assert "downloaded_files" in download_result
        assert len(download_result["downloaded_files"]) &gt; 0
    
        # Step 2: Initial Processing
        processed_files = []
        for file in download_result["downloaded_files"]:
            processed = {
                "content": self.pii_remover.remove_pii(file["content"]),
                "file_path": file.get("path", "test.py"),
                "metadata": {
                    "language": "python",
                    "size": len(file["content"])
                }
            }
            processed_files.append(processed)
        assert len(processed_files) &gt; 0
    
        # Step 3: Anomaly Detection
&gt;       anomalies = self.anomaly_detector.analyze_dataset(processed_files)

tests\integration\test_pipeline_integration.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
scripts\anomaly_detection.py:169: in analyze_dataset
    "encoding_issues": self._detect_encoding_issues(files)
scripts\anomaly_detection.py:243: in _detect_encoding_issues
    detected = chardet.detect(content)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

byte_str = ('def test(): pass', {'api_keys': 0, 'emails': 0, 'github_tokens': 0, 'ips': 0, ...})
should_rename_legacy = False

    def detect(
        byte_str: Union[bytes, bytearray], should_rename_legacy: bool = False
    ) -&gt; ResultDict:
        """
        Detect the encoding of the given byte string.
    
        :param byte_str:     The byte sequence to examine.
        :type byte_str:      ``bytes`` or ``bytearray``
        :param should_rename_legacy:  Should we rename legacy encodings
                                      to their more modern equivalents?
        :type should_rename_legacy:   ``bool``
        """
        if not isinstance(byte_str, bytearray):
            if not isinstance(byte_str, bytes):
&gt;               raise TypeError(
                    f"Expected object of type bytes or bytearray, got: {type(byte_str)}"
                )
E               TypeError: Expected object of type bytes or bytearray, got: &lt;class 'tuple'&gt;

.venv\Lib\site-packages\chardet\__init__.py:44: TypeError</failure></testcase><testcase classname="tests.integration.test_pipeline_integration.TestPipelineIntegration" name="test_error_propagation" time="0.309" /><testcase classname="tests.integration.test_pipeline_integration.TestPipelineIntegration" name="test_data_consistency" time="0.241" /><testcase classname="tests.integration.test_pipeline_integration.TestPipelineIntegration" name="test_performance_metrics" time="0.212"><failure message="TypeError: tuple indices must be integers or slices, not str">self = &lt;test_pipeline_integration.TestPipelineIntegration object at 0x0000020F49A73D40&gt;

    def test_performance_metrics(self):
        """Test pipeline performance metrics"""
        start_time = time.time()
    
        # Process a sample file
        file_data = {
            "content": "def test():\n    print('hello')",
            "file_path": "test.py",
            "size": 28
        }
    
        # Measure preprocessing time
        preprocess_start = time.time()
        processed = self.pii_remover.remove_pii(file_data["content"])
        file_data["content"] = processed
        preprocess_time = time.time() - preprocess_start
    
        # Measure anomaly detection time
        anomaly_start = time.time()
        self.anomaly_detector.analyze_single_file(file_data)
        anomaly_time = time.time() - anomaly_start
    
        total_time = time.time() - start_time
    
        # Basic performance assertions
        assert preprocess_time &lt; 1.0, "Preprocessing took too long"
        assert anomaly_time &lt; 1.0, "Anomaly detection took too long"
        assert total_time &lt; 2.0, "Total pipeline execution took too long"
&gt;       self.anomaly_detector.analyze_single_file(processed)

tests\integration\test_pipeline_integration.py:130: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
scripts\anomaly_detection.py:281: in analyze_single_file
    "file_size": self._detect_size_anomalies([file_data]),
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = &lt;scripts.anomaly_detection.AnomalyDetector object at 0x0000020F4C6153A0&gt;
files = [("def test():\n    print('hello')", {'api_keys': 0, 'emails': 0, 'github_tokens': 0, 'ips': 0, ...})]

    def _detect_size_anomalies(self, files: List[Dict[str, Any]]) -&gt; List[Dict[str, Any]]:
        """Detect files with anomalous sizes."""
        anomalies = []
        for file in files:
            # Get size from metadata or content length
            size = 0
            if 'metadata' in file and 'size' in file['metadata']:
                size = file['metadata']['size']
            elif 'content' in file:
                size = len(file['content'])
    
            if size &gt; self.thresholds['file_size_max']:
                anomalies.append({
                    'file': file['file_path'],
                    'size': size,
                    'type': 'oversized'
                })
            elif size &lt; 100:  # Minimum size threshold
                anomalies.append({
&gt;                   'file': file['file_path'],
                    'size': size,
                    'type': 'undersized'
                })
E               TypeError: tuple indices must be integers or slices, not str

scripts\anomaly_detection.py:191: TypeError</failure></testcase><testcase classname="tests.unit.test_acquisition.TestDataAcquisition" name="test_aws_credentials_validation" time="0.003" /><testcase classname="tests.unit.test_acquisition.TestDataAcquisition" name="test_download_dataset" time="0.002" /><testcase classname="tests.unit.test_acquisition.TestDataAcquisition" name="test_metadata_validation" time="0.003" /><testcase classname="tests.unit.test_acquisition.TestDataAcquisition" name="test_file_size_validation" time="0.002" /><testcase classname="tests.unit.test_acquisition.TestDataAcquisition" name="test_sha256_verification" time="0.002" /><testcase classname="tests.unit.test_acquisition.TestDataAcquisition" name="test_error_handling" time="0.003" /></testsuite></testsuites>